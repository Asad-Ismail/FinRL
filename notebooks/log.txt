[*********************100%***********************]  1 of 1 completed
[*********************100%***********************]  1 of 1 completed
[*********************100%***********************]  1 of 1 completed
[*********************100%***********************]  1 of 1 completed
[*********************100%***********************]  1 of 1 completed
[*********************100%***********************]  1 of 1 completed
[*********************100%***********************]  1 of 1 completed
[*********************100%***********************]  1 of 1 completed
[*********************100%***********************]  1 of 1 completed
[*********************100%***********************]  1 of 1 completed
[*********************100%***********************]  1 of 1 completed
[*********************100%***********************]  1 of 1 completed
[*********************100%***********************]  1 of 1 completed
[*********************100%***********************]  1 of 1 completed
[*********************100%***********************]  1 of 1 completed
[*********************100%***********************]  1 of 1 completed
[*********************100%***********************]  1 of 1 completed
[*********************100%***********************]  1 of 1 completed
[*********************100%***********************]  1 of 1 completed
[*********************100%***********************]  1 of 1 completed
[*********************100%***********************]  1 of 1 completed
[*********************100%***********************]  1 of 1 completed
[*********************100%***********************]  1 of 1 completed
[*********************100%***********************]  1 of 1 completed
[*********************100%***********************]  1 of 1 completed
[*********************100%***********************]  1 of 1 completed
[*********************100%***********************]  1 of 1 completed
[*********************100%***********************]  1 of 1 completed
[*********************100%***********************]  1 of 1 completed
[*********************100%***********************]  1 of 1 completed
Shape of DataFrame:  (130829, 8)
Successfully added technical indicators
Successfully added turbulence index
Stock Dimension: 28, State Space: 281
============Training Best Model============
Turbulence_threshold:  639.3252580437234
Intialize Environment StartDay: 0, ResetDay: 1680,Episode: 0
======Model training from:  2005-04-01 to  2023-01-29
{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}
Using cuda device
======PPO Training========
Reseting Environment StartDay: 816, ResetDay: 2496,Episode: 1
Logging to tensorboard_log/ppo/ppo_1_1
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1273, ResetDay: 2953,Episode: 2
--------------------------------------
| time/              |               |
|    fps             | 69            |
|    iterations      | 1             |
|    time_elapsed    | 29            |
|    total_timesteps | 2048          |
| train/             |               |
|    reward          | 1.3408442e-06 |
--------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1467, ResetDay: 3147,Episode: 3
------------------------------------------
| time/                   |              |
|    fps                  | 78           |
|    iterations           | 2            |
|    time_elapsed         | 51           |
|    total_timesteps      | 4096         |
| train/                  |              |
|    approx_kl            | 3969.1973    |
|    clip_fraction        | 0.943        |
|    clip_range           | 0.2          |
|    entropy_loss         | -39.8        |
|    explained_variance   | -2.91        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.143       |
|    n_updates            | 10           |
|    policy_gradient_loss | 0.286        |
|    reward               | 3.291855e-05 |
|    std                  | 1.01         |
|    value_loss           | 0.074        |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 618, ResetDay: 2298,Episode: 4
--------------------------------------
| time/                   |          |
|    fps                  | 82       |
|    iterations           | 3        |
|    time_elapsed         | 74       |
|    total_timesteps      | 6144     |
| train/                  |          |
|    approx_kl            | 77.03006 |
|    clip_fraction        | 0.661    |
|    clip_range           | 0.2      |
|    entropy_loss         | -40.1    |
|    explained_variance   | -2.82    |
|    learning_rate        | 0.00025  |
|    loss                 | -0.301   |
|    n_updates            | 20       |
|    policy_gradient_loss | 0.128    |
|    reward               | 0.0      |
|    std                  | 1.02     |
|    value_loss           | 0.0158   |
--------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 571, ResetDay: 2251,Episode: 5
---------------------------------------
| time/                   |           |
|    fps                  | 84        |
|    iterations           | 4         |
|    time_elapsed         | 96        |
|    total_timesteps      | 8192      |
| train/                  |           |
|    approx_kl            | 35.916206 |
|    clip_fraction        | 0.689     |
|    clip_range           | 0.2       |
|    entropy_loss         | -40.3     |
|    explained_variance   | -3.82     |
|    learning_rate        | 0.00025   |
|    loss                 | -0.243    |
|    n_updates            | 30        |
|    policy_gradient_loss | 0.135     |
|    reward               | 0.0       |
|    std                  | 1.02      |
|    value_loss           | 0.0125    |
---------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2251, episode: 5
begin_total_asset: 200.00
end_total_asset: 13.19
total_reward: -186.81
total_cost: 116.13
total_trades: 9814
Sharpe: -1.106
=================================
Reseting Environment StartDay: 1991, ResetDay: 3671,Episode: 6
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2586, ResetDay: 4266,Episode: 7
--------------------------------------------
| time/                   |                |
|    fps                  | 85             |
|    iterations           | 5              |
|    time_elapsed         | 119            |
|    total_timesteps      | 10240          |
| train/                  |                |
|    approx_kl            | 74.5865        |
|    clip_fraction        | 0.693          |
|    clip_range           | 0.2            |
|    entropy_loss         | -40.4          |
|    explained_variance   | -4.84          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.339         |
|    n_updates            | 40             |
|    policy_gradient_loss | 0.186          |
|    reward               | -5.9946833e-05 |
|    std                  | 1.03           |
|    value_loss           | 0.00851        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 183, ResetDay: 1863,Episode: 8
-------------------------------------------
| time/                   |               |
|    fps                  | 86            |
|    iterations           | 6             |
|    time_elapsed         | 141           |
|    total_timesteps      | 12288         |
| train/                  |               |
|    approx_kl            | 106.00534     |
|    clip_fraction        | 0.695         |
|    clip_range           | 0.2           |
|    entropy_loss         | -40.5         |
|    explained_variance   | -3.86         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.303        |
|    n_updates            | 50            |
|    policy_gradient_loss | 0.148         |
|    reward               | -6.834787e-05 |
|    std                  | 1.03          |
|    value_loss           | 0.00407       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1848, ResetDay: 3528,Episode: 9
------------------------------------------
| time/                   |              |
|    fps                  | 87           |
|    iterations           | 7            |
|    time_elapsed         | 163          |
|    total_timesteps      | 14336        |
| train/                  |              |
|    approx_kl            | 150.03914    |
|    clip_fraction        | 0.714        |
|    clip_range           | 0.2          |
|    entropy_loss         | -40.7        |
|    explained_variance   | -4.51        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.339       |
|    n_updates            | 60           |
|    policy_gradient_loss | 0.115        |
|    reward               | 5.211601e-05 |
|    std                  | 1.04         |
|    value_loss           | 0.00509      |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1831, ResetDay: 3511,Episode: 10
---------------------------------------
| time/                   |           |
|    fps                  | 88        |
|    iterations           | 8         |
|    time_elapsed         | 186       |
|    total_timesteps      | 16384     |
| train/                  |           |
|    approx_kl            | 51.421432 |
|    clip_fraction        | 0.717     |
|    clip_range           | 0.2       |
|    entropy_loss         | -40.8     |
|    explained_variance   | -7.94     |
|    learning_rate        | 0.00025   |
|    loss                 | -0.302    |
|    n_updates            | 70        |
|    policy_gradient_loss | 0.132     |
|    reward               | 0.0       |
|    std                  | 1.04      |
|    value_loss           | 0.00531   |
---------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3511, episode: 10
begin_total_asset: 200.00
end_total_asset: 21.74
total_reward: -178.26
total_cost: 83.86
total_trades: 10869
Sharpe: -1.025
=================================
Reseting Environment StartDay: 1800, ResetDay: 3480,Episode: 11
---------------------------------------
| time/                   |           |
|    fps                  | 88        |
|    iterations           | 9         |
|    time_elapsed         | 208       |
|    total_timesteps      | 18432     |
| train/                  |           |
|    approx_kl            | 145.27734 |
|    clip_fraction        | 0.731     |
|    clip_range           | 0.2       |
|    entropy_loss         | -40.9     |
|    explained_variance   | -5.8      |
|    learning_rate        | 0.00025   |
|    loss                 | -0.275    |
|    n_updates            | 80        |
|    policy_gradient_loss | 0.185     |
|    reward               | 0.0       |
|    std                  | 1.05      |
|    value_loss           | 0.00166   |
---------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1778, ResetDay: 3458,Episode: 12
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1348, ResetDay: 3028,Episode: 13
-------------------------------------------
| time/                   |               |
|    fps                  | 88            |
|    iterations           | 10            |
|    time_elapsed         | 231           |
|    total_timesteps      | 20480         |
| train/                  |               |
|    approx_kl            | 259.9075      |
|    clip_fraction        | 0.706         |
|    clip_range           | 0.2           |
|    entropy_loss         | -41           |
|    explained_variance   | -6.82         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.264        |
|    n_updates            | 90            |
|    policy_gradient_loss | 0.169         |
|    reward               | -2.848816e-06 |
|    std                  | 1.05          |
|    value_loss           | 0.00119       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 445, ResetDay: 2125,Episode: 14
-------------------------------------------
| time/                   |               |
|    fps                  | 88            |
|    iterations           | 11            |
|    time_elapsed         | 253           |
|    total_timesteps      | 22528         |
| train/                  |               |
|    approx_kl            | 365.0924      |
|    clip_fraction        | 0.718         |
|    clip_range           | 0.2           |
|    entropy_loss         | -41.1         |
|    explained_variance   | -5.64         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.31         |
|    n_updates            | 100           |
|    policy_gradient_loss | 0.137         |
|    reward               | 4.0672683e-05 |
|    std                  | 1.05          |
|    value_loss           | 0.00156       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1677, ResetDay: 3357,Episode: 15
--------------------------------------------
| time/                   |                |
|    fps                  | 89             |
|    iterations           | 12             |
|    time_elapsed         | 276            |
|    total_timesteps      | 24576          |
| train/                  |                |
|    approx_kl            | 62.680412      |
|    clip_fraction        | 0.726          |
|    clip_range           | 0.2            |
|    entropy_loss         | -41.2          |
|    explained_variance   | -8.66          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.293         |
|    n_updates            | 110            |
|    policy_gradient_loss | 0.132          |
|    reward               | -0.00013854282 |
|    std                  | 1.06           |
|    value_loss           | 0.00264        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3357, episode: 15
begin_total_asset: 200.00
end_total_asset: 42.35
total_reward: -157.65
total_cost: 225.92
total_trades: 12948
Sharpe: -1.024
=================================
Reseting Environment StartDay: 1176, ResetDay: 2856,Episode: 16
--------------------------------------------
| time/                   |                |
|    fps                  | 89             |
|    iterations           | 13             |
|    time_elapsed         | 298            |
|    total_timesteps      | 26624          |
| train/                  |                |
|    approx_kl            | 53.549603      |
|    clip_fraction        | 0.73           |
|    clip_range           | 0.2            |
|    entropy_loss         | -41.4          |
|    explained_variance   | -8.85          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.291         |
|    n_updates            | 120            |
|    policy_gradient_loss | 0.115          |
|    reward               | -0.00012969841 |
|    std                  | 1.06           |
|    value_loss           | 0.00164        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2638, ResetDay: 4318,Episode: 17
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 697, ResetDay: 2377,Episode: 18
-------------------------------------------
| time/                   |               |
|    fps                  | 89            |
|    iterations           | 14            |
|    time_elapsed         | 320           |
|    total_timesteps      | 28672         |
| train/                  |               |
|    approx_kl            | 131.07616     |
|    clip_fraction        | 0.733         |
|    clip_range           | 0.2           |
|    entropy_loss         | -41.6         |
|    explained_variance   | -8.58         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.307        |
|    n_updates            | 130           |
|    policy_gradient_loss | 0.133         |
|    reward               | -4.312992e-05 |
|    std                  | 1.07          |
|    value_loss           | 0.00106       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1724, ResetDay: 3404,Episode: 19
--------------------------------------------
| time/                   |                |
|    fps                  | 89             |
|    iterations           | 15             |
|    time_elapsed         | 343            |
|    total_timesteps      | 30720          |
| train/                  |                |
|    approx_kl            | 152.29364      |
|    clip_fraction        | 0.776          |
|    clip_range           | 0.2            |
|    entropy_loss         | -41.7          |
|    explained_variance   | -4.11          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.326         |
|    n_updates            | 140            |
|    policy_gradient_loss | 0.175          |
|    reward               | -0.00017805948 |
|    std                  | 1.08           |
|    value_loss           | 0.000721       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 116, ResetDay: 1796,Episode: 20
--------------------------------------------
| time/                   |                |
|    fps                  | 89             |
|    iterations           | 16             |
|    time_elapsed         | 365            |
|    total_timesteps      | 32768          |
| train/                  |                |
|    approx_kl            | 50.128708      |
|    clip_fraction        | 0.735          |
|    clip_range           | 0.2            |
|    entropy_loss         | -41.9          |
|    explained_variance   | -11.6          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.32          |
|    n_updates            | 150            |
|    policy_gradient_loss | 0.179          |
|    reward               | -1.1488485e-05 |
|    std                  | 1.08           |
|    value_loss           | 0.00153        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 1796, episode: 20
begin_total_asset: 200.00
end_total_asset: 33.95
total_reward: -166.05
total_cost: 95.88
total_trades: 15432
Sharpe: -0.490
=================================
Reseting Environment StartDay: 1844, ResetDay: 3524,Episode: 21
-------------------------------------------
| time/                   |               |
|    fps                  | 89            |
|    iterations           | 17            |
|    time_elapsed         | 388           |
|    total_timesteps      | 34816         |
| train/                  |               |
|    approx_kl            | 106.18704     |
|    clip_fraction        | 0.748         |
|    clip_range           | 0.2           |
|    entropy_loss         | -42.1         |
|    explained_variance   | -8.01         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.319        |
|    n_updates            | 160           |
|    policy_gradient_loss | 0.175         |
|    reward               | 0.00012952251 |
|    std                  | 1.09          |
|    value_loss           | 0.00209       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2584, ResetDay: 4264,Episode: 22
---------------------------------------
| time/                   |           |
|    fps                  | 89        |
|    iterations           | 18        |
|    time_elapsed         | 410       |
|    total_timesteps      | 36864     |
| train/                  |           |
|    approx_kl            | 30.356197 |
|    clip_fraction        | 0.755     |
|    clip_range           | 0.2       |
|    entropy_loss         | -42.2     |
|    explained_variance   | -7.69     |
|    learning_rate        | 0.00025   |
|    loss                 | -0.247    |
|    n_updates            | 170       |
|    policy_gradient_loss | 0.186     |
|    reward               | 0.0       |
|    std                  | 1.1       |
|    value_loss           | 0.00103   |
---------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2716, ResetDay: 4396,Episode: 23
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 327, ResetDay: 2007,Episode: 24
-------------------------------------------
| time/                   |               |
|    fps                  | 89            |
|    iterations           | 19            |
|    time_elapsed         | 433           |
|    total_timesteps      | 38912         |
| train/                  |               |
|    approx_kl            | 212.83055     |
|    clip_fraction        | 0.767         |
|    clip_range           | 0.2           |
|    entropy_loss         | -42.4         |
|    explained_variance   | -5.1          |
|    learning_rate        | 0.00025       |
|    loss                 | -0.247        |
|    n_updates            | 180           |
|    policy_gradient_loss | 0.163         |
|    reward               | 9.4544936e-05 |
|    std                  | 1.1           |
|    value_loss           | 0.000268      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2784, ResetDay: 4464,Episode: 25
-------------------------------------------
| time/                   |               |
|    fps                  | 89            |
|    iterations           | 20            |
|    time_elapsed         | 455           |
|    total_timesteps      | 40960         |
| train/                  |               |
|    approx_kl            | 744.53345     |
|    clip_fraction        | 0.765         |
|    clip_range           | 0.2           |
|    entropy_loss         | -42.5         |
|    explained_variance   | -2.39         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.279        |
|    n_updates            | 190           |
|    policy_gradient_loss | 0.121         |
|    reward               | 0.00035025214 |
|    std                  | 1.11          |
|    value_loss           | 0.000399      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4464, episode: 25
begin_total_asset: 200.00
end_total_asset: 272.01
total_reward: 72.01
total_cost: 127.26
total_trades: 20022
Sharpe: 0.311
=================================
Reseting Environment StartDay: 1274, ResetDay: 2954,Episode: 26
------------------------------------------
| time/                   |              |
|    fps                  | 89           |
|    iterations           | 21           |
|    time_elapsed         | 478          |
|    total_timesteps      | 43008        |
| train/                  |              |
|    approx_kl            | 53.699604    |
|    clip_fraction        | 0.723        |
|    clip_range           | 0.2          |
|    entropy_loss         | -42.7        |
|    explained_variance   | -8.09        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.363       |
|    n_updates            | 200          |
|    policy_gradient_loss | 0.112        |
|    reward               | 6.031189e-05 |
|    std                  | 1.11         |
|    value_loss           | 0.00106      |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 968, ResetDay: 2648,Episode: 27
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 22            |
|    time_elapsed         | 500           |
|    total_timesteps      | 45056         |
| train/                  |               |
|    approx_kl            | 347.02115     |
|    clip_fraction        | 0.748         |
|    clip_range           | 0.2           |
|    entropy_loss         | -42.7         |
|    explained_variance   | -3.86         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.179        |
|    n_updates            | 210           |
|    policy_gradient_loss | 0.154         |
|    reward               | -4.865837e-05 |
|    std                  | 1.12          |
|    value_loss           | 0.000404      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 862, ResetDay: 2542,Episode: 28
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1758, ResetDay: 3438,Episode: 29
-------------------------------------------
| time/                   |               |
|    fps                  | 89            |
|    iterations           | 23            |
|    time_elapsed         | 523           |
|    total_timesteps      | 47104         |
| train/                  |               |
|    approx_kl            | 108.02884     |
|    clip_fraction        | 0.747         |
|    clip_range           | 0.2           |
|    entropy_loss         | -42.9         |
|    explained_variance   | -8.22         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.288        |
|    n_updates            | 220           |
|    policy_gradient_loss | 0.129         |
|    reward               | -4.642353e-05 |
|    std                  | 1.12          |
|    value_loss           | 0.00054       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2016, ResetDay: 3696,Episode: 30
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 24            |
|    time_elapsed         | 545           |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 114.44344     |
|    clip_fraction        | 0.748         |
|    clip_range           | 0.2           |
|    entropy_loss         | -43           |
|    explained_variance   | -11.2         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.359        |
|    n_updates            | 230           |
|    policy_gradient_loss | 0.156         |
|    reward               | 2.8582383e-05 |
|    std                  | 1.13          |
|    value_loss           | 0.000499      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3696, episode: 30
begin_total_asset: 200.00
end_total_asset: 298.75
total_reward: 98.75
total_cost: 43.16
total_trades: 25184
Sharpe: 0.410
=================================
Reseting Environment StartDay: 2150, ResetDay: 3830,Episode: 31
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 25             |
|    time_elapsed         | 568            |
|    total_timesteps      | 51200          |
| train/                  |                |
|    approx_kl            | 56.046917      |
|    clip_fraction        | 0.736          |
|    clip_range           | 0.2            |
|    entropy_loss         | -43.2          |
|    explained_variance   | -9.47          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.258         |
|    n_updates            | 240            |
|    policy_gradient_loss | 0.143          |
|    reward               | -6.8869784e-05 |
|    std                  | 1.13           |
|    value_loss           | 0.000225       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 103, ResetDay: 1783,Episode: 32
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 26            |
|    time_elapsed         | 590           |
|    total_timesteps      | 53248         |
| train/                  |               |
|    approx_kl            | 122.73881     |
|    clip_fraction        | 0.734         |
|    clip_range           | 0.2           |
|    entropy_loss         | -43.3         |
|    explained_variance   | -9.74         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.319        |
|    n_updates            | 250           |
|    policy_gradient_loss | 0.13          |
|    reward               | 0.00062618137 |
|    std                  | 1.14          |
|    value_loss           | 0.000155      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 270, ResetDay: 1950,Episode: 33
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 27           |
|    time_elapsed         | 613          |
|    total_timesteps      | 55296        |
| train/                  |              |
|    approx_kl            | 158.48717    |
|    clip_fraction        | 0.742        |
|    clip_range           | 0.2          |
|    entropy_loss         | -43.5        |
|    explained_variance   | -9.19        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.357       |
|    n_updates            | 260          |
|    policy_gradient_loss | 0.109        |
|    reward               | 0.0042790594 |
|    std                  | 1.15         |
|    value_loss           | 0.000914     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1280, ResetDay: 2960,Episode: 34
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1081, ResetDay: 2761,Episode: 35
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 28            |
|    time_elapsed         | 635           |
|    total_timesteps      | 57344         |
| train/                  |               |
|    approx_kl            | 48.502647     |
|    clip_fraction        | 0.748         |
|    clip_range           | 0.2           |
|    entropy_loss         | -43.6         |
|    explained_variance   | -8.03         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.218        |
|    n_updates            | 270           |
|    policy_gradient_loss | 0.134         |
|    reward               | 9.4862935e-06 |
|    std                  | 1.15          |
|    value_loss           | 0.000666      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2761, episode: 35
begin_total_asset: 200.00
end_total_asset: 163.14
total_reward: -36.86
total_cost: 19.61
total_trades: 29838
Sharpe: 0.146
=================================
Reseting Environment StartDay: 1869, ResetDay: 3549,Episode: 36
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 29            |
|    time_elapsed         | 658           |
|    total_timesteps      | 59392         |
| train/                  |               |
|    approx_kl            | 59.810127     |
|    clip_fraction        | 0.724         |
|    clip_range           | 0.2           |
|    entropy_loss         | -43.8         |
|    explained_variance   | -8.62         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.335        |
|    n_updates            | 280           |
|    policy_gradient_loss | 0.131         |
|    reward               | 0.00027868958 |
|    std                  | 1.16          |
|    value_loss           | 0.000298      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1070, ResetDay: 2750,Episode: 37
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 30            |
|    time_elapsed         | 680           |
|    total_timesteps      | 61440         |
| train/                  |               |
|    approx_kl            | 46.8558       |
|    clip_fraction        | 0.75          |
|    clip_range           | 0.2           |
|    entropy_loss         | -43.9         |
|    explained_variance   | -9.49         |
|    learning_rate        | 0.00025       |
|    loss                 | 0.0339        |
|    n_updates            | 290           |
|    policy_gradient_loss | 0.201         |
|    reward               | 0.00035159854 |
|    std                  | 1.16          |
|    value_loss           | 0.000203      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 287, ResetDay: 1967,Episode: 38
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 31           |
|    time_elapsed         | 703          |
|    total_timesteps      | 63488        |
| train/                  |              |
|    approx_kl            | 120.22281    |
|    clip_fraction        | 0.732        |
|    clip_range           | 0.2          |
|    entropy_loss         | -44          |
|    explained_variance   | -9.05        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.272       |
|    n_updates            | 300          |
|    policy_gradient_loss | 0.209        |
|    reward               | 0.0005306038 |
|    std                  | 1.17         |
|    value_loss           | 0.000164     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2148, ResetDay: 3828,Episode: 39
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 32           |
|    time_elapsed         | 725          |
|    total_timesteps      | 65536        |
| train/                  |              |
|    approx_kl            | 77.225555    |
|    clip_fraction        | 0.738        |
|    clip_range           | 0.2          |
|    entropy_loss         | -44.1        |
|    explained_variance   | -10.9        |
|    learning_rate        | 0.00025      |
|    loss                 | 0.461        |
|    n_updates            | 310          |
|    policy_gradient_loss | 0.301        |
|    reward               | 0.0024876231 |
|    std                  | 1.17         |
|    value_loss           | 0.00035      |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 916, ResetDay: 2596,Episode: 40
Environment reached Terminal state as number of trading days reached limit!!
day: 2596, episode: 40
begin_total_asset: 200.00
end_total_asset: 278.82
total_reward: 78.82
total_cost: 12.36
total_trades: 34616
Sharpe: 0.409
=================================
Reseting Environment StartDay: 416, ResetDay: 2096,Episode: 41
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 33            |
|    time_elapsed         | 748           |
|    total_timesteps      | 67584         |
| train/                  |               |
|    approx_kl            | 52.816113     |
|    clip_fraction        | 0.755         |
|    clip_range           | 0.2           |
|    entropy_loss         | -44.2         |
|    explained_variance   | -6.97         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.261        |
|    n_updates            | 320           |
|    policy_gradient_loss | 0.172         |
|    reward               | 2.5864983e-05 |
|    std                  | 1.18          |
|    value_loss           | 0.000103      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2216, ResetDay: 3896,Episode: 42
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 34             |
|    time_elapsed         | 770            |
|    total_timesteps      | 69632          |
| train/                  |                |
|    approx_kl            | 233.05371      |
|    clip_fraction        | 0.75           |
|    clip_range           | 0.2            |
|    entropy_loss         | -44.3          |
|    explained_variance   | -8.34          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.294         |
|    n_updates            | 330            |
|    policy_gradient_loss | 0.144          |
|    reward               | -0.00015664882 |
|    std                  | 1.18           |
|    value_loss           | 0.000223       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2712, ResetDay: 4392,Episode: 43
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 35            |
|    time_elapsed         | 793           |
|    total_timesteps      | 71680         |
| train/                  |               |
|    approx_kl            | 45.193016     |
|    clip_fraction        | 0.75          |
|    clip_range           | 0.2           |
|    entropy_loss         | -44.4         |
|    explained_variance   | -12.9         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.331        |
|    n_updates            | 340           |
|    policy_gradient_loss | 0.174         |
|    reward               | 0.00064569246 |
|    std                  | 1.18          |
|    value_loss           | 0.000193      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 102, ResetDay: 1782,Episode: 44
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 36             |
|    time_elapsed         | 816            |
|    total_timesteps      | 73728          |
| train/                  |                |
|    approx_kl            | 155.11363      |
|    clip_fraction        | 0.776          |
|    clip_range           | 0.2            |
|    entropy_loss         | -44.5          |
|    explained_variance   | -5.91          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.247         |
|    n_updates            | 350            |
|    policy_gradient_loss | 0.212          |
|    reward               | -0.00013239059 |
|    std                  | 1.19           |
|    value_loss           | 5e-05          |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 918, ResetDay: 2598,Episode: 45
Environment reached Terminal state as number of trading days reached limit!!
day: 2598, episode: 45
begin_total_asset: 200.00
end_total_asset: 504.38
total_reward: 304.38
total_cost: 11.05
total_trades: 39159
Sharpe: 0.772
=================================
Reseting Environment StartDay: 1600, ResetDay: 3280,Episode: 46
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 37             |
|    time_elapsed         | 838            |
|    total_timesteps      | 75776          |
| train/                  |                |
|    approx_kl            | 284.14142      |
|    clip_fraction        | 0.74           |
|    clip_range           | 0.2            |
|    entropy_loss         | -44.6          |
|    explained_variance   | -10.9          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.349         |
|    n_updates            | 360            |
|    policy_gradient_loss | 0.124          |
|    reward               | -2.0891819e-05 |
|    std                  | 1.19           |
|    value_loss           | 0.000315       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2073, ResetDay: 3753,Episode: 47
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 38            |
|    time_elapsed         | 861           |
|    total_timesteps      | 77824         |
| train/                  |               |
|    approx_kl            | 50.648563     |
|    clip_fraction        | 0.759         |
|    clip_range           | 0.2           |
|    entropy_loss         | -44.7         |
|    explained_variance   | -7.43         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.191        |
|    n_updates            | 370           |
|    policy_gradient_loss | 0.177         |
|    reward               | 0.00018862591 |
|    std                  | 1.2           |
|    value_loss           | 0.000134      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2630, ResetDay: 4310,Episode: 48
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 39             |
|    time_elapsed         | 883            |
|    total_timesteps      | 79872          |
| train/                  |                |
|    approx_kl            | 59.621784      |
|    clip_fraction        | 0.735          |
|    clip_range           | 0.2            |
|    entropy_loss         | -44.8          |
|    explained_variance   | -10.1          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.28          |
|    n_updates            | 380            |
|    policy_gradient_loss | 0.321          |
|    reward               | -0.00021853027 |
|    std                  | 1.21           |
|    value_loss           | 6.45e-05       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2522, ResetDay: 4202,Episode: 49
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 40           |
|    time_elapsed         | 906          |
|    total_timesteps      | 81920        |
| train/                  |              |
|    approx_kl            | 121.346664   |
|    clip_fraction        | 0.731        |
|    clip_range           | 0.2          |
|    entropy_loss         | -45          |
|    explained_variance   | -7.9         |
|    learning_rate        | 0.00025      |
|    loss                 | -0.299       |
|    n_updates            | 390          |
|    policy_gradient_loss | 0.243        |
|    reward               | 0.0008013622 |
|    std                  | 1.21         |
|    value_loss           | 3.62e-05     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2377, ResetDay: 4057,Episode: 50
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 41             |
|    time_elapsed         | 928            |
|    total_timesteps      | 83968          |
| train/                  |                |
|    approx_kl            | 325.64508      |
|    clip_fraction        | 0.735          |
|    clip_range           | 0.2            |
|    entropy_loss         | -45.1          |
|    explained_variance   | -5.05          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.302         |
|    n_updates            | 400            |
|    policy_gradient_loss | 0.151          |
|    reward               | -0.00023022995 |
|    std                  | 1.22           |
|    value_loss           | 2.85e-05       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4057, episode: 50
begin_total_asset: 200.00
end_total_asset: 275.21
total_reward: 75.21
total_cost: 6.78
total_trades: 42491
Sharpe: 0.322
=================================
Reseting Environment StartDay: 136, ResetDay: 1816,Episode: 51
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1444, ResetDay: 3124,Episode: 52
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 42             |
|    time_elapsed         | 951            |
|    total_timesteps      | 86016          |
| train/                  |                |
|    approx_kl            | 215.47568      |
|    clip_fraction        | 0.702          |
|    clip_range           | 0.2            |
|    entropy_loss         | -45.3          |
|    explained_variance   | -6.61          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.0295        |
|    n_updates            | 410            |
|    policy_gradient_loss | 0.177          |
|    reward               | -4.4056414e-05 |
|    std                  | 1.22           |
|    value_loss           | 2.45e-05       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1873, ResetDay: 3553,Episode: 53
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 43             |
|    time_elapsed         | 973            |
|    total_timesteps      | 88064          |
| train/                  |                |
|    approx_kl            | 452.4049       |
|    clip_fraction        | 0.713          |
|    clip_range           | 0.2            |
|    entropy_loss         | -45.4          |
|    explained_variance   | -8.51          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.325         |
|    n_updates            | 420            |
|    policy_gradient_loss | 0.511          |
|    reward               | -2.7581214e-05 |
|    std                  | 1.23           |
|    value_loss           | 0.000251       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1715, ResetDay: 3395,Episode: 54
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 44             |
|    time_elapsed         | 996            |
|    total_timesteps      | 90112          |
| train/                  |                |
|    approx_kl            | 57.454132      |
|    clip_fraction        | 0.706          |
|    clip_range           | 0.2            |
|    entropy_loss         | -45.5          |
|    explained_variance   | -11.8          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.291         |
|    n_updates            | 430            |
|    policy_gradient_loss | 0.157          |
|    reward               | -0.00014138184 |
|    std                  | 1.23           |
|    value_loss           | 6.09e-05       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1809, ResetDay: 3489,Episode: 55
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 45             |
|    time_elapsed         | 1019           |
|    total_timesteps      | 92160          |
| train/                  |                |
|    approx_kl            | 118.133316     |
|    clip_fraction        | 0.716          |
|    clip_range           | 0.2            |
|    entropy_loss         | -45.7          |
|    explained_variance   | -8.65          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.352         |
|    n_updates            | 440            |
|    policy_gradient_loss | 0.168          |
|    reward               | -5.1490213e-05 |
|    std                  | 1.24           |
|    value_loss           | 3.76e-05       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3489, episode: 55
begin_total_asset: 200.00
end_total_asset: 313.47
total_reward: 113.47
total_cost: 5.22
total_trades: 44538
Sharpe: 0.432
=================================
Reseting Environment StartDay: 74, ResetDay: 1754,Episode: 56
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2415, ResetDay: 4095,Episode: 57
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 46            |
|    time_elapsed         | 1041          |
|    total_timesteps      | 94208         |
| train/                  |               |
|    approx_kl            | 102.7429      |
|    clip_fraction        | 0.718         |
|    clip_range           | 0.2           |
|    entropy_loss         | -45.8         |
|    explained_variance   | -9.93         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.305        |
|    n_updates            | 450           |
|    policy_gradient_loss | 0.15          |
|    reward               | 0.00021033802 |
|    std                  | 1.24          |
|    value_loss           | 2.69e-05      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 246, ResetDay: 1926,Episode: 58
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 47            |
|    time_elapsed         | 1064          |
|    total_timesteps      | 96256         |
| train/                  |               |
|    approx_kl            | 260.70343     |
|    clip_fraction        | 0.731         |
|    clip_range           | 0.2           |
|    entropy_loss         | -45.9         |
|    explained_variance   | -10.7         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.383        |
|    n_updates            | 460           |
|    policy_gradient_loss | 0.139         |
|    reward               | 1.2527084e-05 |
|    std                  | 1.25          |
|    value_loss           | 0.000199      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 282, ResetDay: 1962,Episode: 59
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 48            |
|    time_elapsed         | 1086          |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 113.46361     |
|    clip_fraction        | 0.731         |
|    clip_range           | 0.2           |
|    entropy_loss         | -46           |
|    explained_variance   | -6.77         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.411        |
|    n_updates            | 470           |
|    policy_gradient_loss | 0.126         |
|    reward               | 2.8903962e-06 |
|    std                  | 1.26          |
|    value_loss           | 5.15e-05      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 526, ResetDay: 2206,Episode: 60
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 49             |
|    time_elapsed         | 1109           |
|    total_timesteps      | 100352         |
| train/                  |                |
|    approx_kl            | 42.070713      |
|    clip_fraction        | 0.733          |
|    clip_range           | 0.2            |
|    entropy_loss         | -46.2          |
|    explained_variance   | -12.5          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.358         |
|    n_updates            | 480            |
|    policy_gradient_loss | 0.191          |
|    reward               | -8.6456486e-05 |
|    std                  | 1.26           |
|    value_loss           | 0.000129       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2206, episode: 60
begin_total_asset: 200.00
end_total_asset: 258.68
total_reward: 58.68
total_cost: 4.93
total_trades: 45578
Sharpe: 0.294
=================================
Reseting Environment StartDay: 1598, ResetDay: 3278,Episode: 61
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 50             |
|    time_elapsed         | 1132           |
|    total_timesteps      | 102400         |
| train/                  |                |
|    approx_kl            | 37.390484      |
|    clip_fraction        | 0.719          |
|    clip_range           | 0.2            |
|    entropy_loss         | -46.3          |
|    explained_variance   | -9.55          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.37          |
|    n_updates            | 490            |
|    policy_gradient_loss | 0.213          |
|    reward               | -2.0968628e-05 |
|    std                  | 1.27           |
|    value_loss           | 9.04e-05       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2180, ResetDay: 3860,Episode: 62
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1655, ResetDay: 3335,Episode: 63
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 51            |
|    time_elapsed         | 1154          |
|    total_timesteps      | 104448        |
| train/                  |               |
|    approx_kl            | 48.28856      |
|    clip_fraction        | 0.709         |
|    clip_range           | 0.2           |
|    entropy_loss         | -46.5         |
|    explained_variance   | -11.5         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.306        |
|    n_updates            | 500           |
|    policy_gradient_loss | 0.149         |
|    reward               | -1.704216e-05 |
|    std                  | 1.28          |
|    value_loss           | 3.87e-05      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1684, ResetDay: 3364,Episode: 64
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 52            |
|    time_elapsed         | 1177          |
|    total_timesteps      | 106496        |
| train/                  |               |
|    approx_kl            | 201.04427     |
|    clip_fraction        | 0.7           |
|    clip_range           | 0.2           |
|    entropy_loss         | -46.7         |
|    explained_variance   | -7.25         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.363        |
|    n_updates            | 510           |
|    policy_gradient_loss | 0.161         |
|    reward               | 0.00014068795 |
|    std                  | 1.29          |
|    value_loss           | 1.6e-05       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2593, ResetDay: 4273,Episode: 65
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 53            |
|    time_elapsed         | 1199          |
|    total_timesteps      | 108544        |
| train/                  |               |
|    approx_kl            | 54.24439      |
|    clip_fraction        | 0.728         |
|    clip_range           | 0.2           |
|    entropy_loss         | -46.9         |
|    explained_variance   | -10.4         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.385        |
|    n_updates            | 520           |
|    policy_gradient_loss | 0.181         |
|    reward               | 0.00020512124 |
|    std                  | 1.3           |
|    value_loss           | 2.08e-05      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4273, episode: 65
begin_total_asset: 200.00
end_total_asset: 296.72
total_reward: 96.72
total_cost: 1.97
total_trades: 46442
Sharpe: 0.400
=================================
Reseting Environment StartDay: 2719, ResetDay: 4399,Episode: 66
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 54             |
|    time_elapsed         | 1222           |
|    total_timesteps      | 110592         |
| train/                  |                |
|    approx_kl            | 83.07991       |
|    clip_fraction        | 0.731          |
|    clip_range           | 0.2            |
|    entropy_loss         | -47            |
|    explained_variance   | -6.71          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.313         |
|    n_updates            | 530            |
|    policy_gradient_loss | 0.214          |
|    reward               | -5.7776262e-05 |
|    std                  | 1.3            |
|    value_loss           | 1.54e-05       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1625, ResetDay: 3305,Episode: 67
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1128, ResetDay: 2808,Episode: 68
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 55            |
|    time_elapsed         | 1245          |
|    total_timesteps      | 112640        |
| train/                  |               |
|    approx_kl            | 273.4918      |
|    clip_fraction        | 0.783         |
|    clip_range           | 0.2           |
|    entropy_loss         | -47.1         |
|    explained_variance   | -3.09         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.309        |
|    n_updates            | 540           |
|    policy_gradient_loss | 0.253         |
|    reward               | -4.992676e-05 |
|    std                  | 1.31          |
|    value_loss           | 1.29e-05      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 184, ResetDay: 1864,Episode: 69
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 56             |
|    time_elapsed         | 1267           |
|    total_timesteps      | 114688         |
| train/                  |                |
|    approx_kl            | 517.39166      |
|    clip_fraction        | 0.702          |
|    clip_range           | 0.2            |
|    entropy_loss         | -47.2          |
|    explained_variance   | -9.13          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.307         |
|    n_updates            | 550            |
|    policy_gradient_loss | 0.153          |
|    reward               | -0.00010332329 |
|    std                  | 1.31           |
|    value_loss           | 1.58e-05       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2757, ResetDay: 4437,Episode: 70
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 57             |
|    time_elapsed         | 1290           |
|    total_timesteps      | 116736         |
| train/                  |                |
|    approx_kl            | 38.14713       |
|    clip_fraction        | 0.721          |
|    clip_range           | 0.2            |
|    entropy_loss         | -47.3          |
|    explained_variance   | -7.75          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.315         |
|    n_updates            | 560            |
|    policy_gradient_loss | 0.399          |
|    reward               | -0.00016728324 |
|    std                  | 1.31           |
|    value_loss           | 6.4e-05        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4437, episode: 70
begin_total_asset: 200.00
end_total_asset: 524.22
total_reward: 324.22
total_cost: 4.93
total_trades: 46801
Sharpe: 0.654
=================================
Reseting Environment StartDay: 906, ResetDay: 2586,Episode: 71
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 58            |
|    time_elapsed         | 1312          |
|    total_timesteps      | 118784        |
| train/                  |               |
|    approx_kl            | 43.27686      |
|    clip_fraction        | 0.709         |
|    clip_range           | 0.2           |
|    entropy_loss         | -47.4         |
|    explained_variance   | -14.1         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.454        |
|    n_updates            | 570           |
|    policy_gradient_loss | 0.111         |
|    reward               | 0.00011383925 |
|    std                  | 1.32          |
|    value_loss           | 5.95e-05      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 330, ResetDay: 2010,Episode: 72
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 59            |
|    time_elapsed         | 1334          |
|    total_timesteps      | 120832        |
| train/                  |               |
|    approx_kl            | 267.3677      |
|    clip_fraction        | 0.729         |
|    clip_range           | 0.2           |
|    entropy_loss         | -47.6         |
|    explained_variance   | -5.05         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.379        |
|    n_updates            | 580           |
|    policy_gradient_loss | 0.148         |
|    reward               | 0.00030098305 |
|    std                  | 1.33          |
|    value_loss           | 3.55e-05      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1193, ResetDay: 2873,Episode: 73
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1551, ResetDay: 3231,Episode: 74
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 60            |
|    time_elapsed         | 1357          |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 61.453156     |
|    clip_fraction        | 0.722         |
|    clip_range           | 0.2           |
|    entropy_loss         | -47.8         |
|    explained_variance   | -15.1         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.39         |
|    n_updates            | 590           |
|    policy_gradient_loss | 0.127         |
|    reward               | -8.831377e-05 |
|    std                  | 1.34          |
|    value_loss           | 4.99e-05      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1367, ResetDay: 3047,Episode: 75
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 61            |
|    time_elapsed         | 1380          |
|    total_timesteps      | 124928        |
| train/                  |               |
|    approx_kl            | 43.82328      |
|    clip_fraction        | 0.722         |
|    clip_range           | 0.2           |
|    entropy_loss         | -48           |
|    explained_variance   | -7.24         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.354        |
|    n_updates            | 600           |
|    policy_gradient_loss | 0.154         |
|    reward               | 1.7485047e-05 |
|    std                  | 1.35          |
|    value_loss           | 2.08e-05      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3047, episode: 75
begin_total_asset: 200.00
end_total_asset: 169.99
total_reward: -30.01
total_cost: 1.95
total_trades: 46920
Sharpe: 0.134
=================================
Reseting Environment StartDay: 238, ResetDay: 1918,Episode: 76
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 62           |
|    time_elapsed         | 1402         |
|    total_timesteps      | 126976       |
| train/                  |              |
|    approx_kl            | 47.90268     |
|    clip_fraction        | 0.724        |
|    clip_range           | 0.2          |
|    entropy_loss         | -48.1        |
|    explained_variance   | -6.95        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.329       |
|    n_updates            | 610          |
|    policy_gradient_loss | 0.153        |
|    reward               | 6.737919e-05 |
|    std                  | 1.35         |
|    value_loss           | 1.44e-05     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1120, ResetDay: 2800,Episode: 77
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 63            |
|    time_elapsed         | 1425          |
|    total_timesteps      | 129024        |
| train/                  |               |
|    approx_kl            | 49.154713     |
|    clip_fraction        | 0.736         |
|    clip_range           | 0.2           |
|    entropy_loss         | -48.2         |
|    explained_variance   | -12.6         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.0544       |
|    n_updates            | 620           |
|    policy_gradient_loss | 0.148         |
|    reward               | -0.0005273338 |
|    std                  | 1.36          |
|    value_loss           | 5.12e-05      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 176, ResetDay: 1856,Episode: 78
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 64           |
|    time_elapsed         | 1448         |
|    total_timesteps      | 131072       |
| train/                  |              |
|    approx_kl            | 36.810658    |
|    clip_fraction        | 0.725        |
|    clip_range           | 0.2          |
|    entropy_loss         | -48.4        |
|    explained_variance   | -10          |
|    learning_rate        | 0.00025      |
|    loss                 | -0.2         |
|    n_updates            | 630          |
|    policy_gradient_loss | 0.178        |
|    reward               | 0.0003042139 |
|    std                  | 1.37         |
|    value_loss           | 2.38e-05     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 688, ResetDay: 2368,Episode: 79
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 571, ResetDay: 2251,Episode: 80
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 65            |
|    time_elapsed         | 1471          |
|    total_timesteps      | 133120        |
| train/                  |               |
|    approx_kl            | 82.5305       |
|    clip_fraction        | 0.769         |
|    clip_range           | 0.2           |
|    entropy_loss         | -48.5         |
|    explained_variance   | -11.3         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.384        |
|    n_updates            | 640           |
|    policy_gradient_loss | 0.155         |
|    reward               | -0.0007479924 |
|    std                  | 1.37          |
|    value_loss           | 4.64e-05      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2251, episode: 80
begin_total_asset: 200.00
end_total_asset: 256.75
total_reward: 56.75
total_cost: 2.10
total_trades: 46983
Sharpe: 0.290
=================================
Reseting Environment StartDay: 13, ResetDay: 1693,Episode: 81
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 66           |
|    time_elapsed         | 1493         |
|    total_timesteps      | 135168       |
| train/                  |              |
|    approx_kl            | 43.14785     |
|    clip_fraction        | 0.761        |
|    clip_range           | 0.2          |
|    entropy_loss         | -48.7        |
|    explained_variance   | -16.6        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.334       |
|    n_updates            | 650          |
|    policy_gradient_loss | 0.181        |
|    reward               | 4.627638e-05 |
|    std                  | 1.38         |
|    value_loss           | 3.21e-05     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 829, ResetDay: 2509,Episode: 82
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 67             |
|    time_elapsed         | 1516           |
|    total_timesteps      | 137216         |
| train/                  |                |
|    approx_kl            | 20.374477      |
|    clip_fraction        | 0.736          |
|    clip_range           | 0.2            |
|    entropy_loss         | -48.8          |
|    explained_variance   | -20.8          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.358         |
|    n_updates            | 660            |
|    policy_gradient_loss | 0.128          |
|    reward               | -0.00014974909 |
|    std                  | 1.39           |
|    value_loss           | 6.06e-05       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1436, ResetDay: 3116,Episode: 83
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 68             |
|    time_elapsed         | 1538           |
|    total_timesteps      | 139264         |
| train/                  |                |
|    approx_kl            | 32.62972       |
|    clip_fraction        | 0.713          |
|    clip_range           | 0.2            |
|    entropy_loss         | -48.9          |
|    explained_variance   | -13.3          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.327         |
|    n_updates            | 670            |
|    policy_gradient_loss | 0.177          |
|    reward               | -5.6266786e-06 |
|    std                  | 1.39           |
|    value_loss           | 2.65e-05       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2162, ResetDay: 3842,Episode: 84
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 694, ResetDay: 2374,Episode: 85
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 69            |
|    time_elapsed         | 1561          |
|    total_timesteps      | 141312        |
| train/                  |               |
|    approx_kl            | 48.171707     |
|    clip_fraction        | 0.709         |
|    clip_range           | 0.2           |
|    entropy_loss         | -49           |
|    explained_variance   | -7.05         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.407        |
|    n_updates            | 680           |
|    policy_gradient_loss | 0.144         |
|    reward               | 0.00016710644 |
|    std                  | 1.39          |
|    value_loss           | 1.08e-05      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2374, episode: 85
begin_total_asset: 200.00
end_total_asset: 201.59
total_reward: 1.59
total_cost: 2.40
total_trades: 47016
Sharpe: 0.187
=================================
Reseting Environment StartDay: 1570, ResetDay: 3250,Episode: 86
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 70             |
|    time_elapsed         | 1583           |
|    total_timesteps      | 143360         |
| train/                  |                |
|    approx_kl            | 108.17159      |
|    clip_fraction        | 0.721          |
|    clip_range           | 0.2            |
|    entropy_loss         | -49.1          |
|    explained_variance   | -2.32          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.305         |
|    n_updates            | 690            |
|    policy_gradient_loss | 0.159          |
|    reward               | -0.00022721749 |
|    std                  | 1.4            |
|    value_loss           | 7.46e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1589, ResetDay: 3269,Episode: 87
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 71            |
|    time_elapsed         | 1606          |
|    total_timesteps      | 145408        |
| train/                  |               |
|    approx_kl            | 33.049828     |
|    clip_fraction        | 0.737         |
|    clip_range           | 0.2           |
|    entropy_loss         | -49.2         |
|    explained_variance   | -13.8         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.392        |
|    n_updates            | 700           |
|    policy_gradient_loss | 0.215         |
|    reward               | 7.1949007e-06 |
|    std                  | 1.4           |
|    value_loss           | 2.04e-05      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1590, ResetDay: 3270,Episode: 88
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 72             |
|    time_elapsed         | 1629           |
|    total_timesteps      | 147456         |
| train/                  |                |
|    approx_kl            | 62.355106      |
|    clip_fraction        | 0.695          |
|    clip_range           | 0.2            |
|    entropy_loss         | -49.3          |
|    explained_variance   | -9.39          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.4           |
|    n_updates            | 710            |
|    policy_gradient_loss | 0.142          |
|    reward               | -0.00027825317 |
|    std                  | 1.41           |
|    value_loss           | 7.31e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1135, ResetDay: 2815,Episode: 89
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 73             |
|    time_elapsed         | 1651           |
|    total_timesteps      | 149504         |
| train/                  |                |
|    approx_kl            | 87.94653       |
|    clip_fraction        | 0.721          |
|    clip_range           | 0.2            |
|    entropy_loss         | -49.4          |
|    explained_variance   | -8.14          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.336         |
|    n_updates            | 720            |
|    policy_gradient_loss | 0.157          |
|    reward               | -0.00019127654 |
|    std                  | 1.42           |
|    value_loss           | 5.7e-06        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2051, ResetDay: 3731,Episode: 90
Environment reached Terminal state as number of trading days reached limit!!
day: 3731, episode: 90
begin_total_asset: 200.00
end_total_asset: 362.04
total_reward: 162.04
total_cost: 1.98
total_trades: 47036
Sharpe: 0.661
=================================
Reseting Environment StartDay: 818, ResetDay: 2498,Episode: 91
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 74             |
|    time_elapsed         | 1674           |
|    total_timesteps      | 151552         |
| train/                  |                |
|    approx_kl            | 95.83161       |
|    clip_fraction        | 0.695          |
|    clip_range           | 0.2            |
|    entropy_loss         | -49.5          |
|    explained_variance   | -7.15          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.279         |
|    n_updates            | 730            |
|    policy_gradient_loss | 0.142          |
|    reward               | -4.7348785e-05 |
|    std                  | 1.43           |
|    value_loss           | 8.49e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1564, ResetDay: 3244,Episode: 92
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 75            |
|    time_elapsed         | 1696          |
|    total_timesteps      | 153600        |
| train/                  |               |
|    approx_kl            | 76.93748      |
|    clip_fraction        | 0.701         |
|    clip_range           | 0.2           |
|    entropy_loss         | -49.7         |
|    explained_variance   | -8.79         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.203        |
|    n_updates            | 740           |
|    policy_gradient_loss | 0.148         |
|    reward               | 4.0192223e-05 |
|    std                  | 1.44          |
|    value_loss           | 1.63e-05      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1839, ResetDay: 3519,Episode: 93
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 76             |
|    time_elapsed         | 1719           |
|    total_timesteps      | 155648         |
| train/                  |                |
|    approx_kl            | 29.800335      |
|    clip_fraction        | 0.719          |
|    clip_range           | 0.2            |
|    entropy_loss         | -49.9          |
|    explained_variance   | -9.41          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.353         |
|    n_updates            | 750            |
|    policy_gradient_loss | 0.136          |
|    reward               | -3.4338762e-05 |
|    std                  | 1.44           |
|    value_loss           | 1.53e-05       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 589, ResetDay: 2269,Episode: 94
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 77            |
|    time_elapsed         | 1742          |
|    total_timesteps      | 157696        |
| train/                  |               |
|    approx_kl            | 69.56094      |
|    clip_fraction        | 0.742         |
|    clip_range           | 0.2           |
|    entropy_loss         | -50           |
|    explained_variance   | -5.49         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.183        |
|    n_updates            | 760           |
|    policy_gradient_loss | 0.177         |
|    reward               | 0.00026147804 |
|    std                  | 1.45          |
|    value_loss           | 4.74e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2237, ResetDay: 3917,Episode: 95
Environment reached Terminal state as number of trading days reached limit!!
day: 3917, episode: 95
begin_total_asset: 200.00
end_total_asset: 279.78
total_reward: 79.78
total_cost: 1.90
total_trades: 47039
Sharpe: 0.361
=================================
Reseting Environment StartDay: 442, ResetDay: 2122,Episode: 96
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 78            |
|    time_elapsed         | 1764          |
|    total_timesteps      | 159744        |
| train/                  |               |
|    approx_kl            | 100.95355     |
|    clip_fraction        | 0.724         |
|    clip_range           | 0.2           |
|    entropy_loss         | -50.1         |
|    explained_variance   | -13.6         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.37         |
|    n_updates            | 770           |
|    policy_gradient_loss | 0.127         |
|    reward               | 8.1246304e-05 |
|    std                  | 1.45          |
|    value_loss           | 3.2e-05       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 776, ResetDay: 2456,Episode: 97
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 79            |
|    time_elapsed         | 1788          |
|    total_timesteps      | 161792        |
| train/                  |               |
|    approx_kl            | 50.216476     |
|    clip_fraction        | 0.747         |
|    clip_range           | 0.2           |
|    entropy_loss         | -50.2         |
|    explained_variance   | -5.46         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.193        |
|    n_updates            | 780           |
|    policy_gradient_loss | 0.159         |
|    reward               | 5.1488685e-05 |
|    std                  | 1.46          |
|    value_loss           | 4.59e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1407, ResetDay: 3087,Episode: 98
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 80            |
|    time_elapsed         | 1810          |
|    total_timesteps      | 163840        |
| train/                  |               |
|    approx_kl            | 35.561882     |
|    clip_fraction        | 0.834         |
|    clip_range           | 0.2           |
|    entropy_loss         | -50.4         |
|    explained_variance   | -23           |
|    learning_rate        | 0.00025       |
|    loss                 | -0.351        |
|    n_updates            | 790           |
|    policy_gradient_loss | 0.207         |
|    reward               | -0.0001455967 |
|    std                  | 1.47          |
|    value_loss           | 3.34e-05      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2210, ResetDay: 3890,Episode: 99
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 81           |
|    time_elapsed         | 1833         |
|    total_timesteps      | 165888       |
| train/                  |              |
|    approx_kl            | 72.724655    |
|    clip_fraction        | 0.708        |
|    clip_range           | 0.2          |
|    entropy_loss         | -50.6        |
|    explained_variance   | -9.47        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.401       |
|    n_updates            | 800          |
|    policy_gradient_loss | 0.154        |
|    reward               | 6.152954e-05 |
|    std                  | 1.48         |
|    value_loss           | 1.23e-05     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2583, ResetDay: 4263,Episode: 100
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 82            |
|    time_elapsed         | 1855          |
|    total_timesteps      | 167936        |
| train/                  |               |
|    approx_kl            | 66.66263      |
|    clip_fraction        | 0.706         |
|    clip_range           | 0.2           |
|    entropy_loss         | -50.7         |
|    explained_variance   | -7.65         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.33         |
|    n_updates            | 810           |
|    policy_gradient_loss | 0.154         |
|    reward               | -8.957558e-05 |
|    std                  | 1.48          |
|    value_loss           | 3.1e-06       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4263, episode: 100
begin_total_asset: 200.00
end_total_asset: 247.18
total_reward: 47.18
total_cost: 1.85
total_trades: 47030
Sharpe: 0.263
=================================
Reseting Environment StartDay: 2268, ResetDay: 3948,Episode: 101
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2465, ResetDay: 4145,Episode: 102
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 83             |
|    time_elapsed         | 1878           |
|    total_timesteps      | 169984         |
| train/                  |                |
|    approx_kl            | 206.75262      |
|    clip_fraction        | 0.704          |
|    clip_range           | 0.2            |
|    entropy_loss         | -50.8          |
|    explained_variance   | -1.52          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.233         |
|    n_updates            | 820            |
|    policy_gradient_loss | 0.168          |
|    reward               | -3.6924743e-05 |
|    std                  | 1.49           |
|    value_loss           | 1.85e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 484, ResetDay: 2164,Episode: 103
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 84             |
|    time_elapsed         | 1900           |
|    total_timesteps      | 172032         |
| train/                  |                |
|    approx_kl            | 423.1933       |
|    clip_fraction        | 0.713          |
|    clip_range           | 0.2            |
|    entropy_loss         | -50.9          |
|    explained_variance   | -2.93          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.363         |
|    n_updates            | 830            |
|    policy_gradient_loss | 0.153          |
|    reward               | -3.8152695e-05 |
|    std                  | 1.5            |
|    value_loss           | 2.03e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2053, ResetDay: 3733,Episode: 104
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 85           |
|    time_elapsed         | 1923         |
|    total_timesteps      | 174080       |
| train/                  |              |
|    approx_kl            | 83.890434    |
|    clip_fraction        | 0.764        |
|    clip_range           | 0.2          |
|    entropy_loss         | -51.1        |
|    explained_variance   | -9.2         |
|    learning_rate        | 0.00025      |
|    loss                 | -0.436       |
|    n_updates            | 840          |
|    policy_gradient_loss | 0.18         |
|    reward               | 9.976807e-05 |
|    std                  | 1.51         |
|    value_loss           | 1.22e-05     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 852, ResetDay: 2532,Episode: 105
---------------------------------------------
| time/                   |                 |
|    fps                  | 90              |
|    iterations           | 86              |
|    time_elapsed         | 1946            |
|    total_timesteps      | 176128          |
| train/                  |                 |
|    approx_kl            | 26.07463        |
|    clip_fraction        | 0.736           |
|    clip_range           | 0.2             |
|    entropy_loss         | -51.3           |
|    explained_variance   | -8.56           |
|    learning_rate        | 0.00025         |
|    loss                 | -0.359          |
|    n_updates            | 850             |
|    policy_gradient_loss | 0.384           |
|    reward               | -0.000113045884 |
|    std                  | 1.52            |
|    value_loss           | 8.84e-06        |
---------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2532, episode: 105
begin_total_asset: 200.00
end_total_asset: 272.23
total_reward: 72.23
total_cost: 1.97
total_trades: 47030
Sharpe: 0.331
=================================
Reseting Environment StartDay: 1029, ResetDay: 2709,Episode: 106
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 87            |
|    time_elapsed         | 1968          |
|    total_timesteps      | 178176        |
| train/                  |               |
|    approx_kl            | 120.84194     |
|    clip_fraction        | 0.777         |
|    clip_range           | 0.2           |
|    entropy_loss         | -51.4         |
|    explained_variance   | -6.98         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.434        |
|    n_updates            | 860           |
|    policy_gradient_loss | 0.32          |
|    reward               | 0.00036436273 |
|    std                  | 1.53          |
|    value_loss           | 1.18e-05      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 63, ResetDay: 1743,Episode: 107
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 979, ResetDay: 2659,Episode: 108
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 88            |
|    time_elapsed         | 1990          |
|    total_timesteps      | 180224        |
| train/                  |               |
|    approx_kl            | 60.543285     |
|    clip_fraction        | 0.703         |
|    clip_range           | 0.2           |
|    entropy_loss         | -51.6         |
|    explained_variance   | -9.65         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.371        |
|    n_updates            | 870           |
|    policy_gradient_loss | 0.138         |
|    reward               | 0.00039041167 |
|    std                  | 1.54          |
|    value_loss           | 6.86e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 165, ResetDay: 1845,Episode: 109
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 89             |
|    time_elapsed         | 2013           |
|    total_timesteps      | 182272         |
| train/                  |                |
|    approx_kl            | 63.899647      |
|    clip_fraction        | 0.718          |
|    clip_range           | 0.2            |
|    entropy_loss         | -51.8          |
|    explained_variance   | -16.7          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.395         |
|    n_updates            | 880            |
|    policy_gradient_loss | 0.149          |
|    reward               | -0.00022624269 |
|    std                  | 1.54           |
|    value_loss           | 3.28e-05       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 928, ResetDay: 2608,Episode: 110
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 90            |
|    time_elapsed         | 2036          |
|    total_timesteps      | 184320        |
| train/                  |               |
|    approx_kl            | 30.970314     |
|    clip_fraction        | 0.727         |
|    clip_range           | 0.2           |
|    entropy_loss         | -51.9         |
|    explained_variance   | -9.97         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.377        |
|    n_updates            | 890           |
|    policy_gradient_loss | 0.169         |
|    reward               | 0.00037841577 |
|    std                  | 1.56          |
|    value_loss           | 1.3e-05       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2608, episode: 110
begin_total_asset: 200.00
end_total_asset: 389.84
total_reward: 189.84
total_cost: 3.56
total_trades: 47036
Sharpe: 0.579
=================================
Reseting Environment StartDay: 1582, ResetDay: 3262,Episode: 111
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 91            |
|    time_elapsed         | 2058          |
|    total_timesteps      | 186368        |
| train/                  |               |
|    approx_kl            | 20.454617     |
|    clip_fraction        | 0.771         |
|    clip_range           | 0.2           |
|    entropy_loss         | -52.1         |
|    explained_variance   | -9.36         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.36         |
|    n_updates            | 900           |
|    policy_gradient_loss | 0.168         |
|    reward               | -2.478199e-05 |
|    std                  | 1.56          |
|    value_loss           | 9.38e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 71, ResetDay: 1751,Episode: 112
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2268, ResetDay: 3948,Episode: 113
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 92            |
|    time_elapsed         | 2081          |
|    total_timesteps      | 188416        |
| train/                  |               |
|    approx_kl            | 51.08304      |
|    clip_fraction        | 0.807         |
|    clip_range           | 0.2           |
|    entropy_loss         | -52.3         |
|    explained_variance   | -5.87         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.307        |
|    n_updates            | 910           |
|    policy_gradient_loss | 0.222         |
|    reward               | 0.00010105896 |
|    std                  | 1.57          |
|    value_loss           | 3.34e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1555, ResetDay: 3235,Episode: 114
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 93           |
|    time_elapsed         | 2104         |
|    total_timesteps      | 190464       |
| train/                  |              |
|    approx_kl            | 116.76409    |
|    clip_fraction        | 0.736        |
|    clip_range           | 0.2          |
|    entropy_loss         | -52.4        |
|    explained_variance   | -11.2        |
|    learning_rate        | 0.00025      |
|    loss                 | 0.123        |
|    n_updates            | 920          |
|    policy_gradient_loss | 0.195        |
|    reward               | 6.659317e-05 |
|    std                  | 1.58         |
|    value_loss           | 1.25e-05     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1175, ResetDay: 2855,Episode: 115
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 94             |
|    time_elapsed         | 2126           |
|    total_timesteps      | 192512         |
| train/                  |                |
|    approx_kl            | 73.78508       |
|    clip_fraction        | 0.748          |
|    clip_range           | 0.2            |
|    entropy_loss         | -52.5          |
|    explained_variance   | -1.13          |
|    learning_rate        | 0.00025        |
|    loss                 | 0.174          |
|    n_updates            | 930            |
|    policy_gradient_loss | 0.23           |
|    reward               | -0.00010178108 |
|    std                  | 1.59           |
|    value_loss           | 3.32e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2855, episode: 115
begin_total_asset: 200.00
end_total_asset: 187.08
total_reward: -12.92
total_cost: 2.43
total_trades: 47032
Sharpe: 0.131
=================================
Reseting Environment StartDay: 812, ResetDay: 2492,Episode: 116
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 95             |
|    time_elapsed         | 2149           |
|    total_timesteps      | 194560         |
| train/                  |                |
|    approx_kl            | 52.717686      |
|    clip_fraction        | 0.732          |
|    clip_range           | 0.2            |
|    entropy_loss         | -52.7          |
|    explained_variance   | -5.15          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.399         |
|    n_updates            | 940            |
|    policy_gradient_loss | 0.172          |
|    reward               | -5.9631348e-05 |
|    std                  | 1.6            |
|    value_loss           | 3.17e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2749, ResetDay: 4429,Episode: 117
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 96           |
|    time_elapsed         | 2171         |
|    total_timesteps      | 196608       |
| train/                  |              |
|    approx_kl            | 51.8484      |
|    clip_fraction        | 0.752        |
|    clip_range           | 0.2          |
|    entropy_loss         | -52.9        |
|    explained_variance   | -7.58        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.185       |
|    n_updates            | 950          |
|    policy_gradient_loss | 0.189        |
|    reward               | 0.0004336563 |
|    std                  | 1.61         |
|    value_loss           | 5.56e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1977, ResetDay: 3657,Episode: 118
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 569, ResetDay: 2249,Episode: 119
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 97           |
|    time_elapsed         | 2194         |
|    total_timesteps      | 198656       |
| train/                  |              |
|    approx_kl            | 51.462315    |
|    clip_fraction        | 0.721        |
|    clip_range           | 0.2          |
|    entropy_loss         | -53          |
|    explained_variance   | -0.346       |
|    learning_rate        | 0.00025      |
|    loss                 | -0.361       |
|    n_updates            | 960          |
|    policy_gradient_loss | 0.251        |
|    reward               | 0.0001642633 |
|    std                  | 1.61         |
|    value_loss           | 2.63e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1258, ResetDay: 2938,Episode: 120
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 98            |
|    time_elapsed         | 2217          |
|    total_timesteps      | 200704        |
| train/                  |               |
|    approx_kl            | 364.70377     |
|    clip_fraction        | 0.747         |
|    clip_range           | 0.2           |
|    entropy_loss         | -53.1         |
|    explained_variance   | -4.99         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.395        |
|    n_updates            | 970           |
|    policy_gradient_loss | 0.166         |
|    reward               | 0.00019572639 |
|    std                  | 1.62          |
|    value_loss           | 1.47e-05      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2938, episode: 120
begin_total_asset: 200.00
end_total_asset: 199.60
total_reward: -0.40
total_cost: 1.95
total_trades: 47030
Sharpe: 0.154
=================================
Reseting Environment StartDay: 1758, ResetDay: 3438,Episode: 121
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 99            |
|    time_elapsed         | 2239          |
|    total_timesteps      | 202752        |
| train/                  |               |
|    approx_kl            | 23.77746      |
|    clip_fraction        | 0.736         |
|    clip_range           | 0.2           |
|    entropy_loss         | -53.3         |
|    explained_variance   | -6.44         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.382        |
|    n_updates            | 980           |
|    policy_gradient_loss | 0.158         |
|    reward               | 0.00018729591 |
|    std                  | 1.63          |
|    value_loss           | 5.36e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1059, ResetDay: 2739,Episode: 122
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 100           |
|    time_elapsed         | 2262          |
|    total_timesteps      | 204800        |
| train/                  |               |
|    approx_kl            | 40.178368     |
|    clip_fraction        | 0.711         |
|    clip_range           | 0.2           |
|    entropy_loss         | -53.4         |
|    explained_variance   | -6.07         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.42         |
|    n_updates            | 990           |
|    policy_gradient_loss | 0.285         |
|    reward               | 6.9561385e-05 |
|    std                  | 1.64          |
|    value_loss           | 1.66e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1106, ResetDay: 2786,Episode: 123
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 606, ResetDay: 2286,Episode: 124
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 101           |
|    time_elapsed         | 2284          |
|    total_timesteps      | 206848        |
| train/                  |               |
|    approx_kl            | 77.94083      |
|    clip_fraction        | 0.73          |
|    clip_range           | 0.2           |
|    entropy_loss         | -53.6         |
|    explained_variance   | -4.6          |
|    learning_rate        | 0.00025       |
|    loss                 | -0.479        |
|    n_updates            | 1000          |
|    policy_gradient_loss | 0.158         |
|    reward               | 2.7092552e-05 |
|    std                  | 1.65          |
|    value_loss           | 2.39e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2371, ResetDay: 4051,Episode: 125
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 102            |
|    time_elapsed         | 2307           |
|    total_timesteps      | 208896         |
| train/                  |                |
|    approx_kl            | 69.33756       |
|    clip_fraction        | 0.707          |
|    clip_range           | 0.2            |
|    entropy_loss         | -53.8          |
|    explained_variance   | -4.42          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.428         |
|    n_updates            | 1010           |
|    policy_gradient_loss | 0.741          |
|    reward               | -7.7058794e-05 |
|    std                  | 1.66           |
|    value_loss           | 2.82e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4051, episode: 125
begin_total_asset: 200.00
end_total_asset: 342.46
total_reward: 142.46
total_cost: 1.95
total_trades: 47030
Sharpe: 0.506
=================================
Reseting Environment StartDay: 1836, ResetDay: 3516,Episode: 126
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 103          |
|    time_elapsed         | 2330         |
|    total_timesteps      | 210944       |
| train/                  |              |
|    approx_kl            | 30.940084    |
|    clip_fraction        | 0.721        |
|    clip_range           | 0.2          |
|    entropy_loss         | -53.9        |
|    explained_variance   | -7.12        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.329       |
|    n_updates            | 1020         |
|    policy_gradient_loss | 0.158        |
|    reward               | 3.971081e-05 |
|    std                  | 1.67         |
|    value_loss           | 4.35e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 989, ResetDay: 2669,Episode: 127
---------------------------------------------
| time/                   |                 |
|    fps                  | 90              |
|    iterations           | 104             |
|    time_elapsed         | 2353            |
|    total_timesteps      | 212992          |
| train/                  |                 |
|    approx_kl            | 77.43437        |
|    clip_fraction        | 0.765           |
|    clip_range           | 0.2             |
|    entropy_loss         | -54.1           |
|    explained_variance   | -0.931          |
|    learning_rate        | 0.00025         |
|    loss                 | -0.398          |
|    n_updates            | 1030            |
|    policy_gradient_loss | 0.221           |
|    reward               | -0.000101929094 |
|    std                  | 1.67            |
|    value_loss           | 1.27e-06        |
---------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2178, ResetDay: 3858,Episode: 128
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 105           |
|    time_elapsed         | 2375          |
|    total_timesteps      | 215040        |
| train/                  |               |
|    approx_kl            | 74.759705     |
|    clip_fraction        | 0.761         |
|    clip_range           | 0.2           |
|    entropy_loss         | -54.1         |
|    explained_variance   | -4.55         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.377        |
|    n_updates            | 1040          |
|    policy_gradient_loss | 0.165         |
|    reward               | 0.00029191934 |
|    std                  | 1.68          |
|    value_loss           | 2.43e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2087, ResetDay: 3767,Episode: 129
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2596, ResetDay: 4276,Episode: 130
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 106           |
|    time_elapsed         | 2398          |
|    total_timesteps      | 217088        |
| train/                  |               |
|    approx_kl            | 56.52304      |
|    clip_fraction        | 0.707         |
|    clip_range           | 0.2           |
|    entropy_loss         | -54.3         |
|    explained_variance   | -2.76         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.359        |
|    n_updates            | 1050          |
|    policy_gradient_loss | 0.168         |
|    reward               | -6.618252e-05 |
|    std                  | 1.69          |
|    value_loss           | 3.39e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4276, episode: 130
begin_total_asset: 200.00
end_total_asset: 246.65
total_reward: 46.65
total_cost: 1.91
total_trades: 47030
Sharpe: 0.259
=================================
Reseting Environment StartDay: 69, ResetDay: 1749,Episode: 131
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 107           |
|    time_elapsed         | 2421          |
|    total_timesteps      | 219136        |
| train/                  |               |
|    approx_kl            | 205.31815     |
|    clip_fraction        | 0.706         |
|    clip_range           | 0.2           |
|    entropy_loss         | -54.4         |
|    explained_variance   | -1.27         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.362        |
|    n_updates            | 1060          |
|    policy_gradient_loss | 0.204         |
|    reward               | 0.00014833646 |
|    std                  | 1.7           |
|    value_loss           | 1.22e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2553, ResetDay: 4233,Episode: 132
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 108            |
|    time_elapsed         | 2443           |
|    total_timesteps      | 221184         |
| train/                  |                |
|    approx_kl            | 81.372925      |
|    clip_fraction        | 0.724          |
|    clip_range           | 0.2            |
|    entropy_loss         | -54.5          |
|    explained_variance   | -5.83          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.457         |
|    n_updates            | 1070           |
|    policy_gradient_loss | 0.112          |
|    reward               | -4.1697695e-05 |
|    std                  | 1.7            |
|    value_loss           | 6.11e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1662, ResetDay: 3342,Episode: 133
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 109            |
|    time_elapsed         | 2466           |
|    total_timesteps      | 223232         |
| train/                  |                |
|    approx_kl            | 32.561867      |
|    clip_fraction        | 0.778          |
|    clip_range           | 0.2            |
|    entropy_loss         | -54.6          |
|    explained_variance   | -3.41          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.397         |
|    n_updates            | 1080           |
|    policy_gradient_loss | 0.348          |
|    reward               | -1.4156341e-05 |
|    std                  | 1.71           |
|    value_loss           | 4.79e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 463, ResetDay: 2143,Episode: 134
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1254, ResetDay: 2934,Episode: 135
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 110          |
|    time_elapsed         | 2489         |
|    total_timesteps      | 225280       |
| train/                  |              |
|    approx_kl            | 178.47968    |
|    clip_fraction        | 0.701        |
|    clip_range           | 0.2          |
|    entropy_loss         | -54.7        |
|    explained_variance   | -0.697       |
|    learning_rate        | 0.00025      |
|    loss                 | -0.123       |
|    n_updates            | 1090         |
|    policy_gradient_loss | 0.183        |
|    reward               | 7.714691e-05 |
|    std                  | 1.72         |
|    value_loss           | 1.89e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2934, episode: 135
begin_total_asset: 200.00
end_total_asset: 277.51
total_reward: 77.51
total_cost: 2.89
total_trades: 47036
Sharpe: 0.351
=================================
Reseting Environment StartDay: 1446, ResetDay: 3126,Episode: 136
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 111            |
|    time_elapsed         | 2511           |
|    total_timesteps      | 227328         |
| train/                  |                |
|    approx_kl            | 103.332726     |
|    clip_fraction        | 0.74           |
|    clip_range           | 0.2            |
|    entropy_loss         | -54.9          |
|    explained_variance   | -8.8           |
|    learning_rate        | 0.00025        |
|    loss                 | -0.439         |
|    n_updates            | 1100           |
|    policy_gradient_loss | 0.174          |
|    reward               | -1.3545036e-05 |
|    std                  | 1.73           |
|    value_loss           | 4.25e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 119, ResetDay: 1799,Episode: 137
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 112           |
|    time_elapsed         | 2534          |
|    total_timesteps      | 229376        |
| train/                  |               |
|    approx_kl            | 28.567541     |
|    clip_fraction        | 0.727         |
|    clip_range           | 0.2           |
|    entropy_loss         | -55.1         |
|    explained_variance   | -2.82         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.451        |
|    n_updates            | 1110          |
|    policy_gradient_loss | 0.172         |
|    reward               | 0.00013649646 |
|    std                  | 1.74          |
|    value_loss           | 4.75e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1049, ResetDay: 2729,Episode: 138
-----------------------------------------
| time/                   |             |
|    fps                  | 90          |
|    iterations           | 113         |
|    time_elapsed         | 2557        |
|    total_timesteps      | 231424      |
| train/                  |             |
|    approx_kl            | 36.112022   |
|    clip_fraction        | 0.764       |
|    clip_range           | 0.2         |
|    entropy_loss         | -55.2       |
|    explained_variance   | -5.82       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.429      |
|    n_updates            | 1120        |
|    policy_gradient_loss | 0.171       |
|    reward               | 9.56069e-05 |
|    std                  | 1.75        |
|    value_loss           | 7.65e-06    |
-----------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1600, ResetDay: 3280,Episode: 139
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 114           |
|    time_elapsed         | 2580          |
|    total_timesteps      | 233472        |
| train/                  |               |
|    approx_kl            | 21.769514     |
|    clip_fraction        | 0.777         |
|    clip_range           | 0.2           |
|    entropy_loss         | -55.3         |
|    explained_variance   | -5.72         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.225        |
|    n_updates            | 1130          |
|    policy_gradient_loss | 0.33          |
|    reward               | 3.2691194e-05 |
|    std                  | 1.75          |
|    value_loss           | 9.79e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2573, ResetDay: 4253,Episode: 140
Environment reached Terminal state as number of trading days reached limit!!
day: 4253, episode: 140
begin_total_asset: 200.00
end_total_asset: 293.42
total_reward: 93.42
total_cost: 1.92
total_trades: 47040
Sharpe: 0.397
=================================
Reseting Environment StartDay: 2037, ResetDay: 3717,Episode: 141
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 115            |
|    time_elapsed         | 2602           |
|    total_timesteps      | 235520         |
| train/                  |                |
|    approx_kl            | 53.54696       |
|    clip_fraction        | 0.722          |
|    clip_range           | 0.2            |
|    entropy_loss         | -55.5          |
|    explained_variance   | -2.13          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.127         |
|    n_updates            | 1140           |
|    policy_gradient_loss | 0.232          |
|    reward               | -2.5691605e-05 |
|    std                  | 1.77           |
|    value_loss           | 1.3e-06        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 131, ResetDay: 1811,Episode: 142
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 116          |
|    time_elapsed         | 2625         |
|    total_timesteps      | 237568       |
| train/                  |              |
|    approx_kl            | 110.023796   |
|    clip_fraction        | 0.681        |
|    clip_range           | 0.2          |
|    entropy_loss         | -55.7        |
|    explained_variance   | -0.534       |
|    learning_rate        | 0.00025      |
|    loss                 | -0.433       |
|    n_updates            | 1150         |
|    policy_gradient_loss | 0.196        |
|    reward               | 6.637478e-05 |
|    std                  | 1.77         |
|    value_loss           | 8.84e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 857, ResetDay: 2537,Episode: 143
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 117           |
|    time_elapsed         | 2648          |
|    total_timesteps      | 239616        |
| train/                  |               |
|    approx_kl            | 52.286167     |
|    clip_fraction        | 0.785         |
|    clip_range           | 0.2           |
|    entropy_loss         | -55.8         |
|    explained_variance   | -6.18         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.497        |
|    n_updates            | 1160          |
|    policy_gradient_loss | 0.17          |
|    reward               | 0.00013189325 |
|    std                  | 1.78          |
|    value_loss           | 8.81e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 824, ResetDay: 2504,Episode: 144
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 118          |
|    time_elapsed         | 2670         |
|    total_timesteps      | 241664       |
| train/                  |              |
|    approx_kl            | 31.298458    |
|    clip_fraction        | 0.741        |
|    clip_range           | 0.2          |
|    entropy_loss         | -55.9        |
|    explained_variance   | -8.86        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.467       |
|    n_updates            | 1170         |
|    policy_gradient_loss | 0.251        |
|    reward               | 0.0001482255 |
|    std                  | 1.79         |
|    value_loss           | 4.58e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 389, ResetDay: 2069,Episode: 145
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 119            |
|    time_elapsed         | 2693           |
|    total_timesteps      | 243712         |
| train/                  |                |
|    approx_kl            | 36.224854      |
|    clip_fraction        | 0.725          |
|    clip_range           | 0.2            |
|    entropy_loss         | -56            |
|    explained_variance   | -4.96          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.465         |
|    n_updates            | 1180           |
|    policy_gradient_loss | 0.171          |
|    reward               | -1.0707855e-06 |
|    std                  | 1.8            |
|    value_loss           | 2.51e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2069, episode: 145
begin_total_asset: 200.00
end_total_asset: 158.92
total_reward: -41.08
total_cost: 1.98
total_trades: 47031
Sharpe: 0.053
=================================
Reseting Environment StartDay: 220, ResetDay: 1900,Episode: 146
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2617, ResetDay: 4297,Episode: 147
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 120            |
|    time_elapsed         | 2715           |
|    total_timesteps      | 245760         |
| train/                  |                |
|    approx_kl            | 47.725403      |
|    clip_fraction        | 0.753          |
|    clip_range           | 0.2            |
|    entropy_loss         | -56.2          |
|    explained_variance   | -5.48          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.444         |
|    n_updates            | 1190           |
|    policy_gradient_loss | 0.173          |
|    reward               | -0.00011882362 |
|    std                  | 1.81           |
|    value_loss           | 3.19e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 569, ResetDay: 2249,Episode: 148
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 121          |
|    time_elapsed         | 2738         |
|    total_timesteps      | 247808       |
| train/                  |              |
|    approx_kl            | 47.172386    |
|    clip_fraction        | 0.727        |
|    clip_range           | 0.2          |
|    entropy_loss         | -56.3        |
|    explained_variance   | -6.34        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.431       |
|    n_updates            | 1200         |
|    policy_gradient_loss | 0.134        |
|    reward               | 3.982525e-05 |
|    std                  | 1.82         |
|    value_loss           | 4.7e-06      |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1103, ResetDay: 2783,Episode: 149
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 122           |
|    time_elapsed         | 2761          |
|    total_timesteps      | 249856        |
| train/                  |               |
|    approx_kl            | 85.464516     |
|    clip_fraction        | 0.718         |
|    clip_range           | 0.2           |
|    entropy_loss         | -56.4         |
|    explained_variance   | -0.65         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.417        |
|    n_updates            | 1210          |
|    policy_gradient_loss | 0.19          |
|    reward               | 0.00013578415 |
|    std                  | 1.82          |
|    value_loss           | 3.21e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 198, ResetDay: 1878,Episode: 150
-----------------------------------------
| time/                   |             |
|    fps                  | 90          |
|    iterations           | 123         |
|    time_elapsed         | 2783        |
|    total_timesteps      | 251904      |
| train/                  |             |
|    approx_kl            | 30.474804   |
|    clip_fraction        | 0.706       |
|    clip_range           | 0.2         |
|    entropy_loss         | -56.5       |
|    explained_variance   | -5.26       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.435      |
|    n_updates            | 1220        |
|    policy_gradient_loss | 0.14        |
|    reward               | 8.97234e-05 |
|    std                  | 1.83        |
|    value_loss           | 2.13e-06    |
-----------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 1878, episode: 150
begin_total_asset: 200.00
end_total_asset: 205.40
total_reward: 5.40
total_cost: 2.43
total_trades: 47033
Sharpe: 0.179
=================================
Reseting Environment StartDay: 1142, ResetDay: 2822,Episode: 151
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2670, ResetDay: 4350,Episode: 152
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 124           |
|    time_elapsed         | 2806          |
|    total_timesteps      | 253952        |
| train/                  |               |
|    approx_kl            | 51.20058      |
|    clip_fraction        | 0.782         |
|    clip_range           | 0.2           |
|    entropy_loss         | -56.7         |
|    explained_variance   | -7.38         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.42         |
|    n_updates            | 1230          |
|    policy_gradient_loss | 0.132         |
|    reward               | -5.472908e-05 |
|    std                  | 1.84          |
|    value_loss           | 4.18e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 673, ResetDay: 2353,Episode: 153
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 125           |
|    time_elapsed         | 2829          |
|    total_timesteps      | 256000        |
| train/                  |               |
|    approx_kl            | 30.01335      |
|    clip_fraction        | 0.726         |
|    clip_range           | 0.2           |
|    entropy_loss         | -56.8         |
|    explained_variance   | -1.86         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.26         |
|    n_updates            | 1240          |
|    policy_gradient_loss | 0.169         |
|    reward               | 0.00012328004 |
|    std                  | 1.85          |
|    value_loss           | 1.98e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1099, ResetDay: 2779,Episode: 154
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 126          |
|    time_elapsed         | 2851         |
|    total_timesteps      | 258048       |
| train/                  |              |
|    approx_kl            | 67.10484     |
|    clip_fraction        | 0.74         |
|    clip_range           | 0.2          |
|    entropy_loss         | -56.9        |
|    explained_variance   | -1.4         |
|    learning_rate        | 0.00025      |
|    loss                 | -0.457       |
|    n_updates            | 1250         |
|    policy_gradient_loss | 0.185        |
|    reward               | 5.061989e-05 |
|    std                  | 1.86         |
|    value_loss           | 1.94e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 548, ResetDay: 2228,Episode: 155
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 127           |
|    time_elapsed         | 2874          |
|    total_timesteps      | 260096        |
| train/                  |               |
|    approx_kl            | 28.503563     |
|    clip_fraction        | 0.721         |
|    clip_range           | 0.2           |
|    entropy_loss         | -57.1         |
|    explained_variance   | -4.45         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.48         |
|    n_updates            | 1260          |
|    policy_gradient_loss | 0.233         |
|    reward               | 0.00022122555 |
|    std                  | 1.87          |
|    value_loss           | 1.89e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2228, episode: 155
begin_total_asset: 200.00
end_total_asset: 264.35
total_reward: 64.35
total_cost: 2.29
total_trades: 47032
Sharpe: 0.300
=================================
Reseting Environment StartDay: 848, ResetDay: 2528,Episode: 156
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 128            |
|    time_elapsed         | 2896           |
|    total_timesteps      | 262144         |
| train/                  |                |
|    approx_kl            | 39.175507      |
|    clip_fraction        | 0.751          |
|    clip_range           | 0.2            |
|    entropy_loss         | -57.2          |
|    explained_variance   | -3.95          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.439         |
|    n_updates            | 1270           |
|    policy_gradient_loss | 0.173          |
|    reward               | -0.00010522175 |
|    std                  | 1.88           |
|    value_loss           | 2.29e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1145, ResetDay: 2825,Episode: 157
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 596, ResetDay: 2276,Episode: 158
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 129           |
|    time_elapsed         | 2919          |
|    total_timesteps      | 264192        |
| train/                  |               |
|    approx_kl            | 34.90444      |
|    clip_fraction        | 0.764         |
|    clip_range           | 0.2           |
|    entropy_loss         | -57.4         |
|    explained_variance   | -3.69         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.432        |
|    n_updates            | 1280          |
|    policy_gradient_loss | 0.294         |
|    reward               | 6.5725515e-05 |
|    std                  | 1.89          |
|    value_loss           | 7.65e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1049, ResetDay: 2729,Episode: 159
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 130            |
|    time_elapsed         | 2942           |
|    total_timesteps      | 266240         |
| train/                  |                |
|    approx_kl            | 58.67389       |
|    clip_fraction        | 0.724          |
|    clip_range           | 0.2            |
|    entropy_loss         | -57.5          |
|    explained_variance   | -3.15          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.455         |
|    n_updates            | 1290           |
|    policy_gradient_loss | 0.178          |
|    reward               | -2.7837754e-07 |
|    std                  | 1.9            |
|    value_loss           | 1.5e-05        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1960, ResetDay: 3640,Episode: 160
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 131           |
|    time_elapsed         | 2964          |
|    total_timesteps      | 268288        |
| train/                  |               |
|    approx_kl            | 24.378265     |
|    clip_fraction        | 0.676         |
|    clip_range           | 0.2           |
|    entropy_loss         | -57.6         |
|    explained_variance   | -4.01         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.47         |
|    n_updates            | 1300          |
|    policy_gradient_loss | 0.209         |
|    reward               | 0.00016101723 |
|    std                  | 1.9           |
|    value_loss           | 2.09e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3640, episode: 160
begin_total_asset: 200.00
end_total_asset: 362.10
total_reward: 162.10
total_cost: 2.51
total_trades: 47032
Sharpe: 0.637
=================================
Reseting Environment StartDay: 2409, ResetDay: 4089,Episode: 161
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 132            |
|    time_elapsed         | 2987           |
|    total_timesteps      | 270336         |
| train/                  |                |
|    approx_kl            | 31.777786      |
|    clip_fraction        | 0.741          |
|    clip_range           | 0.2            |
|    entropy_loss         | -57.7          |
|    explained_variance   | -2.61          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.324         |
|    n_updates            | 1310           |
|    policy_gradient_loss | 0.206          |
|    reward               | -0.00051255606 |
|    std                  | 1.91           |
|    value_loss           | 8.49e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1960, ResetDay: 3640,Episode: 162
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1514, ResetDay: 3194,Episode: 163
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 133           |
|    time_elapsed         | 3010          |
|    total_timesteps      | 272384        |
| train/                  |               |
|    approx_kl            | 84.73352      |
|    clip_fraction        | 0.723         |
|    clip_range           | 0.2           |
|    entropy_loss         | -57.8         |
|    explained_variance   | -0.396        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.451        |
|    n_updates            | 1320          |
|    policy_gradient_loss | 0.186         |
|    reward               | -4.815388e-06 |
|    std                  | 1.92          |
|    value_loss           | 7.03e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1962, ResetDay: 3642,Episode: 164
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 134           |
|    time_elapsed         | 3032          |
|    total_timesteps      | 274432        |
| train/                  |               |
|    approx_kl            | 129.91411     |
|    clip_fraction        | 0.75          |
|    clip_range           | 0.2           |
|    entropy_loss         | -57.9         |
|    explained_variance   | -0.673        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.502        |
|    n_updates            | 1330          |
|    policy_gradient_loss | 0.195         |
|    reward               | 4.4060518e-05 |
|    std                  | 1.92          |
|    value_loss           | 2.18e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2592, ResetDay: 4272,Episode: 165
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 135            |
|    time_elapsed         | 3055           |
|    total_timesteps      | 276480         |
| train/                  |                |
|    approx_kl            | 31.910198      |
|    clip_fraction        | 0.704          |
|    clip_range           | 0.2            |
|    entropy_loss         | -58.1          |
|    explained_variance   | -1.49          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.469         |
|    n_updates            | 1340           |
|    policy_gradient_loss | 0.172          |
|    reward               | -5.2067186e-05 |
|    std                  | 1.94           |
|    value_loss           | 7.76e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4272, episode: 165
begin_total_asset: 200.00
end_total_asset: 259.83
total_reward: 59.83
total_cost: 1.80
total_trades: 47031
Sharpe: 0.308
=================================
Reseting Environment StartDay: 1756, ResetDay: 3436,Episode: 166
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 136            |
|    time_elapsed         | 3077           |
|    total_timesteps      | 278528         |
| train/                  |                |
|    approx_kl            | 53.78182       |
|    clip_fraction        | 0.706          |
|    clip_range           | 0.2            |
|    entropy_loss         | -58.2          |
|    explained_variance   | -0.696         |
|    learning_rate        | 0.00025        |
|    loss                 | -0.414         |
|    n_updates            | 1350           |
|    policy_gradient_loss | 0.188          |
|    reward               | -2.9364013e-05 |
|    std                  | 1.95           |
|    value_loss           | 6.93e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1969, ResetDay: 3649,Episode: 167
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 137          |
|    time_elapsed         | 3100         |
|    total_timesteps      | 280576       |
| train/                  |              |
|    approx_kl            | 143.97769    |
|    clip_fraction        | 0.736        |
|    clip_range           | 0.2          |
|    entropy_loss         | -58.3        |
|    explained_variance   | -1.05        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.335       |
|    n_updates            | 1360         |
|    policy_gradient_loss | 0.186        |
|    reward               | 8.785248e-06 |
|    std                  | 1.95         |
|    value_loss           | 6.51e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1519, ResetDay: 3199,Episode: 168
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2418, ResetDay: 4098,Episode: 169
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 138            |
|    time_elapsed         | 3123           |
|    total_timesteps      | 282624         |
| train/                  |                |
|    approx_kl            | 70.50927       |
|    clip_fraction        | 0.684          |
|    clip_range           | 0.2            |
|    entropy_loss         | -58.5          |
|    explained_variance   | -0.741         |
|    learning_rate        | 0.00025        |
|    loss                 | -0.456         |
|    n_updates            | 1370           |
|    policy_gradient_loss | 0.196          |
|    reward               | -0.00013097438 |
|    std                  | 1.97           |
|    value_loss           | 7.28e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2415, ResetDay: 4095,Episode: 170
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 139            |
|    time_elapsed         | 3145           |
|    total_timesteps      | 284672         |
| train/                  |                |
|    approx_kl            | 143.29405      |
|    clip_fraction        | 0.754          |
|    clip_range           | 0.2            |
|    entropy_loss         | -58.7          |
|    explained_variance   | -1.24          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.145         |
|    n_updates            | 1380           |
|    policy_gradient_loss | 0.169          |
|    reward               | -0.00014021683 |
|    std                  | 1.98           |
|    value_loss           | 8.54e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4095, episode: 170
begin_total_asset: 200.00
end_total_asset: 196.67
total_reward: -3.33
total_cost: 1.81
total_trades: 47031
Sharpe: 0.112
=================================
Reseting Environment StartDay: 2107, ResetDay: 3787,Episode: 171
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 140           |
|    time_elapsed         | 3168          |
|    total_timesteps      | 286720        |
| train/                  |               |
|    approx_kl            | 53.431763     |
|    clip_fraction        | 0.756         |
|    clip_range           | 0.2           |
|    entropy_loss         | -58.9         |
|    explained_variance   | -0.388        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.501        |
|    n_updates            | 1390          |
|    policy_gradient_loss | 0.231         |
|    reward               | 6.7672727e-07 |
|    std                  | 2             |
|    value_loss           | 9.35e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1983, ResetDay: 3663,Episode: 172
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 141          |
|    time_elapsed         | 3191         |
|    total_timesteps      | 288768       |
| train/                  |              |
|    approx_kl            | 84.501816    |
|    clip_fraction        | 0.722        |
|    clip_range           | 0.2          |
|    entropy_loss         | -59.1        |
|    explained_variance   | -0.561       |
|    learning_rate        | 0.00025      |
|    loss                 | -0.461       |
|    n_updates            | 1400         |
|    policy_gradient_loss | 0.224        |
|    reward               | 0.0001580452 |
|    std                  | 2            |
|    value_loss           | 6.11e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2377, ResetDay: 4057,Episode: 173
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2281, ResetDay: 3961,Episode: 174
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 142            |
|    time_elapsed         | 3214           |
|    total_timesteps      | 290816         |
| train/                  |                |
|    approx_kl            | 85.50408       |
|    clip_fraction        | 0.696          |
|    clip_range           | 0.2            |
|    entropy_loss         | -59.2          |
|    explained_variance   | -0.679         |
|    learning_rate        | 0.00025        |
|    loss                 | -0.429         |
|    n_updates            | 1410           |
|    policy_gradient_loss | 0.197          |
|    reward               | -1.7422866e-05 |
|    std                  | 2.01           |
|    value_loss           | 6.61e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2216, ResetDay: 3896,Episode: 175
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 143           |
|    time_elapsed         | 3237          |
|    total_timesteps      | 292864        |
| train/                  |               |
|    approx_kl            | 124.646805    |
|    clip_fraction        | 0.711         |
|    clip_range           | 0.2           |
|    entropy_loss         | -59.3         |
|    explained_variance   | -0.137        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.324        |
|    n_updates            | 1420          |
|    policy_gradient_loss | 0.181         |
|    reward               | 0.00033813572 |
|    std                  | 2.02          |
|    value_loss           | 7.42e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3896, episode: 175
begin_total_asset: 200.00
end_total_asset: 207.87
total_reward: 7.87
total_cost: 1.92
total_trades: 47031
Sharpe: 0.153
=================================
Reseting Environment StartDay: 1936, ResetDay: 3616,Episode: 176
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 144            |
|    time_elapsed         | 3259           |
|    total_timesteps      | 294912         |
| train/                  |                |
|    approx_kl            | 48.619057      |
|    clip_fraction        | 0.704          |
|    clip_range           | 0.2            |
|    entropy_loss         | -59.4          |
|    explained_variance   | -0.512         |
|    learning_rate        | 0.00025        |
|    loss                 | -0.462         |
|    n_updates            | 1430           |
|    policy_gradient_loss | 0.205          |
|    reward               | -0.00036433182 |
|    std                  | 2.03           |
|    value_loss           | 6.03e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2538, ResetDay: 4218,Episode: 177
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 145            |
|    time_elapsed         | 3282           |
|    total_timesteps      | 296960         |
| train/                  |                |
|    approx_kl            | 59.88171       |
|    clip_fraction        | 0.75           |
|    clip_range           | 0.2            |
|    entropy_loss         | -59.5          |
|    explained_variance   | -0.584         |
|    learning_rate        | 0.00025        |
|    loss                 | -0.42          |
|    n_updates            | 1440           |
|    policy_gradient_loss | 0.233          |
|    reward               | -4.3735504e-06 |
|    std                  | 2.04           |
|    value_loss           | 7.11e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2580, ResetDay: 4260,Episode: 178
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 146           |
|    time_elapsed         | 3305          |
|    total_timesteps      | 299008        |
| train/                  |               |
|    approx_kl            | 59.956547     |
|    clip_fraction        | 0.713         |
|    clip_range           | 0.2           |
|    entropy_loss         | -59.7         |
|    explained_variance   | -0.247        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.423        |
|    n_updates            | 1450          |
|    policy_gradient_loss | 0.173         |
|    reward               | 2.0425796e-05 |
|    std                  | 2.05          |
|    value_loss           | 4.13e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1476, ResetDay: 3156,Episode: 179
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1322, ResetDay: 3002,Episode: 180
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 147            |
|    time_elapsed         | 3327           |
|    total_timesteps      | 301056         |
| train/                  |                |
|    approx_kl            | 138.67598      |
|    clip_fraction        | 0.704          |
|    clip_range           | 0.2            |
|    entropy_loss         | -59.9          |
|    explained_variance   | -0.208         |
|    learning_rate        | 0.00025        |
|    loss                 | -0.447         |
|    n_updates            | 1460           |
|    policy_gradient_loss | 0.19           |
|    reward               | -0.00010217838 |
|    std                  | 2.06           |
|    value_loss           | 4.81e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3002, episode: 180
begin_total_asset: 200.00
end_total_asset: 191.69
total_reward: -8.31
total_cost: 1.97
total_trades: 47032
Sharpe: 0.178
=================================
Reseting Environment StartDay: 2665, ResetDay: 4345,Episode: 181
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 148            |
|    time_elapsed         | 3350           |
|    total_timesteps      | 303104         |
| train/                  |                |
|    approx_kl            | 227.31018      |
|    clip_fraction        | 0.725          |
|    clip_range           | 0.2            |
|    entropy_loss         | -60            |
|    explained_variance   | -1.25          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.525         |
|    n_updates            | 1470           |
|    policy_gradient_loss | 0.124          |
|    reward               | -4.3048858e-05 |
|    std                  | 2.07           |
|    value_loss           | 1.6e-06        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1227, ResetDay: 2907,Episode: 182
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 149           |
|    time_elapsed         | 3374          |
|    total_timesteps      | 305152        |
| train/                  |               |
|    approx_kl            | 31.455084     |
|    clip_fraction        | 0.751         |
|    clip_range           | 0.2           |
|    entropy_loss         | -60.1         |
|    explained_variance   | -3.09         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.358        |
|    n_updates            | 1480          |
|    policy_gradient_loss | 0.164         |
|    reward               | 2.5513458e-05 |
|    std                  | 2.08          |
|    value_loss           | 9.15e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1541, ResetDay: 3221,Episode: 183
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 150            |
|    time_elapsed         | 3397           |
|    total_timesteps      | 307200         |
| train/                  |                |
|    approx_kl            | 110.083984     |
|    clip_fraction        | 0.697          |
|    clip_range           | 0.2            |
|    entropy_loss         | -60.2          |
|    explained_variance   | -1.19          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.49          |
|    n_updates            | 1490           |
|    policy_gradient_loss | 0.165          |
|    reward               | -0.00029917582 |
|    std                  | 2.09           |
|    value_loss           | 2.06e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1730, ResetDay: 3410,Episode: 184
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 151           |
|    time_elapsed         | 3419          |
|    total_timesteps      | 309248        |
| train/                  |               |
|    approx_kl            | 42.422626     |
|    clip_fraction        | 0.71          |
|    clip_range           | 0.2           |
|    entropy_loss         | -60.3         |
|    explained_variance   | -1.79         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.117        |
|    n_updates            | 1500          |
|    policy_gradient_loss | 0.211         |
|    reward               | 7.7736666e-05 |
|    std                  | 2.1           |
|    value_loss           | 6.71e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 39, ResetDay: 1719,Episode: 185
Environment reached Terminal state as number of trading days reached limit!!
day: 1719, episode: 185
begin_total_asset: 200.00
end_total_asset: 128.12
total_reward: -71.88
total_cost: 1.97
total_trades: 47040
Sharpe: -0.000
=================================
Reseting Environment StartDay: 585, ResetDay: 2265,Episode: 186
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 152            |
|    time_elapsed         | 3442           |
|    total_timesteps      | 311296         |
| train/                  |                |
|    approx_kl            | 58.065487      |
|    clip_fraction        | 0.784          |
|    clip_range           | 0.2            |
|    entropy_loss         | -60.4          |
|    explained_variance   | -0.975         |
|    learning_rate        | 0.00025        |
|    loss                 | -0.137         |
|    n_updates            | 1510           |
|    policy_gradient_loss | 0.242          |
|    reward               | -3.2882832e-05 |
|    std                  | 2.11           |
|    value_loss           | 6.18e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2535, ResetDay: 4215,Episode: 187
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 153            |
|    time_elapsed         | 3464           |
|    total_timesteps      | 313344         |
| train/                  |                |
|    approx_kl            | 122.43828      |
|    clip_fraction        | 0.733          |
|    clip_range           | 0.2            |
|    entropy_loss         | -60.6          |
|    explained_variance   | -8.65          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.461         |
|    n_updates            | 1520           |
|    policy_gradient_loss | 0.383          |
|    reward               | -0.00016021957 |
|    std                  | 2.12           |
|    value_loss           | 6.47e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2139, ResetDay: 3819,Episode: 188
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 154           |
|    time_elapsed         | 3487          |
|    total_timesteps      | 315392        |
| train/                  |               |
|    approx_kl            | 20.965572     |
|    clip_fraction        | 0.69          |
|    clip_range           | 0.2           |
|    entropy_loss         | -60.7         |
|    explained_variance   | -1.95         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.449        |
|    n_updates            | 1530          |
|    policy_gradient_loss | 0.193         |
|    reward               | -5.585022e-05 |
|    std                  | 2.13          |
|    value_loss           | 1.62e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 638, ResetDay: 2318,Episode: 189
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 155           |
|    time_elapsed         | 3510          |
|    total_timesteps      | 317440        |
| train/                  |               |
|    approx_kl            | 118.09604     |
|    clip_fraction        | 0.7           |
|    clip_range           | 0.2           |
|    entropy_loss         | -60.8         |
|    explained_variance   | -0.397        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.45         |
|    n_updates            | 1540          |
|    policy_gradient_loss | 0.159         |
|    reward               | -8.896904e-05 |
|    std                  | 2.14          |
|    value_loss           | 8.03e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1008, ResetDay: 2688,Episode: 190
Environment reached Terminal state as number of trading days reached limit!!
day: 2688, episode: 190
begin_total_asset: 200.00
end_total_asset: 220.25
total_reward: 20.25
total_cost: 1.95
total_trades: 47040
Sharpe: 0.259
=================================
Reseting Environment StartDay: 1671, ResetDay: 3351,Episode: 191
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 156            |
|    time_elapsed         | 3532           |
|    total_timesteps      | 319488         |
| train/                  |                |
|    approx_kl            | 105.26194      |
|    clip_fraction        | 0.738          |
|    clip_range           | 0.2            |
|    entropy_loss         | -60.9          |
|    explained_variance   | -4.94          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.484         |
|    n_updates            | 1550           |
|    policy_gradient_loss | 0.185          |
|    reward               | -0.00015472222 |
|    std                  | 2.14           |
|    value_loss           | 2.16e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 71, ResetDay: 1751,Episode: 192
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 157           |
|    time_elapsed         | 3555          |
|    total_timesteps      | 321536        |
| train/                  |               |
|    approx_kl            | 40.60253      |
|    clip_fraction        | 0.711         |
|    clip_range           | 0.2           |
|    entropy_loss         | -61           |
|    explained_variance   | -2.5          |
|    learning_rate        | 0.00025       |
|    loss                 | -0.527        |
|    n_updates            | 1560          |
|    policy_gradient_loss | 0.145         |
|    reward               | 0.00010596657 |
|    std                  | 2.15          |
|    value_loss           | 1.14e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1830, ResetDay: 3510,Episode: 193
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 158          |
|    time_elapsed         | 3578         |
|    total_timesteps      | 323584       |
| train/                  |              |
|    approx_kl            | 33.04341     |
|    clip_fraction        | 0.704        |
|    clip_range           | 0.2          |
|    entropy_loss         | -61.1        |
|    explained_variance   | -3.68        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.461       |
|    n_updates            | 1570         |
|    policy_gradient_loss | 0.156        |
|    reward               | 0.0006761303 |
|    std                  | 2.16         |
|    value_loss           | 3.51e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 537, ResetDay: 2217,Episode: 194
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 159            |
|    time_elapsed         | 3600           |
|    total_timesteps      | 325632         |
| train/                  |                |
|    approx_kl            | 31.217384      |
|    clip_fraction        | 0.712          |
|    clip_range           | 0.2            |
|    entropy_loss         | -61.3          |
|    explained_variance   | -3             |
|    learning_rate        | 0.00025        |
|    loss                 | -0.475         |
|    n_updates            | 1580           |
|    policy_gradient_loss | 0.186          |
|    reward               | -0.00013503007 |
|    std                  | 2.17           |
|    value_loss           | 2.01e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 382, ResetDay: 2062,Episode: 195
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 160           |
|    time_elapsed         | 3623          |
|    total_timesteps      | 327680        |
| train/                  |               |
|    approx_kl            | 56.729782     |
|    clip_fraction        | 0.714         |
|    clip_range           | 0.2           |
|    entropy_loss         | -61.4         |
|    explained_variance   | -1.85         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.472        |
|    n_updates            | 1590          |
|    policy_gradient_loss | 0.156         |
|    reward               | -0.0001420475 |
|    std                  | 2.18          |
|    value_loss           | 2.07e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2062, episode: 195
begin_total_asset: 200.00
end_total_asset: 203.74
total_reward: 3.74
total_cost: 1.97
total_trades: 47033
Sharpe: 0.173
=================================
Reseting Environment StartDay: 2776, ResetDay: 4456,Episode: 196
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2324, ResetDay: 4004,Episode: 197
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 161            |
|    time_elapsed         | 3646           |
|    total_timesteps      | 329728         |
| train/                  |                |
|    approx_kl            | 33.70652       |
|    clip_fraction        | 0.742          |
|    clip_range           | 0.2            |
|    entropy_loss         | -61.5          |
|    explained_variance   | -5.11          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.491         |
|    n_updates            | 1600           |
|    policy_gradient_loss | 0.204          |
|    reward               | -2.7765274e-05 |
|    std                  | 2.19           |
|    value_loss           | 9.22e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2028, ResetDay: 3708,Episode: 198
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 162            |
|    time_elapsed         | 3668           |
|    total_timesteps      | 331776         |
| train/                  |                |
|    approx_kl            | 35.082134      |
|    clip_fraction        | 0.71           |
|    clip_range           | 0.2            |
|    entropy_loss         | -61.6          |
|    explained_variance   | -0.263         |
|    learning_rate        | 0.00025        |
|    loss                 | -0.49          |
|    n_updates            | 1610           |
|    policy_gradient_loss | 0.161          |
|    reward               | -0.00027876053 |
|    std                  | 2.2            |
|    value_loss           | 1.2e-05        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1313, ResetDay: 2993,Episode: 199
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 163            |
|    time_elapsed         | 3691           |
|    total_timesteps      | 333824         |
| train/                  |                |
|    approx_kl            | 53.77753       |
|    clip_fraction        | 0.707          |
|    clip_range           | 0.2            |
|    entropy_loss         | -61.8          |
|    explained_variance   | -1.01          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.494         |
|    n_updates            | 1620           |
|    policy_gradient_loss | 0.186          |
|    reward               | -0.00017796783 |
|    std                  | 2.21           |
|    value_loss           | 4.68e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2635, ResetDay: 4315,Episode: 200
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 164          |
|    time_elapsed         | 3714         |
|    total_timesteps      | 335872       |
| train/                  |              |
|    approx_kl            | 53.01191     |
|    clip_fraction        | 0.712        |
|    clip_range           | 0.2          |
|    entropy_loss         | -61.9        |
|    explained_variance   | -1.55        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.491       |
|    n_updates            | 1630         |
|    policy_gradient_loss | 0.168        |
|    reward               | 4.817734e-05 |
|    std                  | 2.22         |
|    value_loss           | 8.42e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4315, episode: 200
begin_total_asset: 200.00
end_total_asset: 245.04
total_reward: 45.04
total_cost: 1.93
total_trades: 47032
Sharpe: 0.253
=================================
Reseting Environment StartDay: 2127, ResetDay: 3807,Episode: 201
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2185, ResetDay: 3865,Episode: 202
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 165           |
|    time_elapsed         | 3736          |
|    total_timesteps      | 337920        |
| train/                  |               |
|    approx_kl            | 46.114502     |
|    clip_fraction        | 0.761         |
|    clip_range           | 0.2           |
|    entropy_loss         | -62           |
|    explained_variance   | -0.234        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.481        |
|    n_updates            | 1640          |
|    policy_gradient_loss | 0.22          |
|    reward               | -4.139328e-06 |
|    std                  | 2.23          |
|    value_loss           | 5.18e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 480, ResetDay: 2160,Episode: 203
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 166           |
|    time_elapsed         | 3759          |
|    total_timesteps      | 339968        |
| train/                  |               |
|    approx_kl            | 169.15971     |
|    clip_fraction        | 0.68          |
|    clip_range           | 0.2           |
|    entropy_loss         | -62.2         |
|    explained_variance   | -0.561        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.485        |
|    n_updates            | 1650          |
|    policy_gradient_loss | 0.169         |
|    reward               | -0.0004981102 |
|    std                  | 2.24          |
|    value_loss           | 6.27e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1240, ResetDay: 2920,Episode: 204
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 167           |
|    time_elapsed         | 3782          |
|    total_timesteps      | 342016        |
| train/                  |               |
|    approx_kl            | 42.89479      |
|    clip_fraction        | 0.75          |
|    clip_range           | 0.2           |
|    entropy_loss         | -62.3         |
|    explained_variance   | -2.13         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.23         |
|    n_updates            | 1660          |
|    policy_gradient_loss | 0.177         |
|    reward               | 0.00010949984 |
|    std                  | 2.25          |
|    value_loss           | 1.02e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 883, ResetDay: 2563,Episode: 205
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 168           |
|    time_elapsed         | 3804          |
|    total_timesteps      | 344064        |
| train/                  |               |
|    approx_kl            | 21.629587     |
|    clip_fraction        | 0.702         |
|    clip_range           | 0.2           |
|    entropy_loss         | -62.4         |
|    explained_variance   | -4.07         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.384        |
|    n_updates            | 1670          |
|    policy_gradient_loss | 0.234         |
|    reward               | 0.00022282296 |
|    std                  | 2.26          |
|    value_loss           | 1.62e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2563, episode: 205
begin_total_asset: 200.00
end_total_asset: 270.75
total_reward: 70.75
total_cost: 1.97
total_trades: 47033
Sharpe: 0.337
=================================
Reseting Environment StartDay: 886, ResetDay: 2566,Episode: 206
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 169           |
|    time_elapsed         | 3827          |
|    total_timesteps      | 346112        |
| train/                  |               |
|    approx_kl            | 38.08943      |
|    clip_fraction        | 0.739         |
|    clip_range           | 0.2           |
|    entropy_loss         | -62.5         |
|    explained_variance   | -2.84         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.487        |
|    n_updates            | 1680          |
|    policy_gradient_loss | 0.271         |
|    reward               | 7.0384594e-05 |
|    std                  | 2.27          |
|    value_loss           | 1.7e-06       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 190, ResetDay: 1870,Episode: 207
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2768, ResetDay: 4448,Episode: 208
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 170          |
|    time_elapsed         | 3849         |
|    total_timesteps      | 348160       |
| train/                  |              |
|    approx_kl            | 37.67112     |
|    clip_fraction        | 0.7          |
|    clip_range           | 0.2          |
|    entropy_loss         | -62.7        |
|    explained_variance   | -2.51        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.405       |
|    n_updates            | 1690         |
|    policy_gradient_loss | 0.198        |
|    reward               | 0.0004412056 |
|    std                  | 2.29         |
|    value_loss           | 1.62e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1696, ResetDay: 3376,Episode: 209
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 171            |
|    time_elapsed         | 3872           |
|    total_timesteps      | 350208         |
| train/                  |                |
|    approx_kl            | 45.312286      |
|    clip_fraction        | 0.743          |
|    clip_range           | 0.2            |
|    entropy_loss         | -62.9          |
|    explained_variance   | -3.3           |
|    learning_rate        | 0.00025        |
|    loss                 | -0.553         |
|    n_updates            | 1700           |
|    policy_gradient_loss | 0.2            |
|    reward               | -6.0639573e-05 |
|    std                  | 2.3            |
|    value_loss           | 6.9e-06        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 977, ResetDay: 2657,Episode: 210
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 172            |
|    time_elapsed         | 3894           |
|    total_timesteps      | 352256         |
| train/                  |                |
|    approx_kl            | 64.1927        |
|    clip_fraction        | 0.747          |
|    clip_range           | 0.2            |
|    entropy_loss         | -63            |
|    explained_variance   | -0.167         |
|    learning_rate        | 0.00025        |
|    loss                 | -0.499         |
|    n_updates            | 1710           |
|    policy_gradient_loss | 0.249          |
|    reward               | -0.00023681717 |
|    std                  | 2.31           |
|    value_loss           | 1.48e-05       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2657, episode: 210
begin_total_asset: 200.00
end_total_asset: 249.30
total_reward: 49.30
total_cost: 2.29
total_trades: 47034
Sharpe: 0.341
=================================
Reseting Environment StartDay: 544, ResetDay: 2224,Episode: 211
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 173            |
|    time_elapsed         | 3917           |
|    total_timesteps      | 354304         |
| train/                  |                |
|    approx_kl            | 43.259377      |
|    clip_fraction        | 0.76           |
|    clip_range           | 0.2            |
|    entropy_loss         | -63.1          |
|    explained_variance   | -2.38          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.504         |
|    n_updates            | 1720           |
|    policy_gradient_loss | 0.288          |
|    reward               | -3.7648773e-05 |
|    std                  | 2.32           |
|    value_loss           | 1.08e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1703, ResetDay: 3383,Episode: 212
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 174           |
|    time_elapsed         | 3939          |
|    total_timesteps      | 356352        |
| train/                  |               |
|    approx_kl            | 31.758251     |
|    clip_fraction        | 0.745         |
|    clip_range           | 0.2           |
|    entropy_loss         | -63.3         |
|    explained_variance   | -3.37         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.614        |
|    n_updates            | 1730          |
|    policy_gradient_loss | 0.604         |
|    reward               | 0.00017446403 |
|    std                  | 2.34          |
|    value_loss           | 1.26e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1713, ResetDay: 3393,Episode: 213
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2176, ResetDay: 3856,Episode: 214
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 175           |
|    time_elapsed         | 3962          |
|    total_timesteps      | 358400        |
| train/                  |               |
|    approx_kl            | 30.636673     |
|    clip_fraction        | 0.707         |
|    clip_range           | 0.2           |
|    entropy_loss         | -63.4         |
|    explained_variance   | -0.715        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.475        |
|    n_updates            | 1740          |
|    policy_gradient_loss | 0.192         |
|    reward               | -3.097267e-05 |
|    std                  | 2.35          |
|    value_loss           | 5.89e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2719, ResetDay: 4399,Episode: 215
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 176            |
|    time_elapsed         | 3985           |
|    total_timesteps      | 360448         |
| train/                  |                |
|    approx_kl            | 82.92415       |
|    clip_fraction        | 0.717          |
|    clip_range           | 0.2            |
|    entropy_loss         | -63.6          |
|    explained_variance   | -0.952         |
|    learning_rate        | 0.00025        |
|    loss                 | -0.465         |
|    n_updates            | 1750           |
|    policy_gradient_loss | 0.331          |
|    reward               | -0.00022630233 |
|    std                  | 2.36           |
|    value_loss           | 5.78e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4399, episode: 215
begin_total_asset: 200.00
end_total_asset: 248.70
total_reward: 48.70
total_cost: 1.98
total_trades: 47033
Sharpe: 0.263
=================================
Reseting Environment StartDay: 559, ResetDay: 2239,Episode: 216
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 177           |
|    time_elapsed         | 4007          |
|    total_timesteps      | 362496        |
| train/                  |               |
|    approx_kl            | 51.58963      |
|    clip_fraction        | 0.68          |
|    clip_range           | 0.2           |
|    entropy_loss         | -63.7         |
|    explained_variance   | -0.413        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.418        |
|    n_updates            | 1760          |
|    policy_gradient_loss | 0.193         |
|    reward               | 0.00013455791 |
|    std                  | 2.37          |
|    value_loss           | 3.78e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 850, ResetDay: 2530,Episode: 217
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 178           |
|    time_elapsed         | 4030          |
|    total_timesteps      | 364544        |
| train/                  |               |
|    approx_kl            | 94.73384      |
|    clip_fraction        | 0.717         |
|    clip_range           | 0.2           |
|    entropy_loss         | -63.9         |
|    explained_variance   | -2.15         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.5          |
|    n_updates            | 1770          |
|    policy_gradient_loss | 0.154         |
|    reward               | 0.00022721672 |
|    std                  | 2.39          |
|    value_loss           | 2.17e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1792, ResetDay: 3472,Episode: 218
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2719, ResetDay: 4399,Episode: 219
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 179          |
|    time_elapsed         | 4052         |
|    total_timesteps      | 366592       |
| train/                  |              |
|    approx_kl            | 28.226372    |
|    clip_fraction        | 0.718        |
|    clip_range           | 0.2          |
|    entropy_loss         | -64          |
|    explained_variance   | -3.15        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.568       |
|    n_updates            | 1780         |
|    policy_gradient_loss | 0.177        |
|    reward               | 8.898792e-05 |
|    std                  | 2.4          |
|    value_loss           | 1.12e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1012, ResetDay: 2692,Episode: 220
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 180          |
|    time_elapsed         | 4075         |
|    total_timesteps      | 368640       |
| train/                  |              |
|    approx_kl            | 43.333813    |
|    clip_fraction        | 0.716        |
|    clip_range           | 0.2          |
|    entropy_loss         | -64.2        |
|    explained_variance   | -0.863       |
|    learning_rate        | 0.00025      |
|    loss                 | -0.454       |
|    n_updates            | 1790         |
|    policy_gradient_loss | 0.197        |
|    reward               | 1.613245e-05 |
|    std                  | 2.41         |
|    value_loss           | 1.11e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2692, episode: 220
begin_total_asset: 200.00
end_total_asset: 148.83
total_reward: -51.17
total_cost: 1.95
total_trades: 47033
Sharpe: 0.088
=================================
Reseting Environment StartDay: 1200, ResetDay: 2880,Episode: 221
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 181           |
|    time_elapsed         | 4097          |
|    total_timesteps      | 370688        |
| train/                  |               |
|    approx_kl            | 54.891003     |
|    clip_fraction        | 0.717         |
|    clip_range           | 0.2           |
|    entropy_loss         | -64.3         |
|    explained_variance   | -0.864        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.534        |
|    n_updates            | 1800          |
|    policy_gradient_loss | 0.284         |
|    reward               | -0.0002291111 |
|    std                  | 2.42          |
|    value_loss           | 5.73e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 422, ResetDay: 2102,Episode: 222
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 182           |
|    time_elapsed         | 4120          |
|    total_timesteps      | 372736        |
| train/                  |               |
|    approx_kl            | 29.575127     |
|    clip_fraction        | 0.708         |
|    clip_range           | 0.2           |
|    entropy_loss         | -64.4         |
|    explained_variance   | -2.47         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.453        |
|    n_updates            | 1810          |
|    policy_gradient_loss | 0.152         |
|    reward               | 0.00025946923 |
|    std                  | 2.44          |
|    value_loss           | 7.8e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1824, ResetDay: 3504,Episode: 223
----------------------------------------
| time/                   |            |
|    fps                  | 90         |
|    iterations           | 183        |
|    time_elapsed         | 4143       |
|    total_timesteps      | 374784     |
| train/                  |            |
|    approx_kl            | 36.176018  |
|    clip_fraction        | 0.726      |
|    clip_range           | 0.2        |
|    entropy_loss         | -64.6      |
|    explained_variance   | -3.16      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.533     |
|    n_updates            | 1820       |
|    policy_gradient_loss | 0.171      |
|    reward               | 0.00080243 |
|    std                  | 2.46       |
|    value_loss           | 1.51e-06   |
----------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1838, ResetDay: 3518,Episode: 224
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 122, ResetDay: 1802,Episode: 225
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 184           |
|    time_elapsed         | 4165          |
|    total_timesteps      | 376832        |
| train/                  |               |
|    approx_kl            | 28.599062     |
|    clip_fraction        | 0.787         |
|    clip_range           | 0.2           |
|    entropy_loss         | -64.8         |
|    explained_variance   | -0.68         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.443        |
|    n_updates            | 1830          |
|    policy_gradient_loss | 0.311         |
|    reward               | 9.1823196e-05 |
|    std                  | 2.47          |
|    value_loss           | 1.05e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 1802, episode: 225
begin_total_asset: 200.00
end_total_asset: 124.12
total_reward: -75.88
total_cost: 1.97
total_trades: 47033
Sharpe: 0.012
=================================
Reseting Environment StartDay: 883, ResetDay: 2563,Episode: 226
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 185           |
|    time_elapsed         | 4188          |
|    total_timesteps      | 378880        |
| train/                  |               |
|    approx_kl            | 90.29278      |
|    clip_fraction        | 0.738         |
|    clip_range           | 0.2           |
|    entropy_loss         | -64.9         |
|    explained_variance   | -2.58         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.493        |
|    n_updates            | 1840          |
|    policy_gradient_loss | 0.141         |
|    reward               | 0.00018503646 |
|    std                  | 2.48          |
|    value_loss           | 2.98e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1542, ResetDay: 3222,Episode: 227
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 186           |
|    time_elapsed         | 4211          |
|    total_timesteps      | 380928        |
| train/                  |               |
|    approx_kl            | 26.972279     |
|    clip_fraction        | 0.725         |
|    clip_range           | 0.2           |
|    entropy_loss         | -65.1         |
|    explained_variance   | -7.34         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.556        |
|    n_updates            | 1850          |
|    policy_gradient_loss | 0.188         |
|    reward               | 9.1659924e-05 |
|    std                  | 2.49          |
|    value_loss           | 1.54e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2694, ResetDay: 4374,Episode: 228
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 187           |
|    time_elapsed         | 4233          |
|    total_timesteps      | 382976        |
| train/                  |               |
|    approx_kl            | 29.191284     |
|    clip_fraction        | 0.718         |
|    clip_range           | 0.2           |
|    entropy_loss         | -65.2         |
|    explained_variance   | -0.7          |
|    learning_rate        | 0.00025       |
|    loss                 | -0.483        |
|    n_updates            | 1860          |
|    policy_gradient_loss | 0.184         |
|    reward               | 0.00032632943 |
|    std                  | 2.5           |
|    value_loss           | 7.77e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2050, ResetDay: 3730,Episode: 229
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2513, ResetDay: 4193,Episode: 230
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 188           |
|    time_elapsed         | 4257          |
|    total_timesteps      | 385024        |
| train/                  |               |
|    approx_kl            | 49.44324      |
|    clip_fraction        | 0.732         |
|    clip_range           | 0.2           |
|    entropy_loss         | -65.3         |
|    explained_variance   | -0.367        |
|    learning_rate        | 0.00025       |
|    loss                 | 0.313         |
|    n_updates            | 1870          |
|    policy_gradient_loss | 0.238         |
|    reward               | -5.226135e-07 |
|    std                  | 2.51          |
|    value_loss           | 1.73e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4193, episode: 230
begin_total_asset: 200.00
end_total_asset: 294.67
total_reward: 94.67
total_cost: 1.98
total_trades: 47033
Sharpe: 0.395
=================================
Reseting Environment StartDay: 447, ResetDay: 2127,Episode: 231
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 189            |
|    time_elapsed         | 4280           |
|    total_timesteps      | 387072         |
| train/                  |                |
|    approx_kl            | 168.06834      |
|    clip_fraction        | 0.739          |
|    clip_range           | 0.2            |
|    entropy_loss         | -65.4          |
|    explained_variance   | -0.445         |
|    learning_rate        | 0.00025        |
|    loss                 | -0.565         |
|    n_updates            | 1880           |
|    policy_gradient_loss | 0.213          |
|    reward               | -0.00014211921 |
|    std                  | 2.53           |
|    value_loss           | 1.97e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 742, ResetDay: 2422,Episode: 232
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 190           |
|    time_elapsed         | 4302          |
|    total_timesteps      | 389120        |
| train/                  |               |
|    approx_kl            | 47.463673     |
|    clip_fraction        | 0.726         |
|    clip_range           | 0.2           |
|    entropy_loss         | -65.6         |
|    explained_variance   | -1.15         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.417        |
|    n_updates            | 1890          |
|    policy_gradient_loss | 0.184         |
|    reward               | -8.927536e-06 |
|    std                  | 2.54          |
|    value_loss           | 9.28e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1031, ResetDay: 2711,Episode: 233
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 191           |
|    time_elapsed         | 4325          |
|    total_timesteps      | 391168        |
| train/                  |               |
|    approx_kl            | 21.5624       |
|    clip_fraction        | 0.7           |
|    clip_range           | 0.2           |
|    entropy_loss         | -65.7         |
|    explained_variance   | -5.56         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.508        |
|    n_updates            | 1900          |
|    policy_gradient_loss | 0.154         |
|    reward               | 0.00017975617 |
|    std                  | 2.55          |
|    value_loss           | 1.18e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1647, ResetDay: 3327,Episode: 234
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 192           |
|    time_elapsed         | 4347          |
|    total_timesteps      | 393216        |
| train/                  |               |
|    approx_kl            | 29.248543     |
|    clip_fraction        | 0.72          |
|    clip_range           | 0.2           |
|    entropy_loss         | -65.9         |
|    explained_variance   | -1.2          |
|    learning_rate        | 0.00025       |
|    loss                 | -0.496        |
|    n_updates            | 1910          |
|    policy_gradient_loss | 0.173         |
|    reward               | 0.00012691326 |
|    std                  | 2.57          |
|    value_loss           | 1.08e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2354, ResetDay: 4034,Episode: 235
Environment reached Terminal state as number of trading days reached limit!!
day: 4034, episode: 235
begin_total_asset: 200.00
end_total_asset: 293.97
total_reward: 93.97
total_cost: 1.88
total_trades: 47040
Sharpe: 0.390
=================================
Reseting Environment StartDay: 1438, ResetDay: 3118,Episode: 236
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 193           |
|    time_elapsed         | 4371          |
|    total_timesteps      | 395264        |
| train/                  |               |
|    approx_kl            | 39.38073      |
|    clip_fraction        | 0.73          |
|    clip_range           | 0.2           |
|    entropy_loss         | -66           |
|    explained_variance   | -0.634        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.359        |
|    n_updates            | 1920          |
|    policy_gradient_loss | 0.216         |
|    reward               | -7.686233e-06 |
|    std                  | 2.58          |
|    value_loss           | 1.37e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2684, ResetDay: 4364,Episode: 237
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 194           |
|    time_elapsed         | 4393          |
|    total_timesteps      | 397312        |
| train/                  |               |
|    approx_kl            | 82.339134     |
|    clip_fraction        | 0.685         |
|    clip_range           | 0.2           |
|    entropy_loss         | -66.2         |
|    explained_variance   | -0.225        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.484        |
|    n_updates            | 1930          |
|    policy_gradient_loss | 0.169         |
|    reward               | 0.00016922073 |
|    std                  | 2.6           |
|    value_loss           | 7.19e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1253, ResetDay: 2933,Episode: 238
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 195           |
|    time_elapsed         | 4416          |
|    total_timesteps      | 399360        |
| train/                  |               |
|    approx_kl            | 28.056557     |
|    clip_fraction        | 0.716         |
|    clip_range           | 0.2           |
|    entropy_loss         | -66.4         |
|    explained_variance   | -1.18         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.54         |
|    n_updates            | 1940          |
|    policy_gradient_loss | 0.222         |
|    reward               | -9.448128e-05 |
|    std                  | 2.61          |
|    value_loss           | 3.7e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2085, ResetDay: 3765,Episode: 239
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 196           |
|    time_elapsed         | 4439          |
|    total_timesteps      | 401408        |
| train/                  |               |
|    approx_kl            | 80.595856     |
|    clip_fraction        | 0.696         |
|    clip_range           | 0.2           |
|    entropy_loss         | -66.5         |
|    explained_variance   | -0.766        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.552        |
|    n_updates            | 1950          |
|    policy_gradient_loss | 0.14          |
|    reward               | 1.6365051e-05 |
|    std                  | 2.63          |
|    value_loss           | 8.53e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1005, ResetDay: 2685,Episode: 240
Environment reached Terminal state as number of trading days reached limit!!
day: 2685, episode: 240
begin_total_asset: 200.00
end_total_asset: 218.77
total_reward: 18.77
total_cost: 1.98
total_trades: 47040
Sharpe: 0.271
=================================
Reseting Environment StartDay: 1802, ResetDay: 3482,Episode: 241
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 197            |
|    time_elapsed         | 4461           |
|    total_timesteps      | 403456         |
| train/                  |                |
|    approx_kl            | 37.548252      |
|    clip_fraction        | 0.728          |
|    clip_range           | 0.2            |
|    entropy_loss         | -66.7          |
|    explained_variance   | -0.61          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.183         |
|    n_updates            | 1960           |
|    policy_gradient_loss | 0.235          |
|    reward               | -6.5663146e-05 |
|    std                  | 2.64           |
|    value_loss           | 4.34e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1305, ResetDay: 2985,Episode: 242
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 198            |
|    time_elapsed         | 4484           |
|    total_timesteps      | 405504         |
| train/                  |                |
|    approx_kl            | 85.812195      |
|    clip_fraction        | 0.744          |
|    clip_range           | 0.2            |
|    entropy_loss         | -66.8          |
|    explained_variance   | -1.11          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.518         |
|    n_updates            | 1970           |
|    policy_gradient_loss | 0.178          |
|    reward               | -6.6842076e-05 |
|    std                  | 2.65           |
|    value_loss           | 4.17e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2090, ResetDay: 3770,Episode: 243
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 199           |
|    time_elapsed         | 4506          |
|    total_timesteps      | 407552        |
| train/                  |               |
|    approx_kl            | 29.538797     |
|    clip_fraction        | 0.725         |
|    clip_range           | 0.2           |
|    entropy_loss         | -66.9         |
|    explained_variance   | -0.627        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.366        |
|    n_updates            | 1980          |
|    policy_gradient_loss | 0.295         |
|    reward               | 8.3818435e-05 |
|    std                  | 2.66          |
|    value_loss           | 9.7e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 71, ResetDay: 1751,Episode: 244
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 200            |
|    time_elapsed         | 4530           |
|    total_timesteps      | 409600         |
| train/                  |                |
|    approx_kl            | 29.029673      |
|    clip_fraction        | 0.728          |
|    clip_range           | 0.2            |
|    entropy_loss         | -67            |
|    explained_variance   | -0.93          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.51          |
|    n_updates            | 1990           |
|    policy_gradient_loss | 0.288          |
|    reward               | -0.00018008494 |
|    std                  | 2.67           |
|    value_loss           | 1.55e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2379, ResetDay: 4059,Episode: 245
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 201            |
|    time_elapsed         | 4553           |
|    total_timesteps      | 411648         |
| train/                  |                |
|    approx_kl            | 49.41761       |
|    clip_fraction        | 0.746          |
|    clip_range           | 0.2            |
|    entropy_loss         | -67.1          |
|    explained_variance   | -3.12          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.58          |
|    n_updates            | 2000           |
|    policy_gradient_loss | 0.189          |
|    reward               | -0.00020002823 |
|    std                  | 2.68           |
|    value_loss           | 1.91e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4059, episode: 245
begin_total_asset: 200.00
end_total_asset: 640.61
total_reward: 440.61
total_cost: 1.86
total_trades: 47033
Sharpe: 0.684
=================================
Reseting Environment StartDay: 430, ResetDay: 2110,Episode: 246
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2358, ResetDay: 4038,Episode: 247
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 202           |
|    time_elapsed         | 4576          |
|    total_timesteps      | 413696        |
| train/                  |               |
|    approx_kl            | 26.37002      |
|    clip_fraction        | 0.728         |
|    clip_range           | 0.2           |
|    entropy_loss         | -67.2         |
|    explained_variance   | -0.241        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.56         |
|    n_updates            | 2010          |
|    policy_gradient_loss | 0.198         |
|    reward               | -0.0006316578 |
|    std                  | 2.69          |
|    value_loss           | 3.97e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 959, ResetDay: 2639,Episode: 248
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 203            |
|    time_elapsed         | 4598           |
|    total_timesteps      | 415744         |
| train/                  |                |
|    approx_kl            | 100.96863      |
|    clip_fraction        | 0.769          |
|    clip_range           | 0.2            |
|    entropy_loss         | -67.4          |
|    explained_variance   | -1.57          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.45          |
|    n_updates            | 2020           |
|    policy_gradient_loss | 0.238          |
|    reward               | -9.5890806e-05 |
|    std                  | 2.71           |
|    value_loss           | 1.67e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2246, ResetDay: 3926,Episode: 249
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 204            |
|    time_elapsed         | 4621           |
|    total_timesteps      | 417792         |
| train/                  |                |
|    approx_kl            | 45.00549       |
|    clip_fraction        | 0.76           |
|    clip_range           | 0.2            |
|    entropy_loss         | -67.5          |
|    explained_variance   | -0.326         |
|    learning_rate        | 0.00025        |
|    loss                 | -0.495         |
|    n_updates            | 2030           |
|    policy_gradient_loss | 0.249          |
|    reward               | -0.00012926025 |
|    std                  | 2.72           |
|    value_loss           | 1.37e-05       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 664, ResetDay: 2344,Episode: 250
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 205          |
|    time_elapsed         | 4643         |
|    total_timesteps      | 419840       |
| train/                  |              |
|    approx_kl            | 28.216686    |
|    clip_fraction        | 0.736        |
|    clip_range           | 0.2          |
|    entropy_loss         | -67.6        |
|    explained_variance   | -1.59        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.379       |
|    n_updates            | 2040         |
|    policy_gradient_loss | 0.213        |
|    reward               | 8.142872e-05 |
|    std                  | 2.74         |
|    value_loss           | 9.08e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2344, episode: 250
begin_total_asset: 200.00
end_total_asset: 218.16
total_reward: 18.16
total_cost: 2.58
total_trades: 47035
Sharpe: 0.250
=================================
Reseting Environment StartDay: 1432, ResetDay: 3112,Episode: 251
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 206           |
|    time_elapsed         | 4666          |
|    total_timesteps      | 421888        |
| train/                  |               |
|    approx_kl            | 67.91543      |
|    clip_fraction        | 0.716         |
|    clip_range           | 0.2           |
|    entropy_loss         | -67.8         |
|    explained_variance   | -1.36         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.526        |
|    n_updates            | 2050          |
|    policy_gradient_loss | 0.155         |
|    reward               | -6.845436e-05 |
|    std                  | 2.76          |
|    value_loss           | 1.02e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1671, ResetDay: 3351,Episode: 252
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 617, ResetDay: 2297,Episode: 253
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 207           |
|    time_elapsed         | 4688          |
|    total_timesteps      | 423936        |
| train/                  |               |
|    approx_kl            | 30.948631     |
|    clip_fraction        | 0.738         |
|    clip_range           | 0.2           |
|    entropy_loss         | -68           |
|    explained_variance   | -0.763        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.464        |
|    n_updates            | 2060          |
|    policy_gradient_loss | 0.497         |
|    reward               | 4.4548367e-05 |
|    std                  | 2.78          |
|    value_loss           | 4.39e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1039, ResetDay: 2719,Episode: 254
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 208          |
|    time_elapsed         | 4711         |
|    total_timesteps      | 425984       |
| train/                  |              |
|    approx_kl            | 58.97473     |
|    clip_fraction        | 0.729        |
|    clip_range           | 0.2          |
|    entropy_loss         | -68.3        |
|    explained_variance   | -1.33        |
|    learning_rate        | 0.00025      |
|    loss                 | 16.7         |
|    n_updates            | 2070         |
|    policy_gradient_loss | 0.907        |
|    reward               | 5.964756e-05 |
|    std                  | 2.8          |
|    value_loss           | 6.83e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2389, ResetDay: 4069,Episode: 255
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 209           |
|    time_elapsed         | 4734          |
|    total_timesteps      | 428032        |
| train/                  |               |
|    approx_kl            | 22.237534     |
|    clip_fraction        | 0.713         |
|    clip_range           | 0.2           |
|    entropy_loss         | -68.4         |
|    explained_variance   | -1.84         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.476        |
|    n_updates            | 2080          |
|    policy_gradient_loss | 0.185         |
|    reward               | 2.0640564e-05 |
|    std                  | 2.8           |
|    value_loss           | 1.12e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4069, episode: 255
begin_total_asset: 200.00
end_total_asset: 404.91
total_reward: 204.91
total_cost: 1.91
total_trades: 47033
Sharpe: 0.644
=================================
Reseting Environment StartDay: 2360, ResetDay: 4040,Episode: 256
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 210           |
|    time_elapsed         | 4756          |
|    total_timesteps      | 430080        |
| train/                  |               |
|    approx_kl            | 30.20361      |
|    clip_fraction        | 0.711         |
|    clip_range           | 0.2           |
|    entropy_loss         | -68.4         |
|    explained_variance   | -0.484        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.531        |
|    n_updates            | 2090          |
|    policy_gradient_loss | 0.175         |
|    reward               | -0.0002810436 |
|    std                  | 2.81          |
|    value_loss           | 4.54e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 22, ResetDay: 1702,Episode: 257
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1599, ResetDay: 3279,Episode: 258
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 211           |
|    time_elapsed         | 4779          |
|    total_timesteps      | 432128        |
| train/                  |               |
|    approx_kl            | 72.49153      |
|    clip_fraction        | 0.716         |
|    clip_range           | 0.2           |
|    entropy_loss         | -68.6         |
|    explained_variance   | -0.0471       |
|    learning_rate        | 0.00025       |
|    loss                 | -0.595        |
|    n_updates            | 2100          |
|    policy_gradient_loss | 0.142         |
|    reward               | -8.031016e-05 |
|    std                  | 2.83          |
|    value_loss           | 6.48e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1619, ResetDay: 3299,Episode: 259
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 212          |
|    time_elapsed         | 4802         |
|    total_timesteps      | 434176       |
| train/                  |              |
|    approx_kl            | 74.16133     |
|    clip_fraction        | 0.754        |
|    clip_range           | 0.2          |
|    entropy_loss         | -68.7        |
|    explained_variance   | -5.06        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.615       |
|    n_updates            | 2110         |
|    policy_gradient_loss | 0.302        |
|    reward               | 3.439846e-05 |
|    std                  | 2.85         |
|    value_loss           | 4.26e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1247, ResetDay: 2927,Episode: 260
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 213            |
|    time_elapsed         | 4824           |
|    total_timesteps      | 436224         |
| train/                  |                |
|    approx_kl            | 28.495054      |
|    clip_fraction        | 0.72           |
|    clip_range           | 0.2            |
|    entropy_loss         | -68.9          |
|    explained_variance   | -0.436         |
|    learning_rate        | 0.00025        |
|    loss                 | -0.525         |
|    n_updates            | 2120           |
|    policy_gradient_loss | 0.23           |
|    reward               | -1.3141251e-05 |
|    std                  | 2.85           |
|    value_loss           | 1.85e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2927, episode: 260
begin_total_asset: 200.00
end_total_asset: 225.25
total_reward: 25.25
total_cost: 1.92
total_trades: 47033
Sharpe: 0.218
=================================
Reseting Environment StartDay: 2485, ResetDay: 4165,Episode: 261
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 214           |
|    time_elapsed         | 4848          |
|    total_timesteps      | 438272        |
| train/                  |               |
|    approx_kl            | 34.360382     |
|    clip_fraction        | 0.729         |
|    clip_range           | 0.2           |
|    entropy_loss         | -68.9         |
|    explained_variance   | -0.688        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.546        |
|    n_updates            | 2130          |
|    policy_gradient_loss | 0.19          |
|    reward               | 0.00028846704 |
|    std                  | 2.86          |
|    value_loss           | 7.02e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 783, ResetDay: 2463,Episode: 262
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 215           |
|    time_elapsed         | 4871          |
|    total_timesteps      | 440320        |
| train/                  |               |
|    approx_kl            | 34.365734     |
|    clip_fraction        | 0.675         |
|    clip_range           | 0.2           |
|    entropy_loss         | -69           |
|    explained_variance   | -0.191        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.395        |
|    n_updates            | 2140          |
|    policy_gradient_loss | 0.199         |
|    reward               | 6.3236235e-05 |
|    std                  | 2.87          |
|    value_loss           | 3.95e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2052, ResetDay: 3732,Episode: 263
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2685, ResetDay: 4365,Episode: 264
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 216           |
|    time_elapsed         | 4893          |
|    total_timesteps      | 442368        |
| train/                  |               |
|    approx_kl            | 92.388916     |
|    clip_fraction        | 0.65          |
|    clip_range           | 0.2           |
|    entropy_loss         | -69.2         |
|    explained_variance   | -1.61         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.577        |
|    n_updates            | 2150          |
|    policy_gradient_loss | 0.127         |
|    reward               | 1.3597107e-05 |
|    std                  | 2.89          |
|    value_loss           | 9e-07         |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2339, ResetDay: 4019,Episode: 265
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 217            |
|    time_elapsed         | 4916           |
|    total_timesteps      | 444416         |
| train/                  |                |
|    approx_kl            | 39.13191       |
|    clip_fraction        | 0.719          |
|    clip_range           | 0.2            |
|    entropy_loss         | -69.3          |
|    explained_variance   | -0.308         |
|    learning_rate        | 0.00025        |
|    loss                 | -0.542         |
|    n_updates            | 2160           |
|    policy_gradient_loss | 0.171          |
|    reward               | -9.8633005e-05 |
|    std                  | 2.9            |
|    value_loss           | 6.87e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4019, episode: 265
begin_total_asset: 200.00
end_total_asset: 233.59
total_reward: 33.59
total_cost: 1.87
total_trades: 47033
Sharpe: 0.220
=================================
Reseting Environment StartDay: 1375, ResetDay: 3055,Episode: 266
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 218           |
|    time_elapsed         | 4939          |
|    total_timesteps      | 446464        |
| train/                  |               |
|    approx_kl            | 49.302345     |
|    clip_fraction        | 0.708         |
|    clip_range           | 0.2           |
|    entropy_loss         | -69.5         |
|    explained_variance   | -0.143        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.633        |
|    n_updates            | 2170          |
|    policy_gradient_loss | 0.179         |
|    reward               | 0.00031076127 |
|    std                  | 2.92          |
|    value_loss           | 6.18e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2702, ResetDay: 4382,Episode: 267
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 219           |
|    time_elapsed         | 4961          |
|    total_timesteps      | 448512        |
| train/                  |               |
|    approx_kl            | 50.37592      |
|    clip_fraction        | 0.696         |
|    clip_range           | 0.2           |
|    entropy_loss         | -69.6         |
|    explained_variance   | -0.531        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.345        |
|    n_updates            | 2180          |
|    policy_gradient_loss | 0.196         |
|    reward               | -6.102905e-05 |
|    std                  | 2.94          |
|    value_loss           | 7.87e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1060, ResetDay: 2740,Episode: 268
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2758, ResetDay: 4438,Episode: 269
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 220          |
|    time_elapsed         | 4984         |
|    total_timesteps      | 450560       |
| train/                  |              |
|    approx_kl            | 38.343155    |
|    clip_fraction        | 0.729        |
|    clip_range           | 0.2          |
|    entropy_loss         | -69.8        |
|    explained_variance   | -0.0471      |
|    learning_rate        | 0.00025      |
|    loss                 | -0.158       |
|    n_updates            | 2190         |
|    policy_gradient_loss | 0.224        |
|    reward               | 6.687355e-05 |
|    std                  | 2.96         |
|    value_loss           | 8.85e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 110, ResetDay: 1790,Episode: 270
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 221           |
|    time_elapsed         | 5006          |
|    total_timesteps      | 452608        |
| train/                  |               |
|    approx_kl            | 129.17216     |
|    clip_fraction        | 0.729         |
|    clip_range           | 0.2           |
|    entropy_loss         | -70           |
|    explained_variance   | -0.782        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.614        |
|    n_updates            | 2200          |
|    policy_gradient_loss | 0.238         |
|    reward               | 1.8287563e-05 |
|    std                  | 2.97          |
|    value_loss           | 3.24e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 1790, episode: 270
begin_total_asset: 200.00
end_total_asset: 160.80
total_reward: -39.20
total_cost: 2.47
total_trades: 47040
Sharpe: 0.145
=================================
Reseting Environment StartDay: 1896, ResetDay: 3576,Episode: 271
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 222           |
|    time_elapsed         | 5029          |
|    total_timesteps      | 454656        |
| train/                  |               |
|    approx_kl            | 41.620846     |
|    clip_fraction        | 0.687         |
|    clip_range           | 0.2           |
|    entropy_loss         | -70.1         |
|    explained_variance   | -0.315        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.492        |
|    n_updates            | 2210          |
|    policy_gradient_loss | 0.184         |
|    reward               | 9.4816205e-06 |
|    std                  | 2.99          |
|    value_loss           | 2.65e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1569, ResetDay: 3249,Episode: 272
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 223            |
|    time_elapsed         | 5051           |
|    total_timesteps      | 456704         |
| train/                  |                |
|    approx_kl            | 27.154572      |
|    clip_fraction        | 0.7            |
|    clip_range           | 0.2            |
|    entropy_loss         | -70.2          |
|    explained_variance   | -1.7           |
|    learning_rate        | 0.00025        |
|    loss                 | 0.896          |
|    n_updates            | 2220           |
|    policy_gradient_loss | 0.252          |
|    reward               | -0.00011924839 |
|    std                  | 3              |
|    value_loss           | 1.27e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 601, ResetDay: 2281,Episode: 273
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 224          |
|    time_elapsed         | 5074         |
|    total_timesteps      | 458752       |
| train/                  |              |
|    approx_kl            | 41.553482    |
|    clip_fraction        | 0.737        |
|    clip_range           | 0.2          |
|    entropy_loss         | -70.4        |
|    explained_variance   | -0.234       |
|    learning_rate        | 0.00025      |
|    loss                 | -0.644       |
|    n_updates            | 2230         |
|    policy_gradient_loss | 0.149        |
|    reward               | 7.955379e-05 |
|    std                  | 3.01         |
|    value_loss           | 9.59e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1280, ResetDay: 2960,Episode: 274
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 717, ResetDay: 2397,Episode: 275
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 225          |
|    time_elapsed         | 5096         |
|    total_timesteps      | 460800       |
| train/                  |              |
|    approx_kl            | 38.103886    |
|    clip_fraction        | 0.692        |
|    clip_range           | 0.2          |
|    entropy_loss         | -70.4        |
|    explained_variance   | -2.15        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.589       |
|    n_updates            | 2240         |
|    policy_gradient_loss | 0.151        |
|    reward               | 3.323555e-05 |
|    std                  | 3.02         |
|    value_loss           | 9.67e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2397, episode: 275
begin_total_asset: 200.00
end_total_asset: 191.51
total_reward: -8.49
total_cost: 1.97
total_trades: 47033
Sharpe: 0.167
=================================
Reseting Environment StartDay: 2457, ResetDay: 4137,Episode: 276
---------------------------------------------
| time/                   |                 |
|    fps                  | 90              |
|    iterations           | 226             |
|    time_elapsed         | 5119            |
|    total_timesteps      | 462848          |
| train/                  |                 |
|    approx_kl            | 33.97284        |
|    clip_fraction        | 0.75            |
|    clip_range           | 0.2             |
|    entropy_loss         | -70.5           |
|    explained_variance   | -0.785          |
|    learning_rate        | 0.00025         |
|    loss                 | -0.597          |
|    n_updates            | 2250            |
|    policy_gradient_loss | 0.366           |
|    reward               | -0.000114342496 |
|    std                  | 3.03            |
|    value_loss           | 1.39e-06        |
---------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 40, ResetDay: 1720,Episode: 277
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 227            |
|    time_elapsed         | 5142           |
|    total_timesteps      | 464896         |
| train/                  |                |
|    approx_kl            | 22.257128      |
|    clip_fraction        | 0.717          |
|    clip_range           | 0.2            |
|    entropy_loss         | -70.6          |
|    explained_variance   | -1.13          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.613         |
|    n_updates            | 2260           |
|    policy_gradient_loss | 0.216          |
|    reward               | -0.00014894304 |
|    std                  | 3.05           |
|    value_loss           | 9.76e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1715, ResetDay: 3395,Episode: 278
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 228           |
|    time_elapsed         | 5164          |
|    total_timesteps      | 466944        |
| train/                  |               |
|    approx_kl            | 50.83422      |
|    clip_fraction        | 0.715         |
|    clip_range           | 0.2           |
|    entropy_loss         | -70.8         |
|    explained_variance   | -1.65         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.563        |
|    n_updates            | 2270          |
|    policy_gradient_loss | 0.157         |
|    reward               | -0.0001112854 |
|    std                  | 3.06          |
|    value_loss           | 2.6e-06       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 358, ResetDay: 2038,Episode: 279
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 229           |
|    time_elapsed         | 5186          |
|    total_timesteps      | 468992        |
| train/                  |               |
|    approx_kl            | 21.835232     |
|    clip_fraction        | 0.711         |
|    clip_range           | 0.2           |
|    entropy_loss         | -70.9         |
|    explained_variance   | -0.735        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.553        |
|    n_updates            | 2280          |
|    policy_gradient_loss | 0.189         |
|    reward               | 0.00010130224 |
|    std                  | 3.08          |
|    value_loss           | 1.09e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2512, ResetDay: 4192,Episode: 280
Environment reached Terminal state as number of trading days reached limit!!
day: 4192, episode: 280
begin_total_asset: 200.00
end_total_asset: 439.53
total_reward: 239.53
total_cost: 1.96
total_trades: 47034
Sharpe: 0.576
=================================
Reseting Environment StartDay: 2352, ResetDay: 4032,Episode: 281
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 230           |
|    time_elapsed         | 5209          |
|    total_timesteps      | 471040        |
| train/                  |               |
|    approx_kl            | 49.36724      |
|    clip_fraction        | 0.737         |
|    clip_range           | 0.2           |
|    entropy_loss         | -71           |
|    explained_variance   | -1.41         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.515        |
|    n_updates            | 2290          |
|    policy_gradient_loss | 0.187         |
|    reward               | -0.0001383316 |
|    std                  | 3.09          |
|    value_loss           | 1.36e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 29, ResetDay: 1709,Episode: 282
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 231          |
|    time_elapsed         | 5232         |
|    total_timesteps      | 473088       |
| train/                  |              |
|    approx_kl            | 38.642715    |
|    clip_fraction        | 0.703        |
|    clip_range           | 0.2          |
|    entropy_loss         | -71.2        |
|    explained_variance   | -0.0685      |
|    learning_rate        | 0.00025      |
|    loss                 | -0.555       |
|    n_updates            | 2300         |
|    policy_gradient_loss | 0.169        |
|    reward               | 6.897745e-05 |
|    std                  | 3.11         |
|    value_loss           | 4.08e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1664, ResetDay: 3344,Episode: 283
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 232           |
|    time_elapsed         | 5254          |
|    total_timesteps      | 475136        |
| train/                  |               |
|    approx_kl            | 37.29818      |
|    clip_fraction        | 0.693         |
|    clip_range           | 0.2           |
|    entropy_loss         | -71.3         |
|    explained_variance   | -2.49         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.629        |
|    n_updates            | 2310          |
|    policy_gradient_loss | 0.162         |
|    reward               | 0.00026156922 |
|    std                  | 3.12          |
|    value_loss           | 1.2e-06       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1007, ResetDay: 2687,Episode: 284
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 233           |
|    time_elapsed         | 5277          |
|    total_timesteps      | 477184        |
| train/                  |               |
|    approx_kl            | 25.280428     |
|    clip_fraction        | 0.747         |
|    clip_range           | 0.2           |
|    entropy_loss         | -71.4         |
|    explained_variance   | -1.56         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.357        |
|    n_updates            | 2320          |
|    policy_gradient_loss | 0.606         |
|    reward               | -5.655422e-05 |
|    std                  | 3.13          |
|    value_loss           | 9.6e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 594, ResetDay: 2274,Episode: 285
Environment reached Terminal state as number of trading days reached limit!!
day: 2274, episode: 285
begin_total_asset: 200.00
end_total_asset: 276.47
total_reward: 76.47
total_cost: 1.98
total_trades: 47040
Sharpe: 0.325
=================================
Reseting Environment StartDay: 1648, ResetDay: 3328,Episode: 286
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 234            |
|    time_elapsed         | 5299           |
|    total_timesteps      | 479232         |
| train/                  |                |
|    approx_kl            | 40.362885      |
|    clip_fraction        | 0.689          |
|    clip_range           | 0.2            |
|    entropy_loss         | -71.5          |
|    explained_variance   | -0.592         |
|    learning_rate        | 0.00025        |
|    loss                 | -0.573         |
|    n_updates            | 2330           |
|    policy_gradient_loss | 0.171          |
|    reward               | -6.7129324e-05 |
|    std                  | 3.14           |
|    value_loss           | 9.32e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1696, ResetDay: 3376,Episode: 287
---------------------------------------------
| time/                   |                 |
|    fps                  | 90              |
|    iterations           | 235             |
|    time_elapsed         | 5322            |
|    total_timesteps      | 481280          |
| train/                  |                 |
|    approx_kl            | 38.95981        |
|    clip_fraction        | 0.718           |
|    clip_range           | 0.2             |
|    entropy_loss         | -71.6           |
|    explained_variance   | -1.44           |
|    learning_rate        | 0.00025         |
|    loss                 | -0.571          |
|    n_updates            | 2340            |
|    policy_gradient_loss | 0.306           |
|    reward               | -0.000113588714 |
|    std                  | 3.15            |
|    value_loss           | 1.95e-06        |
---------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1779, ResetDay: 3459,Episode: 288
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 236          |
|    time_elapsed         | 5345         |
|    total_timesteps      | 483328       |
| train/                  |              |
|    approx_kl            | 27.067299    |
|    clip_fraction        | 0.761        |
|    clip_range           | 0.2          |
|    entropy_loss         | -71.7        |
|    explained_variance   | -0.659       |
|    learning_rate        | 0.00025      |
|    loss                 | -0.523       |
|    n_updates            | 2350         |
|    policy_gradient_loss | 0.242        |
|    reward               | 8.062038e-05 |
|    std                  | 3.18         |
|    value_loss           | 3.05e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2037, ResetDay: 3717,Episode: 289
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 237           |
|    time_elapsed         | 5369          |
|    total_timesteps      | 485376        |
| train/                  |               |
|    approx_kl            | 34.485603     |
|    clip_fraction        | 0.751         |
|    clip_range           | 0.2           |
|    entropy_loss         | -71.9         |
|    explained_variance   | -0.116        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.569        |
|    n_updates            | 2360          |
|    policy_gradient_loss | 0.587         |
|    reward               | -6.395378e-05 |
|    std                  | 3.19          |
|    value_loss           | 4.29e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2630, ResetDay: 4310,Episode: 290
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 238           |
|    time_elapsed         | 5392          |
|    total_timesteps      | 487424        |
| train/                  |               |
|    approx_kl            | 40.539093     |
|    clip_fraction        | 0.787         |
|    clip_range           | 0.2           |
|    entropy_loss         | -72.1         |
|    explained_variance   | -0.144        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.549        |
|    n_updates            | 2370          |
|    policy_gradient_loss | 0.312         |
|    reward               | 8.1246566e-05 |
|    std                  | 3.21          |
|    value_loss           | 9.33e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4310, episode: 290
begin_total_asset: 200.00
end_total_asset: 251.82
total_reward: 51.82
total_cost: 1.83
total_trades: 47033
Sharpe: 0.278
=================================
Reseting Environment StartDay: 792, ResetDay: 2472,Episode: 291
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 150, ResetDay: 1830,Episode: 292
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 239           |
|    time_elapsed         | 5414          |
|    total_timesteps      | 489472        |
| train/                  |               |
|    approx_kl            | 63.33806      |
|    clip_fraction        | 0.738         |
|    clip_range           | 0.2           |
|    entropy_loss         | -72.2         |
|    explained_variance   | -0.145        |
|    learning_rate        | 0.00025       |
|    loss                 | 1.59          |
|    n_updates            | 2380          |
|    policy_gradient_loss | 0.333         |
|    reward               | 5.7075977e-05 |
|    std                  | 3.22          |
|    value_loss           | 1.82e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2688, ResetDay: 4368,Episode: 293
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 240           |
|    time_elapsed         | 5437          |
|    total_timesteps      | 491520        |
| train/                  |               |
|    approx_kl            | 115.05979     |
|    clip_fraction        | 0.729         |
|    clip_range           | 0.2           |
|    entropy_loss         | -72.4         |
|    explained_variance   | -2.05         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.65         |
|    n_updates            | 2390          |
|    policy_gradient_loss | 0.205         |
|    reward               | 0.00030362472 |
|    std                  | 3.25          |
|    value_loss           | 1.41e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2544, ResetDay: 4224,Episode: 294
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 241           |
|    time_elapsed         | 5460          |
|    total_timesteps      | 493568        |
| train/                  |               |
|    approx_kl            | 25.83628      |
|    clip_fraction        | 0.701         |
|    clip_range           | 0.2           |
|    entropy_loss         | -72.5         |
|    explained_variance   | -0.946        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.581        |
|    n_updates            | 2400          |
|    policy_gradient_loss | 0.219         |
|    reward               | 0.00017843628 |
|    std                  | 3.26          |
|    value_loss           | 1.11e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 571, ResetDay: 2251,Episode: 295
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 242          |
|    time_elapsed         | 5482         |
|    total_timesteps      | 495616       |
| train/                  |              |
|    approx_kl            | 65.725845    |
|    clip_fraction        | 0.685        |
|    clip_range           | 0.2          |
|    entropy_loss         | -72.6        |
|    explained_variance   | -0.0941      |
|    learning_rate        | 0.00025      |
|    loss                 | -0.607       |
|    n_updates            | 2410         |
|    policy_gradient_loss | 0.195        |
|    reward               | 6.364784e-05 |
|    std                  | 3.27         |
|    value_loss           | 2.24e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2251, episode: 295
begin_total_asset: 200.00
end_total_asset: 131.25
total_reward: -68.75
total_cost: 3.36
total_trades: 47038
Sharpe: 0.056
=================================
Reseting Environment StartDay: 2697, ResetDay: 4377,Episode: 296
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2171, ResetDay: 3851,Episode: 297
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 243           |
|    time_elapsed         | 5505          |
|    total_timesteps      | 497664        |
| train/                  |               |
|    approx_kl            | 70.7889       |
|    clip_fraction        | 0.702         |
|    clip_range           | 0.2           |
|    entropy_loss         | -72.8         |
|    explained_variance   | -2.16         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.631        |
|    n_updates            | 2420          |
|    policy_gradient_loss | 0.178         |
|    reward               | 1.5421676e-05 |
|    std                  | 3.29          |
|    value_loss           | 9.19e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1041, ResetDay: 2721,Episode: 298
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 244            |
|    time_elapsed         | 5527           |
|    total_timesteps      | 499712         |
| train/                  |                |
|    approx_kl            | 29.866861      |
|    clip_fraction        | 0.744          |
|    clip_range           | 0.2            |
|    entropy_loss         | -72.9          |
|    explained_variance   | -0.13          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.606         |
|    n_updates            | 2430           |
|    policy_gradient_loss | 0.18           |
|    reward               | -0.00012460766 |
|    std                  | 3.3            |
|    value_loss           | 5.7e-06        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1005, ResetDay: 2685,Episode: 299
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 245           |
|    time_elapsed         | 5550          |
|    total_timesteps      | 501760        |
| train/                  |               |
|    approx_kl            | 33.477238     |
|    clip_fraction        | 0.735         |
|    clip_range           | 0.2           |
|    entropy_loss         | -73           |
|    explained_variance   | -1.21         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.62         |
|    n_updates            | 2440          |
|    policy_gradient_loss | 0.229         |
|    reward               | 0.00013458023 |
|    std                  | 3.33          |
|    value_loss           | 7.91e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1113, ResetDay: 2793,Episode: 300
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 246          |
|    time_elapsed         | 5573         |
|    total_timesteps      | 503808       |
| train/                  |              |
|    approx_kl            | 26.972624    |
|    clip_fraction        | 0.696        |
|    clip_range           | 0.2          |
|    entropy_loss         | -73.2        |
|    explained_variance   | -0.781       |
|    learning_rate        | 0.00025      |
|    loss                 | -0.466       |
|    n_updates            | 2450         |
|    policy_gradient_loss | 0.221        |
|    reward               | 8.454743e-05 |
|    std                  | 3.34         |
|    value_loss           | 8.84e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2793, episode: 300
begin_total_asset: 200.00
end_total_asset: 258.94
total_reward: 58.94
total_cost: 1.94
total_trades: 47033
Sharpe: 0.314
=================================
Reseting Environment StartDay: 751, ResetDay: 2431,Episode: 301
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 247           |
|    time_elapsed         | 5595          |
|    total_timesteps      | 505856        |
| train/                  |               |
|    approx_kl            | 26.667448     |
|    clip_fraction        | 0.704         |
|    clip_range           | 0.2           |
|    entropy_loss         | -73.4         |
|    explained_variance   | -0.579        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.599        |
|    n_updates            | 2460          |
|    policy_gradient_loss | 0.294         |
|    reward               | 2.3204802e-06 |
|    std                  | 3.36          |
|    value_loss           | 5.64e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 38, ResetDay: 1718,Episode: 302
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1534, ResetDay: 3214,Episode: 303
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 248            |
|    time_elapsed         | 5618           |
|    total_timesteps      | 507904         |
| train/                  |                |
|    approx_kl            | 34.317795      |
|    clip_fraction        | 0.716          |
|    clip_range           | 0.2            |
|    entropy_loss         | -73.6          |
|    explained_variance   | -0.77          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.596         |
|    n_updates            | 2470           |
|    policy_gradient_loss | 0.217          |
|    reward               | -3.4187316e-05 |
|    std                  | 3.39           |
|    value_loss           | 7.23e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 94, ResetDay: 1774,Episode: 304
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 249            |
|    time_elapsed         | 5640           |
|    total_timesteps      | 509952         |
| train/                  |                |
|    approx_kl            | 33.386482      |
|    clip_fraction        | 0.718          |
|    clip_range           | 0.2            |
|    entropy_loss         | -73.7          |
|    explained_variance   | -2.17          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.559         |
|    n_updates            | 2480           |
|    policy_gradient_loss | 0.162          |
|    reward               | -1.9558096e-05 |
|    std                  | 3.41           |
|    value_loss           | 1.39e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2676, ResetDay: 4356,Episode: 305
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 250           |
|    time_elapsed         | 5663          |
|    total_timesteps      | 512000        |
| train/                  |               |
|    approx_kl            | 27.157364     |
|    clip_fraction        | 0.723         |
|    clip_range           | 0.2           |
|    entropy_loss         | -73.9         |
|    explained_variance   | -0.782        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.573        |
|    n_updates            | 2490          |
|    policy_gradient_loss | 0.259         |
|    reward               | 0.00039366074 |
|    std                  | 3.42          |
|    value_loss           | 1.69e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4356, episode: 305
begin_total_asset: 200.00
end_total_asset: 610.28
total_reward: 410.28
total_cost: 1.89
total_trades: 47033
Sharpe: 0.641
=================================
Reseting Environment StartDay: 466, ResetDay: 2146,Episode: 306
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 251           |
|    time_elapsed         | 5685          |
|    total_timesteps      | 514048        |
| train/                  |               |
|    approx_kl            | 24.72154      |
|    clip_fraction        | 0.719         |
|    clip_range           | 0.2           |
|    entropy_loss         | -74           |
|    explained_variance   | -0.766        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.315        |
|    n_updates            | 2500          |
|    policy_gradient_loss | 0.219         |
|    reward               | 0.00021523323 |
|    std                  | 3.43          |
|    value_loss           | 2.74e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 166, ResetDay: 1846,Episode: 307
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1051, ResetDay: 2731,Episode: 308
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 252           |
|    time_elapsed         | 5708          |
|    total_timesteps      | 516096        |
| train/                  |               |
|    approx_kl            | 66.921974     |
|    clip_fraction        | 0.683         |
|    clip_range           | 0.2           |
|    entropy_loss         | -74.1         |
|    explained_variance   | -0.455        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.567        |
|    n_updates            | 2510          |
|    policy_gradient_loss | 0.152         |
|    reward               | 3.3461856e-05 |
|    std                  | 3.45          |
|    value_loss           | 1.7e-06       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2213, ResetDay: 3893,Episode: 309
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 253           |
|    time_elapsed         | 5730          |
|    total_timesteps      | 518144        |
| train/                  |               |
|    approx_kl            | 26.365726     |
|    clip_fraction        | 0.73          |
|    clip_range           | 0.2           |
|    entropy_loss         | -74.2         |
|    explained_variance   | -1.99         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.666        |
|    n_updates            | 2520          |
|    policy_gradient_loss | 0.168         |
|    reward               | 4.8156166e-05 |
|    std                  | 3.47          |
|    value_loss           | 1.16e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2361, ResetDay: 4041,Episode: 310
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 254           |
|    time_elapsed         | 5753          |
|    total_timesteps      | 520192        |
| train/                  |               |
|    approx_kl            | 23.756056     |
|    clip_fraction        | 0.734         |
|    clip_range           | 0.2           |
|    entropy_loss         | -74.4         |
|    explained_variance   | -0.395        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.366        |
|    n_updates            | 2530          |
|    policy_gradient_loss | 0.291         |
|    reward               | -4.355869e-05 |
|    std                  | 3.49          |
|    value_loss           | 9.62e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4041, episode: 310
begin_total_asset: 200.00
end_total_asset: 250.14
total_reward: 50.14
total_cost: 1.84
total_trades: 47033
Sharpe: 0.271
=================================
Reseting Environment StartDay: 1116, ResetDay: 2796,Episode: 311
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 255            |
|    time_elapsed         | 5775           |
|    total_timesteps      | 522240         |
| train/                  |                |
|    approx_kl            | 34.613995      |
|    clip_fraction        | 0.745          |
|    clip_range           | 0.2            |
|    entropy_loss         | -74.5          |
|    explained_variance   | -0.313         |
|    learning_rate        | 0.00025        |
|    loss                 | -0.602         |
|    n_updates            | 2540           |
|    policy_gradient_loss | 0.221          |
|    reward               | -6.6860965e-05 |
|    std                  | 3.51           |
|    value_loss           | 1.04e-05       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2021, ResetDay: 3701,Episode: 312
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 256            |
|    time_elapsed         | 5798           |
|    total_timesteps      | 524288         |
| train/                  |                |
|    approx_kl            | 48.003155      |
|    clip_fraction        | 0.731          |
|    clip_range           | 0.2            |
|    entropy_loss         | -74.7          |
|    explained_variance   | -1.23          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.68          |
|    n_updates            | 2550           |
|    policy_gradient_loss | 0.173          |
|    reward               | -0.00016704139 |
|    std                  | 3.53           |
|    value_loss           | 6.51e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 953, ResetDay: 2633,Episode: 313
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2052, ResetDay: 3732,Episode: 314
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 257           |
|    time_elapsed         | 5821          |
|    total_timesteps      | 526336        |
| train/                  |               |
|    approx_kl            | 32.421642     |
|    clip_fraction        | 0.727         |
|    clip_range           | 0.2           |
|    entropy_loss         | -74.9         |
|    explained_variance   | -0.314        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.546        |
|    n_updates            | 2560          |
|    policy_gradient_loss | 0.216         |
|    reward               | -5.443573e-05 |
|    std                  | 3.54          |
|    value_loss           | 3.65e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2412, ResetDay: 4092,Episode: 315
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 258           |
|    time_elapsed         | 5843          |
|    total_timesteps      | 528384        |
| train/                  |               |
|    approx_kl            | 62.872723     |
|    clip_fraction        | 0.751         |
|    clip_range           | 0.2           |
|    entropy_loss         | -75           |
|    explained_variance   | -0.896        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.47         |
|    n_updates            | 2570          |
|    policy_gradient_loss | 0.231         |
|    reward               | 2.9004288e-05 |
|    std                  | 3.55          |
|    value_loss           | 7.71e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4092, episode: 315
begin_total_asset: 200.00
end_total_asset: 288.39
total_reward: 88.39
total_cost: 1.93
total_trades: 47033
Sharpe: 0.371
=================================
Reseting Environment StartDay: 1935, ResetDay: 3615,Episode: 316
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 259           |
|    time_elapsed         | 5866          |
|    total_timesteps      | 530432        |
| train/                  |               |
|    approx_kl            | 31.572899     |
|    clip_fraction        | 0.67          |
|    clip_range           | 0.2           |
|    entropy_loss         | -75.1         |
|    explained_variance   | -0.276        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.588        |
|    n_updates            | 2580          |
|    policy_gradient_loss | 0.156         |
|    reward               | -3.967819e-05 |
|    std                  | 3.57          |
|    value_loss           | 3.16e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1094, ResetDay: 2774,Episode: 317
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 260           |
|    time_elapsed         | 5888          |
|    total_timesteps      | 532480        |
| train/                  |               |
|    approx_kl            | 40.938206     |
|    clip_fraction        | 0.714         |
|    clip_range           | 0.2           |
|    entropy_loss         | -75.2         |
|    explained_variance   | -0.108        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.0893       |
|    n_updates            | 2590          |
|    policy_gradient_loss | 0.216         |
|    reward               | 3.7950515e-06 |
|    std                  | 3.59          |
|    value_loss           | 6.57e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1061, ResetDay: 2741,Episode: 318
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 261           |
|    time_elapsed         | 5911          |
|    total_timesteps      | 534528        |
| train/                  |               |
|    approx_kl            | 37.64695      |
|    clip_fraction        | 0.745         |
|    clip_range           | 0.2           |
|    entropy_loss         | -75.3         |
|    explained_variance   | -1.1          |
|    learning_rate        | 0.00025       |
|    loss                 | -0.693        |
|    n_updates            | 2600          |
|    policy_gradient_loss | 0.172         |
|    reward               | -0.0001761284 |
|    std                  | 3.6           |
|    value_loss           | 1.44e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 836, ResetDay: 2516,Episode: 319
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 72, ResetDay: 1752,Episode: 320
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 262          |
|    time_elapsed         | 5934         |
|    total_timesteps      | 536576       |
| train/                  |              |
|    approx_kl            | 32.858456    |
|    clip_fraction        | 0.737        |
|    clip_range           | 0.2          |
|    entropy_loss         | -75.4        |
|    explained_variance   | -1.13        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.552       |
|    n_updates            | 2610         |
|    policy_gradient_loss | 0.202        |
|    reward               | 3.638277e-05 |
|    std                  | 3.61         |
|    value_loss           | 2.75e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 1752, episode: 320
begin_total_asset: 200.00
end_total_asset: 170.61
total_reward: -29.39
total_cost: 1.97
total_trades: 47033
Sharpe: 0.075
=================================
Reseting Environment StartDay: 1563, ResetDay: 3243,Episode: 321
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 263           |
|    time_elapsed         | 5956          |
|    total_timesteps      | 538624        |
| train/                  |               |
|    approx_kl            | 33.069275     |
|    clip_fraction        | 0.674         |
|    clip_range           | 0.2           |
|    entropy_loss         | -75.5         |
|    explained_variance   | -1.71         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.632        |
|    n_updates            | 2620          |
|    policy_gradient_loss | 0.148         |
|    reward               | 1.2245179e-06 |
|    std                  | 3.63          |
|    value_loss           | 1.08e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2310, ResetDay: 3990,Episode: 322
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 264           |
|    time_elapsed         | 5979          |
|    total_timesteps      | 540672        |
| train/                  |               |
|    approx_kl            | 24.669073     |
|    clip_fraction        | 0.716         |
|    clip_range           | 0.2           |
|    entropy_loss         | -75.6         |
|    explained_variance   | -1.44         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.502        |
|    n_updates            | 2630          |
|    policy_gradient_loss | 0.187         |
|    reward               | 0.00012895584 |
|    std                  | 3.64          |
|    value_loss           | 7.5e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2787, ResetDay: 4467,Episode: 323
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 265           |
|    time_elapsed         | 6001          |
|    total_timesteps      | 542720        |
| train/                  |               |
|    approx_kl            | 31.488506     |
|    clip_fraction        | 0.661         |
|    clip_range           | 0.2           |
|    entropy_loss         | -75.7         |
|    explained_variance   | -0.164        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.567        |
|    n_updates            | 2640          |
|    policy_gradient_loss | 0.148         |
|    reward               | 1.6231917e-05 |
|    std                  | 3.66          |
|    value_loss           | 5.75e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1840, ResetDay: 3520,Episode: 324
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 223, ResetDay: 1903,Episode: 325
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 266           |
|    time_elapsed         | 6024          |
|    total_timesteps      | 544768        |
| train/                  |               |
|    approx_kl            | 59.02474      |
|    clip_fraction        | 0.745         |
|    clip_range           | 0.2           |
|    entropy_loss         | -75.8         |
|    explained_variance   | -0.0636       |
|    learning_rate        | 0.00025       |
|    loss                 | -0.652        |
|    n_updates            | 2650          |
|    policy_gradient_loss | 0.343         |
|    reward               | 3.2799362e-05 |
|    std                  | 3.66          |
|    value_loss           | 3.07e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 1903, episode: 325
begin_total_asset: 200.00
end_total_asset: 159.18
total_reward: -40.82
total_cost: 2.28
total_trades: 47040
Sharpe: 0.102
=================================
Reseting Environment StartDay: 124, ResetDay: 1804,Episode: 326
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 267          |
|    time_elapsed         | 6047         |
|    total_timesteps      | 546816       |
| train/                  |              |
|    approx_kl            | 100.48409    |
|    clip_fraction        | 0.741        |
|    clip_range           | 0.2          |
|    entropy_loss         | -75.9        |
|    explained_variance   | -0.99        |
|    learning_rate        | 0.00025      |
|    loss                 | 1.19         |
|    n_updates            | 2660         |
|    policy_gradient_loss | 0.275        |
|    reward               | 0.0003505721 |
|    std                  | 3.69         |
|    value_loss           | 1.29e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1433, ResetDay: 3113,Episode: 327
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 268            |
|    time_elapsed         | 6069           |
|    total_timesteps      | 548864         |
| train/                  |                |
|    approx_kl            | 22.754341      |
|    clip_fraction        | 0.692          |
|    clip_range           | 0.2            |
|    entropy_loss         | -76.1          |
|    explained_variance   | -4.81          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.534         |
|    n_updates            | 2670           |
|    policy_gradient_loss | 0.165          |
|    reward               | -0.00012159462 |
|    std                  | 3.71           |
|    value_loss           | 1.04e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2124, ResetDay: 3804,Episode: 328
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 269            |
|    time_elapsed         | 6091           |
|    total_timesteps      | 550912         |
| train/                  |                |
|    approx_kl            | 24.983284      |
|    clip_fraction        | 0.738          |
|    clip_range           | 0.2            |
|    entropy_loss         | -76.3          |
|    explained_variance   | -1.09          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.66          |
|    n_updates            | 2680           |
|    policy_gradient_loss | 0.152          |
|    reward               | -4.5520783e-06 |
|    std                  | 3.72           |
|    value_loss           | 7.55e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 285, ResetDay: 1965,Episode: 329
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 270           |
|    time_elapsed         | 6114          |
|    total_timesteps      | 552960        |
| train/                  |               |
|    approx_kl            | 30.795052     |
|    clip_fraction        | 0.703         |
|    clip_range           | 0.2           |
|    entropy_loss         | -76.4         |
|    explained_variance   | -0.165        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.443        |
|    n_updates            | 2690          |
|    policy_gradient_loss | 0.162         |
|    reward               | 7.8366276e-05 |
|    std                  | 3.74          |
|    value_loss           | 5.31e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2031, ResetDay: 3711,Episode: 330
Environment reached Terminal state as number of trading days reached limit!!
day: 3711, episode: 330
begin_total_asset: 200.00
end_total_asset: 556.82
total_reward: 356.82
total_cost: 1.91
total_trades: 47040
Sharpe: 0.947
=================================
Reseting Environment StartDay: 1952, ResetDay: 3632,Episode: 331
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 271           |
|    time_elapsed         | 6137          |
|    total_timesteps      | 555008        |
| train/                  |               |
|    approx_kl            | 54.881733     |
|    clip_fraction        | 0.699         |
|    clip_range           | 0.2           |
|    entropy_loss         | -76.5         |
|    explained_variance   | -1.79         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.604        |
|    n_updates            | 2700          |
|    policy_gradient_loss | 0.278         |
|    reward               | -4.658699e-05 |
|    std                  | 3.75          |
|    value_loss           | 1.52e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2123, ResetDay: 3803,Episode: 332
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 272          |
|    time_elapsed         | 6159         |
|    total_timesteps      | 557056       |
| train/                  |              |
|    approx_kl            | 27.212418    |
|    clip_fraction        | 0.736        |
|    clip_range           | 0.2          |
|    entropy_loss         | -76.6        |
|    explained_variance   | -0.0767      |
|    learning_rate        | 0.00025      |
|    loss                 | -0.559       |
|    n_updates            | 2710         |
|    policy_gradient_loss | 0.268        |
|    reward               | 7.020912e-05 |
|    std                  | 3.76         |
|    value_loss           | 2.85e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2307, ResetDay: 3987,Episode: 333
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 273           |
|    time_elapsed         | 6182          |
|    total_timesteps      | 559104        |
| train/                  |               |
|    approx_kl            | 30.799593     |
|    clip_fraction        | 0.668         |
|    clip_range           | 0.2           |
|    entropy_loss         | -76.6         |
|    explained_variance   | -0.607        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.684        |
|    n_updates            | 2720          |
|    policy_gradient_loss | 0.164         |
|    reward               | 2.0722198e-05 |
|    std                  | 3.77          |
|    value_loss           | 7.68e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2553, ResetDay: 4233,Episode: 334
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 274          |
|    time_elapsed         | 6204         |
|    total_timesteps      | 561152       |
| train/                  |              |
|    approx_kl            | 35.22357     |
|    clip_fraction        | 0.697        |
|    clip_range           | 0.2          |
|    entropy_loss         | -76.7        |
|    explained_variance   | -0.0555      |
|    learning_rate        | 0.00025      |
|    loss                 | -0.624       |
|    n_updates            | 2730         |
|    policy_gradient_loss | 0.194        |
|    reward               | 0.0001519577 |
|    std                  | 3.79         |
|    value_loss           | 5.54e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2174, ResetDay: 3854,Episode: 335
Environment reached Terminal state as number of trading days reached limit!!
day: 3854, episode: 335
begin_total_asset: 200.00
end_total_asset: 173.09
total_reward: -26.91
total_cost: 1.87
total_trades: 47040
Sharpe: 0.049
=================================
Reseting Environment StartDay: 216, ResetDay: 1896,Episode: 336
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 275            |
|    time_elapsed         | 6227           |
|    total_timesteps      | 563200         |
| train/                  |                |
|    approx_kl            | 52.632454      |
|    clip_fraction        | 0.674          |
|    clip_range           | 0.2            |
|    entropy_loss         | -76.9          |
|    explained_variance   | -0.0796        |
|    learning_rate        | 0.00025        |
|    loss                 | -0.00927       |
|    n_updates            | 2740           |
|    policy_gradient_loss | 0.21           |
|    reward               | -0.00014673905 |
|    std                  | 3.82           |
|    value_loss           | 5.62e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1771, ResetDay: 3451,Episode: 337
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 276            |
|    time_elapsed         | 6250           |
|    total_timesteps      | 565248         |
| train/                  |                |
|    approx_kl            | 70.476456      |
|    clip_fraction        | 0.713          |
|    clip_range           | 0.2            |
|    entropy_loss         | -77.1          |
|    explained_variance   | -0.34          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.186         |
|    n_updates            | 2750           |
|    policy_gradient_loss | 0.268          |
|    reward               | -0.00013355637 |
|    std                  | 3.84           |
|    value_loss           | 6.41e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2075, ResetDay: 3755,Episode: 338
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 277           |
|    time_elapsed         | 6272          |
|    total_timesteps      | 567296        |
| train/                  |               |
|    approx_kl            | 22.768711     |
|    clip_fraction        | 0.744         |
|    clip_range           | 0.2           |
|    entropy_loss         | -77.2         |
|    explained_variance   | -3.66         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.645        |
|    n_updates            | 2760          |
|    policy_gradient_loss | 0.183         |
|    reward               | 2.4557114e-06 |
|    std                  | 3.86          |
|    value_loss           | 8.66e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2065, ResetDay: 3745,Episode: 339
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 278            |
|    time_elapsed         | 6295           |
|    total_timesteps      | 569344         |
| train/                  |                |
|    approx_kl            | 29.761127      |
|    clip_fraction        | 0.699          |
|    clip_range           | 0.2            |
|    entropy_loss         | -77.4          |
|    explained_variance   | -0.111         |
|    learning_rate        | 0.00025        |
|    loss                 | -0.626         |
|    n_updates            | 2770           |
|    policy_gradient_loss | 0.179          |
|    reward               | -0.00022487107 |
|    std                  | 3.88           |
|    value_loss           | 1.13e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 759, ResetDay: 2439,Episode: 340
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 279          |
|    time_elapsed         | 6317         |
|    total_timesteps      | 571392       |
| train/                  |              |
|    approx_kl            | 35.26542     |
|    clip_fraction        | 0.702        |
|    clip_range           | 0.2          |
|    entropy_loss         | -77.5        |
|    explained_variance   | -0.22        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.643       |
|    n_updates            | 2780         |
|    policy_gradient_loss | 0.146        |
|    reward               | 1.439209e-05 |
|    std                  | 3.89         |
|    value_loss           | 3.57e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2439, episode: 340
begin_total_asset: 200.00
end_total_asset: 241.23
total_reward: 41.23
total_cost: 3.12
total_trades: 47036
Sharpe: 0.273
=================================
Reseting Environment StartDay: 1084, ResetDay: 2764,Episode: 341
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1197, ResetDay: 2877,Episode: 342
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 280            |
|    time_elapsed         | 6340           |
|    total_timesteps      | 573440         |
| train/                  |                |
|    approx_kl            | 49.88852       |
|    clip_fraction        | 0.664          |
|    clip_range           | 0.2            |
|    entropy_loss         | -77.6          |
|    explained_variance   | -1.15          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.55          |
|    n_updates            | 2790           |
|    policy_gradient_loss | 0.188          |
|    reward               | -0.00014033222 |
|    std                  | 3.9            |
|    value_loss           | 1.09e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 673, ResetDay: 2353,Episode: 343
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 281          |
|    time_elapsed         | 6362         |
|    total_timesteps      | 575488       |
| train/                  |              |
|    approx_kl            | 30.91645     |
|    clip_fraction        | 0.688        |
|    clip_range           | 0.2          |
|    entropy_loss         | -77.7        |
|    explained_variance   | -0.405       |
|    learning_rate        | 0.00025      |
|    loss                 | -0.502       |
|    n_updates            | 2800         |
|    policy_gradient_loss | 0.167        |
|    reward               | 8.036146e-05 |
|    std                  | 3.92         |
|    value_loss           | 7.84e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1405, ResetDay: 3085,Episode: 344
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 282           |
|    time_elapsed         | 6385          |
|    total_timesteps      | 577536        |
| train/                  |               |
|    approx_kl            | 25.31664      |
|    clip_fraction        | 0.705         |
|    clip_range           | 0.2           |
|    entropy_loss         | -77.8         |
|    explained_variance   | -0.506        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.623        |
|    n_updates            | 2810          |
|    policy_gradient_loss | 0.195         |
|    reward               | 0.00011043968 |
|    std                  | 3.93          |
|    value_loss           | 6.28e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1339, ResetDay: 3019,Episode: 345
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 283           |
|    time_elapsed         | 6407          |
|    total_timesteps      | 579584        |
| train/                  |               |
|    approx_kl            | 24.781595     |
|    clip_fraction        | 0.704         |
|    clip_range           | 0.2           |
|    entropy_loss         | -77.9         |
|    explained_variance   | -0.636        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.504        |
|    n_updates            | 2820          |
|    policy_gradient_loss | 0.232         |
|    reward               | 0.00024936371 |
|    std                  | 3.95          |
|    value_loss           | 1.28e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3019, episode: 345
begin_total_asset: 200.00
end_total_asset: 224.92
total_reward: 24.92
total_cost: 2.45
total_trades: 47034
Sharpe: 0.234
=================================
Reseting Environment StartDay: 539, ResetDay: 2219,Episode: 346
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2728, ResetDay: 4408,Episode: 347
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 284           |
|    time_elapsed         | 6430          |
|    total_timesteps      | 581632        |
| train/                  |               |
|    approx_kl            | 31.328247     |
|    clip_fraction        | 0.703         |
|    clip_range           | 0.2           |
|    entropy_loss         | -78           |
|    explained_variance   | -0.459        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.728        |
|    n_updates            | 2830          |
|    policy_gradient_loss | 0.153         |
|    reward               | 0.00021764755 |
|    std                  | 3.97          |
|    value_loss           | 6.91e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1529, ResetDay: 3209,Episode: 348
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 285            |
|    time_elapsed         | 6452           |
|    total_timesteps      | 583680         |
| train/                  |                |
|    approx_kl            | 33.453472      |
|    clip_fraction        | 0.69           |
|    clip_range           | 0.2            |
|    entropy_loss         | -78.2          |
|    explained_variance   | -1.68          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.682         |
|    n_updates            | 2840           |
|    policy_gradient_loss | 0.179          |
|    reward               | -7.1050265e-05 |
|    std                  | 4              |
|    value_loss           | 8.11e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2332, ResetDay: 4012,Episode: 349
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 286          |
|    time_elapsed         | 6475         |
|    total_timesteps      | 585728       |
| train/                  |              |
|    approx_kl            | 32.076607    |
|    clip_fraction        | 0.718        |
|    clip_range           | 0.2          |
|    entropy_loss         | -78.3        |
|    explained_variance   | -0.122       |
|    learning_rate        | 0.00025      |
|    loss                 | -0.535       |
|    n_updates            | 2850         |
|    policy_gradient_loss | 0.234        |
|    reward               | 0.0001139307 |
|    std                  | 4.01         |
|    value_loss           | 9.02e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2719, ResetDay: 4399,Episode: 350
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 287            |
|    time_elapsed         | 6497           |
|    total_timesteps      | 587776         |
| train/                  |                |
|    approx_kl            | 26.091604      |
|    clip_fraction        | 0.713          |
|    clip_range           | 0.2            |
|    entropy_loss         | -78.4          |
|    explained_variance   | -1.2           |
|    learning_rate        | 0.00025        |
|    loss                 | -0.556         |
|    n_updates            | 2860           |
|    policy_gradient_loss | 0.269          |
|    reward               | -3.9660645e-05 |
|    std                  | 4.03           |
|    value_loss           | 1.3e-05        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4399, episode: 350
begin_total_asset: 200.00
end_total_asset: 213.03
total_reward: 13.03
total_cost: 1.93
total_trades: 47033
Sharpe: 0.161
=================================
Reseting Environment StartDay: 886, ResetDay: 2566,Episode: 351
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 288            |
|    time_elapsed         | 6520           |
|    total_timesteps      | 589824         |
| train/                  |                |
|    approx_kl            | 40.156128      |
|    clip_fraction        | 0.697          |
|    clip_range           | 0.2            |
|    entropy_loss         | -78.6          |
|    explained_variance   | -0.031         |
|    learning_rate        | 0.00025        |
|    loss                 | -0.678         |
|    n_updates            | 2870           |
|    policy_gradient_loss | 0.143          |
|    reward               | -5.0881194e-05 |
|    std                  | 4.06           |
|    value_loss           | 1.48e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 829, ResetDay: 2509,Episode: 352
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2321, ResetDay: 4001,Episode: 353
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 289            |
|    time_elapsed         | 6543           |
|    total_timesteps      | 591872         |
| train/                  |                |
|    approx_kl            | 53.90066       |
|    clip_fraction        | 0.7            |
|    clip_range           | 0.2            |
|    entropy_loss         | -78.8          |
|    explained_variance   | -1.14          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.618         |
|    n_updates            | 2880           |
|    policy_gradient_loss | 0.145          |
|    reward               | -0.00013855877 |
|    std                  | 4.09           |
|    value_loss           | 2.1e-06        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 124, ResetDay: 1804,Episode: 354
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 290          |
|    time_elapsed         | 6565         |
|    total_timesteps      | 593920       |
| train/                  |              |
|    approx_kl            | 31.038265    |
|    clip_fraction        | 0.737        |
|    clip_range           | 0.2          |
|    entropy_loss         | -79          |
|    explained_variance   | -0.366       |
|    learning_rate        | 0.00025      |
|    loss                 | -0.635       |
|    n_updates            | 2890         |
|    policy_gradient_loss | 0.171        |
|    reward               | 0.0001152152 |
|    std                  | 4.11         |
|    value_loss           | 1.27e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1359, ResetDay: 3039,Episode: 355
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 291            |
|    time_elapsed         | 6588           |
|    total_timesteps      | 595968         |
| train/                  |                |
|    approx_kl            | 32.333008      |
|    clip_fraction        | 0.721          |
|    clip_range           | 0.2            |
|    entropy_loss         | -79.1          |
|    explained_variance   | -1.04          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.713         |
|    n_updates            | 2900           |
|    policy_gradient_loss | 0.229          |
|    reward               | -0.00023140603 |
|    std                  | 4.13           |
|    value_loss           | 3.14e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3039, episode: 355
begin_total_asset: 200.00
end_total_asset: 408.31
total_reward: 208.31
total_cost: 2.27
total_trades: 47034
Sharpe: 0.707
=================================
Reseting Environment StartDay: 1197, ResetDay: 2877,Episode: 356
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 292           |
|    time_elapsed         | 6610          |
|    total_timesteps      | 598016        |
| train/                  |               |
|    approx_kl            | 24.143684     |
|    clip_fraction        | 0.744         |
|    clip_range           | 0.2           |
|    entropy_loss         | -79.2         |
|    explained_variance   | -0.973        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.702        |
|    n_updates            | 2910          |
|    policy_gradient_loss | 0.159         |
|    reward               | 1.6895103e-05 |
|    std                  | 4.14          |
|    value_loss           | 8.41e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2388, ResetDay: 4068,Episode: 357
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 293            |
|    time_elapsed         | 6633           |
|    total_timesteps      | 600064         |
| train/                  |                |
|    approx_kl            | 29.059155      |
|    clip_fraction        | 0.691          |
|    clip_range           | 0.2            |
|    entropy_loss         | -79.4          |
|    explained_variance   | -0.291         |
|    learning_rate        | 0.00025        |
|    loss                 | -0.587         |
|    n_updates            | 2920           |
|    policy_gradient_loss | 0.247          |
|    reward               | -0.00039515304 |
|    std                  | 4.17           |
|    value_loss           | 8.2e-07        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 391, ResetDay: 2071,Episode: 358
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1207, ResetDay: 2887,Episode: 359
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 294            |
|    time_elapsed         | 6656           |
|    total_timesteps      | 602112         |
| train/                  |                |
|    approx_kl            | 31.331154      |
|    clip_fraction        | 0.73           |
|    clip_range           | 0.2            |
|    entropy_loss         | -79.5          |
|    explained_variance   | -0.0645        |
|    learning_rate        | 0.00025        |
|    loss                 | -0.499         |
|    n_updates            | 2930           |
|    policy_gradient_loss | 0.17           |
|    reward               | -2.5794601e-05 |
|    std                  | 4.19           |
|    value_loss           | 8.7e-07        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2045, ResetDay: 3725,Episode: 360
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 295           |
|    time_elapsed         | 6678          |
|    total_timesteps      | 604160        |
| train/                  |               |
|    approx_kl            | 72.77884      |
|    clip_fraction        | 0.715         |
|    clip_range           | 0.2           |
|    entropy_loss         | -79.6         |
|    explained_variance   | -1.35         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.642        |
|    n_updates            | 2940          |
|    policy_gradient_loss | 0.154         |
|    reward               | 0.00040812988 |
|    std                  | 4.2           |
|    value_loss           | 1.05e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3725, episode: 360
begin_total_asset: 200.00
end_total_asset: 294.27
total_reward: 94.27
total_cost: 1.87
total_trades: 47033
Sharpe: 0.459
=================================
Reseting Environment StartDay: 2242, ResetDay: 3922,Episode: 361
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 296           |
|    time_elapsed         | 6701          |
|    total_timesteps      | 606208        |
| train/                  |               |
|    approx_kl            | 24.338064     |
|    clip_fraction        | 0.742         |
|    clip_range           | 0.2           |
|    entropy_loss         | -79.7         |
|    explained_variance   | -0.165        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.682        |
|    n_updates            | 2950          |
|    policy_gradient_loss | 0.185         |
|    reward               | 0.00032406882 |
|    std                  | 4.22          |
|    value_loss           | 4.41e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1680, ResetDay: 3360,Episode: 362
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 297           |
|    time_elapsed         | 6723          |
|    total_timesteps      | 608256        |
| train/                  |               |
|    approx_kl            | 30.175323     |
|    clip_fraction        | 0.72          |
|    clip_range           | 0.2           |
|    entropy_loss         | -79.8         |
|    explained_variance   | -0.171        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.735        |
|    n_updates            | 2960          |
|    policy_gradient_loss | 0.155         |
|    reward               | -9.846878e-05 |
|    std                  | 4.23          |
|    value_loss           | 3.83e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 861, ResetDay: 2541,Episode: 363
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2178, ResetDay: 3858,Episode: 364
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 298           |
|    time_elapsed         | 6746          |
|    total_timesteps      | 610304        |
| train/                  |               |
|    approx_kl            | 45.02871      |
|    clip_fraction        | 0.743         |
|    clip_range           | 0.2           |
|    entropy_loss         | -79.9         |
|    explained_variance   | -0.0864       |
|    learning_rate        | 0.00025       |
|    loss                 | -0.579        |
|    n_updates            | 2970          |
|    policy_gradient_loss | 0.167         |
|    reward               | 0.00010253162 |
|    std                  | 4.25          |
|    value_loss           | 5.06e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 198, ResetDay: 1878,Episode: 365
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 299            |
|    time_elapsed         | 6768           |
|    total_timesteps      | 612352         |
| train/                  |                |
|    approx_kl            | 38.508408      |
|    clip_fraction        | 0.715          |
|    clip_range           | 0.2            |
|    entropy_loss         | -80.1          |
|    explained_variance   | -0.633         |
|    learning_rate        | 0.00025        |
|    loss                 | -0.717         |
|    n_updates            | 2980           |
|    policy_gradient_loss | 0.183          |
|    reward               | -0.00011856384 |
|    std                  | 4.27           |
|    value_loss           | 5.8e-07        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 1878, episode: 365
begin_total_asset: 200.00
end_total_asset: 188.25
total_reward: -11.75
total_cost: 2.66
total_trades: 47039
Sharpe: 0.149
=================================
Reseting Environment StartDay: 17, ResetDay: 1697,Episode: 366
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 300           |
|    time_elapsed         | 6791          |
|    total_timesteps      | 614400        |
| train/                  |               |
|    approx_kl            | 28.459244     |
|    clip_fraction        | 0.715         |
|    clip_range           | 0.2           |
|    entropy_loss         | -80.2         |
|    explained_variance   | -0.683        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.602        |
|    n_updates            | 2990          |
|    policy_gradient_loss | 0.162         |
|    reward               | -7.972708e-05 |
|    std                  | 4.3           |
|    value_loss           | 8.67e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1625, ResetDay: 3305,Episode: 367
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 301          |
|    time_elapsed         | 6814         |
|    total_timesteps      | 616448       |
| train/                  |              |
|    approx_kl            | 23.269527    |
|    clip_fraction        | 0.751        |
|    clip_range           | 0.2          |
|    entropy_loss         | -80.4        |
|    explained_variance   | -3.67        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.539       |
|    n_updates            | 3000         |
|    policy_gradient_loss | 0.167        |
|    reward               | 0.0006347046 |
|    std                  | 4.33         |
|    value_loss           | 1.29e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2504, ResetDay: 4184,Episode: 368
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 302            |
|    time_elapsed         | 6836           |
|    total_timesteps      | 618496         |
| train/                  |                |
|    approx_kl            | 22.355715      |
|    clip_fraction        | 0.717          |
|    clip_range           | 0.2            |
|    entropy_loss         | -80.5          |
|    explained_variance   | -0.204         |
|    learning_rate        | 0.00025        |
|    loss                 | -0.557         |
|    n_updates            | 3010           |
|    policy_gradient_loss | 0.2            |
|    reward               | -0.00014810791 |
|    std                  | 4.35           |
|    value_loss           | 2.34e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 192, ResetDay: 1872,Episode: 369
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2083, ResetDay: 3763,Episode: 370
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 303           |
|    time_elapsed         | 6859          |
|    total_timesteps      | 620544        |
| train/                  |               |
|    approx_kl            | 31.463375     |
|    clip_fraction        | 0.66          |
|    clip_range           | 0.2           |
|    entropy_loss         | -80.7         |
|    explained_variance   | -0.221        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.339        |
|    n_updates            | 3020          |
|    policy_gradient_loss | 0.2           |
|    reward               | 7.6494216e-05 |
|    std                  | 4.37          |
|    value_loss           | 6.66e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3763, episode: 370
begin_total_asset: 200.00
end_total_asset: 494.43
total_reward: 294.43
total_cost: 1.85
total_trades: 47033
Sharpe: 0.806
=================================
Reseting Environment StartDay: 2271, ResetDay: 3951,Episode: 371
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 304            |
|    time_elapsed         | 6881           |
|    total_timesteps      | 622592         |
| train/                  |                |
|    approx_kl            | 74.04639       |
|    clip_fraction        | 0.703          |
|    clip_range           | 0.2            |
|    entropy_loss         | -80.8          |
|    explained_variance   | -2.22          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.691         |
|    n_updates            | 3030           |
|    policy_gradient_loss | 0.287          |
|    reward               | 0.000119508746 |
|    std                  | 4.38           |
|    value_loss           | 1.24e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1137, ResetDay: 2817,Episode: 372
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 305           |
|    time_elapsed         | 6904          |
|    total_timesteps      | 624640        |
| train/                  |               |
|    approx_kl            | 28.983437     |
|    clip_fraction        | 0.708         |
|    clip_range           | 0.2           |
|    entropy_loss         | -80.9         |
|    explained_variance   | -0.0613       |
|    learning_rate        | 0.00025       |
|    loss                 | -0.667        |
|    n_updates            | 3040          |
|    policy_gradient_loss | 0.169         |
|    reward               | -5.722046e-07 |
|    std                  | 4.41          |
|    value_loss           | 1.34e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1677, ResetDay: 3357,Episode: 373
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 306           |
|    time_elapsed         | 6926          |
|    total_timesteps      | 626688        |
| train/                  |               |
|    approx_kl            | 31.755806     |
|    clip_fraction        | 0.706         |
|    clip_range           | 0.2           |
|    entropy_loss         | -81           |
|    explained_variance   | -0.619        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.684        |
|    n_updates            | 3050          |
|    policy_gradient_loss | 0.18          |
|    reward               | 4.8337744e-05 |
|    std                  | 4.43          |
|    value_loss           | 5.36e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2334, ResetDay: 4014,Episode: 374
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2160, ResetDay: 3840,Episode: 375
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 307           |
|    time_elapsed         | 6949          |
|    total_timesteps      | 628736        |
| train/                  |               |
|    approx_kl            | 26.53523      |
|    clip_fraction        | 0.661         |
|    clip_range           | 0.2           |
|    entropy_loss         | -81.1         |
|    explained_variance   | -0.316        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.76         |
|    n_updates            | 3060          |
|    policy_gradient_loss | 0.186         |
|    reward               | 6.1686515e-05 |
|    std                  | 4.45          |
|    value_loss           | 3.5e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3840, episode: 375
begin_total_asset: 200.00
end_total_asset: 196.42
total_reward: -3.58
total_cost: 1.96
total_trades: 47034
Sharpe: 0.120
=================================
Reseting Environment StartDay: 907, ResetDay: 2587,Episode: 376
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 308           |
|    time_elapsed         | 6972          |
|    total_timesteps      | 630784        |
| train/                  |               |
|    approx_kl            | 34.79215      |
|    clip_fraction        | 0.724         |
|    clip_range           | 0.2           |
|    entropy_loss         | -81.3         |
|    explained_variance   | -0.0276       |
|    learning_rate        | 0.00025       |
|    loss                 | -0.655        |
|    n_updates            | 3070          |
|    policy_gradient_loss | 0.179         |
|    reward               | -9.532833e-06 |
|    std                  | 4.48          |
|    value_loss           | 4.2e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2008, ResetDay: 3688,Episode: 377
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 309            |
|    time_elapsed         | 6994           |
|    total_timesteps      | 632832         |
| train/                  |                |
|    approx_kl            | 27.52089       |
|    clip_fraction        | 0.723          |
|    clip_range           | 0.2            |
|    entropy_loss         | -81.4          |
|    explained_variance   | -0.5           |
|    learning_rate        | 0.00025        |
|    loss                 | -0.609         |
|    n_updates            | 3080           |
|    policy_gradient_loss | 0.29           |
|    reward               | -5.2593423e-05 |
|    std                  | 4.48           |
|    value_loss           | 2.11e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 115, ResetDay: 1795,Episode: 378
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 310           |
|    time_elapsed         | 7017          |
|    total_timesteps      | 634880        |
| train/                  |               |
|    approx_kl            | 21.933958     |
|    clip_fraction        | 0.656         |
|    clip_range           | 0.2           |
|    entropy_loss         | -81.5         |
|    explained_variance   | -1.22         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.675        |
|    n_updates            | 3090          |
|    policy_gradient_loss | 0.166         |
|    reward               | -6.944961e-05 |
|    std                  | 4.52          |
|    value_loss           | 3.21e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 403, ResetDay: 2083,Episode: 379
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 311            |
|    time_elapsed         | 7039           |
|    total_timesteps      | 636928         |
| train/                  |                |
|    approx_kl            | 30.57876       |
|    clip_fraction        | 0.718          |
|    clip_range           | 0.2            |
|    entropy_loss         | -81.7          |
|    explained_variance   | -1.6           |
|    learning_rate        | 0.00025        |
|    loss                 | -0.72          |
|    n_updates            | 3100           |
|    policy_gradient_loss | 0.194          |
|    reward               | -0.00010247097 |
|    std                  | 4.55           |
|    value_loss           | 8.85e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2077, ResetDay: 3757,Episode: 380
Environment reached Terminal state as number of trading days reached limit!!
day: 3757, episode: 380
begin_total_asset: 200.00
end_total_asset: 399.34
total_reward: 199.34
total_cost: 1.97
total_trades: 47040
Sharpe: 0.689
=================================
Reseting Environment StartDay: 1073, ResetDay: 2753,Episode: 381
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 312            |
|    time_elapsed         | 7062           |
|    total_timesteps      | 638976         |
| train/                  |                |
|    approx_kl            | 23.023684      |
|    clip_fraction        | 0.732          |
|    clip_range           | 0.2            |
|    entropy_loss         | -81.9          |
|    explained_variance   | -1.72          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.453         |
|    n_updates            | 3110           |
|    policy_gradient_loss | 0.295          |
|    reward               | -7.2405055e-05 |
|    std                  | 4.57           |
|    value_loss           | 3.17e-05       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1110, ResetDay: 2790,Episode: 382
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 313            |
|    time_elapsed         | 7084           |
|    total_timesteps      | 641024         |
| train/                  |                |
|    approx_kl            | 24.216888      |
|    clip_fraction        | 0.742          |
|    clip_range           | 0.2            |
|    entropy_loss         | -82            |
|    explained_variance   | -0.402         |
|    learning_rate        | 0.00025        |
|    loss                 | -0.456         |
|    n_updates            | 3120           |
|    policy_gradient_loss | 0.239          |
|    reward               | -0.00024446877 |
|    std                  | 4.59           |
|    value_loss           | 2.76e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 52, ResetDay: 1732,Episode: 383
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 314            |
|    time_elapsed         | 7107           |
|    total_timesteps      | 643072         |
| train/                  |                |
|    approx_kl            | 22.773872      |
|    clip_fraction        | 0.763          |
|    clip_range           | 0.2            |
|    entropy_loss         | -82.1          |
|    explained_variance   | -1.29          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.709         |
|    n_updates            | 3130           |
|    policy_gradient_loss | 0.243          |
|    reward               | -0.00015892125 |
|    std                  | 4.61           |
|    value_loss           | 4.81e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 355, ResetDay: 2035,Episode: 384
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 315           |
|    time_elapsed         | 7130          |
|    total_timesteps      | 645120        |
| train/                  |               |
|    approx_kl            | 23.284184     |
|    clip_fraction        | 0.704         |
|    clip_range           | 0.2           |
|    entropy_loss         | -82.2         |
|    explained_variance   | -1.62         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.374        |
|    n_updates            | 3140          |
|    policy_gradient_loss | 0.188         |
|    reward               | -8.756351e-06 |
|    std                  | 4.62          |
|    value_loss           | 9.56e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1115, ResetDay: 2795,Episode: 385
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 316          |
|    time_elapsed         | 7152         |
|    total_timesteps      | 647168       |
| train/                  |              |
|    approx_kl            | 20.476894    |
|    clip_fraction        | 0.684        |
|    clip_range           | 0.2          |
|    entropy_loss         | -82.3        |
|    explained_variance   | -1.41        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.663       |
|    n_updates            | 3150         |
|    policy_gradient_loss | 0.227        |
|    reward               | 9.482193e-06 |
|    std                  | 4.64         |
|    value_loss           | 7.31e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2795, episode: 385
begin_total_asset: 200.00
end_total_asset: 274.30
total_reward: 74.30
total_cost: 1.97
total_trades: 47039
Sharpe: 0.344
=================================
Reseting Environment StartDay: 2055, ResetDay: 3735,Episode: 386
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2546, ResetDay: 4226,Episode: 387
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 317           |
|    time_elapsed         | 7175          |
|    total_timesteps      | 649216        |
| train/                  |               |
|    approx_kl            | 22.552681     |
|    clip_fraction        | 0.697         |
|    clip_range           | 0.2           |
|    entropy_loss         | -82.4         |
|    explained_variance   | -0.518        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.706        |
|    n_updates            | 3160          |
|    policy_gradient_loss | 0.155         |
|    reward               | 0.00026309738 |
|    std                  | 4.66          |
|    value_loss           | 5.29e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1225, ResetDay: 2905,Episode: 388
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 318           |
|    time_elapsed         | 7197          |
|    total_timesteps      | 651264        |
| train/                  |               |
|    approx_kl            | 29.24161      |
|    clip_fraction        | 0.687         |
|    clip_range           | 0.2           |
|    entropy_loss         | -82.5         |
|    explained_variance   | -0.11         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.669        |
|    n_updates            | 3170          |
|    policy_gradient_loss | 0.185         |
|    reward               | 6.4413834e-05 |
|    std                  | 4.67          |
|    value_loss           | 3.79e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2554, ResetDay: 4234,Episode: 389
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 319          |
|    time_elapsed         | 7220         |
|    total_timesteps      | 653312       |
| train/                  |              |
|    approx_kl            | 30.240257    |
|    clip_fraction        | 0.699        |
|    clip_range           | 0.2          |
|    entropy_loss         | -82.6        |
|    explained_variance   | -0.415       |
|    learning_rate        | 0.00025      |
|    loss                 | -0.764       |
|    n_updates            | 3180         |
|    policy_gradient_loss | 0.235        |
|    reward               | 0.0001116333 |
|    std                  | 4.69         |
|    value_loss           | 4.52e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1909, ResetDay: 3589,Episode: 390
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 320          |
|    time_elapsed         | 7242         |
|    total_timesteps      | 655360       |
| train/                  |              |
|    approx_kl            | 23.919445    |
|    clip_fraction        | 0.687        |
|    clip_range           | 0.2          |
|    entropy_loss         | -82.7        |
|    explained_variance   | -0.21        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.706       |
|    n_updates            | 3190         |
|    policy_gradient_loss | 0.179        |
|    reward               | 6.415901e-05 |
|    std                  | 4.71         |
|    value_loss           | 3.74e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3589, episode: 390
begin_total_asset: 200.00
end_total_asset: 206.19
total_reward: 6.19
total_cost: 1.96
total_trades: 47035
Sharpe: 0.182
=================================
Reseting Environment StartDay: 1988, ResetDay: 3668,Episode: 391
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 820, ResetDay: 2500,Episode: 392
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 321            |
|    time_elapsed         | 7265           |
|    total_timesteps      | 657408         |
| train/                  |                |
|    approx_kl            | 45.996117      |
|    clip_fraction        | 0.706          |
|    clip_range           | 0.2            |
|    entropy_loss         | -82.9          |
|    explained_variance   | -0.0752        |
|    learning_rate        | 0.00025        |
|    loss                 | -0.779         |
|    n_updates            | 3200           |
|    policy_gradient_loss | 0.129          |
|    reward               | -0.00029159983 |
|    std                  | 4.75           |
|    value_loss           | 7.02e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1646, ResetDay: 3326,Episode: 393
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 322           |
|    time_elapsed         | 7288          |
|    total_timesteps      | 659456        |
| train/                  |               |
|    approx_kl            | 42.405186     |
|    clip_fraction        | 0.677         |
|    clip_range           | 0.2           |
|    entropy_loss         | -83.1         |
|    explained_variance   | -0.178        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.663        |
|    n_updates            | 3210          |
|    policy_gradient_loss | 0.165         |
|    reward               | -8.418598e-05 |
|    std                  | 4.77          |
|    value_loss           | 4e-07         |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 863, ResetDay: 2543,Episode: 394
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 323           |
|    time_elapsed         | 7310          |
|    total_timesteps      | 661504        |
| train/                  |               |
|    approx_kl            | 20.32831      |
|    clip_fraction        | 0.687         |
|    clip_range           | 0.2           |
|    entropy_loss         | -83.2         |
|    explained_variance   | -1.13         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.683        |
|    n_updates            | 3220          |
|    policy_gradient_loss | 0.152         |
|    reward               | 0.00010987539 |
|    std                  | 4.81          |
|    value_loss           | 8.13e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1719, ResetDay: 3399,Episode: 395
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 324            |
|    time_elapsed         | 7333           |
|    total_timesteps      | 663552         |
| train/                  |                |
|    approx_kl            | 26.004833      |
|    clip_fraction        | 0.693          |
|    clip_range           | 0.2            |
|    entropy_loss         | -83.4          |
|    explained_variance   | -0.95          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.776         |
|    n_updates            | 3230           |
|    policy_gradient_loss | 0.182          |
|    reward               | -0.00018701077 |
|    std                  | 4.82           |
|    value_loss           | 1.26e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3399, episode: 395
begin_total_asset: 200.00
end_total_asset: 276.04
total_reward: 76.04
total_cost: 1.97
total_trades: 47036
Sharpe: 0.356
=================================
Reseting Environment StartDay: 456, ResetDay: 2136,Episode: 396
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 325           |
|    time_elapsed         | 7355          |
|    total_timesteps      | 665600        |
| train/                  |               |
|    approx_kl            | 23.668995     |
|    clip_fraction        | 0.673         |
|    clip_range           | 0.2           |
|    entropy_loss         | -83.5         |
|    explained_variance   | -0.275        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.758        |
|    n_updates            | 3240          |
|    policy_gradient_loss | 0.14          |
|    reward               | -5.737133e-05 |
|    std                  | 4.85          |
|    value_loss           | 5.93e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 389, ResetDay: 2069,Episode: 397
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 741, ResetDay: 2421,Episode: 398
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 326            |
|    time_elapsed         | 7378           |
|    total_timesteps      | 667648         |
| train/                  |                |
|    approx_kl            | 32.120678      |
|    clip_fraction        | 0.696          |
|    clip_range           | 0.2            |
|    entropy_loss         | -83.7          |
|    explained_variance   | -1.78          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.758         |
|    n_updates            | 3250           |
|    policy_gradient_loss | 0.158          |
|    reward               | -0.00012796983 |
|    std                  | 4.88           |
|    value_loss           | 6.2e-07        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1792, ResetDay: 3472,Episode: 399
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 327           |
|    time_elapsed         | 7401          |
|    total_timesteps      | 669696        |
| train/                  |               |
|    approx_kl            | 25.006882     |
|    clip_fraction        | 0.686         |
|    clip_range           | 0.2           |
|    entropy_loss         | -83.8         |
|    explained_variance   | -1.27         |
|    learning_rate        | 0.00025       |
|    loss                 | 0.414         |
|    n_updates            | 3260          |
|    policy_gradient_loss | 0.243         |
|    reward               | 0.00026460362 |
|    std                  | 4.89          |
|    value_loss           | 1.84e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2463, ResetDay: 4143,Episode: 400
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 328            |
|    time_elapsed         | 7423           |
|    total_timesteps      | 671744         |
| train/                  |                |
|    approx_kl            | 21.181074      |
|    clip_fraction        | 0.675          |
|    clip_range           | 0.2            |
|    entropy_loss         | -83.9          |
|    explained_variance   | -1.03          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.736         |
|    n_updates            | 3270           |
|    policy_gradient_loss | 0.167          |
|    reward               | -0.00015516015 |
|    std                  | 4.92           |
|    value_loss           | 4.29e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4143, episode: 400
begin_total_asset: 200.00
end_total_asset: 251.99
total_reward: 51.99
total_cost: 1.90
total_trades: 47036
Sharpe: 0.276
=================================
Reseting Environment StartDay: 996, ResetDay: 2676,Episode: 401
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 329            |
|    time_elapsed         | 7446           |
|    total_timesteps      | 673792         |
| train/                  |                |
|    approx_kl            | 27.525997      |
|    clip_fraction        | 0.74           |
|    clip_range           | 0.2            |
|    entropy_loss         | -84            |
|    explained_variance   | -0.0716        |
|    learning_rate        | 0.00025        |
|    loss                 | -0.668         |
|    n_updates            | 3280           |
|    policy_gradient_loss | 0.205          |
|    reward               | -0.00033424568 |
|    std                  | 4.94           |
|    value_loss           | 3.36e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 647, ResetDay: 2327,Episode: 402
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1549, ResetDay: 3229,Episode: 403
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 330          |
|    time_elapsed         | 7469         |
|    total_timesteps      | 675840       |
| train/                  |              |
|    approx_kl            | 43.480465    |
|    clip_fraction        | 0.675        |
|    clip_range           | 0.2          |
|    entropy_loss         | -84.1        |
|    explained_variance   | -0.619       |
|    learning_rate        | 0.00025      |
|    loss                 | -0.764       |
|    n_updates            | 3290         |
|    policy_gradient_loss | 0.176        |
|    reward               | 0.0001415205 |
|    std                  | 4.96         |
|    value_loss           | 2.75e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1531, ResetDay: 3211,Episode: 404
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 331           |
|    time_elapsed         | 7491          |
|    total_timesteps      | 677888        |
| train/                  |               |
|    approx_kl            | 26.86972      |
|    clip_fraction        | 0.735         |
|    clip_range           | 0.2           |
|    entropy_loss         | -84.2         |
|    explained_variance   | -1.56         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.71         |
|    n_updates            | 3300          |
|    policy_gradient_loss | 0.235         |
|    reward               | 5.9671784e-05 |
|    std                  | 4.98          |
|    value_loss           | 1.5e-06       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1322, ResetDay: 3002,Episode: 405
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 332          |
|    time_elapsed         | 7513         |
|    total_timesteps      | 679936       |
| train/                  |              |
|    approx_kl            | 21.755192    |
|    clip_fraction        | 0.651        |
|    clip_range           | 0.2          |
|    entropy_loss         | -84.3        |
|    explained_variance   | -0.274       |
|    learning_rate        | 0.00025      |
|    loss                 | -0.725       |
|    n_updates            | 3310         |
|    policy_gradient_loss | 0.165        |
|    reward               | 7.299328e-05 |
|    std                  | 5            |
|    value_loss           | 3.5e-07      |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3002, episode: 405
begin_total_asset: 200.00
end_total_asset: 190.44
total_reward: -9.56
total_cost: 1.98
total_trades: 47035
Sharpe: 0.177
=================================
Reseting Environment StartDay: 1617, ResetDay: 3297,Episode: 406
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 333           |
|    time_elapsed         | 7536          |
|    total_timesteps      | 681984        |
| train/                  |               |
|    approx_kl            | 24.152576     |
|    clip_fraction        | 0.663         |
|    clip_range           | 0.2           |
|    entropy_loss         | -84.5         |
|    explained_variance   | -0.246        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.334        |
|    n_updates            | 3320          |
|    policy_gradient_loss | 0.184         |
|    reward               | 5.8545877e-05 |
|    std                  | 5.03          |
|    value_loss           | 5.24e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1179, ResetDay: 2859,Episode: 407
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 334            |
|    time_elapsed         | 7559           |
|    total_timesteps      | 684032         |
| train/                  |                |
|    approx_kl            | 25.129585      |
|    clip_fraction        | 0.716          |
|    clip_range           | 0.2            |
|    entropy_loss         | -84.7          |
|    explained_variance   | -0.258         |
|    learning_rate        | 0.00025        |
|    loss                 | -0.784         |
|    n_updates            | 3330           |
|    policy_gradient_loss | 0.149          |
|    reward               | -0.00013554402 |
|    std                  | 5.07           |
|    value_loss           | 7.07e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 786, ResetDay: 2466,Episode: 408
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 666, ResetDay: 2346,Episode: 409
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 335          |
|    time_elapsed         | 7581         |
|    total_timesteps      | 686080       |
| train/                  |              |
|    approx_kl            | 28.572392    |
|    clip_fraction        | 0.701        |
|    clip_range           | 0.2          |
|    entropy_loss         | -84.9        |
|    explained_variance   | -0.287       |
|    learning_rate        | 0.00025      |
|    loss                 | -0.663       |
|    n_updates            | 3340         |
|    policy_gradient_loss | 0.174        |
|    reward               | 3.373256e-05 |
|    std                  | 5.09         |
|    value_loss           | 4.02e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 8, ResetDay: 1688,Episode: 410
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 336           |
|    time_elapsed         | 7604          |
|    total_timesteps      | 688128        |
| train/                  |               |
|    approx_kl            | 26.748638     |
|    clip_fraction        | 0.741         |
|    clip_range           | 0.2           |
|    entropy_loss         | -85           |
|    explained_variance   | -0.643        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.726        |
|    n_updates            | 3350          |
|    policy_gradient_loss | 0.206         |
|    reward               | 0.00026815638 |
|    std                  | 5.13          |
|    value_loss           | 1.1e-06       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 1688, episode: 410
begin_total_asset: 200.00
end_total_asset: 165.07
total_reward: -34.93
total_cost: 2.24
total_trades: 47039
Sharpe: 0.131
=================================
Reseting Environment StartDay: 749, ResetDay: 2429,Episode: 411
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 337            |
|    time_elapsed         | 7626           |
|    total_timesteps      | 690176         |
| train/                  |                |
|    approx_kl            | 20.680023      |
|    clip_fraction        | 0.719          |
|    clip_range           | 0.2            |
|    entropy_loss         | -85.2          |
|    explained_variance   | -9.03          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.82          |
|    n_updates            | 3360           |
|    policy_gradient_loss | 0.144          |
|    reward               | -0.00015834665 |
|    std                  | 5.15           |
|    value_loss           | 5.94e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1669, ResetDay: 3349,Episode: 412
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 338           |
|    time_elapsed         | 7649          |
|    total_timesteps      | 692224        |
| train/                  |               |
|    approx_kl            | 21.631924     |
|    clip_fraction        | 0.701         |
|    clip_range           | 0.2           |
|    entropy_loss         | -85.3         |
|    explained_variance   | -1.25         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.643        |
|    n_updates            | 3370          |
|    policy_gradient_loss | 0.182         |
|    reward               | 5.5397036e-06 |
|    std                  | 5.18          |
|    value_loss           | 2.64e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 150, ResetDay: 1830,Episode: 413
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2345, ResetDay: 4025,Episode: 414
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 339           |
|    time_elapsed         | 7671          |
|    total_timesteps      | 694272        |
| train/                  |               |
|    approx_kl            | 22.681076     |
|    clip_fraction        | 0.652         |
|    clip_range           | 0.2           |
|    entropy_loss         | -85.4         |
|    explained_variance   | -0.635        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.747        |
|    n_updates            | 3380          |
|    policy_gradient_loss | 0.173         |
|    reward               | 3.6352347e-05 |
|    std                  | 5.2           |
|    value_loss           | 5.1e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2291, ResetDay: 3971,Episode: 415
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 340          |
|    time_elapsed         | 7694         |
|    total_timesteps      | 696320       |
| train/                  |              |
|    approx_kl            | 31.28421     |
|    clip_fraction        | 0.71         |
|    clip_range           | 0.2          |
|    entropy_loss         | -85.5        |
|    explained_variance   | -1.18        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.695       |
|    n_updates            | 3390         |
|    policy_gradient_loss | 0.199        |
|    reward               | 0.0002653698 |
|    std                  | 5.22         |
|    value_loss           | 1.2e-06      |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3971, episode: 415
begin_total_asset: 200.00
end_total_asset: 199.89
total_reward: -0.11
total_cost: 1.81
total_trades: 47036
Sharpe: 0.120
=================================
Reseting Environment StartDay: 2361, ResetDay: 4041,Episode: 416
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 341          |
|    time_elapsed         | 7717         |
|    total_timesteps      | 698368       |
| train/                  |              |
|    approx_kl            | 26.16632     |
|    clip_fraction        | 0.694        |
|    clip_range           | 0.2          |
|    entropy_loss         | -85.6        |
|    explained_variance   | -0.0699      |
|    learning_rate        | 0.00025      |
|    loss                 | -0.718       |
|    n_updates            | 3400         |
|    policy_gradient_loss | 0.131        |
|    reward               | 9.325104e-05 |
|    std                  | 5.23         |
|    value_loss           | 1.66e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2248, ResetDay: 3928,Episode: 417
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 342          |
|    time_elapsed         | 7740         |
|    total_timesteps      | 700416       |
| train/                  |              |
|    approx_kl            | 27.000235    |
|    clip_fraction        | 0.715        |
|    clip_range           | 0.2          |
|    entropy_loss         | -85.7        |
|    explained_variance   | -0.151       |
|    learning_rate        | 0.00025      |
|    loss                 | -0.382       |
|    n_updates            | 3410         |
|    policy_gradient_loss | 0.238        |
|    reward               | 0.0008565937 |
|    std                  | 5.25         |
|    value_loss           | 8.19e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 198, ResetDay: 1878,Episode: 418
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 343           |
|    time_elapsed         | 7763          |
|    total_timesteps      | 702464        |
| train/                  |               |
|    approx_kl            | 32.370396     |
|    clip_fraction        | 0.717         |
|    clip_range           | 0.2           |
|    entropy_loss         | -85.8         |
|    explained_variance   | -0.296        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.753        |
|    n_updates            | 3420          |
|    policy_gradient_loss | 0.18          |
|    reward               | 3.8302613e-05 |
|    std                  | 5.28          |
|    value_loss           | 5.82e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1236, ResetDay: 2916,Episode: 419
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 27, ResetDay: 1707,Episode: 420
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 344           |
|    time_elapsed         | 7785          |
|    total_timesteps      | 704512        |
| train/                  |               |
|    approx_kl            | 39.686424     |
|    clip_fraction        | 0.655         |
|    clip_range           | 0.2           |
|    entropy_loss         | -85.9         |
|    explained_variance   | -1.34         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.75         |
|    n_updates            | 3430          |
|    policy_gradient_loss | 0.162         |
|    reward               | -4.326868e-06 |
|    std                  | 5.29          |
|    value_loss           | 9.45e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 1707, episode: 420
begin_total_asset: 200.00
end_total_asset: 191.24
total_reward: -8.76
total_cost: 2.10
total_trades: 47040
Sharpe: 0.159
=================================
Reseting Environment StartDay: 2498, ResetDay: 4178,Episode: 421
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 345           |
|    time_elapsed         | 7807          |
|    total_timesteps      | 706560        |
| train/                  |               |
|    approx_kl            | 22.504776     |
|    clip_fraction        | 0.678         |
|    clip_range           | 0.2           |
|    entropy_loss         | -86           |
|    explained_variance   | -0.403        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.653        |
|    n_updates            | 3440          |
|    policy_gradient_loss | 0.159         |
|    reward               | 3.6380006e-05 |
|    std                  | 5.32          |
|    value_loss           | 7.58e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 700, ResetDay: 2380,Episode: 422
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 346           |
|    time_elapsed         | 7833          |
|    total_timesteps      | 708608        |
| train/                  |               |
|    approx_kl            | 21.116322     |
|    clip_fraction        | 0.7           |
|    clip_range           | 0.2           |
|    entropy_loss         | -86.2         |
|    explained_variance   | -0.397        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.716        |
|    n_updates            | 3450          |
|    policy_gradient_loss | 0.151         |
|    reward               | -9.332161e-05 |
|    std                  | 5.35          |
|    value_loss           | 1.4e-06       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1436, ResetDay: 3116,Episode: 423
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 347            |
|    time_elapsed         | 7855           |
|    total_timesteps      | 710656         |
| train/                  |                |
|    approx_kl            | 30.327784      |
|    clip_fraction        | 0.739          |
|    clip_range           | 0.2            |
|    entropy_loss         | -86.4          |
|    explained_variance   | -0.137         |
|    learning_rate        | 0.00025        |
|    loss                 | -0.787         |
|    n_updates            | 3460           |
|    policy_gradient_loss | 0.214          |
|    reward               | -0.00020945015 |
|    std                  | 5.38           |
|    value_loss           | 1.13e-05       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1925, ResetDay: 3605,Episode: 424
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 348           |
|    time_elapsed         | 7877          |
|    total_timesteps      | 712704        |
| train/                  |               |
|    approx_kl            | 21.865316     |
|    clip_fraction        | 0.689         |
|    clip_range           | 0.2           |
|    entropy_loss         | -86.5         |
|    explained_variance   | -1.32         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.682        |
|    n_updates            | 3470          |
|    policy_gradient_loss | 0.185         |
|    reward               | 0.00012439994 |
|    std                  | 5.4           |
|    value_loss           | 4.19e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 33, ResetDay: 1713,Episode: 425
Environment reached Terminal state as number of trading days reached limit!!
day: 1713, episode: 425
begin_total_asset: 200.00
end_total_asset: 203.14
total_reward: 3.14
total_cost: 1.97
total_trades: 47040
Sharpe: 0.175
=================================
Reseting Environment StartDay: 792, ResetDay: 2472,Episode: 426
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 349           |
|    time_elapsed         | 7900          |
|    total_timesteps      | 714752        |
| train/                  |               |
|    approx_kl            | 25.906029     |
|    clip_fraction        | 0.764         |
|    clip_range           | 0.2           |
|    entropy_loss         | -86.6         |
|    explained_variance   | -0.0248       |
|    learning_rate        | 0.00025       |
|    loss                 | -0.584        |
|    n_updates            | 3480          |
|    policy_gradient_loss | 0.232         |
|    reward               | 5.1941395e-05 |
|    std                  | 5.41          |
|    value_loss           | 6.34e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 164, ResetDay: 1844,Episode: 427
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 350          |
|    time_elapsed         | 7922         |
|    total_timesteps      | 716800       |
| train/                  |              |
|    approx_kl            | 38.17858     |
|    clip_fraction        | 0.691        |
|    clip_range           | 0.2          |
|    entropy_loss         | -86.6        |
|    explained_variance   | -1.7         |
|    learning_rate        | 0.00025      |
|    loss                 | -0.786       |
|    n_updates            | 3490         |
|    policy_gradient_loss | 0.137        |
|    reward               | 6.232834e-05 |
|    std                  | 5.43         |
|    value_loss           | 1.13e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 441, ResetDay: 2121,Episode: 428
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 351           |
|    time_elapsed         | 7945          |
|    total_timesteps      | 718848        |
| train/                  |               |
|    approx_kl            | 21.53967      |
|    clip_fraction        | 0.737         |
|    clip_range           | 0.2           |
|    entropy_loss         | -86.7         |
|    explained_variance   | -0.669        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.755        |
|    n_updates            | 3500          |
|    policy_gradient_loss | 0.189         |
|    reward               | -2.091217e-06 |
|    std                  | 5.46          |
|    value_loss           | 7.58e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1334, ResetDay: 3014,Episode: 429
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 352           |
|    time_elapsed         | 7967          |
|    total_timesteps      | 720896        |
| train/                  |               |
|    approx_kl            | 21.198154     |
|    clip_fraction        | 0.679         |
|    clip_range           | 0.2           |
|    entropy_loss         | -86.9         |
|    explained_variance   | -0.782        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.636        |
|    n_updates            | 3510          |
|    policy_gradient_loss | 0.198         |
|    reward               | 0.00024474983 |
|    std                  | 5.48          |
|    value_loss           | 6.06e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2085, ResetDay: 3765,Episode: 430
Environment reached Terminal state as number of trading days reached limit!!
day: 3765, episode: 430
begin_total_asset: 200.00
end_total_asset: 244.68
total_reward: 44.68
total_cost: 1.88
total_trades: 47040
Sharpe: 0.256
=================================
Reseting Environment StartDay: 2537, ResetDay: 4217,Episode: 431
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 353          |
|    time_elapsed         | 7990         |
|    total_timesteps      | 722944       |
| train/                  |              |
|    approx_kl            | 21.740112    |
|    clip_fraction        | 0.696        |
|    clip_range           | 0.2          |
|    entropy_loss         | -87          |
|    explained_variance   | -0.233       |
|    learning_rate        | 0.00025      |
|    loss                 | -0.556       |
|    n_updates            | 3520         |
|    policy_gradient_loss | 0.172        |
|    reward               | 9.087906e-05 |
|    std                  | 5.51         |
|    value_loss           | 4.44e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2464, ResetDay: 4144,Episode: 432
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 354           |
|    time_elapsed         | 8013          |
|    total_timesteps      | 724992        |
| train/                  |               |
|    approx_kl            | 26.34634      |
|    clip_fraction        | 0.75          |
|    clip_range           | 0.2           |
|    entropy_loss         | -87.1         |
|    explained_variance   | -0.0195       |
|    learning_rate        | 0.00025       |
|    loss                 | -0.761        |
|    n_updates            | 3530          |
|    policy_gradient_loss | 0.169         |
|    reward               | 0.00014731407 |
|    std                  | 5.53          |
|    value_loss           | 3.98e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1643, ResetDay: 3323,Episode: 433
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 355           |
|    time_elapsed         | 8035          |
|    total_timesteps      | 727040        |
| train/                  |               |
|    approx_kl            | 26.401297     |
|    clip_fraction        | 0.726         |
|    clip_range           | 0.2           |
|    entropy_loss         | -87.2         |
|    explained_variance   | 0.088         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.701        |
|    n_updates            | 3540          |
|    policy_gradient_loss | 0.225         |
|    reward               | 0.00013848953 |
|    std                  | 5.56          |
|    value_loss           | 2.07e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1089, ResetDay: 2769,Episode: 434
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 356           |
|    time_elapsed         | 8058          |
|    total_timesteps      | 729088        |
| train/                  |               |
|    approx_kl            | 28.709185     |
|    clip_fraction        | 0.72          |
|    clip_range           | 0.2           |
|    entropy_loss         | -87.3         |
|    explained_variance   | -0.344        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.756        |
|    n_updates            | 3550          |
|    policy_gradient_loss | 0.191         |
|    reward               | -6.816101e-05 |
|    std                  | 5.57          |
|    value_loss           | 3.78e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1447, ResetDay: 3127,Episode: 435
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 357           |
|    time_elapsed         | 8081          |
|    total_timesteps      | 731136        |
| train/                  |               |
|    approx_kl            | 26.35329      |
|    clip_fraction        | 0.746         |
|    clip_range           | 0.2           |
|    entropy_loss         | -87.4         |
|    explained_variance   | -0.633        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.739        |
|    n_updates            | 3560          |
|    policy_gradient_loss | 0.169         |
|    reward               | -5.746231e-05 |
|    std                  | 5.59          |
|    value_loss           | 3.47e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3127, episode: 435
begin_total_asset: 200.00
end_total_asset: 260.03
total_reward: 60.03
total_cost: 1.94
total_trades: 47040
Sharpe: 0.314
=================================
Reseting Environment StartDay: 560, ResetDay: 2240,Episode: 436
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2113, ResetDay: 3793,Episode: 437
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 358           |
|    time_elapsed         | 8103          |
|    total_timesteps      | 733184        |
| train/                  |               |
|    approx_kl            | 25.19179      |
|    clip_fraction        | 0.703         |
|    clip_range           | 0.2           |
|    entropy_loss         | -87.5         |
|    explained_variance   | -0.101        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.806        |
|    n_updates            | 3570          |
|    policy_gradient_loss | 0.189         |
|    reward               | 0.00020040893 |
|    std                  | 5.62          |
|    value_loss           | 6.2e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 766, ResetDay: 2446,Episode: 438
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 359            |
|    time_elapsed         | 8126           |
|    total_timesteps      | 735232         |
| train/                  |                |
|    approx_kl            | 28.386208      |
|    clip_fraction        | 0.7            |
|    clip_range           | 0.2            |
|    entropy_loss         | -87.7          |
|    explained_variance   | -1.42          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.739         |
|    n_updates            | 3580           |
|    policy_gradient_loss | 0.148          |
|    reward               | -1.4433098e-05 |
|    std                  | 5.67           |
|    value_loss           | 4.54e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 259, ResetDay: 1939,Episode: 439
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 360          |
|    time_elapsed         | 8148         |
|    total_timesteps      | 737280       |
| train/                  |              |
|    approx_kl            | 25.057457    |
|    clip_fraction        | 0.694        |
|    clip_range           | 0.2          |
|    entropy_loss         | -87.9        |
|    explained_variance   | -0.382       |
|    learning_rate        | 0.00025      |
|    loss                 | -0.686       |
|    n_updates            | 3590         |
|    policy_gradient_loss | 0.157        |
|    reward               | -5.85289e-06 |
|    std                  | 5.69         |
|    value_loss           | 7.5e-07      |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2801, ResetDay: 4481,Episode: 440
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 361          |
|    time_elapsed         | 8171         |
|    total_timesteps      | 739328       |
| train/                  |              |
|    approx_kl            | 21.451286    |
|    clip_fraction        | 0.711        |
|    clip_range           | 0.2          |
|    entropy_loss         | -88          |
|    explained_variance   | -1.12        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.785       |
|    n_updates            | 3600         |
|    policy_gradient_loss | 0.168        |
|    reward               | 0.0004357727 |
|    std                  | 5.72         |
|    value_loss           | 6.63e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4481, episode: 440
begin_total_asset: 200.00
end_total_asset: 584.64
total_reward: 384.64
total_cost: 1.93
total_trades: 47033
Sharpe: 0.646
=================================
Reseting Environment StartDay: 1078, ResetDay: 2758,Episode: 441
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1285, ResetDay: 2965,Episode: 442
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 362          |
|    time_elapsed         | 8194         |
|    total_timesteps      | 741376       |
| train/                  |              |
|    approx_kl            | 20.971346    |
|    clip_fraction        | 0.699        |
|    clip_range           | 0.2          |
|    entropy_loss         | -88.2        |
|    explained_variance   | -0.00189     |
|    learning_rate        | 0.00025      |
|    loss                 | -0.795       |
|    n_updates            | 3610         |
|    policy_gradient_loss | 0.156        |
|    reward               | 9.689903e-06 |
|    std                  | 5.77         |
|    value_loss           | 2.07e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2080, ResetDay: 3760,Episode: 443
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 363           |
|    time_elapsed         | 8216          |
|    total_timesteps      | 743424        |
| train/                  |               |
|    approx_kl            | 57.836967     |
|    clip_fraction        | 0.735         |
|    clip_range           | 0.2           |
|    entropy_loss         | -88.4         |
|    explained_variance   | -0.548        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.787        |
|    n_updates            | 3620          |
|    policy_gradient_loss | 0.18          |
|    reward               | -6.162491e-05 |
|    std                  | 5.79          |
|    value_loss           | 1.72e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2165, ResetDay: 3845,Episode: 444
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 364            |
|    time_elapsed         | 8239           |
|    total_timesteps      | 745472         |
| train/                  |                |
|    approx_kl            | 20.504175      |
|    clip_fraction        | 0.687          |
|    clip_range           | 0.2            |
|    entropy_loss         | -88.5          |
|    explained_variance   | -0.423         |
|    learning_rate        | 0.00025        |
|    loss                 | -0.749         |
|    n_updates            | 3630           |
|    policy_gradient_loss | 0.15           |
|    reward               | -0.00027112427 |
|    std                  | 5.82           |
|    value_loss           | 3.83e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 755, ResetDay: 2435,Episode: 445
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 365           |
|    time_elapsed         | 8261          |
|    total_timesteps      | 747520        |
| train/                  |               |
|    approx_kl            | 25.765171     |
|    clip_fraction        | 0.697         |
|    clip_range           | 0.2           |
|    entropy_loss         | -88.7         |
|    explained_variance   | -0.163        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.758        |
|    n_updates            | 3640          |
|    policy_gradient_loss | 0.135         |
|    reward               | -7.760124e-05 |
|    std                  | 5.84          |
|    value_loss           | 5.65e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2435, episode: 445
begin_total_asset: 200.00
end_total_asset: 228.01
total_reward: 28.01
total_cost: 2.60
total_trades: 47039
Sharpe: 0.242
=================================
Reseting Environment StartDay: 1514, ResetDay: 3194,Episode: 446
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 366           |
|    time_elapsed         | 8284          |
|    total_timesteps      | 749568        |
| train/                  |               |
|    approx_kl            | 27.481834     |
|    clip_fraction        | 0.706         |
|    clip_range           | 0.2           |
|    entropy_loss         | -88.8         |
|    explained_variance   | -0.79         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.798        |
|    n_updates            | 3650          |
|    policy_gradient_loss | 0.14          |
|    reward               | 0.00022699681 |
|    std                  | 5.87          |
|    value_loss           | 1.58e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1125, ResetDay: 2805,Episode: 447
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 117, ResetDay: 1797,Episode: 448
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 367           |
|    time_elapsed         | 8306          |
|    total_timesteps      | 751616        |
| train/                  |               |
|    approx_kl            | 21.220245     |
|    clip_fraction        | 0.673         |
|    clip_range           | 0.2           |
|    entropy_loss         | -88.8         |
|    explained_variance   | -0.268        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.765        |
|    n_updates            | 3660          |
|    policy_gradient_loss | 0.169         |
|    reward               | 5.0909757e-06 |
|    std                  | 5.88          |
|    value_loss           | 4.57e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 681, ResetDay: 2361,Episode: 449
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 368           |
|    time_elapsed         | 8329          |
|    total_timesteps      | 753664        |
| train/                  |               |
|    approx_kl            | 27.916847     |
|    clip_fraction        | 0.731         |
|    clip_range           | 0.2           |
|    entropy_loss         | -89           |
|    explained_variance   | -0.687        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.835        |
|    n_updates            | 3670          |
|    policy_gradient_loss | 0.174         |
|    reward               | 2.6785945e-05 |
|    std                  | 5.92          |
|    value_loss           | 8e-07         |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1023, ResetDay: 2703,Episode: 450
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 369           |
|    time_elapsed         | 8352          |
|    total_timesteps      | 755712        |
| train/                  |               |
|    approx_kl            | 19.634203     |
|    clip_fraction        | 0.692         |
|    clip_range           | 0.2           |
|    entropy_loss         | -89.1         |
|    explained_variance   | -1.3          |
|    learning_rate        | 0.00025       |
|    loss                 | -0.802        |
|    n_updates            | 3680          |
|    policy_gradient_loss | 0.158         |
|    reward               | 4.2562486e-05 |
|    std                  | 5.96          |
|    value_loss           | 9.03e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2703, episode: 450
begin_total_asset: 200.00
end_total_asset: 262.70
total_reward: 62.70
total_cost: 1.97
total_trades: 47035
Sharpe: 0.344
=================================
Reseting Environment StartDay: 2746, ResetDay: 4426,Episode: 451
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 370            |
|    time_elapsed         | 8375           |
|    total_timesteps      | 757760         |
| train/                  |                |
|    approx_kl            | 21.018396      |
|    clip_fraction        | 0.688          |
|    clip_range           | 0.2            |
|    entropy_loss         | -89.3          |
|    explained_variance   | -0.312         |
|    learning_rate        | 0.00025        |
|    loss                 | -0.677         |
|    n_updates            | 3690           |
|    policy_gradient_loss | 0.154          |
|    reward               | -0.00067123986 |
|    std                  | 6              |
|    value_loss           | 5.35e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1431, ResetDay: 3111,Episode: 452
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 371            |
|    time_elapsed         | 8397           |
|    total_timesteps      | 759808         |
| train/                  |                |
|    approx_kl            | 21.559263      |
|    clip_fraction        | 0.681          |
|    clip_range           | 0.2            |
|    entropy_loss         | -89.5          |
|    explained_variance   | 0.00839        |
|    learning_rate        | 0.00025        |
|    loss                 | -0.774         |
|    n_updates            | 3700           |
|    policy_gradient_loss | 0.131          |
|    reward               | -1.4082146e-05 |
|    std                  | 6.04           |
|    value_loss           | 1.23e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 45, ResetDay: 1725,Episode: 453
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 832, ResetDay: 2512,Episode: 454
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 372            |
|    time_elapsed         | 8420           |
|    total_timesteps      | 761856         |
| train/                  |                |
|    approx_kl            | 48.078674      |
|    clip_fraction        | 0.73           |
|    clip_range           | 0.2            |
|    entropy_loss         | -89.6          |
|    explained_variance   | -0.289         |
|    learning_rate        | 0.00025        |
|    loss                 | -0.52          |
|    n_updates            | 3710           |
|    policy_gradient_loss | 0.166          |
|    reward               | -2.5821448e-05 |
|    std                  | 6.07           |
|    value_loss           | 8.8e-07        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 553, ResetDay: 2233,Episode: 455
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 373            |
|    time_elapsed         | 8442           |
|    total_timesteps      | 763904         |
| train/                  |                |
|    approx_kl            | 20.071503      |
|    clip_fraction        | 0.694          |
|    clip_range           | 0.2            |
|    entropy_loss         | -89.8          |
|    explained_variance   | -2.47          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.75          |
|    n_updates            | 3720           |
|    policy_gradient_loss | 0.181          |
|    reward               | -0.00044674333 |
|    std                  | 6.09           |
|    value_loss           | 1.02e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2233, episode: 455
begin_total_asset: 200.00
end_total_asset: 230.51
total_reward: 30.51
total_cost: 2.73
total_trades: 47040
Sharpe: 0.235
=================================
Reseting Environment StartDay: 2701, ResetDay: 4381,Episode: 456
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 374            |
|    time_elapsed         | 8465           |
|    total_timesteps      | 765952         |
| train/                  |                |
|    approx_kl            | 20.359493      |
|    clip_fraction        | 0.723          |
|    clip_range           | 0.2            |
|    entropy_loss         | -89.9          |
|    explained_variance   | -0.366         |
|    learning_rate        | 0.00025        |
|    loss                 | -0.762         |
|    n_updates            | 3730           |
|    policy_gradient_loss | 0.153          |
|    reward               | -4.2998887e-05 |
|    std                  | 6.14           |
|    value_loss           | 8.1e-07        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1351, ResetDay: 3031,Episode: 457
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 375          |
|    time_elapsed         | 8487         |
|    total_timesteps      | 768000       |
| train/                  |              |
|    approx_kl            | 19.663092    |
|    clip_fraction        | 0.678        |
|    clip_range           | 0.2          |
|    entropy_loss         | -90.1        |
|    explained_variance   | -0.252       |
|    learning_rate        | 0.00025      |
|    loss                 | -0.806       |
|    n_updates            | 3740         |
|    policy_gradient_loss | 0.152        |
|    reward               | 7.187919e-05 |
|    std                  | 6.16         |
|    value_loss           | 7.29e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 177, ResetDay: 1857,Episode: 458
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1791, ResetDay: 3471,Episode: 459
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 376           |
|    time_elapsed         | 8510          |
|    total_timesteps      | 770048        |
| train/                  |               |
|    approx_kl            | 32.992855     |
|    clip_fraction        | 0.713         |
|    clip_range           | 0.2           |
|    entropy_loss         | -90.2         |
|    explained_variance   | -0.118        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.78         |
|    n_updates            | 3750          |
|    policy_gradient_loss | 0.165         |
|    reward               | -9.310455e-05 |
|    std                  | 6.19          |
|    value_loss           | 2.11e-05      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1533, ResetDay: 3213,Episode: 460
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 377            |
|    time_elapsed         | 8532           |
|    total_timesteps      | 772096         |
| train/                  |                |
|    approx_kl            | 25.08612       |
|    clip_fraction        | 0.707          |
|    clip_range           | 0.2            |
|    entropy_loss         | -90.3          |
|    explained_variance   | -5.18          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.704         |
|    n_updates            | 3760           |
|    policy_gradient_loss | 0.146          |
|    reward               | -2.4573897e-05 |
|    std                  | 6.21           |
|    value_loss           | 1.14e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3213, episode: 460
begin_total_asset: 200.00
end_total_asset: 191.97
total_reward: -8.03
total_cost: 1.89
total_trades: 47039
Sharpe: 0.151
=================================
Reseting Environment StartDay: 470, ResetDay: 2150,Episode: 461
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 378           |
|    time_elapsed         | 8555          |
|    total_timesteps      | 774144        |
| train/                  |               |
|    approx_kl            | 21.401705     |
|    clip_fraction        | 0.703         |
|    clip_range           | 0.2           |
|    entropy_loss         | -90.5         |
|    explained_variance   | -0.183        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.727        |
|    n_updates            | 3770          |
|    policy_gradient_loss | 0.173         |
|    reward               | 0.00013799868 |
|    std                  | 6.25          |
|    value_loss           | 7.14e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 213, ResetDay: 1893,Episode: 462
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 379           |
|    time_elapsed         | 8578          |
|    total_timesteps      | 776192        |
| train/                  |               |
|    approx_kl            | 22.12749      |
|    clip_fraction        | 0.761         |
|    clip_range           | 0.2           |
|    entropy_loss         | -90.6         |
|    explained_variance   | -1.58         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.67         |
|    n_updates            | 3780          |
|    policy_gradient_loss | 0.162         |
|    reward               | 0.00016438446 |
|    std                  | 6.29          |
|    value_loss           | 4.6e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1396, ResetDay: 3076,Episode: 463
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 380           |
|    time_elapsed         | 8600          |
|    total_timesteps      | 778240        |
| train/                  |               |
|    approx_kl            | 20.011253     |
|    clip_fraction        | 0.693         |
|    clip_range           | 0.2           |
|    entropy_loss         | -90.8         |
|    explained_variance   | -1.9          |
|    learning_rate        | 0.00025       |
|    loss                 | -0.825        |
|    n_updates            | 3790          |
|    policy_gradient_loss | 0.122         |
|    reward               | 0.00010000763 |
|    std                  | 6.31          |
|    value_loss           | 7.03e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 394, ResetDay: 2074,Episode: 464
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 550, ResetDay: 2230,Episode: 465
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 381           |
|    time_elapsed         | 8623          |
|    total_timesteps      | 780288        |
| train/                  |               |
|    approx_kl            | 20.536455     |
|    clip_fraction        | 0.694         |
|    clip_range           | 0.2           |
|    entropy_loss         | -90.9         |
|    explained_variance   | -0.203        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.657        |
|    n_updates            | 3800          |
|    policy_gradient_loss | 0.146         |
|    reward               | 4.5847606e-05 |
|    std                  | 6.36          |
|    value_loss           | 5.55e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2230, episode: 465
begin_total_asset: 200.00
end_total_asset: 252.42
total_reward: 52.42
total_cost: 1.97
total_trades: 47038
Sharpe: 0.276
=================================
Reseting Environment StartDay: 1635, ResetDay: 3315,Episode: 466
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 382           |
|    time_elapsed         | 8645          |
|    total_timesteps      | 782336        |
| train/                  |               |
|    approx_kl            | 25.78957      |
|    clip_fraction        | 0.738         |
|    clip_range           | 0.2           |
|    entropy_loss         | -91.1         |
|    explained_variance   | -2.07         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.75         |
|    n_updates            | 3810          |
|    policy_gradient_loss | 0.146         |
|    reward               | 0.00014217568 |
|    std                  | 6.4           |
|    value_loss           | 6.18e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 291, ResetDay: 1971,Episode: 467
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 383           |
|    time_elapsed         | 8668          |
|    total_timesteps      | 784384        |
| train/                  |               |
|    approx_kl            | 19.926718     |
|    clip_fraction        | 0.689         |
|    clip_range           | 0.2           |
|    entropy_loss         | -91.2         |
|    explained_variance   | -0.875        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.838        |
|    n_updates            | 3820          |
|    policy_gradient_loss | 0.133         |
|    reward               | 0.00015064326 |
|    std                  | 6.42          |
|    value_loss           | 4.26e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1303, ResetDay: 2983,Episode: 468
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 384            |
|    time_elapsed         | 8691           |
|    total_timesteps      | 786432         |
| train/                  |                |
|    approx_kl            | 22.934196      |
|    clip_fraction        | 0.731          |
|    clip_range           | 0.2            |
|    entropy_loss         | -91.3          |
|    explained_variance   | -1.01          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.745         |
|    n_updates            | 3830           |
|    policy_gradient_loss | 0.17           |
|    reward               | -0.00064586906 |
|    std                  | 6.44           |
|    value_loss           | 6.21e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2236, ResetDay: 3916,Episode: 469
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 666, ResetDay: 2346,Episode: 470
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 385          |
|    time_elapsed         | 8713         |
|    total_timesteps      | 788480       |
| train/                  |              |
|    approx_kl            | 19.924795    |
|    clip_fraction        | 0.752        |
|    clip_range           | 0.2          |
|    entropy_loss         | -91.5        |
|    explained_variance   | -0.435       |
|    learning_rate        | 0.00025      |
|    loss                 | -0.772       |
|    n_updates            | 3840         |
|    policy_gradient_loss | 0.164        |
|    reward               | 9.167576e-06 |
|    std                  | 6.48         |
|    value_loss           | 4.72e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2346, episode: 470
begin_total_asset: 200.00
end_total_asset: 216.69
total_reward: 16.69
total_cost: 2.39
total_trades: 47039
Sharpe: 0.249
=================================
Reseting Environment StartDay: 2292, ResetDay: 3972,Episode: 471
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 386           |
|    time_elapsed         | 8736          |
|    total_timesteps      | 790528        |
| train/                  |               |
|    approx_kl            | 23.006386     |
|    clip_fraction        | 0.713         |
|    clip_range           | 0.2           |
|    entropy_loss         | -91.6         |
|    explained_variance   | -0.124        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.776        |
|    n_updates            | 3850          |
|    policy_gradient_loss | 0.147         |
|    reward               | 3.8268663e-05 |
|    std                  | 6.5           |
|    value_loss           | 9.99e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1573, ResetDay: 3253,Episode: 472
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 387           |
|    time_elapsed         | 8758          |
|    total_timesteps      | 792576        |
| train/                  |               |
|    approx_kl            | 19.467709     |
|    clip_fraction        | 0.724         |
|    clip_range           | 0.2           |
|    entropy_loss         | -91.7         |
|    explained_variance   | -0.797        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.655        |
|    n_updates            | 3860          |
|    policy_gradient_loss | 0.159         |
|    reward               | -6.108608e-05 |
|    std                  | 6.53          |
|    value_loss           | 4.6e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 653, ResetDay: 2333,Episode: 473
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 388           |
|    time_elapsed         | 8781          |
|    total_timesteps      | 794624        |
| train/                  |               |
|    approx_kl            | 23.729935     |
|    clip_fraction        | 0.734         |
|    clip_range           | 0.2           |
|    entropy_loss         | -91.8         |
|    explained_variance   | -0.000585     |
|    learning_rate        | 0.00025       |
|    loss                 | -0.642        |
|    n_updates            | 3870          |
|    policy_gradient_loss | 0.169         |
|    reward               | 0.00034805297 |
|    std                  | 6.56          |
|    value_loss           | 9.35e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 857, ResetDay: 2537,Episode: 474
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 389           |
|    time_elapsed         | 8804          |
|    total_timesteps      | 796672        |
| train/                  |               |
|    approx_kl            | 22.408285     |
|    clip_fraction        | 0.692         |
|    clip_range           | 0.2           |
|    entropy_loss         | -92           |
|    explained_variance   | -1.04         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.861        |
|    n_updates            | 3880          |
|    policy_gradient_loss | 0.109         |
|    reward               | 0.00010541248 |
|    std                  | 6.61          |
|    value_loss           | 4.32e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 412, ResetDay: 2092,Episode: 475
Environment reached Terminal state as number of trading days reached limit!!
day: 2092, episode: 475
begin_total_asset: 200.00
end_total_asset: 221.54
total_reward: 21.54
total_cost: 1.98
total_trades: 47040
Sharpe: 0.217
=================================
Reseting Environment StartDay: 1834, ResetDay: 3514,Episode: 476
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 390           |
|    time_elapsed         | 8826          |
|    total_timesteps      | 798720        |
| train/                  |               |
|    approx_kl            | 20.114        |
|    clip_fraction        | 0.72          |
|    clip_range           | 0.2           |
|    entropy_loss         | -92.2         |
|    explained_variance   | -0.686        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.84         |
|    n_updates            | 3890          |
|    policy_gradient_loss | 0.108         |
|    reward               | 0.00018625279 |
|    std                  | 6.65          |
|    value_loss           | 4.72e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 906, ResetDay: 2586,Episode: 477
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 391           |
|    time_elapsed         | 8849          |
|    total_timesteps      | 800768        |
| train/                  |               |
|    approx_kl            | 22.940918     |
|    clip_fraction        | 0.718         |
|    clip_range           | 0.2           |
|    entropy_loss         | -92.3         |
|    explained_variance   | -0.625        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.764        |
|    n_updates            | 3900          |
|    policy_gradient_loss | 0.185         |
|    reward               | 1.9307137e-05 |
|    std                  | 6.67          |
|    value_loss           | 7.53e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2004, ResetDay: 3684,Episode: 478
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 392           |
|    time_elapsed         | 8872          |
|    total_timesteps      | 802816        |
| train/                  |               |
|    approx_kl            | 21.484343     |
|    clip_fraction        | 0.685         |
|    clip_range           | 0.2           |
|    entropy_loss         | -92.4         |
|    explained_variance   | -0.299        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.851        |
|    n_updates            | 3910          |
|    policy_gradient_loss | 0.122         |
|    reward               | -6.619072e-06 |
|    std                  | 6.7           |
|    value_loss           | 7.52e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1302, ResetDay: 2982,Episode: 479
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 393          |
|    time_elapsed         | 8894         |
|    total_timesteps      | 804864       |
| train/                  |              |
|    approx_kl            | 19.831272    |
|    clip_fraction        | 0.7          |
|    clip_range           | 0.2          |
|    entropy_loss         | -92.6        |
|    explained_variance   | -0.346       |
|    learning_rate        | 0.00025      |
|    loss                 | -0.778       |
|    n_updates            | 3920         |
|    policy_gradient_loss | 0.132        |
|    reward               | 9.992371e-05 |
|    std                  | 6.75         |
|    value_loss           | 2.22e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2123, ResetDay: 3803,Episode: 480
Environment reached Terminal state as number of trading days reached limit!!
day: 3803, episode: 480
begin_total_asset: 200.00
end_total_asset: 240.10
total_reward: 40.10
total_cost: 1.96
total_trades: 47040
Sharpe: 0.238
=================================
Reseting Environment StartDay: 1177, ResetDay: 2857,Episode: 481
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 394            |
|    time_elapsed         | 8917           |
|    total_timesteps      | 806912         |
| train/                  |                |
|    approx_kl            | 25.51112       |
|    clip_fraction        | 0.747          |
|    clip_range           | 0.2            |
|    entropy_loss         | -92.7          |
|    explained_variance   | -0.0732        |
|    learning_rate        | 0.00025        |
|    loss                 | -0.657         |
|    n_updates            | 3930           |
|    policy_gradient_loss | 0.153          |
|    reward               | -2.9013252e-05 |
|    std                  | 6.78           |
|    value_loss           | 4.71e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1622, ResetDay: 3302,Episode: 482
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 395           |
|    time_elapsed         | 8939          |
|    total_timesteps      | 808960        |
| train/                  |               |
|    approx_kl            | 22.58072      |
|    clip_fraction        | 0.677         |
|    clip_range           | 0.2           |
|    entropy_loss         | -92.8         |
|    explained_variance   | -0.0531       |
|    learning_rate        | 0.00025       |
|    loss                 | -0.776        |
|    n_updates            | 3940          |
|    policy_gradient_loss | 0.127         |
|    reward               | 6.4370724e-05 |
|    std                  | 6.79          |
|    value_loss           | 5.04e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 923, ResetDay: 2603,Episode: 483
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 396           |
|    time_elapsed         | 8962          |
|    total_timesteps      | 811008        |
| train/                  |               |
|    approx_kl            | 19.255627     |
|    clip_fraction        | 0.732         |
|    clip_range           | 0.2           |
|    entropy_loss         | -92.9         |
|    explained_variance   | -0.956        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.807        |
|    n_updates            | 3950          |
|    policy_gradient_loss | 0.158         |
|    reward               | -0.0001492897 |
|    std                  | 6.84          |
|    value_loss           | 2.42e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 569, ResetDay: 2249,Episode: 484
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 397           |
|    time_elapsed         | 8984          |
|    total_timesteps      | 813056        |
| train/                  |               |
|    approx_kl            | 20.402575     |
|    clip_fraction        | 0.739         |
|    clip_range           | 0.2           |
|    entropy_loss         | -93.2         |
|    explained_variance   | -0.295        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.818        |
|    n_updates            | 3960          |
|    policy_gradient_loss | 0.163         |
|    reward               | 0.00012112904 |
|    std                  | 6.89          |
|    value_loss           | 3.81e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1500, ResetDay: 3180,Episode: 485
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 398            |
|    time_elapsed         | 9007           |
|    total_timesteps      | 815104         |
| train/                  |                |
|    approx_kl            | 19.836662      |
|    clip_fraction        | 0.721          |
|    clip_range           | 0.2            |
|    entropy_loss         | -93.3          |
|    explained_variance   | -0.602         |
|    learning_rate        | 0.00025        |
|    loss                 | -0.834         |
|    n_updates            | 3970           |
|    policy_gradient_loss | 0.161          |
|    reward               | -0.00014179497 |
|    std                  | 6.93           |
|    value_loss           | 4.59e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3180, episode: 485
begin_total_asset: 200.00
end_total_asset: 229.08
total_reward: 29.08
total_cost: 1.95
total_trades: 47034
Sharpe: 0.236
=================================
Reseting Environment StartDay: 1374, ResetDay: 3054,Episode: 486
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1544, ResetDay: 3224,Episode: 487
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 399           |
|    time_elapsed         | 9030          |
|    total_timesteps      | 817152        |
| train/                  |               |
|    approx_kl            | 19.53398      |
|    clip_fraction        | 0.668         |
|    clip_range           | 0.2           |
|    entropy_loss         | -93.5         |
|    explained_variance   | -0.282        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.788        |
|    n_updates            | 3980          |
|    policy_gradient_loss | 0.154         |
|    reward               | 1.8822193e-05 |
|    std                  | 6.98          |
|    value_loss           | 3.82e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2349, ResetDay: 4029,Episode: 488
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 400           |
|    time_elapsed         | 9052          |
|    total_timesteps      | 819200        |
| train/                  |               |
|    approx_kl            | 24.684958     |
|    clip_fraction        | 0.706         |
|    clip_range           | 0.2           |
|    entropy_loss         | -93.6         |
|    explained_variance   | -0.0475       |
|    learning_rate        | 0.00025       |
|    loss                 | -0.763        |
|    n_updates            | 3990          |
|    policy_gradient_loss | 0.148         |
|    reward               | -8.209038e-05 |
|    std                  | 7.02          |
|    value_loss           | 2.12e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 915, ResetDay: 2595,Episode: 489
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 401           |
|    time_elapsed         | 9074          |
|    total_timesteps      | 821248        |
| train/                  |               |
|    approx_kl            | 19.92416      |
|    clip_fraction        | 0.713         |
|    clip_range           | 0.2           |
|    entropy_loss         | -93.8         |
|    explained_variance   | -0.149        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.861        |
|    n_updates            | 4000          |
|    policy_gradient_loss | 0.167         |
|    reward               | 0.00019790058 |
|    std                  | 7.06          |
|    value_loss           | 2.38e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 280, ResetDay: 1960,Episode: 490
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 402          |
|    time_elapsed         | 9097         |
|    total_timesteps      | 823296       |
| train/                  |              |
|    approx_kl            | 23.061605    |
|    clip_fraction        | 0.73         |
|    clip_range           | 0.2          |
|    entropy_loss         | -94          |
|    explained_variance   | -0.361       |
|    learning_rate        | 0.00025      |
|    loss                 | -0.896       |
|    n_updates            | 4010         |
|    policy_gradient_loss | 0.159        |
|    reward               | 7.143526e-05 |
|    std                  | 7.1          |
|    value_loss           | 5.23e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 1960, episode: 490
begin_total_asset: 200.00
end_total_asset: 182.81
total_reward: -17.19
total_cost: 1.98
total_trades: 47038
Sharpe: 0.134
=================================
Reseting Environment StartDay: 1281, ResetDay: 2961,Episode: 491
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 403          |
|    time_elapsed         | 9119         |
|    total_timesteps      | 825344       |
| train/                  |              |
|    approx_kl            | 19.840954    |
|    clip_fraction        | 0.74         |
|    clip_range           | 0.2          |
|    entropy_loss         | -94.1        |
|    explained_variance   | -1.07        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.814       |
|    n_updates            | 4020         |
|    policy_gradient_loss | 0.169        |
|    reward               | 7.730065e-05 |
|    std                  | 7.11         |
|    value_loss           | 4.88e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1980, ResetDay: 3660,Episode: 492
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1571, ResetDay: 3251,Episode: 493
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 404            |
|    time_elapsed         | 9142           |
|    total_timesteps      | 827392         |
| train/                  |                |
|    approx_kl            | 19.51623       |
|    clip_fraction        | 0.735          |
|    clip_range           | 0.2            |
|    entropy_loss         | -94.2          |
|    explained_variance   | -0.0812        |
|    learning_rate        | 0.00025        |
|    loss                 | -0.826         |
|    n_updates            | 4030           |
|    policy_gradient_loss | 0.126          |
|    reward               | -8.5051346e-05 |
|    std                  | 7.15           |
|    value_loss           | 5.11e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2082, ResetDay: 3762,Episode: 494
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 405            |
|    time_elapsed         | 9165           |
|    total_timesteps      | 829440         |
| train/                  |                |
|    approx_kl            | 23.284418      |
|    clip_fraction        | 0.694          |
|    clip_range           | 0.2            |
|    entropy_loss         | -94.4          |
|    explained_variance   | -0.0468        |
|    learning_rate        | 0.00025        |
|    loss                 | -0.879         |
|    n_updates            | 4040           |
|    policy_gradient_loss | 0.137          |
|    reward               | -0.00033897744 |
|    std                  | 7.19           |
|    value_loss           | 4.09e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1103, ResetDay: 2783,Episode: 495
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 406           |
|    time_elapsed         | 9188          |
|    total_timesteps      | 831488        |
| train/                  |               |
|    approx_kl            | 19.523283     |
|    clip_fraction        | 0.709         |
|    clip_range           | 0.2           |
|    entropy_loss         | -94.5         |
|    explained_variance   | 0.0489        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.759        |
|    n_updates            | 4050          |
|    policy_gradient_loss | 0.165         |
|    reward               | 0.00018328581 |
|    std                  | 7.21          |
|    value_loss           | 3.48e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2783, episode: 495
begin_total_asset: 200.00
end_total_asset: 260.39
total_reward: 60.39
total_cost: 2.64
total_trades: 47040
Sharpe: 0.316
=================================
Reseting Environment StartDay: 1848, ResetDay: 3528,Episode: 496
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 407            |
|    time_elapsed         | 9210           |
|    total_timesteps      | 833536         |
| train/                  |                |
|    approx_kl            | 21.930687      |
|    clip_fraction        | 0.729          |
|    clip_range           | 0.2            |
|    entropy_loss         | -94.6          |
|    explained_variance   | -0.155         |
|    learning_rate        | 0.00025        |
|    loss                 | -0.827         |
|    n_updates            | 4060           |
|    policy_gradient_loss | 0.121          |
|    reward               | -2.0303727e-05 |
|    std                  | 7.25           |
|    value_loss           | 6.64e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2053, ResetDay: 3733,Episode: 497
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1268, ResetDay: 2948,Episode: 498
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 408            |
|    time_elapsed         | 9233           |
|    total_timesteps      | 835584         |
| train/                  |                |
|    approx_kl            | 20.78131       |
|    clip_fraction        | 0.704          |
|    clip_range           | 0.2            |
|    entropy_loss         | -94.8          |
|    explained_variance   | -0.0226        |
|    learning_rate        | 0.00025        |
|    loss                 | -0.87          |
|    n_updates            | 4070           |
|    policy_gradient_loss | 0.157          |
|    reward               | -0.00010815563 |
|    std                  | 7.3            |
|    value_loss           | 3.61e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2784, ResetDay: 4464,Episode: 499
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 409           |
|    time_elapsed         | 9256          |
|    total_timesteps      | 837632        |
| train/                  |               |
|    approx_kl            | 27.168934     |
|    clip_fraction        | 0.74          |
|    clip_range           | 0.2           |
|    entropy_loss         | -94.9         |
|    explained_variance   | -0.0603       |
|    learning_rate        | 0.00025       |
|    loss                 | -0.755        |
|    n_updates            | 4080          |
|    policy_gradient_loss | 0.173         |
|    reward               | 0.00035599823 |
|    std                  | 7.33          |
|    value_loss           | 7.81e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1536, ResetDay: 3216,Episode: 500
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 410           |
|    time_elapsed         | 9278          |
|    total_timesteps      | 839680        |
| train/                  |               |
|    approx_kl            | 18.696314     |
|    clip_fraction        | 0.714         |
|    clip_range           | 0.2           |
|    entropy_loss         | -95           |
|    explained_variance   | -0.271        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.843        |
|    n_updates            | 4090          |
|    policy_gradient_loss | 0.148         |
|    reward               | 0.00020590992 |
|    std                  | 7.37          |
|    value_loss           | 2.61e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3216, episode: 500
begin_total_asset: 200.00
end_total_asset: 190.40
total_reward: -9.60
total_cost: 1.94
total_trades: 47038
Sharpe: 0.158
=================================
Reseting Environment StartDay: 2710, ResetDay: 4390,Episode: 501
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 411           |
|    time_elapsed         | 9300          |
|    total_timesteps      | 841728        |
| train/                  |               |
|    approx_kl            | 27.187248     |
|    clip_fraction        | 0.721         |
|    clip_range           | 0.2           |
|    entropy_loss         | -95.2         |
|    explained_variance   | -0.053        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.821        |
|    n_updates            | 4100          |
|    policy_gradient_loss | 0.144         |
|    reward               | 0.00024403153 |
|    std                  | 7.41          |
|    value_loss           | 6.65e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2691, ResetDay: 4371,Episode: 502
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 412          |
|    time_elapsed         | 9323         |
|    total_timesteps      | 843776       |
| train/                  |              |
|    approx_kl            | 20.878662    |
|    clip_fraction        | 0.719        |
|    clip_range           | 0.2          |
|    entropy_loss         | -95.3        |
|    explained_variance   | -0.0175      |
|    learning_rate        | 0.00025      |
|    loss                 | -0.773       |
|    n_updates            | 4110         |
|    policy_gradient_loss | 0.206        |
|    reward               | 8.142853e-05 |
|    std                  | 7.45         |
|    value_loss           | 1.49e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2012, ResetDay: 3692,Episode: 503
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 341, ResetDay: 2021,Episode: 504
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 413            |
|    time_elapsed         | 9346           |
|    total_timesteps      | 845824         |
| train/                  |                |
|    approx_kl            | 32.233078      |
|    clip_fraction        | 0.702          |
|    clip_range           | 0.2            |
|    entropy_loss         | -95.5          |
|    explained_variance   | 0.00452        |
|    learning_rate        | 0.00025        |
|    loss                 | -0.764         |
|    n_updates            | 4120           |
|    policy_gradient_loss | 0.162          |
|    reward               | -0.00010988936 |
|    std                  | 7.5            |
|    value_loss           | 4.92e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1498, ResetDay: 3178,Episode: 505
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 414           |
|    time_elapsed         | 9368          |
|    total_timesteps      | 847872        |
| train/                  |               |
|    approx_kl            | 38.683624     |
|    clip_fraction        | 0.713         |
|    clip_range           | 0.2           |
|    entropy_loss         | -95.7         |
|    explained_variance   | -0.293        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.862        |
|    n_updates            | 4130          |
|    policy_gradient_loss | 0.104         |
|    reward               | -7.764435e-05 |
|    std                  | 7.54          |
|    value_loss           | 6.02e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3178, episode: 505
begin_total_asset: 200.00
end_total_asset: 315.19
total_reward: 115.19
total_cost: 2.29
total_trades: 47036
Sharpe: 0.440
=================================
Reseting Environment StartDay: 2151, ResetDay: 3831,Episode: 506
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 415            |
|    time_elapsed         | 9391           |
|    total_timesteps      | 849920         |
| train/                  |                |
|    approx_kl            | 18.841076      |
|    clip_fraction        | 0.7            |
|    clip_range           | 0.2            |
|    entropy_loss         | -95.8          |
|    explained_variance   | -1.42          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.815         |
|    n_updates            | 4140           |
|    policy_gradient_loss | 0.174          |
|    reward               | -0.00017669181 |
|    std                  | 7.58           |
|    value_loss           | 5.79e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2752, ResetDay: 4432,Episode: 507
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 416           |
|    time_elapsed         | 9413          |
|    total_timesteps      | 851968        |
| train/                  |               |
|    approx_kl            | 19.996832     |
|    clip_fraction        | 0.676         |
|    clip_range           | 0.2           |
|    entropy_loss         | -96           |
|    explained_variance   | -0.0321       |
|    learning_rate        | 0.00025       |
|    loss                 | -0.877        |
|    n_updates            | 4150          |
|    policy_gradient_loss | 0.151         |
|    reward               | -7.244339e-05 |
|    std                  | 7.62          |
|    value_loss           | 3.57e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1573, ResetDay: 3253,Episode: 508
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2774, ResetDay: 4454,Episode: 509
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 417           |
|    time_elapsed         | 9436          |
|    total_timesteps      | 854016        |
| train/                  |               |
|    approx_kl            | 24.97106      |
|    clip_fraction        | 0.717         |
|    clip_range           | 0.2           |
|    entropy_loss         | -96.1         |
|    explained_variance   | 0.02          |
|    learning_rate        | 0.00025       |
|    loss                 | -0.879        |
|    n_updates            | 4160          |
|    policy_gradient_loss | 0.158         |
|    reward               | -9.938374e-05 |
|    std                  | 7.65          |
|    value_loss           | 5.23e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1352, ResetDay: 3032,Episode: 510
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 418           |
|    time_elapsed         | 9459          |
|    total_timesteps      | 856064        |
| train/                  |               |
|    approx_kl            | 38.317844     |
|    clip_fraction        | 0.733         |
|    clip_range           | 0.2           |
|    entropy_loss         | -96.3         |
|    explained_variance   | -0.144        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.843        |
|    n_updates            | 4170          |
|    policy_gradient_loss | 0.159         |
|    reward               | -8.705406e-05 |
|    std                  | 7.71          |
|    value_loss           | 1.98e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3032, episode: 510
begin_total_asset: 200.00
end_total_asset: 167.23
total_reward: -32.77
total_cost: 2.26
total_trades: 47037
Sharpe: 0.163
=================================
Reseting Environment StartDay: 1246, ResetDay: 2926,Episode: 511
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 419           |
|    time_elapsed         | 9481          |
|    total_timesteps      | 858112        |
| train/                  |               |
|    approx_kl            | 22.061745     |
|    clip_fraction        | 0.744         |
|    clip_range           | 0.2           |
|    entropy_loss         | -96.4         |
|    explained_variance   | 0.00688       |
|    learning_rate        | 0.00025       |
|    loss                 | -0.822        |
|    n_updates            | 4180          |
|    policy_gradient_loss | 0.179         |
|    reward               | 2.5900936e-05 |
|    std                  | 7.76          |
|    value_loss           | 5.91e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2161, ResetDay: 3841,Episode: 512
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 420          |
|    time_elapsed         | 9504         |
|    total_timesteps      | 860160       |
| train/                  |              |
|    approx_kl            | 19.347145    |
|    clip_fraction        | 0.718        |
|    clip_range           | 0.2          |
|    entropy_loss         | -96.6        |
|    explained_variance   | -0.495       |
|    learning_rate        | 0.00025      |
|    loss                 | -0.678       |
|    n_updates            | 4190         |
|    policy_gradient_loss | 0.15         |
|    reward               | 9.743805e-05 |
|    std                  | 7.77         |
|    value_loss           | 2.65e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1284, ResetDay: 2964,Episode: 513
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 421           |
|    time_elapsed         | 9526          |
|    total_timesteps      | 862208        |
| train/                  |               |
|    approx_kl            | 20.206352     |
|    clip_fraction        | 0.723         |
|    clip_range           | 0.2           |
|    entropy_loss         | -96.6         |
|    explained_variance   | 0.00417       |
|    learning_rate        | 0.00025       |
|    loss                 | -0.818        |
|    n_updates            | 4200          |
|    policy_gradient_loss | 0.143         |
|    reward               | 4.4954108e-05 |
|    std                  | 7.79          |
|    value_loss           | 3.49e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 435, ResetDay: 2115,Episode: 514
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2079, ResetDay: 3759,Episode: 515
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 422           |
|    time_elapsed         | 9549          |
|    total_timesteps      | 864256        |
| train/                  |               |
|    approx_kl            | 26.346859     |
|    clip_fraction        | 0.702         |
|    clip_range           | 0.2           |
|    entropy_loss         | -96.7         |
|    explained_variance   | -0.256        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.884        |
|    n_updates            | 4210          |
|    policy_gradient_loss | 0.14          |
|    reward               | 0.00016417656 |
|    std                  | 7.83          |
|    value_loss           | 4.52e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3759, episode: 515
begin_total_asset: 200.00
end_total_asset: 371.56
total_reward: 171.56
total_cost: 2.37
total_trades: 47036
Sharpe: 0.626
=================================
Reseting Environment StartDay: 1250, ResetDay: 2930,Episode: 516
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 423           |
|    time_elapsed         | 9572          |
|    total_timesteps      | 866304        |
| train/                  |               |
|    approx_kl            | 21.1692       |
|    clip_fraction        | 0.734         |
|    clip_range           | 0.2           |
|    entropy_loss         | -96.9         |
|    explained_variance   | -0.976        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.841        |
|    n_updates            | 4220          |
|    policy_gradient_loss | 0.134         |
|    reward               | 0.00018673134 |
|    std                  | 7.88          |
|    value_loss           | 4.14e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 572, ResetDay: 2252,Episode: 517
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 424          |
|    time_elapsed         | 9594         |
|    total_timesteps      | 868352       |
| train/                  |              |
|    approx_kl            | 20.3386      |
|    clip_fraction        | 0.745        |
|    clip_range           | 0.2          |
|    entropy_loss         | -97.1        |
|    explained_variance   | -0.0651      |
|    learning_rate        | 0.00025      |
|    loss                 | -0.825       |
|    n_updates            | 4230         |
|    policy_gradient_loss | 0.139        |
|    reward               | 6.766834e-05 |
|    std                  | 7.93         |
|    value_loss           | 1.24e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 889, ResetDay: 2569,Episode: 518
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 425          |
|    time_elapsed         | 9617         |
|    total_timesteps      | 870400       |
| train/                  |              |
|    approx_kl            | 18.629448    |
|    clip_fraction        | 0.708        |
|    clip_range           | 0.2          |
|    entropy_loss         | -97.2        |
|    explained_variance   | -0.706       |
|    learning_rate        | 0.00025      |
|    loss                 | -0.89        |
|    n_updates            | 4240         |
|    policy_gradient_loss | 0.155        |
|    reward               | 6.818295e-05 |
|    std                  | 7.97         |
|    value_loss           | 5.55e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1187, ResetDay: 2867,Episode: 519
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1608, ResetDay: 3288,Episode: 520
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 426          |
|    time_elapsed         | 9639         |
|    total_timesteps      | 872448       |
| train/                  |              |
|    approx_kl            | 18.86346     |
|    clip_fraction        | 0.682        |
|    clip_range           | 0.2          |
|    entropy_loss         | -97.4        |
|    explained_variance   | -0.478       |
|    learning_rate        | 0.00025      |
|    loss                 | -0.849       |
|    n_updates            | 4250         |
|    policy_gradient_loss | 0.135        |
|    reward               | 9.686375e-05 |
|    std                  | 8.02         |
|    value_loss           | 8.19e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3288, episode: 520
begin_total_asset: 200.00
end_total_asset: 235.02
total_reward: 35.02
total_cost: 1.90
total_trades: 47038
Sharpe: 0.250
=================================
Reseting Environment StartDay: 775, ResetDay: 2455,Episode: 521
---------------------------------------------
| time/                   |                 |
|    fps                  | 90              |
|    iterations           | 427             |
|    time_elapsed         | 9662            |
|    total_timesteps      | 874496          |
| train/                  |                 |
|    approx_kl            | 20.351376       |
|    clip_fraction        | 0.744           |
|    clip_range           | 0.2             |
|    entropy_loss         | -97.5           |
|    explained_variance   | -0.129          |
|    learning_rate        | 0.00025         |
|    loss                 | -0.747          |
|    n_updates            | 4260            |
|    policy_gradient_loss | 0.146           |
|    reward               | -0.000102769896 |
|    std                  | 8.07            |
|    value_loss           | 4.68e-07        |
---------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1719, ResetDay: 3399,Episode: 522
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 428           |
|    time_elapsed         | 9684          |
|    total_timesteps      | 876544        |
| train/                  |               |
|    approx_kl            | 18.166716     |
|    clip_fraction        | 0.712         |
|    clip_range           | 0.2           |
|    entropy_loss         | -97.7         |
|    explained_variance   | -0.286        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.907        |
|    n_updates            | 4270          |
|    policy_gradient_loss | 0.133         |
|    reward               | 1.5695954e-05 |
|    std                  | 8.1           |
|    value_loss           | 4.28e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1077, ResetDay: 2757,Episode: 523
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 429          |
|    time_elapsed         | 9707         |
|    total_timesteps      | 878592       |
| train/                  |              |
|    approx_kl            | 18.179214    |
|    clip_fraction        | 0.734        |
|    clip_range           | 0.2          |
|    entropy_loss         | -97.8        |
|    explained_variance   | -0.325       |
|    learning_rate        | 0.00025      |
|    loss                 | -0.89        |
|    n_updates            | 4280         |
|    policy_gradient_loss | 0.149        |
|    reward               | 8.981838e-05 |
|    std                  | 8.13         |
|    value_loss           | 3.6e-07      |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 602, ResetDay: 2282,Episode: 524
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 430           |
|    time_elapsed         | 9729          |
|    total_timesteps      | 880640        |
| train/                  |               |
|    approx_kl            | 20.661795     |
|    clip_fraction        | 0.719         |
|    clip_range           | 0.2           |
|    entropy_loss         | -97.9         |
|    explained_variance   | -0.257        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.786        |
|    n_updates            | 4290          |
|    policy_gradient_loss | 0.141         |
|    reward               | 0.00020460701 |
|    std                  | 8.19          |
|    value_loss           | 1.07e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1439, ResetDay: 3119,Episode: 525
Environment reached Terminal state as number of trading days reached limit!!
day: 3119, episode: 525
begin_total_asset: 200.00
end_total_asset: 222.70
total_reward: 22.70
total_cost: 1.93
total_trades: 47040
Sharpe: 0.215
=================================
Reseting Environment StartDay: 2456, ResetDay: 4136,Episode: 526
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 431           |
|    time_elapsed         | 9752          |
|    total_timesteps      | 882688        |
| train/                  |               |
|    approx_kl            | 20.344885     |
|    clip_fraction        | 0.712         |
|    clip_range           | 0.2           |
|    entropy_loss         | -98.1         |
|    explained_variance   | -0.493        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.705        |
|    n_updates            | 4300          |
|    policy_gradient_loss | 0.147         |
|    reward               | 0.00069515343 |
|    std                  | 8.22          |
|    value_loss           | 8.09e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 793, ResetDay: 2473,Episode: 527
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 432            |
|    time_elapsed         | 9775           |
|    total_timesteps      | 884736         |
| train/                  |                |
|    approx_kl            | 19.071003      |
|    clip_fraction        | 0.706          |
|    clip_range           | 0.2            |
|    entropy_loss         | -98.2          |
|    explained_variance   | -0.0193        |
|    learning_rate        | 0.00025        |
|    loss                 | -0.868         |
|    n_updates            | 4310           |
|    policy_gradient_loss | 0.138          |
|    reward               | -4.4297172e-05 |
|    std                  | 8.25           |
|    value_loss           | 5.14e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2380, ResetDay: 4060,Episode: 528
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 433            |
|    time_elapsed         | 9797           |
|    total_timesteps      | 886784         |
| train/                  |                |
|    approx_kl            | 20.338736      |
|    clip_fraction        | 0.74           |
|    clip_range           | 0.2            |
|    entropy_loss         | -98.3          |
|    explained_variance   | -0.279         |
|    learning_rate        | 0.00025        |
|    loss                 | -0.835         |
|    n_updates            | 4320           |
|    policy_gradient_loss | 0.128          |
|    reward               | -8.1066515e-05 |
|    std                  | 8.29           |
|    value_loss           | 2.94e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1508, ResetDay: 3188,Episode: 529
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 434          |
|    time_elapsed         | 9820         |
|    total_timesteps      | 888832       |
| train/                  |              |
|    approx_kl            | 17.811712    |
|    clip_fraction        | 0.718        |
|    clip_range           | 0.2          |
|    entropy_loss         | -98.5        |
|    explained_variance   | -0.484       |
|    learning_rate        | 0.00025      |
|    loss                 | -0.862       |
|    n_updates            | 4330         |
|    policy_gradient_loss | 0.158        |
|    reward               | 6.113091e-05 |
|    std                  | 8.34         |
|    value_loss           | 2.76e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1933, ResetDay: 3613,Episode: 530
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 435           |
|    time_elapsed         | 9843          |
|    total_timesteps      | 890880        |
| train/                  |               |
|    approx_kl            | 25.280495     |
|    clip_fraction        | 0.728         |
|    clip_range           | 0.2           |
|    entropy_loss         | -98.6         |
|    explained_variance   | -0.019        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.837        |
|    n_updates            | 4340          |
|    policy_gradient_loss | 0.115         |
|    reward               | 2.6467515e-05 |
|    std                  | 8.37          |
|    value_loss           | 5.85e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3613, episode: 530
begin_total_asset: 200.00
end_total_asset: 248.16
total_reward: 48.16
total_cost: 1.94
total_trades: 47036
Sharpe: 0.281
=================================
Reseting Environment StartDay: 2433, ResetDay: 4113,Episode: 531
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2406, ResetDay: 4086,Episode: 532
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 436            |
|    time_elapsed         | 9865           |
|    total_timesteps      | 892928         |
| train/                  |                |
|    approx_kl            | 21.089413      |
|    clip_fraction        | 0.734          |
|    clip_range           | 0.2            |
|    entropy_loss         | -98.7          |
|    explained_variance   | -0.107         |
|    learning_rate        | 0.00025        |
|    loss                 | -0.897         |
|    n_updates            | 4350           |
|    policy_gradient_loss | 0.141          |
|    reward               | 0.000105437466 |
|    std                  | 8.42           |
|    value_loss           | 2.73e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2362, ResetDay: 4042,Episode: 533
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 437            |
|    time_elapsed         | 9888           |
|    total_timesteps      | 894976         |
| train/                  |                |
|    approx_kl            | 26.056713      |
|    clip_fraction        | 0.71           |
|    clip_range           | 0.2            |
|    entropy_loss         | -98.9          |
|    explained_variance   | -0.0328        |
|    learning_rate        | 0.00025        |
|    loss                 | -0.923         |
|    n_updates            | 4360           |
|    policy_gradient_loss | 0.126          |
|    reward               | -3.8110353e-05 |
|    std                  | 8.47           |
|    value_loss           | 5.14e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 78, ResetDay: 1758,Episode: 534
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 438           |
|    time_elapsed         | 9911          |
|    total_timesteps      | 897024        |
| train/                  |               |
|    approx_kl            | 19.74947      |
|    clip_fraction        | 0.714         |
|    clip_range           | 0.2           |
|    entropy_loss         | -99.1         |
|    explained_variance   | 0.0747        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.95         |
|    n_updates            | 4370          |
|    policy_gradient_loss | 0.112         |
|    reward               | -9.586463e-05 |
|    std                  | 8.51          |
|    value_loss           | 4.15e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1439, ResetDay: 3119,Episode: 535
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 439           |
|    time_elapsed         | 9933          |
|    total_timesteps      | 899072        |
| train/                  |               |
|    approx_kl            | 22.269054     |
|    clip_fraction        | 0.689         |
|    clip_range           | 0.2           |
|    entropy_loss         | -99.2         |
|    explained_variance   | -1.67         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.959        |
|    n_updates            | 4380          |
|    policy_gradient_loss | 0.113         |
|    reward               | 0.00037671375 |
|    std                  | 8.56          |
|    value_loss           | 8.01e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3119, episode: 535
begin_total_asset: 200.00
end_total_asset: 413.82
total_reward: 213.82
total_cost: 2.46
total_trades: 47038
Sharpe: 0.761
=================================
Reseting Environment StartDay: 2305, ResetDay: 3985,Episode: 536
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 403, ResetDay: 2083,Episode: 537
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 440           |
|    time_elapsed         | 9956          |
|    total_timesteps      | 901120        |
| train/                  |               |
|    approx_kl            | 18.410322     |
|    clip_fraction        | 0.711         |
|    clip_range           | 0.2           |
|    entropy_loss         | -99.3         |
|    explained_variance   | -0.22         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.912        |
|    n_updates            | 4390          |
|    policy_gradient_loss | 0.14          |
|    reward               | 5.4044915e-05 |
|    std                  | 8.61          |
|    value_loss           | 5.95e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 406, ResetDay: 2086,Episode: 538
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 441            |
|    time_elapsed         | 9978           |
|    total_timesteps      | 903168         |
| train/                  |                |
|    approx_kl            | 20.951742      |
|    clip_fraction        | 0.73           |
|    clip_range           | 0.2            |
|    entropy_loss         | -99.5          |
|    explained_variance   | -0.0312        |
|    learning_rate        | 0.00025        |
|    loss                 | -0.878         |
|    n_updates            | 4400           |
|    policy_gradient_loss | 0.111          |
|    reward               | 0.000120745564 |
|    std                  | 8.64           |
|    value_loss           | 5.81e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1186, ResetDay: 2866,Episode: 539
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 442            |
|    time_elapsed         | 10001          |
|    total_timesteps      | 905216         |
| train/                  |                |
|    approx_kl            | 18.354706      |
|    clip_fraction        | 0.741          |
|    clip_range           | 0.2            |
|    entropy_loss         | -99.6          |
|    explained_variance   | -2.04          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.877         |
|    n_updates            | 4410           |
|    policy_gradient_loss | 0.129          |
|    reward               | -0.00023282165 |
|    std                  | 8.67           |
|    value_loss           | 4.98e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2195, ResetDay: 3875,Episode: 540
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 443           |
|    time_elapsed         | 10023         |
|    total_timesteps      | 907264        |
| train/                  |               |
|    approx_kl            | 17.762222     |
|    clip_fraction        | 0.71          |
|    clip_range           | 0.2           |
|    entropy_loss         | -99.7         |
|    explained_variance   | -1.04         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.962        |
|    n_updates            | 4420          |
|    policy_gradient_loss | 0.146         |
|    reward               | 0.00020207977 |
|    std                  | 8.72          |
|    value_loss           | 6.09e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3875, episode: 540
begin_total_asset: 200.00
end_total_asset: 262.00
total_reward: 62.00
total_cost: 1.92
total_trades: 47037
Sharpe: 0.308
=================================
Reseting Environment StartDay: 878, ResetDay: 2558,Episode: 541
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 444           |
|    time_elapsed         | 10046         |
|    total_timesteps      | 909312        |
| train/                  |               |
|    approx_kl            | 19.578228     |
|    clip_fraction        | 0.733         |
|    clip_range           | 0.2           |
|    entropy_loss         | -99.8         |
|    explained_variance   | -0.0149       |
|    learning_rate        | 0.00025       |
|    loss                 | -0.861        |
|    n_updates            | 4430          |
|    policy_gradient_loss | 0.13          |
|    reward               | 0.00043702545 |
|    std                  | 8.74          |
|    value_loss           | 4.1e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2613, ResetDay: 4293,Episode: 542
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 581, ResetDay: 2261,Episode: 543
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 445          |
|    time_elapsed         | 10068        |
|    total_timesteps      | 911360       |
| train/                  |              |
|    approx_kl            | 25.125042    |
|    clip_fraction        | 0.735        |
|    clip_range           | 0.2          |
|    entropy_loss         | -99.9        |
|    explained_variance   | -0.232       |
|    learning_rate        | 0.00025      |
|    loss                 | -0.772       |
|    n_updates            | 4440         |
|    policy_gradient_loss | 0.121        |
|    reward               | 5.837822e-06 |
|    std                  | 8.8          |
|    value_loss           | 2.22e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1090, ResetDay: 2770,Episode: 544
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 446           |
|    time_elapsed         | 10091         |
|    total_timesteps      | 913408        |
| train/                  |               |
|    approx_kl            | 20.116264     |
|    clip_fraction        | 0.698         |
|    clip_range           | 0.2           |
|    entropy_loss         | -100          |
|    explained_variance   | -0.139        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.905        |
|    n_updates            | 4450          |
|    policy_gradient_loss | 0.124         |
|    reward               | -9.912491e-06 |
|    std                  | 8.83          |
|    value_loss           | 8.47e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 811, ResetDay: 2491,Episode: 545
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 447           |
|    time_elapsed         | 10114         |
|    total_timesteps      | 915456        |
| train/                  |               |
|    approx_kl            | 17.813065     |
|    clip_fraction        | 0.723         |
|    clip_range           | 0.2           |
|    entropy_loss         | -100          |
|    explained_variance   | -1.43         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.834        |
|    n_updates            | 4460          |
|    policy_gradient_loss | 0.133         |
|    reward               | 0.00013641357 |
|    std                  | 8.88          |
|    value_loss           | 4.83e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2491, episode: 545
begin_total_asset: 200.00
end_total_asset: 233.41
total_reward: 33.41
total_cost: 1.98
total_trades: 47035
Sharpe: 0.246
=================================
Reseting Environment StartDay: 1096, ResetDay: 2776,Episode: 546
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 448          |
|    time_elapsed         | 10136        |
|    total_timesteps      | 917504       |
| train/                  |              |
|    approx_kl            | 18.322708    |
|    clip_fraction        | 0.711        |
|    clip_range           | 0.2          |
|    entropy_loss         | -100         |
|    explained_variance   | -0.214       |
|    learning_rate        | 0.00025      |
|    loss                 | -0.84        |
|    n_updates            | 4470         |
|    policy_gradient_loss | 0.122        |
|    reward               | -7.68425e-05 |
|    std                  | 8.95         |
|    value_loss           | 3.95e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2083, ResetDay: 3763,Episode: 547
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2544, ResetDay: 4224,Episode: 548
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 449           |
|    time_elapsed         | 10159         |
|    total_timesteps      | 919552        |
| train/                  |               |
|    approx_kl            | 18.149017     |
|    clip_fraction        | 0.694         |
|    clip_range           | 0.2           |
|    entropy_loss         | -101          |
|    explained_variance   | -0.353        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.929        |
|    n_updates            | 4480          |
|    policy_gradient_loss | 0.119         |
|    reward               | -3.548832e-05 |
|    std                  | 8.99          |
|    value_loss           | 3.84e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2092, ResetDay: 3772,Episode: 549
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 450            |
|    time_elapsed         | 10182          |
|    total_timesteps      | 921600         |
| train/                  |                |
|    approx_kl            | 20.134186      |
|    clip_fraction        | 0.711          |
|    clip_range           | 0.2            |
|    entropy_loss         | -101           |
|    explained_variance   | 0.0576         |
|    learning_rate        | 0.00025        |
|    loss                 | -0.899         |
|    n_updates            | 4490           |
|    policy_gradient_loss | 0.114          |
|    reward               | -4.1520692e-05 |
|    std                  | 9.02           |
|    value_loss           | 5.8e-07        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1020, ResetDay: 2700,Episode: 550
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 451           |
|    time_elapsed         | 10205         |
|    total_timesteps      | 923648        |
| train/                  |               |
|    approx_kl            | 20.28196      |
|    clip_fraction        | 0.719         |
|    clip_range           | 0.2           |
|    entropy_loss         | -101          |
|    explained_variance   | 0.027         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.838        |
|    n_updates            | 4500          |
|    policy_gradient_loss | 0.159         |
|    reward               | 5.3335476e-05 |
|    std                  | 9.07          |
|    value_loss           | 6.74e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2700, episode: 550
begin_total_asset: 200.00
end_total_asset: 201.35
total_reward: 1.35
total_cost: 1.98
total_trades: 47038
Sharpe: 0.206
=================================
Reseting Environment StartDay: 578, ResetDay: 2258,Episode: 551
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 452          |
|    time_elapsed         | 10227        |
|    total_timesteps      | 925696       |
| train/                  |              |
|    approx_kl            | 20.070316    |
|    clip_fraction        | 0.725        |
|    clip_range           | 0.2          |
|    entropy_loss         | -101         |
|    explained_variance   | -0.385       |
|    learning_rate        | 0.00025      |
|    loss                 | -0.932       |
|    n_updates            | 4510         |
|    policy_gradient_loss | 0.123        |
|    reward               | 0.0002820875 |
|    std                  | 9.1          |
|    value_loss           | 3.8e-06      |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1336, ResetDay: 3016,Episode: 552
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 453            |
|    time_elapsed         | 10250          |
|    total_timesteps      | 927744         |
| train/                  |                |
|    approx_kl            | 18.304531      |
|    clip_fraction        | 0.706          |
|    clip_range           | 0.2            |
|    entropy_loss         | -101           |
|    explained_variance   | -0.366         |
|    learning_rate        | 0.00025        |
|    loss                 | -0.855         |
|    n_updates            | 4520           |
|    policy_gradient_loss | 0.142          |
|    reward               | -1.7330933e-05 |
|    std                  | 9.16           |
|    value_loss           | 4.16e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2080, ResetDay: 3760,Episode: 553
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2750, ResetDay: 4430,Episode: 554
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 454            |
|    time_elapsed         | 10272          |
|    total_timesteps      | 929792         |
| train/                  |                |
|    approx_kl            | 18.228764      |
|    clip_fraction        | 0.725          |
|    clip_range           | 0.2            |
|    entropy_loss         | -101           |
|    explained_variance   | -0.103         |
|    learning_rate        | 0.00025        |
|    loss                 | -0.906         |
|    n_updates            | 4530           |
|    policy_gradient_loss | 0.139          |
|    reward               | -1.0748672e-05 |
|    std                  | 9.2            |
|    value_loss           | 2.89e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 336, ResetDay: 2016,Episode: 555
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 455          |
|    time_elapsed         | 10295        |
|    total_timesteps      | 931840       |
| train/                  |              |
|    approx_kl            | 21.062918    |
|    clip_fraction        | 0.734        |
|    clip_range           | 0.2          |
|    entropy_loss         | -101         |
|    explained_variance   | 0.00455      |
|    learning_rate        | 0.00025      |
|    loss                 | -0.8         |
|    n_updates            | 4540         |
|    policy_gradient_loss | 0.141        |
|    reward               | -6.44177e-05 |
|    std                  | 9.22         |
|    value_loss           | 2.6e-07      |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2016, episode: 555
begin_total_asset: 200.00
end_total_asset: 179.59
total_reward: -20.41
total_cost: 2.20
total_trades: 47039
Sharpe: 0.158
=================================
Reseting Environment StartDay: 1803, ResetDay: 3483,Episode: 556
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 456           |
|    time_elapsed         | 10317         |
|    total_timesteps      | 933888        |
| train/                  |               |
|    approx_kl            | 20.99848      |
|    clip_fraction        | 0.741         |
|    clip_range           | 0.2           |
|    entropy_loss         | -101          |
|    explained_variance   | -0.267        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.884        |
|    n_updates            | 4550          |
|    policy_gradient_loss | 0.125         |
|    reward               | 0.00049778994 |
|    std                  | 9.26          |
|    value_loss           | 7.57e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1760, ResetDay: 3440,Episode: 557
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 457           |
|    time_elapsed         | 10340         |
|    total_timesteps      | 935936        |
| train/                  |               |
|    approx_kl            | 17.80606      |
|    clip_fraction        | 0.689         |
|    clip_range           | 0.2           |
|    entropy_loss         | -102          |
|    explained_variance   | -0.535        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.942        |
|    n_updates            | 4560          |
|    policy_gradient_loss | 0.135         |
|    reward               | 2.9536628e-05 |
|    std                  | 9.29          |
|    value_loss           | 4.14e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 716, ResetDay: 2396,Episode: 558
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 458            |
|    time_elapsed         | 10362          |
|    total_timesteps      | 937984         |
| train/                  |                |
|    approx_kl            | 20.38508       |
|    clip_fraction        | 0.714          |
|    clip_range           | 0.2            |
|    entropy_loss         | -102           |
|    explained_variance   | -0.0416        |
|    learning_rate        | 0.00025        |
|    loss                 | -0.818         |
|    n_updates            | 4570           |
|    policy_gradient_loss | 0.106          |
|    reward               | -4.6030043e-05 |
|    std                  | 9.36           |
|    value_loss           | 6.15e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1856, ResetDay: 3536,Episode: 559
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1085, ResetDay: 2765,Episode: 560
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 459           |
|    time_elapsed         | 10385         |
|    total_timesteps      | 940032        |
| train/                  |               |
|    approx_kl            | 21.84507      |
|    clip_fraction        | 0.737         |
|    clip_range           | 0.2           |
|    entropy_loss         | -102          |
|    explained_variance   | -0.633        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.874        |
|    n_updates            | 4580          |
|    policy_gradient_loss | 0.154         |
|    reward               | 5.3135873e-06 |
|    std                  | 9.41          |
|    value_loss           | 3.63e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2765, episode: 560
begin_total_asset: 200.00
end_total_asset: 152.19
total_reward: -47.81
total_cost: 1.94
total_trades: 47036
Sharpe: 0.076
=================================
Reseting Environment StartDay: 1208, ResetDay: 2888,Episode: 561
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 460            |
|    time_elapsed         | 10407          |
|    total_timesteps      | 942080         |
| train/                  |                |
|    approx_kl            | 19.610785      |
|    clip_fraction        | 0.723          |
|    clip_range           | 0.2            |
|    entropy_loss         | -102           |
|    explained_variance   | -0.151         |
|    learning_rate        | 0.00025        |
|    loss                 | -0.938         |
|    n_updates            | 4590           |
|    policy_gradient_loss | 0.111          |
|    reward               | -0.00023980218 |
|    std                  | 9.47           |
|    value_loss           | 6.07e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1505, ResetDay: 3185,Episode: 562
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 461          |
|    time_elapsed         | 10430        |
|    total_timesteps      | 944128       |
| train/                  |              |
|    approx_kl            | 18.325       |
|    clip_fraction        | 0.723        |
|    clip_range           | 0.2          |
|    entropy_loss         | -102         |
|    explained_variance   | -0.237       |
|    learning_rate        | 0.00025      |
|    loss                 | -0.918       |
|    n_updates            | 4600         |
|    policy_gradient_loss | 0.122        |
|    reward               | 3.008194e-05 |
|    std                  | 9.54         |
|    value_loss           | 2.59e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 382, ResetDay: 2062,Episode: 563
---------------------------------------------
| time/                   |                 |
|    fps                  | 90              |
|    iterations           | 462             |
|    time_elapsed         | 10453           |
|    total_timesteps      | 946176          |
| train/                  |                 |
|    approx_kl            | 18.702091       |
|    clip_fraction        | 0.701           |
|    clip_range           | 0.2             |
|    entropy_loss         | -102            |
|    explained_variance   | 0.0964          |
|    learning_rate        | 0.00025         |
|    loss                 | -0.818          |
|    n_updates            | 4610            |
|    policy_gradient_loss | 0.134           |
|    reward               | -0.000115462586 |
|    std                  | 9.59            |
|    value_loss           | 3.23e-07        |
---------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1279, ResetDay: 2959,Episode: 564
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1892, ResetDay: 3572,Episode: 565
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 463            |
|    time_elapsed         | 10475          |
|    total_timesteps      | 948224         |
| train/                  |                |
|    approx_kl            | 20.24309       |
|    clip_fraction        | 0.704          |
|    clip_range           | 0.2            |
|    entropy_loss         | -102           |
|    explained_variance   | -0.887         |
|    learning_rate        | 0.00025        |
|    loss                 | -0.951         |
|    n_updates            | 4620           |
|    policy_gradient_loss | 0.104          |
|    reward               | -5.1546478e-05 |
|    std                  | 9.63           |
|    value_loss           | 5.96e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3572, episode: 565
begin_total_asset: 200.00
end_total_asset: 266.14
total_reward: 66.14
total_cost: 1.96
total_trades: 47034
Sharpe: 0.330
=================================
Reseting Environment StartDay: 2013, ResetDay: 3693,Episode: 566
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 464           |
|    time_elapsed         | 10498         |
|    total_timesteps      | 950272        |
| train/                  |               |
|    approx_kl            | 19.041893     |
|    clip_fraction        | 0.718         |
|    clip_range           | 0.2           |
|    entropy_loss         | -103          |
|    explained_variance   | -0.073        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.849        |
|    n_updates            | 4630          |
|    policy_gradient_loss | 0.114         |
|    reward               | -8.123493e-05 |
|    std                  | 9.7           |
|    value_loss           | 4.65e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 211, ResetDay: 1891,Episode: 567
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 465           |
|    time_elapsed         | 10520         |
|    total_timesteps      | 952320        |
| train/                  |               |
|    approx_kl            | 19.206474     |
|    clip_fraction        | 0.711         |
|    clip_range           | 0.2           |
|    entropy_loss         | -103          |
|    explained_variance   | -0.0506       |
|    learning_rate        | 0.00025       |
|    loss                 | -0.894        |
|    n_updates            | 4640          |
|    policy_gradient_loss | 0.118         |
|    reward               | -6.448898e-05 |
|    std                  | 9.75          |
|    value_loss           | 3.48e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1749, ResetDay: 3429,Episode: 568
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 466           |
|    time_elapsed         | 10544         |
|    total_timesteps      | 954368        |
| train/                  |               |
|    approx_kl            | 20.160114     |
|    clip_fraction        | 0.702         |
|    clip_range           | 0.2           |
|    entropy_loss         | -103          |
|    explained_variance   | -0.885        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.876        |
|    n_updates            | 4650          |
|    policy_gradient_loss | 0.111         |
|    reward               | 0.00042824057 |
|    std                  | 9.8           |
|    value_loss           | 5e-07         |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 916, ResetDay: 2596,Episode: 569
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 467            |
|    time_elapsed         | 10566          |
|    total_timesteps      | 956416         |
| train/                  |                |
|    approx_kl            | 18.291332      |
|    clip_fraction        | 0.692          |
|    clip_range           | 0.2            |
|    entropy_loss         | -103           |
|    explained_variance   | -0.225         |
|    learning_rate        | 0.00025        |
|    loss                 | -0.968         |
|    n_updates            | 4660           |
|    policy_gradient_loss | 0.113          |
|    reward               | -0.00010748596 |
|    std                  | 9.87           |
|    value_loss           | 6.77e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2161, ResetDay: 3841,Episode: 570
Environment reached Terminal state as number of trading days reached limit!!
day: 3841, episode: 570
begin_total_asset: 200.00
end_total_asset: 274.84
total_reward: 74.84
total_cost: 1.97
total_trades: 47040
Sharpe: 0.338
=================================
Reseting Environment StartDay: 1667, ResetDay: 3347,Episode: 571
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 468          |
|    time_elapsed         | 10589        |
|    total_timesteps      | 958464       |
| train/                  |              |
|    approx_kl            | 21.10355     |
|    clip_fraction        | 0.717        |
|    clip_range           | 0.2          |
|    entropy_loss         | -103         |
|    explained_variance   | -0.101       |
|    learning_rate        | 0.00025      |
|    loss                 | -0.902       |
|    n_updates            | 4670         |
|    policy_gradient_loss | 0.129        |
|    reward               | 7.460632e-05 |
|    std                  | 9.92         |
|    value_loss           | 8.53e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 872, ResetDay: 2552,Episode: 572
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 469          |
|    time_elapsed         | 10611        |
|    total_timesteps      | 960512       |
| train/                  |              |
|    approx_kl            | 19.89105     |
|    clip_fraction        | 0.683        |
|    clip_range           | 0.2          |
|    entropy_loss         | -103         |
|    explained_variance   | 0.0174       |
|    learning_rate        | 0.00025      |
|    loss                 | -0.941       |
|    n_updates            | 4680         |
|    policy_gradient_loss | 0.109        |
|    reward               | 0.0001356678 |
|    std                  | 9.99         |
|    value_loss           | 2.74e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1144, ResetDay: 2824,Episode: 573
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 470            |
|    time_elapsed         | 10634          |
|    total_timesteps      | 962560         |
| train/                  |                |
|    approx_kl            | 18.897903      |
|    clip_fraction        | 0.73           |
|    clip_range           | 0.2            |
|    entropy_loss         | -104           |
|    explained_variance   | -0.481         |
|    learning_rate        | 0.00025        |
|    loss                 | -0.931         |
|    n_updates            | 4690           |
|    policy_gradient_loss | 0.117          |
|    reward               | -0.00022593013 |
|    std                  | 10             |
|    value_loss           | 3.49e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1651, ResetDay: 3331,Episode: 574
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 471           |
|    time_elapsed         | 10657         |
|    total_timesteps      | 964608        |
| train/                  |               |
|    approx_kl            | 18.681683     |
|    clip_fraction        | 0.74          |
|    clip_range           | 0.2           |
|    entropy_loss         | -104          |
|    explained_variance   | -0.318        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.958        |
|    n_updates            | 4700          |
|    policy_gradient_loss | 0.138         |
|    reward               | -6.122398e-05 |
|    std                  | 10.1          |
|    value_loss           | 4.98e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 609, ResetDay: 2289,Episode: 575
Environment reached Terminal state as number of trading days reached limit!!
day: 2289, episode: 575
begin_total_asset: 200.00
end_total_asset: 238.05
total_reward: 38.05
total_cost: 1.98
total_trades: 47040
Sharpe: 0.258
=================================
Reseting Environment StartDay: 1808, ResetDay: 3488,Episode: 576
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 472            |
|    time_elapsed         | 10679          |
|    total_timesteps      | 966656         |
| train/                  |                |
|    approx_kl            | 19.066406      |
|    clip_fraction        | 0.721          |
|    clip_range           | 0.2            |
|    entropy_loss         | -104           |
|    explained_variance   | 0.031          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.952         |
|    n_updates            | 4710           |
|    policy_gradient_loss | 0.121          |
|    reward               | -1.2367249e-06 |
|    std                  | 10.1           |
|    value_loss           | 3.26e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2579, ResetDay: 4259,Episode: 577
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 473          |
|    time_elapsed         | 10702        |
|    total_timesteps      | 968704       |
| train/                  |              |
|    approx_kl            | 20.745632    |
|    clip_fraction        | 0.71         |
|    clip_range           | 0.2          |
|    entropy_loss         | -104         |
|    explained_variance   | -0.474       |
|    learning_rate        | 0.00025      |
|    loss                 | -0.975       |
|    n_updates            | 4720         |
|    policy_gradient_loss | 0.116        |
|    reward               | 3.313427e-05 |
|    std                  | 10.2         |
|    value_loss           | 4.37e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2699, ResetDay: 4379,Episode: 578
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 474          |
|    time_elapsed         | 10724        |
|    total_timesteps      | 970752       |
| train/                  |              |
|    approx_kl            | 19.01847     |
|    clip_fraction        | 0.719        |
|    clip_range           | 0.2          |
|    entropy_loss         | -104         |
|    explained_variance   | 0.0119       |
|    learning_rate        | 0.00025      |
|    loss                 | -0.893       |
|    n_updates            | 4730         |
|    policy_gradient_loss | 0.104        |
|    reward               | 5.870247e-05 |
|    std                  | 10.2         |
|    value_loss           | 2.83e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1076, ResetDay: 2756,Episode: 579
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 475            |
|    time_elapsed         | 10747          |
|    total_timesteps      | 972800         |
| train/                  |                |
|    approx_kl            | 21.074736      |
|    clip_fraction        | 0.709          |
|    clip_range           | 0.2            |
|    entropy_loss         | -104           |
|    explained_variance   | 0.021          |
|    learning_rate        | 0.00025        |
|    loss                 | -0.846         |
|    n_updates            | 4740           |
|    policy_gradient_loss | 0.131          |
|    reward               | -0.00019627286 |
|    std                  | 10.2           |
|    value_loss           | 4.3e-07        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2000, ResetDay: 3680,Episode: 580
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 476            |
|    time_elapsed         | 10770          |
|    total_timesteps      | 974848         |
| train/                  |                |
|    approx_kl            | 24.0219        |
|    clip_fraction        | 0.723          |
|    clip_range           | 0.2            |
|    entropy_loss         | -104           |
|    explained_variance   | -0.301         |
|    learning_rate        | 0.00025        |
|    loss                 | -0.927         |
|    n_updates            | 4750           |
|    policy_gradient_loss | 0.117          |
|    reward               | -0.00011387749 |
|    std                  | 10.3           |
|    value_loss           | 1.07e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3680, episode: 580
begin_total_asset: 200.00
end_total_asset: 331.46
total_reward: 131.46
total_cost: 1.93
total_trades: 47035
Sharpe: 0.561
=================================
Reseting Environment StartDay: 1577, ResetDay: 3257,Episode: 581
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 441, ResetDay: 2121,Episode: 582
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 477          |
|    time_elapsed         | 10792        |
|    total_timesteps      | 976896       |
| train/                  |              |
|    approx_kl            | 19.534819    |
|    clip_fraction        | 0.723        |
|    clip_range           | 0.2          |
|    entropy_loss         | -104         |
|    explained_variance   | -0.139       |
|    learning_rate        | 0.00025      |
|    loss                 | -0.937       |
|    n_updates            | 4760         |
|    policy_gradient_loss | 0.114        |
|    reward               | 6.278591e-05 |
|    std                  | 10.3         |
|    value_loss           | 4.27e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1843, ResetDay: 3523,Episode: 583
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 478            |
|    time_elapsed         | 10815          |
|    total_timesteps      | 978944         |
| train/                  |                |
|    approx_kl            | 23.757137      |
|    clip_fraction        | 0.691          |
|    clip_range           | 0.2            |
|    entropy_loss         | -104           |
|    explained_variance   | -0.152         |
|    learning_rate        | 0.00025        |
|    loss                 | -0.916         |
|    n_updates            | 4770           |
|    policy_gradient_loss | 0.107          |
|    reward               | -0.00018400383 |
|    std                  | 10.4           |
|    value_loss           | 4.01e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 461, ResetDay: 2141,Episode: 584
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 479           |
|    time_elapsed         | 10837         |
|    total_timesteps      | 980992        |
| train/                  |               |
|    approx_kl            | 18.756855     |
|    clip_fraction        | 0.713         |
|    clip_range           | 0.2           |
|    entropy_loss         | -105          |
|    explained_variance   | -0.341        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.953        |
|    n_updates            | 4780          |
|    policy_gradient_loss | 0.111         |
|    reward               | 3.0692576e-05 |
|    std                  | 10.4          |
|    value_loss           | 6.99e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1953, ResetDay: 3633,Episode: 585
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 480           |
|    time_elapsed         | 10860         |
|    total_timesteps      | 983040        |
| train/                  |               |
|    approx_kl            | 20.453999     |
|    clip_fraction        | 0.705         |
|    clip_range           | 0.2           |
|    entropy_loss         | -105          |
|    explained_variance   | -0.255        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.862        |
|    n_updates            | 4790          |
|    policy_gradient_loss | 0.0999        |
|    reward               | 0.00038646965 |
|    std                  | 10.5          |
|    value_loss           | 9.38e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3633, episode: 585
begin_total_asset: 200.00
end_total_asset: 348.63
total_reward: 148.63
total_cost: 1.91
total_trades: 47035
Sharpe: 0.542
=================================
Reseting Environment StartDay: 2293, ResetDay: 3973,Episode: 586
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1535, ResetDay: 3215,Episode: 587
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 481           |
|    time_elapsed         | 10886         |
|    total_timesteps      | 985088        |
| train/                  |               |
|    approx_kl            | 19.370178     |
|    clip_fraction        | 0.71          |
|    clip_range           | 0.2           |
|    entropy_loss         | -105          |
|    explained_variance   | -0.0576       |
|    learning_rate        | 0.00025       |
|    loss                 | -0.881        |
|    n_updates            | 4800          |
|    policy_gradient_loss | 0.103         |
|    reward               | 4.6844484e-06 |
|    std                  | 10.5          |
|    value_loss           | 4.21e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 716, ResetDay: 2396,Episode: 588
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 482           |
|    time_elapsed         | 10909         |
|    total_timesteps      | 987136        |
| train/                  |               |
|    approx_kl            | 23.460985     |
|    clip_fraction        | 0.718         |
|    clip_range           | 0.2           |
|    entropy_loss         | -105          |
|    explained_variance   | 0.00518       |
|    learning_rate        | 0.00025       |
|    loss                 | -0.974        |
|    n_updates            | 4810          |
|    policy_gradient_loss | 0.117         |
|    reward               | 6.0363483e-05 |
|    std                  | 10.6          |
|    value_loss           | 5.17e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1178, ResetDay: 2858,Episode: 589
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 483           |
|    time_elapsed         | 10931         |
|    total_timesteps      | 989184        |
| train/                  |               |
|    approx_kl            | 19.113785     |
|    clip_fraction        | 0.687         |
|    clip_range           | 0.2           |
|    entropy_loss         | -105          |
|    explained_variance   | -0.745        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.999        |
|    n_updates            | 4820          |
|    policy_gradient_loss | 0.0942        |
|    reward               | 2.5993919e-05 |
|    std                  | 10.7          |
|    value_loss           | 4.93e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 473, ResetDay: 2153,Episode: 590
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 484           |
|    time_elapsed         | 10954         |
|    total_timesteps      | 991232        |
| train/                  |               |
|    approx_kl            | 19.248598     |
|    clip_fraction        | 0.711         |
|    clip_range           | 0.2           |
|    entropy_loss         | -105          |
|    explained_variance   | -0.691        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.914        |
|    n_updates            | 4830          |
|    policy_gradient_loss | 0.113         |
|    reward               | -0.0003334216 |
|    std                  | 10.7          |
|    value_loss           | 3.05e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2153, episode: 590
begin_total_asset: 200.00
end_total_asset: 230.16
total_reward: 30.16
total_cost: 2.63
total_trades: 47038
Sharpe: 0.230
=================================
Reseting Environment StartDay: 2201, ResetDay: 3881,Episode: 591
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 485           |
|    time_elapsed         | 10976         |
|    total_timesteps      | 993280        |
| train/                  |               |
|    approx_kl            | 19.655159     |
|    clip_fraction        | 0.703         |
|    clip_range           | 0.2           |
|    entropy_loss         | -105          |
|    explained_variance   | -0.397        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.927        |
|    n_updates            | 4840          |
|    policy_gradient_loss | 0.126         |
|    reward               | 1.4570236e-05 |
|    std                  | 10.7          |
|    value_loss           | 5.04e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1863, ResetDay: 3543,Episode: 592
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 194, ResetDay: 1874,Episode: 593
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 486           |
|    time_elapsed         | 10999         |
|    total_timesteps      | 995328        |
| train/                  |               |
|    approx_kl            | 19.37321      |
|    clip_fraction        | 0.702         |
|    clip_range           | 0.2           |
|    entropy_loss         | -106          |
|    explained_variance   | -0.025        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.968        |
|    n_updates            | 4850          |
|    policy_gradient_loss | 0.0995        |
|    reward               | 5.4439355e-05 |
|    std                  | 10.8          |
|    value_loss           | 8.45e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2402, ResetDay: 4082,Episode: 594
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 487           |
|    time_elapsed         | 11022         |
|    total_timesteps      | 997376        |
| train/                  |               |
|    approx_kl            | 24.366835     |
|    clip_fraction        | 0.723         |
|    clip_range           | 0.2           |
|    entropy_loss         | -106          |
|    explained_variance   | -0.196        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.957        |
|    n_updates            | 4860          |
|    policy_gradient_loss | 0.0903        |
|    reward               | 0.00031621207 |
|    std                  | 10.9          |
|    value_loss           | 2.7e-06       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2647, ResetDay: 4327,Episode: 595
-----------------------------------------
| time/                   |             |
|    fps                  | 90          |
|    iterations           | 488         |
|    time_elapsed         | 11044       |
|    total_timesteps      | 999424      |
| train/                  |             |
|    approx_kl            | 18.617458   |
|    clip_fraction        | 0.708       |
|    clip_range           | 0.2         |
|    entropy_loss         | -106        |
|    explained_variance   | -0.782      |
|    learning_rate        | 0.00025     |
|    loss                 | -0.937      |
|    n_updates            | 4870        |
|    policy_gradient_loss | 0.12        |
|    reward               | 3.11718e-05 |
|    std                  | 10.9        |
|    value_loss           | 6.41e-07    |
-----------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4327, episode: 595
begin_total_asset: 200.00
end_total_asset: 206.71
total_reward: 6.71
total_cost: 1.97
total_trades: 47038
Sharpe: 0.141
=================================
Reseting Environment StartDay: 2498, ResetDay: 4178,Episode: 596
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 489            |
|    time_elapsed         | 11067          |
|    total_timesteps      | 1001472        |
| train/                  |                |
|    approx_kl            | 21.229404      |
|    clip_fraction        | 0.709          |
|    clip_range           | 0.2            |
|    entropy_loss         | -106           |
|    explained_variance   | 0.0647         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.01          |
|    n_updates            | 4880           |
|    policy_gradient_loss | 0.094          |
|    reward               | -0.00019044342 |
|    std                  | 11             |
|    value_loss           | 1.55e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1384, ResetDay: 3064,Episode: 597
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 490           |
|    time_elapsed         | 11090         |
|    total_timesteps      | 1003520       |
| train/                  |               |
|    approx_kl            | 24.112347     |
|    clip_fraction        | 0.72          |
|    clip_range           | 0.2           |
|    entropy_loss         | -106          |
|    explained_variance   | -0.124        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.927        |
|    n_updates            | 4890          |
|    policy_gradient_loss | 0.113         |
|    reward               | 4.6952056e-05 |
|    std                  | 11            |
|    value_loss           | 4.04e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 209, ResetDay: 1889,Episode: 598
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2802, ResetDay: 4482,Episode: 599
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 491            |
|    time_elapsed         | 11113          |
|    total_timesteps      | 1005568        |
| train/                  |                |
|    approx_kl            | 23.226612      |
|    clip_fraction        | 0.701          |
|    clip_range           | 0.2            |
|    entropy_loss         | -106           |
|    explained_variance   | -0.432         |
|    learning_rate        | 0.00025        |
|    loss                 | -0.881         |
|    n_updates            | 4900           |
|    policy_gradient_loss | 0.103          |
|    reward               | -0.00016243897 |
|    std                  | 11.1           |
|    value_loss           | 3.23e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 606, ResetDay: 2286,Episode: 600
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 492            |
|    time_elapsed         | 11136          |
|    total_timesteps      | 1007616        |
| train/                  |                |
|    approx_kl            | 21.830568      |
|    clip_fraction        | 0.716          |
|    clip_range           | 0.2            |
|    entropy_loss         | -106           |
|    explained_variance   | -0.704         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.01          |
|    n_updates            | 4910           |
|    policy_gradient_loss | 0.091          |
|    reward               | -0.00040601674 |
|    std                  | 11.1           |
|    value_loss           | 6.98e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2286, episode: 600
begin_total_asset: 200.00
end_total_asset: 204.98
total_reward: 4.98
total_cost: 1.97
total_trades: 47035
Sharpe: 0.225
=================================
Reseting Environment StartDay: 155, ResetDay: 1835,Episode: 601
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 493            |
|    time_elapsed         | 11158          |
|    total_timesteps      | 1009664        |
| train/                  |                |
|    approx_kl            | 21.940208      |
|    clip_fraction        | 0.72           |
|    clip_range           | 0.2            |
|    entropy_loss         | -106           |
|    explained_variance   | -0.073         |
|    learning_rate        | 0.00025        |
|    loss                 | -0.973         |
|    n_updates            | 4920           |
|    policy_gradient_loss | 0.105          |
|    reward               | -0.00013924098 |
|    std                  | 11.2           |
|    value_loss           | 2.58e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2661, ResetDay: 4341,Episode: 602
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 494           |
|    time_elapsed         | 11181         |
|    total_timesteps      | 1011712       |
| train/                  |               |
|    approx_kl            | 19.29227      |
|    clip_fraction        | 0.697         |
|    clip_range           | 0.2           |
|    entropy_loss         | -107          |
|    explained_variance   | -1.16         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.891        |
|    n_updates            | 4930          |
|    policy_gradient_loss | 0.1           |
|    reward               | 0.00035052223 |
|    std                  | 11.2          |
|    value_loss           | 5.74e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2399, ResetDay: 4079,Episode: 603
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1883, ResetDay: 3563,Episode: 604
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 495           |
|    time_elapsed         | 11204         |
|    total_timesteps      | 1013760       |
| train/                  |               |
|    approx_kl            | 19.350227     |
|    clip_fraction        | 0.696         |
|    clip_range           | 0.2           |
|    entropy_loss         | -107          |
|    explained_variance   | 0.0249        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.961        |
|    n_updates            | 4940          |
|    policy_gradient_loss | 0.0956        |
|    reward               | 0.00013480663 |
|    std                  | 11.3          |
|    value_loss           | 1.46e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 784, ResetDay: 2464,Episode: 605
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 496            |
|    time_elapsed         | 11227          |
|    total_timesteps      | 1015808        |
| train/                  |                |
|    approx_kl            | 28.694578      |
|    clip_fraction        | 0.718          |
|    clip_range           | 0.2            |
|    entropy_loss         | -107           |
|    explained_variance   | -0.0912        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.03          |
|    n_updates            | 4950           |
|    policy_gradient_loss | 0.099          |
|    reward               | -1.4139652e-05 |
|    std                  | 11.3           |
|    value_loss           | 9.21e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2464, episode: 605
begin_total_asset: 200.00
end_total_asset: 185.02
total_reward: -14.98
total_cost: 2.51
total_trades: 47040
Sharpe: 0.142
=================================
Reseting Environment StartDay: 1406, ResetDay: 3086,Episode: 606
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 497           |
|    time_elapsed         | 11249         |
|    total_timesteps      | 1017856       |
| train/                  |               |
|    approx_kl            | 19.67264      |
|    clip_fraction        | 0.718         |
|    clip_range           | 0.2           |
|    entropy_loss         | -107          |
|    explained_variance   | -0.639        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.975        |
|    n_updates            | 4960          |
|    policy_gradient_loss | 0.102         |
|    reward               | 0.00011813603 |
|    std                  | 11.4          |
|    value_loss           | 3.49e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1478, ResetDay: 3158,Episode: 607
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 498           |
|    time_elapsed         | 11272         |
|    total_timesteps      | 1019904       |
| train/                  |               |
|    approx_kl            | 19.378458     |
|    clip_fraction        | 0.724         |
|    clip_range           | 0.2           |
|    entropy_loss         | -107          |
|    explained_variance   | -0.501        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.978        |
|    n_updates            | 4970          |
|    policy_gradient_loss | 0.107         |
|    reward               | -5.986595e-05 |
|    std                  | 11.4          |
|    value_loss           | 2.92e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2038, ResetDay: 3718,Episode: 608
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 499           |
|    time_elapsed         | 11294         |
|    total_timesteps      | 1021952       |
| train/                  |               |
|    approx_kl            | 20.215294     |
|    clip_fraction        | 0.688         |
|    clip_range           | 0.2           |
|    entropy_loss         | -107          |
|    explained_variance   | -0.0569       |
|    learning_rate        | 0.00025       |
|    loss                 | -0.981        |
|    n_updates            | 4980          |
|    policy_gradient_loss | 0.106         |
|    reward               | -9.227791e-05 |
|    std                  | 11.4          |
|    value_loss           | 2.65e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 25, ResetDay: 1705,Episode: 609
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 726, ResetDay: 2406,Episode: 610
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 500          |
|    time_elapsed         | 11317        |
|    total_timesteps      | 1024000      |
| train/                  |              |
|    approx_kl            | 20.552591    |
|    clip_fraction        | 0.696        |
|    clip_range           | 0.2          |
|    entropy_loss         | -107         |
|    explained_variance   | 0.0731       |
|    learning_rate        | 0.00025      |
|    loss                 | -0.997       |
|    n_updates            | 4990         |
|    policy_gradient_loss | 0.109        |
|    reward               | 6.213265e-05 |
|    std                  | 11.5         |
|    value_loss           | 2.81e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2406, episode: 610
begin_total_asset: 200.00
end_total_asset: 383.83
total_reward: 183.83
total_cost: 1.98
total_trades: 47034
Sharpe: 0.531
=================================
Reseting Environment StartDay: 2202, ResetDay: 3882,Episode: 611
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 501           |
|    time_elapsed         | 11340         |
|    total_timesteps      | 1026048       |
| train/                  |               |
|    approx_kl            | 24.043036     |
|    clip_fraction        | 0.735         |
|    clip_range           | 0.2           |
|    entropy_loss         | -107          |
|    explained_variance   | -0.941        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.02         |
|    n_updates            | 5000          |
|    policy_gradient_loss | 0.115         |
|    reward               | 8.3818435e-05 |
|    std                  | 11.5          |
|    value_loss           | 9.71e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2019, ResetDay: 3699,Episode: 612
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 502            |
|    time_elapsed         | 11362          |
|    total_timesteps      | 1028096        |
| train/                  |                |
|    approx_kl            | 19.205978      |
|    clip_fraction        | 0.713          |
|    clip_range           | 0.2            |
|    entropy_loss         | -108           |
|    explained_variance   | -0.0633        |
|    learning_rate        | 0.00025        |
|    loss                 | -0.978         |
|    n_updates            | 5010           |
|    policy_gradient_loss | 0.105          |
|    reward               | -0.00017452106 |
|    std                  | 11.6           |
|    value_loss           | 1.02e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2557, ResetDay: 4237,Episode: 613
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 503           |
|    time_elapsed         | 11385         |
|    total_timesteps      | 1030144       |
| train/                  |               |
|    approx_kl            | 21.585918     |
|    clip_fraction        | 0.698         |
|    clip_range           | 0.2           |
|    entropy_loss         | -108          |
|    explained_variance   | -0.0375       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.04         |
|    n_updates            | 5020          |
|    policy_gradient_loss | 0.107         |
|    reward               | 0.00023036232 |
|    std                  | 11.6          |
|    value_loss           | 1.72e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1128, ResetDay: 2808,Episode: 614
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1284, ResetDay: 2964,Episode: 615
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 504           |
|    time_elapsed         | 11408         |
|    total_timesteps      | 1032192       |
| train/                  |               |
|    approx_kl            | 21.386946     |
|    clip_fraction        | 0.702         |
|    clip_range           | 0.2           |
|    entropy_loss         | -108          |
|    explained_variance   | 0.155         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.04         |
|    n_updates            | 5030          |
|    policy_gradient_loss | 0.0772        |
|    reward               | 3.6431313e-06 |
|    std                  | 11.7          |
|    value_loss           | 2.76e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2964, episode: 615
begin_total_asset: 200.00
end_total_asset: 228.25
total_reward: 28.25
total_cost: 1.98
total_trades: 47037
Sharpe: 0.225
=================================
Reseting Environment StartDay: 1458, ResetDay: 3138,Episode: 616
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 505            |
|    time_elapsed         | 11431          |
|    total_timesteps      | 1034240        |
| train/                  |                |
|    approx_kl            | 26.226973      |
|    clip_fraction        | 0.707          |
|    clip_range           | 0.2            |
|    entropy_loss         | -108           |
|    explained_variance   | -0.254         |
|    learning_rate        | 0.00025        |
|    loss                 | -0.997         |
|    n_updates            | 5040           |
|    policy_gradient_loss | 0.116          |
|    reward               | -1.7380142e-05 |
|    std                  | 11.7           |
|    value_loss           | 3.78e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 524, ResetDay: 2204,Episode: 617
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 506            |
|    time_elapsed         | 11453          |
|    total_timesteps      | 1036288        |
| train/                  |                |
|    approx_kl            | 20.09545       |
|    clip_fraction        | 0.714          |
|    clip_range           | 0.2            |
|    entropy_loss         | -108           |
|    explained_variance   | 0.0117         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.01          |
|    n_updates            | 5050           |
|    policy_gradient_loss | 0.106          |
|    reward               | -3.5873413e-06 |
|    std                  | 11.8           |
|    value_loss           | 3.16e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 76, ResetDay: 1756,Episode: 618
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 507           |
|    time_elapsed         | 11476         |
|    total_timesteps      | 1038336       |
| train/                  |               |
|    approx_kl            | 20.037868     |
|    clip_fraction        | 0.708         |
|    clip_range           | 0.2           |
|    entropy_loss         | -108          |
|    explained_variance   | -0.281        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.856        |
|    n_updates            | 5060          |
|    policy_gradient_loss | 0.134         |
|    reward               | -1.775303e-05 |
|    std                  | 11.9          |
|    value_loss           | 3.44e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1445, ResetDay: 3125,Episode: 619
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 508           |
|    time_elapsed         | 11500         |
|    total_timesteps      | 1040384       |
| train/                  |               |
|    approx_kl            | 19.56725      |
|    clip_fraction        | 0.708         |
|    clip_range           | 0.2           |
|    entropy_loss         | -108          |
|    explained_variance   | -0.522        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.97         |
|    n_updates            | 5070          |
|    policy_gradient_loss | 0.109         |
|    reward               | -0.0003407877 |
|    std                  | 11.9          |
|    value_loss           | 5.69e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1183, ResetDay: 2863,Episode: 620
Environment reached Terminal state as number of trading days reached limit!!
day: 2863, episode: 620
begin_total_asset: 200.00
end_total_asset: 189.68
total_reward: -10.32
total_cost: 1.95
total_trades: 47040
Sharpe: 0.129
=================================
Reseting Environment StartDay: 575, ResetDay: 2255,Episode: 621
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 509            |
|    time_elapsed         | 11523          |
|    total_timesteps      | 1042432        |
| train/                  |                |
|    approx_kl            | 20.183205      |
|    clip_fraction        | 0.71           |
|    clip_range           | 0.2            |
|    entropy_loss         | -108           |
|    explained_variance   | -0.0115        |
|    learning_rate        | 0.00025        |
|    loss                 | -0.92          |
|    n_updates            | 5080           |
|    policy_gradient_loss | 0.119          |
|    reward               | -0.00011799727 |
|    std                  | 11.9           |
|    value_loss           | 6.37e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 3, ResetDay: 1683,Episode: 622
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 510          |
|    time_elapsed         | 11545        |
|    total_timesteps      | 1044480      |
| train/                  |              |
|    approx_kl            | 22.476593    |
|    clip_fraction        | 0.702        |
|    clip_range           | 0.2          |
|    entropy_loss         | -108         |
|    explained_variance   | -0.291       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.04        |
|    n_updates            | 5090         |
|    policy_gradient_loss | 0.0956       |
|    reward               | 7.315245e-05 |
|    std                  | 12           |
|    value_loss           | 3.94e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 764, ResetDay: 2444,Episode: 623
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 511           |
|    time_elapsed         | 11567         |
|    total_timesteps      | 1046528       |
| train/                  |               |
|    approx_kl            | 19.943253     |
|    clip_fraction        | 0.707         |
|    clip_range           | 0.2           |
|    entropy_loss         | -109          |
|    explained_variance   | -5.15         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.04         |
|    n_updates            | 5100          |
|    policy_gradient_loss | 0.0712        |
|    reward               | -8.828688e-05 |
|    std                  | 12.1          |
|    value_loss           | 1.42e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 228, ResetDay: 1908,Episode: 624
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 512            |
|    time_elapsed         | 11590          |
|    total_timesteps      | 1048576        |
| train/                  |                |
|    approx_kl            | 20.519218      |
|    clip_fraction        | 0.705          |
|    clip_range           | 0.2            |
|    entropy_loss         | -109           |
|    explained_variance   | -0.182         |
|    learning_rate        | 0.00025        |
|    loss                 | -0.936         |
|    n_updates            | 5110           |
|    policy_gradient_loss | 0.106          |
|    reward               | -8.1499005e-05 |
|    std                  | 12.1           |
|    value_loss           | 6.21e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 399, ResetDay: 2079,Episode: 625
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 513          |
|    time_elapsed         | 11612        |
|    total_timesteps      | 1050624      |
| train/                  |              |
|    approx_kl            | 20.342583    |
|    clip_fraction        | 0.717        |
|    clip_range           | 0.2          |
|    entropy_loss         | -109         |
|    explained_variance   | -0.168       |
|    learning_rate        | 0.00025      |
|    loss                 | -0.961       |
|    n_updates            | 5120         |
|    policy_gradient_loss | 0.103        |
|    reward               | 0.0001952526 |
|    std                  | 12.1         |
|    value_loss           | 7.76e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2079, episode: 625
begin_total_asset: 200.00
end_total_asset: 248.89
total_reward: 48.89
total_cost: 1.97
total_trades: 47040
Sharpe: 0.264
=================================
Reseting Environment StartDay: 372, ResetDay: 2052,Episode: 626
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 953, ResetDay: 2633,Episode: 627
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 514            |
|    time_elapsed         | 11635          |
|    total_timesteps      | 1052672        |
| train/                  |                |
|    approx_kl            | 20.350006      |
|    clip_fraction        | 0.709          |
|    clip_range           | 0.2            |
|    entropy_loss         | -109           |
|    explained_variance   | -0.273         |
|    learning_rate        | 0.00025        |
|    loss                 | -0.977         |
|    n_updates            | 5130           |
|    policy_gradient_loss | 0.0988         |
|    reward               | -2.4791718e-06 |
|    std                  | 12.2           |
|    value_loss           | 7.7e-07        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 267, ResetDay: 1947,Episode: 628
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 515           |
|    time_elapsed         | 11658         |
|    total_timesteps      | 1054720       |
| train/                  |               |
|    approx_kl            | 19.863365     |
|    clip_fraction        | 0.723         |
|    clip_range           | 0.2           |
|    entropy_loss         | -109          |
|    explained_variance   | -0.619        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.924        |
|    n_updates            | 5140          |
|    policy_gradient_loss | 0.11          |
|    reward               | 0.00049885525 |
|    std                  | 12.2          |
|    value_loss           | 4.39e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 50, ResetDay: 1730,Episode: 629
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 516           |
|    time_elapsed         | 11680         |
|    total_timesteps      | 1056768       |
| train/                  |               |
|    approx_kl            | 20.281631     |
|    clip_fraction        | 0.686         |
|    clip_range           | 0.2           |
|    entropy_loss         | -109          |
|    explained_variance   | -0.246        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.96         |
|    n_updates            | 5150          |
|    policy_gradient_loss | 0.105         |
|    reward               | -6.536212e-05 |
|    std                  | 12.3          |
|    value_loss           | 9.33e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2759, ResetDay: 4439,Episode: 630
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 517            |
|    time_elapsed         | 11703          |
|    total_timesteps      | 1058816        |
| train/                  |                |
|    approx_kl            | 20.437742      |
|    clip_fraction        | 0.701          |
|    clip_range           | 0.2            |
|    entropy_loss         | -109           |
|    explained_variance   | -0.669         |
|    learning_rate        | 0.00025        |
|    loss                 | -0.995         |
|    n_updates            | 5160           |
|    policy_gradient_loss | 0.0901         |
|    reward               | -0.00028795624 |
|    std                  | 12.3           |
|    value_loss           | 8.02e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4439, episode: 630
begin_total_asset: 200.00
end_total_asset: 679.53
total_reward: 479.53
total_cost: 1.84
total_trades: 47034
Sharpe: 0.697
=================================
Reseting Environment StartDay: 2727, ResetDay: 4407,Episode: 631
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2726, ResetDay: 4406,Episode: 632
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 518          |
|    time_elapsed         | 11725        |
|    total_timesteps      | 1060864      |
| train/                  |              |
|    approx_kl            | 19.993877    |
|    clip_fraction        | 0.683        |
|    clip_range           | 0.2          |
|    entropy_loss         | -109         |
|    explained_variance   | -0.0231      |
|    learning_rate        | 0.00025      |
|    loss                 | -0.919       |
|    n_updates            | 5170         |
|    policy_gradient_loss | 0.0832       |
|    reward               | 7.541847e-06 |
|    std                  | 12.4         |
|    value_loss           | 1.97e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 91, ResetDay: 1771,Episode: 633
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 519            |
|    time_elapsed         | 11748          |
|    total_timesteps      | 1062912        |
| train/                  |                |
|    approx_kl            | 28.616917      |
|    clip_fraction        | 0.702          |
|    clip_range           | 0.2            |
|    entropy_loss         | -110           |
|    explained_variance   | -0.149         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.02          |
|    n_updates            | 5180           |
|    policy_gradient_loss | 0.0883         |
|    reward               | -0.00019964157 |
|    std                  | 12.4           |
|    value_loss           | 9.8e-07        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1274, ResetDay: 2954,Episode: 634
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 520           |
|    time_elapsed         | 11770         |
|    total_timesteps      | 1064960       |
| train/                  |               |
|    approx_kl            | 21.917295     |
|    clip_fraction        | 0.71          |
|    clip_range           | 0.2           |
|    entropy_loss         | -110          |
|    explained_variance   | -0.52         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.991        |
|    n_updates            | 5190          |
|    policy_gradient_loss | 0.0862        |
|    reward               | -0.0002010477 |
|    std                  | 12.5          |
|    value_loss           | 5.6e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1556, ResetDay: 3236,Episode: 635
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 521           |
|    time_elapsed         | 11793         |
|    total_timesteps      | 1067008       |
| train/                  |               |
|    approx_kl            | 20.534586     |
|    clip_fraction        | 0.699         |
|    clip_range           | 0.2           |
|    entropy_loss         | -110          |
|    explained_variance   | -0.546        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.02         |
|    n_updates            | 5200          |
|    policy_gradient_loss | 0.102         |
|    reward               | 5.7338715e-05 |
|    std                  | 12.6          |
|    value_loss           | 4.59e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3236, episode: 635
begin_total_asset: 200.00
end_total_asset: 262.36
total_reward: 62.36
total_cost: 1.97
total_trades: 47037
Sharpe: 0.322
=================================
Reseting Environment StartDay: 1926, ResetDay: 3606,Episode: 636
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 522           |
|    time_elapsed         | 11816         |
|    total_timesteps      | 1069056       |
| train/                  |               |
|    approx_kl            | 21.390915     |
|    clip_fraction        | 0.69          |
|    clip_range           | 0.2           |
|    entropy_loss         | -110          |
|    explained_variance   | -0.0253       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.02         |
|    n_updates            | 5210          |
|    policy_gradient_loss | 0.114         |
|    reward               | -9.071731e-06 |
|    std                  | 12.6          |
|    value_loss           | 6.36e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 834, ResetDay: 2514,Episode: 637
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1417, ResetDay: 3097,Episode: 638
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 523          |
|    time_elapsed         | 11838        |
|    total_timesteps      | 1071104      |
| train/                  |              |
|    approx_kl            | 22.01646     |
|    clip_fraction        | 0.718        |
|    clip_range           | 0.2          |
|    entropy_loss         | -110         |
|    explained_variance   | -0.139       |
|    learning_rate        | 0.00025      |
|    loss                 | -0.997       |
|    n_updates            | 5220         |
|    policy_gradient_loss | 0.11         |
|    reward               | 9.002895e-05 |
|    std                  | 12.7         |
|    value_loss           | 9.78e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 475, ResetDay: 2155,Episode: 639
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 524          |
|    time_elapsed         | 11861        |
|    total_timesteps      | 1073152      |
| train/                  |              |
|    approx_kl            | 23.92334     |
|    clip_fraction        | 0.687        |
|    clip_range           | 0.2          |
|    entropy_loss         | -110         |
|    explained_variance   | -0.602       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.03        |
|    n_updates            | 5230         |
|    policy_gradient_loss | 0.107        |
|    reward               | 2.823782e-05 |
|    std                  | 12.7         |
|    value_loss           | 3.18e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 585, ResetDay: 2265,Episode: 640
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 525           |
|    time_elapsed         | 11883         |
|    total_timesteps      | 1075200       |
| train/                  |               |
|    approx_kl            | 21.09222      |
|    clip_fraction        | 0.696         |
|    clip_range           | 0.2           |
|    entropy_loss         | -110          |
|    explained_variance   | -0.248        |
|    learning_rate        | 0.00025       |
|    loss                 | -0.956        |
|    n_updates            | 5240          |
|    policy_gradient_loss | 0.104         |
|    reward               | 0.00012538777 |
|    std                  | 12.8          |
|    value_loss           | 3.67e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2265, episode: 640
begin_total_asset: 200.00
end_total_asset: 213.67
total_reward: 13.67
total_cost: 1.97
total_trades: 47034
Sharpe: 0.206
=================================
Reseting Environment StartDay: 1883, ResetDay: 3563,Episode: 641
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 526            |
|    time_elapsed         | 11906          |
|    total_timesteps      | 1077248        |
| train/                  |                |
|    approx_kl            | 20.707355      |
|    clip_fraction        | 0.69           |
|    clip_range           | 0.2            |
|    entropy_loss         | -110           |
|    explained_variance   | -0.447         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.03          |
|    n_updates            | 5250           |
|    policy_gradient_loss | 0.0944         |
|    reward               | -8.6977765e-05 |
|    std                  | 12.8           |
|    value_loss           | 3.39e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2624, ResetDay: 4304,Episode: 642
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 196, ResetDay: 1876,Episode: 643
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 527            |
|    time_elapsed         | 11928          |
|    total_timesteps      | 1079296        |
| train/                  |                |
|    approx_kl            | 21.341146      |
|    clip_fraction        | 0.687          |
|    clip_range           | 0.2            |
|    entropy_loss         | -111           |
|    explained_variance   | -0.099         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.08          |
|    n_updates            | 5260           |
|    policy_gradient_loss | 0.0847         |
|    reward               | 0.000112981346 |
|    std                  | 12.9           |
|    value_loss           | 4.02e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2666, ResetDay: 4346,Episode: 644
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 528           |
|    time_elapsed         | 11951         |
|    total_timesteps      | 1081344       |
| train/                  |               |
|    approx_kl            | 23.502047     |
|    clip_fraction        | 0.69          |
|    clip_range           | 0.2           |
|    entropy_loss         | -111          |
|    explained_variance   | -0.0892       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.05         |
|    n_updates            | 5270          |
|    policy_gradient_loss | 0.0941        |
|    reward               | 0.00034730684 |
|    std                  | 13            |
|    value_loss           | 8.33e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2047, ResetDay: 3727,Episode: 645
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 529          |
|    time_elapsed         | 11974        |
|    total_timesteps      | 1083392      |
| train/                  |              |
|    approx_kl            | 21.145172    |
|    clip_fraction        | 0.708        |
|    clip_range           | 0.2          |
|    entropy_loss         | -111         |
|    explained_variance   | -1.42        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.03        |
|    n_updates            | 5280         |
|    policy_gradient_loss | 0.0982       |
|    reward               | 4.253216e-05 |
|    std                  | 13           |
|    value_loss           | 7.79e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3727, episode: 645
begin_total_asset: 200.00
end_total_asset: 213.91
total_reward: 13.91
total_cost: 1.98
total_trades: 47033
Sharpe: 0.179
=================================
Reseting Environment StartDay: 23, ResetDay: 1703,Episode: 646
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 530           |
|    time_elapsed         | 11996         |
|    total_timesteps      | 1085440       |
| train/                  |               |
|    approx_kl            | 23.049961     |
|    clip_fraction        | 0.694         |
|    clip_range           | 0.2           |
|    entropy_loss         | -111          |
|    explained_variance   | 0.00445       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.06         |
|    n_updates            | 5290          |
|    policy_gradient_loss | 0.0769        |
|    reward               | 3.6649228e-05 |
|    std                  | 13.1          |
|    value_loss           | 1.91e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1829, ResetDay: 3509,Episode: 647
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 531            |
|    time_elapsed         | 12019          |
|    total_timesteps      | 1087488        |
| train/                  |                |
|    approx_kl            | 22.432964      |
|    clip_fraction        | 0.718          |
|    clip_range           | 0.2            |
|    entropy_loss         | -111           |
|    explained_variance   | -0.693         |
|    learning_rate        | 0.00025        |
|    loss                 | -0.993         |
|    n_updates            | 5300           |
|    policy_gradient_loss | 0.102          |
|    reward               | -0.00019147492 |
|    std                  | 13.1           |
|    value_loss           | 9.26e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2282, ResetDay: 3962,Episode: 648
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1743, ResetDay: 3423,Episode: 649
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 532          |
|    time_elapsed         | 12041        |
|    total_timesteps      | 1089536      |
| train/                  |              |
|    approx_kl            | 21.253136    |
|    clip_fraction        | 0.686        |
|    clip_range           | 0.2          |
|    entropy_loss         | -111         |
|    explained_variance   | -0.00615     |
|    learning_rate        | 0.00025      |
|    loss                 | -0.939       |
|    n_updates            | 5310         |
|    policy_gradient_loss | 0.0888       |
|    reward               | -8.99601e-05 |
|    std                  | 13.2         |
|    value_loss           | 1.1e-06      |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1103, ResetDay: 2783,Episode: 650
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 533            |
|    time_elapsed         | 12064          |
|    total_timesteps      | 1091584        |
| train/                  |                |
|    approx_kl            | 24.62267       |
|    clip_fraction        | 0.701          |
|    clip_range           | 0.2            |
|    entropy_loss         | -111           |
|    explained_variance   | -0.0107        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.03          |
|    n_updates            | 5320           |
|    policy_gradient_loss | 0.0929         |
|    reward               | -0.00014073907 |
|    std                  | 13.3           |
|    value_loss           | 8.31e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2783, episode: 650
begin_total_asset: 200.00
end_total_asset: 269.78
total_reward: 69.78
total_cost: 1.93
total_trades: 47038
Sharpe: 0.343
=================================
Reseting Environment StartDay: 1818, ResetDay: 3498,Episode: 651
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 534           |
|    time_elapsed         | 12086         |
|    total_timesteps      | 1093632       |
| train/                  |               |
|    approx_kl            | 21.600655     |
|    clip_fraction        | 0.681         |
|    clip_range           | 0.2           |
|    entropy_loss         | -111          |
|    explained_variance   | -0.312        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.04         |
|    n_updates            | 5330          |
|    policy_gradient_loss | 0.0886        |
|    reward               | 0.00017545375 |
|    std                  | 13.3          |
|    value_loss           | 3.55e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 100, ResetDay: 1780,Episode: 652
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 535           |
|    time_elapsed         | 12109         |
|    total_timesteps      | 1095680       |
| train/                  |               |
|    approx_kl            | 21.49121      |
|    clip_fraction        | 0.698         |
|    clip_range           | 0.2           |
|    entropy_loss         | -112          |
|    explained_variance   | -0.0318       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.07         |
|    n_updates            | 5340          |
|    policy_gradient_loss | 0.0947        |
|    reward               | -2.721634e-05 |
|    std                  | 13.4          |
|    value_loss           | 3.65e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 971, ResetDay: 2651,Episode: 653
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1442, ResetDay: 3122,Episode: 654
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 536            |
|    time_elapsed         | 12131          |
|    total_timesteps      | 1097728        |
| train/                  |                |
|    approx_kl            | 22.916162      |
|    clip_fraction        | 0.689          |
|    clip_range           | 0.2            |
|    entropy_loss         | -112           |
|    explained_variance   | -0.777         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.06          |
|    n_updates            | 5350           |
|    policy_gradient_loss | 0.0807         |
|    reward               | -2.0900154e-05 |
|    std                  | 13.4           |
|    value_loss           | 5.16e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2399, ResetDay: 4079,Episode: 655
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 537            |
|    time_elapsed         | 12154          |
|    total_timesteps      | 1099776        |
| train/                  |                |
|    approx_kl            | 21.944023      |
|    clip_fraction        | 0.68           |
|    clip_range           | 0.2            |
|    entropy_loss         | -112           |
|    explained_variance   | 0.0329         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.02          |
|    n_updates            | 5360           |
|    policy_gradient_loss | 0.079          |
|    reward               | -0.00033168698 |
|    std                  | 13.5           |
|    value_loss           | 7.25e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4079, episode: 655
begin_total_asset: 200.00
end_total_asset: 297.29
total_reward: 97.29
total_cost: 1.93
total_trades: 47034
Sharpe: 0.393
=================================
Reseting Environment StartDay: 1124, ResetDay: 2804,Episode: 656
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 538           |
|    time_elapsed         | 12176         |
|    total_timesteps      | 1101824       |
| train/                  |               |
|    approx_kl            | 21.713493     |
|    clip_fraction        | 0.69          |
|    clip_range           | 0.2           |
|    entropy_loss         | -112          |
|    explained_variance   | -0.0231       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.02         |
|    n_updates            | 5370          |
|    policy_gradient_loss | 0.0862        |
|    reward               | 2.7962495e-05 |
|    std                  | 13.5          |
|    value_loss           | 2.35e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 11, ResetDay: 1691,Episode: 657
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 539            |
|    time_elapsed         | 12199          |
|    total_timesteps      | 1103872        |
| train/                  |                |
|    approx_kl            | 22.654186      |
|    clip_fraction        | 0.678          |
|    clip_range           | 0.2            |
|    entropy_loss         | -112           |
|    explained_variance   | -0.161         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.06          |
|    n_updates            | 5380           |
|    policy_gradient_loss | 0.0786         |
|    reward               | -6.2724444e-05 |
|    std                  | 13.6           |
|    value_loss           | 4.64e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 966, ResetDay: 2646,Episode: 658
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 540           |
|    time_elapsed         | 12221         |
|    total_timesteps      | 1105920       |
| train/                  |               |
|    approx_kl            | 22.405563     |
|    clip_fraction        | 0.694         |
|    clip_range           | 0.2           |
|    entropy_loss         | -112          |
|    explained_variance   | -1.17         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.06         |
|    n_updates            | 5390          |
|    policy_gradient_loss | 0.0791        |
|    reward               | 0.00019903622 |
|    std                  | 13.7          |
|    value_loss           | 6.39e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1440, ResetDay: 3120,Episode: 659
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2246, ResetDay: 3926,Episode: 660
---------------------------------------------
| time/                   |                 |
|    fps                  | 90              |
|    iterations           | 541             |
|    time_elapsed         | 12244           |
|    total_timesteps      | 1107968         |
| train/                  |                 |
|    approx_kl            | 21.80934        |
|    clip_fraction        | 0.688           |
|    clip_range           | 0.2             |
|    entropy_loss         | -112            |
|    explained_variance   | -0.134          |
|    learning_rate        | 0.00025         |
|    loss                 | -1.07           |
|    n_updates            | 5400            |
|    policy_gradient_loss | 0.115           |
|    reward               | -1.29541395e-05 |
|    std                  | 13.7            |
|    value_loss           | 8.75e-07        |
---------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3926, episode: 660
begin_total_asset: 200.00
end_total_asset: 249.71
total_reward: 49.71
total_cost: 1.95
total_trades: 47035
Sharpe: 0.267
=================================
Reseting Environment StartDay: 1693, ResetDay: 3373,Episode: 661
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 542           |
|    time_elapsed         | 12267         |
|    total_timesteps      | 1110016       |
| train/                  |               |
|    approx_kl            | 22.730457     |
|    clip_fraction        | 0.683         |
|    clip_range           | 0.2           |
|    entropy_loss         | -112          |
|    explained_variance   | -0.142        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.04         |
|    n_updates            | 5410          |
|    policy_gradient_loss | 0.0905        |
|    reward               | -7.846489e-05 |
|    std                  | 13.8          |
|    value_loss           | 8.08e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 6, ResetDay: 1686,Episode: 662
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 543           |
|    time_elapsed         | 12289         |
|    total_timesteps      | 1112064       |
| train/                  |               |
|    approx_kl            | 23.233139     |
|    clip_fraction        | 0.679         |
|    clip_range           | 0.2           |
|    entropy_loss         | -112          |
|    explained_variance   | 0.0187        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.06         |
|    n_updates            | 5420          |
|    policy_gradient_loss | 0.0818        |
|    reward               | 0.00029000916 |
|    std                  | 13.8          |
|    value_loss           | 3.9e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 795, ResetDay: 2475,Episode: 663
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 544           |
|    time_elapsed         | 12312         |
|    total_timesteps      | 1114112       |
| train/                  |               |
|    approx_kl            | 23.159683     |
|    clip_fraction        | 0.677         |
|    clip_range           | 0.2           |
|    entropy_loss         | -113          |
|    explained_variance   | -2.12         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.11         |
|    n_updates            | 5430          |
|    policy_gradient_loss | 0.0727        |
|    reward               | -8.376904e-05 |
|    std                  | 13.9          |
|    value_loss           | 1.15e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2249, ResetDay: 3929,Episode: 664
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 545            |
|    time_elapsed         | 12334          |
|    total_timesteps      | 1116160        |
| train/                  |                |
|    approx_kl            | 22.55984       |
|    clip_fraction        | 0.69           |
|    clip_range           | 0.2            |
|    entropy_loss         | -113           |
|    explained_variance   | -0.245         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.03          |
|    n_updates            | 5440           |
|    policy_gradient_loss | 0.0963         |
|    reward               | -0.00035869292 |
|    std                  | 14             |
|    value_loss           | 5.9e-07        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1930, ResetDay: 3610,Episode: 665
Environment reached Terminal state as number of trading days reached limit!!
day: 3610, episode: 665
begin_total_asset: 200.00
end_total_asset: 200.41
total_reward: 0.41
total_cost: 1.88
total_trades: 47039
Sharpe: 0.153
=================================
Reseting Environment StartDay: 1941, ResetDay: 3621,Episode: 666
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 546            |
|    time_elapsed         | 12357          |
|    total_timesteps      | 1118208        |
| train/                  |                |
|    approx_kl            | 23.515617      |
|    clip_fraction        | 0.696          |
|    clip_range           | 0.2            |
|    entropy_loss         | -113           |
|    explained_variance   | -0.0327        |
|    learning_rate        | 0.00025        |
|    loss                 | -0.994         |
|    n_updates            | 5450           |
|    policy_gradient_loss | 0.0903         |
|    reward               | -6.7790984e-06 |
|    std                  | 14             |
|    value_loss           | 7.72e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1356, ResetDay: 3036,Episode: 667
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 547          |
|    time_elapsed         | 12379        |
|    total_timesteps      | 1120256      |
| train/                  |              |
|    approx_kl            | 26.763157    |
|    clip_fraction        | 0.695        |
|    clip_range           | 0.2          |
|    entropy_loss         | -113         |
|    explained_variance   | -0.0668      |
|    learning_rate        | 0.00025      |
|    loss                 | -1.07        |
|    n_updates            | 5460         |
|    policy_gradient_loss | 0.073        |
|    reward               | 6.659317e-05 |
|    std                  | 14           |
|    value_loss           | 5.43e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1776, ResetDay: 3456,Episode: 668
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 548           |
|    time_elapsed         | 12402         |
|    total_timesteps      | 1122304       |
| train/                  |               |
|    approx_kl            | 23.143824     |
|    clip_fraction        | 0.688         |
|    clip_range           | 0.2           |
|    entropy_loss         | -113          |
|    explained_variance   | -0.0198       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.01         |
|    n_updates            | 5470          |
|    policy_gradient_loss | 0.0888        |
|    reward               | 8.8163564e-05 |
|    std                  | 14.1          |
|    value_loss           | 7.57e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2286, ResetDay: 3966,Episode: 669
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 549          |
|    time_elapsed         | 12425        |
|    total_timesteps      | 1124352      |
| train/                  |              |
|    approx_kl            | 23.494366    |
|    clip_fraction        | 0.68         |
|    clip_range           | 0.2          |
|    entropy_loss         | -113         |
|    explained_variance   | 0.088        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.05        |
|    n_updates            | 5480         |
|    policy_gradient_loss | 0.0926       |
|    reward               | -9.26197e-05 |
|    std                  | 14.2         |
|    value_loss           | 2.78e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2777, ResetDay: 4457,Episode: 670
Environment reached Terminal state as number of trading days reached limit!!
day: 4457, episode: 670
begin_total_asset: 200.00
end_total_asset: 333.53
total_reward: 133.53
total_cost: 1.98
total_trades: 47040
Sharpe: 0.454
=================================
Reseting Environment StartDay: 2647, ResetDay: 4327,Episode: 671
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 550          |
|    time_elapsed         | 12448        |
|    total_timesteps      | 1126400      |
| train/                  |              |
|    approx_kl            | 24.072563    |
|    clip_fraction        | 0.691        |
|    clip_range           | 0.2          |
|    entropy_loss         | -113         |
|    explained_variance   | 0.0699       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.1         |
|    n_updates            | 5490         |
|    policy_gradient_loss | 0.0707       |
|    reward               | 1.215477e-05 |
|    std                  | 14.3         |
|    value_loss           | 3.69e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1250, ResetDay: 2930,Episode: 672
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 551           |
|    time_elapsed         | 12471         |
|    total_timesteps      | 1128448       |
| train/                  |               |
|    approx_kl            | 26.355633     |
|    clip_fraction        | 0.702         |
|    clip_range           | 0.2           |
|    entropy_loss         | -113          |
|    explained_variance   | 0.08          |
|    learning_rate        | 0.00025       |
|    loss                 | -1.08         |
|    n_updates            | 5500          |
|    policy_gradient_loss | 0.0768        |
|    reward               | 5.7123376e-05 |
|    std                  | 14.4          |
|    value_loss           | 1.82e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 214, ResetDay: 1894,Episode: 673
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 552           |
|    time_elapsed         | 12493         |
|    total_timesteps      | 1130496       |
| train/                  |               |
|    approx_kl            | 24.633434     |
|    clip_fraction        | 0.674         |
|    clip_range           | 0.2           |
|    entropy_loss         | -114          |
|    explained_variance   | -0.259        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.07         |
|    n_updates            | 5510          |
|    policy_gradient_loss | 0.0712        |
|    reward               | 2.2478818e-05 |
|    std                  | 14.4          |
|    value_loss           | 3.62e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2530, ResetDay: 4210,Episode: 674
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 553          |
|    time_elapsed         | 12515        |
|    total_timesteps      | 1132544      |
| train/                  |              |
|    approx_kl            | 23.267403    |
|    clip_fraction        | 0.698        |
|    clip_range           | 0.2          |
|    entropy_loss         | -114         |
|    explained_variance   | -0.364       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.1         |
|    n_updates            | 5520         |
|    policy_gradient_loss | 0.0844       |
|    reward               | -0.002203598 |
|    std                  | 14.5         |
|    value_loss           | 4.68e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1272, ResetDay: 2952,Episode: 675
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 554           |
|    time_elapsed         | 12538         |
|    total_timesteps      | 1134592       |
| train/                  |               |
|    approx_kl            | 23.462723     |
|    clip_fraction        | 0.682         |
|    clip_range           | 0.2           |
|    entropy_loss         | -114          |
|    explained_variance   | -0.0444       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.04         |
|    n_updates            | 5530          |
|    policy_gradient_loss | 0.0874        |
|    reward               | -6.926079e-05 |
|    std                  | 14.5          |
|    value_loss           | 1.11e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2952, episode: 675
begin_total_asset: 200.00
end_total_asset: 164.13
total_reward: -35.87
total_cost: 2.42
total_trades: 47035
Sharpe: 0.100
=================================
Reseting Environment StartDay: 622, ResetDay: 2302,Episode: 676
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2520, ResetDay: 4200,Episode: 677
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 555          |
|    time_elapsed         | 12561        |
|    total_timesteps      | 1136640      |
| train/                  |              |
|    approx_kl            | 25.860128    |
|    clip_fraction        | 0.679        |
|    clip_range           | 0.2          |
|    entropy_loss         | -114         |
|    explained_variance   | -0.0749      |
|    learning_rate        | 0.00025      |
|    loss                 | -1.05        |
|    n_updates            | 5540         |
|    policy_gradient_loss | 0.0904       |
|    reward               | 0.0002454464 |
|    std                  | 14.6         |
|    value_loss           | 2.02e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1124, ResetDay: 2804,Episode: 678
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 556            |
|    time_elapsed         | 12584          |
|    total_timesteps      | 1138688        |
| train/                  |                |
|    approx_kl            | 24.309244      |
|    clip_fraction        | 0.696          |
|    clip_range           | 0.2            |
|    entropy_loss         | -114           |
|    explained_variance   | -1.57          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.04          |
|    n_updates            | 5550           |
|    policy_gradient_loss | 0.0742         |
|    reward               | 0.000108813096 |
|    std                  | 14.6           |
|    value_loss           | 4.03e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 540, ResetDay: 2220,Episode: 679
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 557            |
|    time_elapsed         | 12607          |
|    total_timesteps      | 1140736        |
| train/                  |                |
|    approx_kl            | 24.69558       |
|    clip_fraction        | 0.685          |
|    clip_range           | 0.2            |
|    entropy_loss         | -114           |
|    explained_variance   | -0.0607        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.07          |
|    n_updates            | 5560           |
|    policy_gradient_loss | 0.0778         |
|    reward               | -0.00010301886 |
|    std                  | 14.7           |
|    value_loss           | 6.11e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1928, ResetDay: 3608,Episode: 680
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 558           |
|    time_elapsed         | 12630         |
|    total_timesteps      | 1142784       |
| train/                  |               |
|    approx_kl            | 23.879164     |
|    clip_fraction        | 0.672         |
|    clip_range           | 0.2           |
|    entropy_loss         | -114          |
|    explained_variance   | -0.268        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.1          |
|    n_updates            | 5570          |
|    policy_gradient_loss | 0.094         |
|    reward               | 0.00047204093 |
|    std                  | 14.7          |
|    value_loss           | 4.12e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3608, episode: 680
begin_total_asset: 200.00
end_total_asset: 316.89
total_reward: 116.89
total_cost: 1.97
total_trades: 47035
Sharpe: 0.452
=================================
Reseting Environment StartDay: 1947, ResetDay: 3627,Episode: 681
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1266, ResetDay: 2946,Episode: 682
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 559           |
|    time_elapsed         | 12652         |
|    total_timesteps      | 1144832       |
| train/                  |               |
|    approx_kl            | 23.965889     |
|    clip_fraction        | 0.682         |
|    clip_range           | 0.2           |
|    entropy_loss         | -114          |
|    explained_variance   | 0.0314        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.05         |
|    n_updates            | 5580          |
|    policy_gradient_loss | 0.0784        |
|    reward               | 0.00011782494 |
|    std                  | 14.7          |
|    value_loss           | 4.83e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1133, ResetDay: 2813,Episode: 683
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 560          |
|    time_elapsed         | 12675        |
|    total_timesteps      | 1146880      |
| train/                  |              |
|    approx_kl            | 26.106512    |
|    clip_fraction        | 0.694        |
|    clip_range           | 0.2          |
|    entropy_loss         | -114         |
|    explained_variance   | 0.0571       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.01        |
|    n_updates            | 5590         |
|    policy_gradient_loss | 0.0909       |
|    reward               | 4.987917e-05 |
|    std                  | 14.8         |
|    value_loss           | 4.07e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1258, ResetDay: 2938,Episode: 684
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 561            |
|    time_elapsed         | 12697          |
|    total_timesteps      | 1148928        |
| train/                  |                |
|    approx_kl            | 24.230755      |
|    clip_fraction        | 0.674          |
|    clip_range           | 0.2            |
|    entropy_loss         | -114           |
|    explained_variance   | -0.413         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.05          |
|    n_updates            | 5600           |
|    policy_gradient_loss | 0.103          |
|    reward               | -0.00022155953 |
|    std                  | 14.8           |
|    value_loss           | 2.54e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 979, ResetDay: 2659,Episode: 685
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 562           |
|    time_elapsed         | 12720         |
|    total_timesteps      | 1150976       |
| train/                  |               |
|    approx_kl            | 23.693274     |
|    clip_fraction        | 0.669         |
|    clip_range           | 0.2           |
|    entropy_loss         | -114          |
|    explained_variance   | 0.0378        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.11         |
|    n_updates            | 5610          |
|    policy_gradient_loss | 0.0694        |
|    reward               | 0.00029200743 |
|    std                  | 14.8          |
|    value_loss           | 2.79e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2659, episode: 685
begin_total_asset: 200.00
end_total_asset: 187.02
total_reward: -12.98
total_cost: 1.96
total_trades: 47034
Sharpe: 0.236
=================================
Reseting Environment StartDay: 2385, ResetDay: 4065,Episode: 686
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 563            |
|    time_elapsed         | 12744          |
|    total_timesteps      | 1153024        |
| train/                  |                |
|    approx_kl            | 24.63578       |
|    clip_fraction        | 0.646          |
|    clip_range           | 0.2            |
|    entropy_loss         | -115           |
|    explained_variance   | -0.0647        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.05          |
|    n_updates            | 5620           |
|    policy_gradient_loss | 0.0732         |
|    reward               | -4.9751852e-05 |
|    std                  | 14.9           |
|    value_loss           | 4.67e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 313, ResetDay: 1993,Episode: 687
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2384, ResetDay: 4064,Episode: 688
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 564           |
|    time_elapsed         | 12767         |
|    total_timesteps      | 1155072       |
| train/                  |               |
|    approx_kl            | 24.076605     |
|    clip_fraction        | 0.685         |
|    clip_range           | 0.2           |
|    entropy_loss         | -115          |
|    explained_variance   | 0.0428        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.06         |
|    n_updates            | 5630          |
|    policy_gradient_loss | 0.0827        |
|    reward               | 0.00028324718 |
|    std                  | 14.9          |
|    value_loss           | 8.06e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1140, ResetDay: 2820,Episode: 689
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 565            |
|    time_elapsed         | 12789          |
|    total_timesteps      | 1157120        |
| train/                  |                |
|    approx_kl            | 28.510069      |
|    clip_fraction        | 0.672          |
|    clip_range           | 0.2            |
|    entropy_loss         | -115           |
|    explained_variance   | -0.532         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.06          |
|    n_updates            | 5640           |
|    policy_gradient_loss | 0.0896         |
|    reward               | -0.00011449137 |
|    std                  | 15             |
|    value_loss           | 5.98e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2419, ResetDay: 4099,Episode: 690
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 566           |
|    time_elapsed         | 12812         |
|    total_timesteps      | 1159168       |
| train/                  |               |
|    approx_kl            | 25.100422     |
|    clip_fraction        | 0.673         |
|    clip_range           | 0.2           |
|    entropy_loss         | -115          |
|    explained_variance   | 0.0427        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.08         |
|    n_updates            | 5650          |
|    policy_gradient_loss | 0.0683        |
|    reward               | -7.444801e-05 |
|    std                  | 15.1          |
|    value_loss           | 1.29e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4099, episode: 690
begin_total_asset: 200.00
end_total_asset: 364.14
total_reward: 164.14
total_cost: 1.85
total_trades: 47037
Sharpe: 0.566
=================================
Reseting Environment StartDay: 1579, ResetDay: 3259,Episode: 691
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 567          |
|    time_elapsed         | 12835        |
|    total_timesteps      | 1161216      |
| train/                  |              |
|    approx_kl            | 24.728226    |
|    clip_fraction        | 0.677        |
|    clip_range           | 0.2          |
|    entropy_loss         | -115         |
|    explained_variance   | -0.57        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.12        |
|    n_updates            | 5660         |
|    policy_gradient_loss | 0.0827       |
|    reward               | 4.598217e-05 |
|    std                  | 15.2         |
|    value_loss           | 3.37e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1283, ResetDay: 2963,Episode: 692
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1531, ResetDay: 3211,Episode: 693
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 568            |
|    time_elapsed         | 12857          |
|    total_timesteps      | 1163264        |
| train/                  |                |
|    approx_kl            | 27.576035      |
|    clip_fraction        | 0.681          |
|    clip_range           | 0.2            |
|    entropy_loss         | -115           |
|    explained_variance   | 0.0414         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.13          |
|    n_updates            | 5670           |
|    policy_gradient_loss | 0.0615         |
|    reward               | -4.0288545e-05 |
|    std                  | 15.2           |
|    value_loss           | 7.24e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 75, ResetDay: 1755,Episode: 694
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 569           |
|    time_elapsed         | 12880         |
|    total_timesteps      | 1165312       |
| train/                  |               |
|    approx_kl            | 25.910053     |
|    clip_fraction        | 0.69          |
|    clip_range           | 0.2           |
|    entropy_loss         | -115          |
|    explained_variance   | -0.0389       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.07         |
|    n_updates            | 5680          |
|    policy_gradient_loss | 0.0802        |
|    reward               | -7.633462e-05 |
|    std                  | 15.3          |
|    value_loss           | 3.84e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 849, ResetDay: 2529,Episode: 695
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 570            |
|    time_elapsed         | 12902          |
|    total_timesteps      | 1167360        |
| train/                  |                |
|    approx_kl            | 25.053661      |
|    clip_fraction        | 0.681          |
|    clip_range           | 0.2            |
|    entropy_loss         | -115           |
|    explained_variance   | -0.186         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.11          |
|    n_updates            | 5690           |
|    policy_gradient_loss | 0.0755         |
|    reward               | -4.5262717e-05 |
|    std                  | 15.3           |
|    value_loss           | 4.34e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2529, episode: 695
begin_total_asset: 200.00
end_total_asset: 403.25
total_reward: 203.25
total_cost: 2.42
total_trades: 47037
Sharpe: 0.599
=================================
Reseting Environment StartDay: 1477, ResetDay: 3157,Episode: 696
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 571           |
|    time_elapsed         | 12925         |
|    total_timesteps      | 1169408       |
| train/                  |               |
|    approx_kl            | 24.557852     |
|    clip_fraction        | 0.685         |
|    clip_range           | 0.2           |
|    entropy_loss         | -115          |
|    explained_variance   | -0.413        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.06         |
|    n_updates            | 5700          |
|    policy_gradient_loss | 0.0873        |
|    reward               | 0.00023352566 |
|    std                  | 15.4          |
|    value_loss           | 3.88e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1577, ResetDay: 3257,Episode: 697
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 572          |
|    time_elapsed         | 12947        |
|    total_timesteps      | 1171456      |
| train/                  |              |
|    approx_kl            | 25.157028    |
|    clip_fraction        | 0.694        |
|    clip_range           | 0.2          |
|    entropy_loss         | -116         |
|    explained_variance   | 0.0122       |
|    learning_rate        | 0.00025      |
|    loss                 | -1           |
|    n_updates            | 5710         |
|    policy_gradient_loss | 0.0982       |
|    reward               | 8.314705e-06 |
|    std                  | 15.5         |
|    value_loss           | 3.56e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 282, ResetDay: 1962,Episode: 698
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1281, ResetDay: 2961,Episode: 699
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 573           |
|    time_elapsed         | 12970         |
|    total_timesteps      | 1173504       |
| train/                  |               |
|    approx_kl            | 25.714554     |
|    clip_fraction        | 0.669         |
|    clip_range           | 0.2           |
|    entropy_loss         | -116          |
|    explained_variance   | -0.0876       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.13         |
|    n_updates            | 5720          |
|    policy_gradient_loss | 0.0737        |
|    reward               | 1.0640907e-05 |
|    std                  | 15.6          |
|    value_loss           | 2.63e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 820, ResetDay: 2500,Episode: 700
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 574           |
|    time_elapsed         | 12993         |
|    total_timesteps      | 1175552       |
| train/                  |               |
|    approx_kl            | 26.670536     |
|    clip_fraction        | 0.677         |
|    clip_range           | 0.2           |
|    entropy_loss         | -116          |
|    explained_variance   | -0.437        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.05         |
|    n_updates            | 5730          |
|    policy_gradient_loss | 0.0776        |
|    reward               | 8.4336854e-05 |
|    std                  | 15.6          |
|    value_loss           | 5.53e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2500, episode: 700
begin_total_asset: 200.00
end_total_asset: 210.78
total_reward: 10.78
total_cost: 1.97
total_trades: 47035
Sharpe: 0.194
=================================
Reseting Environment StartDay: 28, ResetDay: 1708,Episode: 701
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 575          |
|    time_elapsed         | 13016        |
|    total_timesteps      | 1177600      |
| train/                  |              |
|    approx_kl            | 25.45974     |
|    clip_fraction        | 0.671        |
|    clip_range           | 0.2          |
|    entropy_loss         | -116         |
|    explained_variance   | -0.0316      |
|    learning_rate        | 0.00025      |
|    loss                 | -1.13        |
|    n_updates            | 5740         |
|    policy_gradient_loss | 0.0687       |
|    reward               | 0.0005087589 |
|    std                  | 15.8         |
|    value_loss           | 7.39e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 657, ResetDay: 2337,Episode: 702
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 576           |
|    time_elapsed         | 13038         |
|    total_timesteps      | 1179648       |
| train/                  |               |
|    approx_kl            | 25.347134     |
|    clip_fraction        | 0.677         |
|    clip_range           | 0.2           |
|    entropy_loss         | -116          |
|    explained_variance   | -0.71         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.09         |
|    n_updates            | 5750          |
|    policy_gradient_loss | 0.0841        |
|    reward               | 8.2486535e-05 |
|    std                  | 15.9          |
|    value_loss           | 5.38e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1733, ResetDay: 3413,Episode: 703
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 577            |
|    time_elapsed         | 13061          |
|    total_timesteps      | 1181696        |
| train/                  |                |
|    approx_kl            | 25.66037       |
|    clip_fraction        | 0.673          |
|    clip_range           | 0.2            |
|    entropy_loss         | -116           |
|    explained_variance   | -0.0757        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.1           |
|    n_updates            | 5760           |
|    policy_gradient_loss | 0.0677         |
|    reward               | -0.00021792068 |
|    std                  | 15.9           |
|    value_loss           | 4.59e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 799, ResetDay: 2479,Episode: 704
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 470, ResetDay: 2150,Episode: 705
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 578            |
|    time_elapsed         | 13084          |
|    total_timesteps      | 1183744        |
| train/                  |                |
|    approx_kl            | 26.758013      |
|    clip_fraction        | 0.68           |
|    clip_range           | 0.2            |
|    entropy_loss         | -116           |
|    explained_variance   | -0.0288        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.09          |
|    n_updates            | 5770           |
|    policy_gradient_loss | 0.0878         |
|    reward               | -0.00015675678 |
|    std                  | 15.9           |
|    value_loss           | 4.23e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2150, episode: 705
begin_total_asset: 200.00
end_total_asset: 186.61
total_reward: -13.39
total_cost: 2.50
total_trades: 47040
Sharpe: 0.181
=================================
Reseting Environment StartDay: 2556, ResetDay: 4236,Episode: 706
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 579           |
|    time_elapsed         | 13106         |
|    total_timesteps      | 1185792       |
| train/                  |               |
|    approx_kl            | 28.048069     |
|    clip_fraction        | 0.67          |
|    clip_range           | 0.2           |
|    entropy_loss         | -117          |
|    explained_variance   | -0.469        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.05         |
|    n_updates            | 5780          |
|    policy_gradient_loss | 0.075         |
|    reward               | 0.00023161354 |
|    std                  | 16            |
|    value_loss           | 4.87e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2130, ResetDay: 3810,Episode: 707
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 580           |
|    time_elapsed         | 13129         |
|    total_timesteps      | 1187840       |
| train/                  |               |
|    approx_kl            | 25.966972     |
|    clip_fraction        | 0.666         |
|    clip_range           | 0.2           |
|    entropy_loss         | -117          |
|    explained_variance   | -0.128        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.08         |
|    n_updates            | 5790          |
|    policy_gradient_loss | 0.0767        |
|    reward               | 1.9155503e-05 |
|    std                  | 16.1          |
|    value_loss           | 1.04e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 387, ResetDay: 2067,Episode: 708
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 581            |
|    time_elapsed         | 13151          |
|    total_timesteps      | 1189888        |
| train/                  |                |
|    approx_kl            | 27.563343      |
|    clip_fraction        | 0.671          |
|    clip_range           | 0.2            |
|    entropy_loss         | -117           |
|    explained_variance   | -0.102         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.13          |
|    n_updates            | 5800           |
|    policy_gradient_loss | 0.0685         |
|    reward               | -3.2955933e-05 |
|    std                  | 16.1           |
|    value_loss           | 1.06e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 71, ResetDay: 1751,Episode: 709
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2011, ResetDay: 3691,Episode: 710
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 582           |
|    time_elapsed         | 13174         |
|    total_timesteps      | 1191936       |
| train/                  |               |
|    approx_kl            | 28.05048      |
|    clip_fraction        | 0.672         |
|    clip_range           | 0.2           |
|    entropy_loss         | -117          |
|    explained_variance   | -0.887        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.11         |
|    n_updates            | 5810          |
|    policy_gradient_loss | 0.0809        |
|    reward               | 3.4791185e-05 |
|    std                  | 16.2          |
|    value_loss           | 3.94e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3691, episode: 710
begin_total_asset: 200.00
end_total_asset: 545.35
total_reward: 345.35
total_cost: 1.86
total_trades: 47035
Sharpe: 0.877
=================================
Reseting Environment StartDay: 244, ResetDay: 1924,Episode: 711
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 583          |
|    time_elapsed         | 13197        |
|    total_timesteps      | 1193984      |
| train/                  |              |
|    approx_kl            | 26.427292    |
|    clip_fraction        | 0.667        |
|    clip_range           | 0.2          |
|    entropy_loss         | -117         |
|    explained_variance   | -0.544       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.06        |
|    n_updates            | 5820         |
|    policy_gradient_loss | 0.0714       |
|    reward               | 9.971552e-05 |
|    std                  | 16.3         |
|    value_loss           | 4.57e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 645, ResetDay: 2325,Episode: 712
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 584           |
|    time_elapsed         | 13219         |
|    total_timesteps      | 1196032       |
| train/                  |               |
|    approx_kl            | 26.79563      |
|    clip_fraction        | 0.679         |
|    clip_range           | 0.2           |
|    entropy_loss         | -117          |
|    explained_variance   | -0.0921       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.09         |
|    n_updates            | 5830          |
|    policy_gradient_loss | 0.0866        |
|    reward               | -6.312847e-05 |
|    std                  | 16.3          |
|    value_loss           | 1.2e-06       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1585, ResetDay: 3265,Episode: 713
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 585            |
|    time_elapsed         | 13241          |
|    total_timesteps      | 1198080        |
| train/                  |                |
|    approx_kl            | 26.94313       |
|    clip_fraction        | 0.669          |
|    clip_range           | 0.2            |
|    entropy_loss         | -117           |
|    explained_variance   | -1.31          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.11          |
|    n_updates            | 5840           |
|    policy_gradient_loss | 0.0665         |
|    reward               | -3.7261772e-05 |
|    std                  | 16.4           |
|    value_loss           | 3.3e-07        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 78, ResetDay: 1758,Episode: 714
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 586           |
|    time_elapsed         | 13264         |
|    total_timesteps      | 1200128       |
| train/                  |               |
|    approx_kl            | 26.407265     |
|    clip_fraction        | 0.671         |
|    clip_range           | 0.2           |
|    entropy_loss         | -117          |
|    explained_variance   | 0.0417        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.09         |
|    n_updates            | 5850          |
|    policy_gradient_loss | 0.091         |
|    reward               | 0.00012740688 |
|    std                  | 16.4          |
|    value_loss           | 3.41e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1656, ResetDay: 3336,Episode: 715
Environment reached Terminal state as number of trading days reached limit!!
day: 3336, episode: 715
begin_total_asset: 200.00
end_total_asset: 463.96
total_reward: 263.96
total_cost: 1.98
total_trades: 47040
Sharpe: 0.901
=================================
Reseting Environment StartDay: 2400, ResetDay: 4080,Episode: 716
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 587            |
|    time_elapsed         | 13287          |
|    total_timesteps      | 1202176        |
| train/                  |                |
|    approx_kl            | 27.967163      |
|    clip_fraction        | 0.664          |
|    clip_range           | 0.2            |
|    entropy_loss         | -117           |
|    explained_variance   | -0.447         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.06          |
|    n_updates            | 5860           |
|    policy_gradient_loss | 0.0715         |
|    reward               | -0.00012555237 |
|    std                  | 16.5           |
|    value_loss           | 4.88e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1821, ResetDay: 3501,Episode: 717
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 588          |
|    time_elapsed         | 13310        |
|    total_timesteps      | 1204224      |
| train/                  |              |
|    approx_kl            | 27.123226    |
|    clip_fraction        | 0.656        |
|    clip_range           | 0.2          |
|    entropy_loss         | -118         |
|    explained_variance   | 0.0768       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.06        |
|    n_updates            | 5870         |
|    policy_gradient_loss | 0.0751       |
|    reward               | 0.0002184824 |
|    std                  | 16.6         |
|    value_loss           | 5.81e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1528, ResetDay: 3208,Episode: 718
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 589          |
|    time_elapsed         | 13333        |
|    total_timesteps      | 1206272      |
| train/                  |              |
|    approx_kl            | 27.637857    |
|    clip_fraction        | 0.66         |
|    clip_range           | 0.2          |
|    entropy_loss         | -118         |
|    explained_variance   | -0.0694      |
|    learning_rate        | 0.00025      |
|    loss                 | -1.11        |
|    n_updates            | 5880         |
|    policy_gradient_loss | 0.0664       |
|    reward               | -7.63422e-05 |
|    std                  | 16.6         |
|    value_loss           | 5.17e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1350, ResetDay: 3030,Episode: 719
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 590            |
|    time_elapsed         | 13355          |
|    total_timesteps      | 1208320        |
| train/                  |                |
|    approx_kl            | 28.201042      |
|    clip_fraction        | 0.661          |
|    clip_range           | 0.2            |
|    entropy_loss         | -118           |
|    explained_variance   | -0.222         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.1           |
|    n_updates            | 5890           |
|    policy_gradient_loss | 0.0806         |
|    reward               | -0.00021556682 |
|    std                  | 16.7           |
|    value_loss           | 2.8e-07        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1793, ResetDay: 3473,Episode: 720
Environment reached Terminal state as number of trading days reached limit!!
day: 3473, episode: 720
begin_total_asset: 200.00
end_total_asset: 241.77
total_reward: 41.77
total_cost: 1.89
total_trades: 47040
Sharpe: 0.269
=================================
Reseting Environment StartDay: 1053, ResetDay: 2733,Episode: 721
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 591            |
|    time_elapsed         | 13378          |
|    total_timesteps      | 1210368        |
| train/                  |                |
|    approx_kl            | 29.028677      |
|    clip_fraction        | 0.668          |
|    clip_range           | 0.2            |
|    entropy_loss         | -118           |
|    explained_variance   | -0.011         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.04          |
|    n_updates            | 5900           |
|    policy_gradient_loss | 0.0687         |
|    reward               | -4.1627885e-05 |
|    std                  | 16.8           |
|    value_loss           | 4.11e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 794, ResetDay: 2474,Episode: 722
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 592           |
|    time_elapsed         | 13400         |
|    total_timesteps      | 1212416       |
| train/                  |               |
|    approx_kl            | 28.324722     |
|    clip_fraction        | 0.678         |
|    clip_range           | 0.2           |
|    entropy_loss         | -118          |
|    explained_variance   | 0.0455        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.11         |
|    n_updates            | 5910          |
|    policy_gradient_loss | 0.0845        |
|    reward               | -2.537079e-05 |
|    std                  | 16.8          |
|    value_loss           | 8.95e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1616, ResetDay: 3296,Episode: 723
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 593           |
|    time_elapsed         | 13423         |
|    total_timesteps      | 1214464       |
| train/                  |               |
|    approx_kl            | 27.811405     |
|    clip_fraction        | 0.656         |
|    clip_range           | 0.2           |
|    entropy_loss         | -118          |
|    explained_variance   | -0.502        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.14         |
|    n_updates            | 5920          |
|    policy_gradient_loss | 0.0695        |
|    reward               | -0.0002718685 |
|    std                  | 16.9          |
|    value_loss           | 4.01e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 268, ResetDay: 1948,Episode: 724
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 594            |
|    time_elapsed         | 13445          |
|    total_timesteps      | 1216512        |
| train/                  |                |
|    approx_kl            | 27.665955      |
|    clip_fraction        | 0.649          |
|    clip_range           | 0.2            |
|    entropy_loss         | -118           |
|    explained_variance   | -0.0552        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.07          |
|    n_updates            | 5930           |
|    policy_gradient_loss | 0.0754         |
|    reward               | -0.00010203094 |
|    std                  | 17             |
|    value_loss           | 2.53e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1990, ResetDay: 3670,Episode: 725
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 595           |
|    time_elapsed         | 13470         |
|    total_timesteps      | 1218560       |
| train/                  |               |
|    approx_kl            | 28.091795     |
|    clip_fraction        | 0.666         |
|    clip_range           | 0.2           |
|    entropy_loss         | -118          |
|    explained_variance   | -0.236        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.04         |
|    n_updates            | 5940          |
|    policy_gradient_loss | 0.0804        |
|    reward               | -0.0004426548 |
|    std                  | 17            |
|    value_loss           | 4.61e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3670, episode: 725
begin_total_asset: 200.00
end_total_asset: 460.64
total_reward: 260.64
total_cost: 1.98
total_trades: 47033
Sharpe: 0.855
=================================
Reseting Environment StartDay: 2108, ResetDay: 3788,Episode: 726
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1123, ResetDay: 2803,Episode: 727
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 596           |
|    time_elapsed         | 13493         |
|    total_timesteps      | 1220608       |
| train/                  |               |
|    approx_kl            | 28.092186     |
|    clip_fraction        | 0.65          |
|    clip_range           | 0.2           |
|    entropy_loss         | -118          |
|    explained_variance   | 0.0624        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.12         |
|    n_updates            | 5950          |
|    policy_gradient_loss | 0.0642        |
|    reward               | 0.00016179381 |
|    std                  | 17            |
|    value_loss           | 6.64e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1651, ResetDay: 3331,Episode: 728
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 597            |
|    time_elapsed         | 13515          |
|    total_timesteps      | 1222656        |
| train/                  |                |
|    approx_kl            | 30.159937      |
|    clip_fraction        | 0.659          |
|    clip_range           | 0.2            |
|    entropy_loss         | -118           |
|    explained_variance   | -0.0531        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.08          |
|    n_updates            | 5960           |
|    policy_gradient_loss | 0.0574         |
|    reward               | -0.00013203679 |
|    std                  | 17.1           |
|    value_loss           | 6.57e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 539, ResetDay: 2219,Episode: 729
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 598          |
|    time_elapsed         | 13538        |
|    total_timesteps      | 1224704      |
| train/                  |              |
|    approx_kl            | 28.100882    |
|    clip_fraction        | 0.653        |
|    clip_range           | 0.2          |
|    entropy_loss         | -118         |
|    explained_variance   | -0.168       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.1         |
|    n_updates            | 5970         |
|    policy_gradient_loss | 0.0831       |
|    reward               | 3.568964e-05 |
|    std                  | 17.1         |
|    value_loss           | 4.68e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1046, ResetDay: 2726,Episode: 730
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 599            |
|    time_elapsed         | 13560          |
|    total_timesteps      | 1226752        |
| train/                  |                |
|    approx_kl            | 28.641895      |
|    clip_fraction        | 0.658          |
|    clip_range           | 0.2            |
|    entropy_loss         | -119           |
|    explained_variance   | -0.0755        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.13          |
|    n_updates            | 5980           |
|    policy_gradient_loss | 0.0678         |
|    reward               | -0.00046974563 |
|    std                  | 17.2           |
|    value_loss           | 4.7e-07        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2726, episode: 730
begin_total_asset: 200.00
end_total_asset: 244.59
total_reward: 44.59
total_cost: 1.98
total_trades: 47034
Sharpe: 0.293
=================================
Reseting Environment StartDay: 1236, ResetDay: 2916,Episode: 731
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 600           |
|    time_elapsed         | 13583         |
|    total_timesteps      | 1228800       |
| train/                  |               |
|    approx_kl            | 28.435108     |
|    clip_fraction        | 0.647         |
|    clip_range           | 0.2           |
|    entropy_loss         | -119          |
|    explained_variance   | -0.354        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.11         |
|    n_updates            | 5990          |
|    policy_gradient_loss | 0.0687        |
|    reward               | 2.0458221e-05 |
|    std                  | 17.3          |
|    value_loss           | 3.45e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2076, ResetDay: 3756,Episode: 732
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2429, ResetDay: 4109,Episode: 733
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 601           |
|    time_elapsed         | 13605         |
|    total_timesteps      | 1230848       |
| train/                  |               |
|    approx_kl            | 29.26921      |
|    clip_fraction        | 0.653         |
|    clip_range           | 0.2           |
|    entropy_loss         | -119          |
|    explained_variance   | 0.0888        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.17         |
|    n_updates            | 6000          |
|    policy_gradient_loss | 0.0838        |
|    reward               | 9.1711234e-05 |
|    std                  | 17.3          |
|    value_loss           | 5.27e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1474, ResetDay: 3154,Episode: 734
-----------------------------------------
| time/                   |             |
|    fps                  | 90          |
|    iterations           | 602         |
|    time_elapsed         | 13628       |
|    total_timesteps      | 1232896     |
| train/                  |             |
|    approx_kl            | 28.69964    |
|    clip_fraction        | 0.654       |
|    clip_range           | 0.2         |
|    entropy_loss         | -119        |
|    explained_variance   | 0.0694      |
|    learning_rate        | 0.00025     |
|    loss                 | -1.07       |
|    n_updates            | 6010        |
|    policy_gradient_loss | 0.0758      |
|    reward               | 0.000180657 |
|    std                  | 17.4        |
|    value_loss           | 9.08e-07    |
-----------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1480, ResetDay: 3160,Episode: 735
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 603           |
|    time_elapsed         | 13650         |
|    total_timesteps      | 1234944       |
| train/                  |               |
|    approx_kl            | 29.229774     |
|    clip_fraction        | 0.657         |
|    clip_range           | 0.2           |
|    entropy_loss         | -119          |
|    explained_variance   | -0.0265       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.15         |
|    n_updates            | 6020          |
|    policy_gradient_loss | 0.0622        |
|    reward               | 5.3862383e-05 |
|    std                  | 17.5          |
|    value_loss           | 3.95e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3160, episode: 735
begin_total_asset: 200.00
end_total_asset: 198.72
total_reward: -1.28
total_cost: 1.96
total_trades: 47035
Sharpe: 0.156
=================================
Reseting Environment StartDay: 979, ResetDay: 2659,Episode: 736
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 604           |
|    time_elapsed         | 13673         |
|    total_timesteps      | 1236992       |
| train/                  |               |
|    approx_kl            | 29.60356      |
|    clip_fraction        | 0.635         |
|    clip_range           | 0.2           |
|    entropy_loss         | -119          |
|    explained_variance   | -0.0698       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.14         |
|    n_updates            | 6030          |
|    policy_gradient_loss | 0.0644        |
|    reward               | -3.661194e-05 |
|    std                  | 17.5          |
|    value_loss           | 2.32e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 868, ResetDay: 2548,Episode: 737
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1986, ResetDay: 3666,Episode: 738
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 605          |
|    time_elapsed         | 13695        |
|    total_timesteps      | 1239040      |
| train/                  |              |
|    approx_kl            | 29.584023    |
|    clip_fraction        | 0.645        |
|    clip_range           | 0.2          |
|    entropy_loss         | -119         |
|    explained_variance   | -0.0969      |
|    learning_rate        | 0.00025      |
|    loss                 | -1.15        |
|    n_updates            | 6040         |
|    policy_gradient_loss | 0.0688       |
|    reward               | 8.915815e-05 |
|    std                  | 17.6         |
|    value_loss           | 4.49e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 813, ResetDay: 2493,Episode: 739
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 606           |
|    time_elapsed         | 13718         |
|    total_timesteps      | 1241088       |
| train/                  |               |
|    approx_kl            | 29.671755     |
|    clip_fraction        | 0.645         |
|    clip_range           | 0.2           |
|    entropy_loss         | -119          |
|    explained_variance   | 0.0315        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.07         |
|    n_updates            | 6050          |
|    policy_gradient_loss | 0.063         |
|    reward               | -5.702591e-05 |
|    std                  | 17.6          |
|    value_loss           | 4.04e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1225, ResetDay: 2905,Episode: 740
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 607            |
|    time_elapsed         | 13741          |
|    total_timesteps      | 1243136        |
| train/                  |                |
|    approx_kl            | 29.663115      |
|    clip_fraction        | 0.638          |
|    clip_range           | 0.2            |
|    entropy_loss         | -119           |
|    explained_variance   | -0.0622        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.16          |
|    n_updates            | 6060           |
|    policy_gradient_loss | 0.0582         |
|    reward               | -6.5801236e-05 |
|    std                  | 17.7           |
|    value_loss           | 3.88e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2905, episode: 740
begin_total_asset: 200.00
end_total_asset: 209.38
total_reward: 9.38
total_cost: 1.98
total_trades: 47035
Sharpe: 0.181
=================================
Reseting Environment StartDay: 2036, ResetDay: 3716,Episode: 741
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 608          |
|    time_elapsed         | 13763        |
|    total_timesteps      | 1245184      |
| train/                  |              |
|    approx_kl            | 29.086311    |
|    clip_fraction        | 0.643        |
|    clip_range           | 0.2          |
|    entropy_loss         | -119         |
|    explained_variance   | -0.257       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.1         |
|    n_updates            | 6070         |
|    policy_gradient_loss | 0.0736       |
|    reward               | 0.0001925335 |
|    std                  | 17.8         |
|    value_loss           | 2.99e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 632, ResetDay: 2312,Episode: 742
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 609          |
|    time_elapsed         | 13786        |
|    total_timesteps      | 1247232      |
| train/                  |              |
|    approx_kl            | 29.973148    |
|    clip_fraction        | 0.662        |
|    clip_range           | 0.2          |
|    entropy_loss         | -120         |
|    explained_variance   | 0.0806       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.13        |
|    n_updates            | 6080         |
|    policy_gradient_loss | 0.0863       |
|    reward               | 4.537964e-06 |
|    std                  | 17.9         |
|    value_loss           | 3.53e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1625, ResetDay: 3305,Episode: 743
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2256, ResetDay: 3936,Episode: 744
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 610            |
|    time_elapsed         | 13809          |
|    total_timesteps      | 1249280        |
| train/                  |                |
|    approx_kl            | 31.852097      |
|    clip_fraction        | 0.642          |
|    clip_range           | 0.2            |
|    entropy_loss         | -120           |
|    explained_variance   | -0.314         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.15          |
|    n_updates            | 6090           |
|    policy_gradient_loss | 0.0567         |
|    reward               | -0.00010218315 |
|    std                  | 17.9           |
|    value_loss           | 3.97e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 114, ResetDay: 1794,Episode: 745
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 611           |
|    time_elapsed         | 13831         |
|    total_timesteps      | 1251328       |
| train/                  |               |
|    approx_kl            | 30.714252     |
|    clip_fraction        | 0.661         |
|    clip_range           | 0.2           |
|    entropy_loss         | -120          |
|    explained_variance   | 0.0114        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.08         |
|    n_updates            | 6100          |
|    policy_gradient_loss | 0.0752        |
|    reward               | 3.0724907e-05 |
|    std                  | 17.9          |
|    value_loss           | 5.61e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 1794, episode: 745
begin_total_asset: 200.00
end_total_asset: 164.32
total_reward: -35.68
total_cost: 2.42
total_trades: 47040
Sharpe: 0.133
=================================
Reseting Environment StartDay: 102, ResetDay: 1782,Episode: 746
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 612            |
|    time_elapsed         | 13854          |
|    total_timesteps      | 1253376        |
| train/                  |                |
|    approx_kl            | 31.2847        |
|    clip_fraction        | 0.663          |
|    clip_range           | 0.2            |
|    entropy_loss         | -120           |
|    explained_variance   | -0.376         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.15          |
|    n_updates            | 6110           |
|    policy_gradient_loss | 0.0695         |
|    reward               | -6.3973425e-06 |
|    std                  | 18             |
|    value_loss           | 5.72e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 596, ResetDay: 2276,Episode: 747
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 613           |
|    time_elapsed         | 13877         |
|    total_timesteps      | 1255424       |
| train/                  |               |
|    approx_kl            | 30.327934     |
|    clip_fraction        | 0.647         |
|    clip_range           | 0.2           |
|    entropy_loss         | -120          |
|    explained_variance   | -0.123        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.19         |
|    n_updates            | 6120          |
|    policy_gradient_loss | 0.0618        |
|    reward               | 0.00018843269 |
|    std                  | 18.1          |
|    value_loss           | 6.78e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 364, ResetDay: 2044,Episode: 748
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 491, ResetDay: 2171,Episode: 749
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 614           |
|    time_elapsed         | 13899         |
|    total_timesteps      | 1257472       |
| train/                  |               |
|    approx_kl            | 29.858461     |
|    clip_fraction        | 0.644         |
|    clip_range           | 0.2           |
|    entropy_loss         | -120          |
|    explained_variance   | 0.088         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.13         |
|    n_updates            | 6130          |
|    policy_gradient_loss | 0.08          |
|    reward               | -0.0001076725 |
|    std                  | 18.1          |
|    value_loss           | 5.52e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 970, ResetDay: 2650,Episode: 750
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 615          |
|    time_elapsed         | 13922        |
|    total_timesteps      | 1259520      |
| train/                  |              |
|    approx_kl            | 30.612516    |
|    clip_fraction        | 0.648        |
|    clip_range           | 0.2          |
|    entropy_loss         | -120         |
|    explained_variance   | -0.441       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.17        |
|    n_updates            | 6140         |
|    policy_gradient_loss | 0.0808       |
|    reward               | 9.188814e-05 |
|    std                  | 18.2         |
|    value_loss           | 4.19e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2650, episode: 750
begin_total_asset: 200.00
end_total_asset: 203.40
total_reward: 3.40
total_cost: 2.08
total_trades: 47036
Sharpe: 0.246
=================================
Reseting Environment StartDay: 461, ResetDay: 2141,Episode: 751
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 616            |
|    time_elapsed         | 13944          |
|    total_timesteps      | 1261568        |
| train/                  |                |
|    approx_kl            | 29.893932      |
|    clip_fraction        | 0.637          |
|    clip_range           | 0.2            |
|    entropy_loss         | -120           |
|    explained_variance   | -0.0671        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.17          |
|    n_updates            | 6150           |
|    policy_gradient_loss | 0.07           |
|    reward               | -0.00020066013 |
|    std                  | 18.3           |
|    value_loss           | 4.59e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1709, ResetDay: 3389,Episode: 752
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 617           |
|    time_elapsed         | 13967         |
|    total_timesteps      | 1263616       |
| train/                  |               |
|    approx_kl            | 31.08392      |
|    clip_fraction        | 0.655         |
|    clip_range           | 0.2           |
|    entropy_loss         | -120          |
|    explained_variance   | -0.0642       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.19         |
|    n_updates            | 6160          |
|    policy_gradient_loss | 0.0638        |
|    reward               | -0.0002312664 |
|    std                  | 18.4          |
|    value_loss           | 5.54e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2241, ResetDay: 3921,Episode: 753
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 618           |
|    time_elapsed         | 13990         |
|    total_timesteps      | 1265664       |
| train/                  |               |
|    approx_kl            | 31.055214     |
|    clip_fraction        | 0.642         |
|    clip_range           | 0.2           |
|    entropy_loss         | -120          |
|    explained_variance   | -0.0108       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.1          |
|    n_updates            | 6170          |
|    policy_gradient_loss | 0.0688        |
|    reward               | 1.0284424e-06 |
|    std                  | 18.4          |
|    value_loss           | 5.59e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 913, ResetDay: 2593,Episode: 754
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 857, ResetDay: 2537,Episode: 755
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 619          |
|    time_elapsed         | 14012        |
|    total_timesteps      | 1267712      |
| train/                  |              |
|    approx_kl            | 32.41109     |
|    clip_fraction        | 0.635        |
|    clip_range           | 0.2          |
|    entropy_loss         | -121         |
|    explained_variance   | -0.013       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.17        |
|    n_updates            | 6180         |
|    policy_gradient_loss | 0.0513       |
|    reward               | 8.545876e-06 |
|    std                  | 18.5         |
|    value_loss           | 4.57e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2537, episode: 755
begin_total_asset: 200.00
end_total_asset: 253.92
total_reward: 53.92
total_cost: 1.96
total_trades: 47034
Sharpe: 0.288
=================================
Reseting Environment StartDay: 1310, ResetDay: 2990,Episode: 756
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 620            |
|    time_elapsed         | 14035          |
|    total_timesteps      | 1269760        |
| train/                  |                |
|    approx_kl            | 32.906227      |
|    clip_fraction        | 0.657          |
|    clip_range           | 0.2            |
|    entropy_loss         | -121           |
|    explained_variance   | -0.139         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.13          |
|    n_updates            | 6190           |
|    policy_gradient_loss | 0.0698         |
|    reward               | -0.00016786919 |
|    std                  | 18.5           |
|    value_loss           | 6.96e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 84, ResetDay: 1764,Episode: 757
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 621            |
|    time_elapsed         | 14058          |
|    total_timesteps      | 1271808        |
| train/                  |                |
|    approx_kl            | 31.09389       |
|    clip_fraction        | 0.644          |
|    clip_range           | 0.2            |
|    entropy_loss         | -121           |
|    explained_variance   | -0.199         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.14          |
|    n_updates            | 6200           |
|    policy_gradient_loss | 0.0724         |
|    reward               | -1.7210294e-05 |
|    std                  | 18.6           |
|    value_loss           | 3.22e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 475, ResetDay: 2155,Episode: 758
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 622            |
|    time_elapsed         | 14081          |
|    total_timesteps      | 1273856        |
| train/                  |                |
|    approx_kl            | 32.040207      |
|    clip_fraction        | 0.629          |
|    clip_range           | 0.2            |
|    entropy_loss         | -121           |
|    explained_variance   | -0.285         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.19          |
|    n_updates            | 6210           |
|    policy_gradient_loss | 0.0697         |
|    reward               | -0.00022763119 |
|    std                  | 18.7           |
|    value_loss           | 1.69e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 683, ResetDay: 2363,Episode: 759
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2474, ResetDay: 4154,Episode: 760
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 623            |
|    time_elapsed         | 14104          |
|    total_timesteps      | 1275904        |
| train/                  |                |
|    approx_kl            | 31.266018      |
|    clip_fraction        | 0.644          |
|    clip_range           | 0.2            |
|    entropy_loss         | -121           |
|    explained_variance   | -0.132         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.18          |
|    n_updates            | 6220           |
|    policy_gradient_loss | 0.0704         |
|    reward               | -0.00022346879 |
|    std                  | 18.8           |
|    value_loss           | 3.62e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4154, episode: 760
begin_total_asset: 200.00
end_total_asset: 405.81
total_reward: 205.81
total_cost: 3.36
total_trades: 47033
Sharpe: 0.639
=================================
Reseting Environment StartDay: 2603, ResetDay: 4283,Episode: 761
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 624           |
|    time_elapsed         | 14127         |
|    total_timesteps      | 1277952       |
| train/                  |               |
|    approx_kl            | 32.05762      |
|    clip_fraction        | 0.625         |
|    clip_range           | 0.2           |
|    entropy_loss         | -121          |
|    explained_variance   | -0.00202      |
|    learning_rate        | 0.00025       |
|    loss                 | -1.13         |
|    n_updates            | 6230          |
|    policy_gradient_loss | 0.0625        |
|    reward               | 2.1211625e-05 |
|    std                  | 18.8          |
|    value_loss           | 3.98e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1318, ResetDay: 2998,Episode: 762
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 625           |
|    time_elapsed         | 14149         |
|    total_timesteps      | 1280000       |
| train/                  |               |
|    approx_kl            | 32.55051      |
|    clip_fraction        | 0.65          |
|    clip_range           | 0.2           |
|    entropy_loss         | -121          |
|    explained_variance   | -0.0835       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.2          |
|    n_updates            | 6240          |
|    policy_gradient_loss | 0.0615        |
|    reward               | 1.8803406e-05 |
|    std                  | 18.9          |
|    value_loss           | 7.85e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 959, ResetDay: 2639,Episode: 763
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 626            |
|    time_elapsed         | 14172          |
|    total_timesteps      | 1282048        |
| train/                  |                |
|    approx_kl            | 33.10441       |
|    clip_fraction        | 0.664          |
|    clip_range           | 0.2            |
|    entropy_loss         | -121           |
|    explained_variance   | -0.0925        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.15          |
|    n_updates            | 6250           |
|    policy_gradient_loss | 0.0752         |
|    reward               | -2.0832063e-06 |
|    std                  | 19             |
|    value_loss           | 3.93e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1145, ResetDay: 2825,Episode: 764
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 627           |
|    time_elapsed         | 14195         |
|    total_timesteps      | 1284096       |
| train/                  |               |
|    approx_kl            | 32.66559      |
|    clip_fraction        | 0.645         |
|    clip_range           | 0.2           |
|    entropy_loss         | -121          |
|    explained_variance   | -0.268        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.19         |
|    n_updates            | 6260          |
|    policy_gradient_loss | 0.0534        |
|    reward               | 8.2574275e-05 |
|    std                  | 19.1          |
|    value_loss           | 2.47e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 860, ResetDay: 2540,Episode: 765
Environment reached Terminal state as number of trading days reached limit!!
day: 2540, episode: 765
begin_total_asset: 200.00
end_total_asset: 259.52
total_reward: 59.52
total_cost: 1.96
total_trades: 47040
Sharpe: 0.303
=================================
Reseting Environment StartDay: 1944, ResetDay: 3624,Episode: 766
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 628            |
|    time_elapsed         | 14217          |
|    total_timesteps      | 1286144        |
| train/                  |                |
|    approx_kl            | 33.310966      |
|    clip_fraction        | 0.634          |
|    clip_range           | 0.2            |
|    entropy_loss         | -122           |
|    explained_variance   | 0.0443         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.19          |
|    n_updates            | 6270           |
|    policy_gradient_loss | 0.0614         |
|    reward               | -7.7563855e-05 |
|    std                  | 19.1           |
|    value_loss           | 2.55e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2651, ResetDay: 4331,Episode: 767
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 629          |
|    time_elapsed         | 14240        |
|    total_timesteps      | 1288192      |
| train/                  |              |
|    approx_kl            | 33.41826     |
|    clip_fraction        | 0.631        |
|    clip_range           | 0.2          |
|    entropy_loss         | -122         |
|    explained_variance   | 0.0162       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.11        |
|    n_updates            | 6280         |
|    policy_gradient_loss | 0.0804       |
|    reward               | 9.171181e-05 |
|    std                  | 19.2         |
|    value_loss           | 6.37e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 701, ResetDay: 2381,Episode: 768
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 630           |
|    time_elapsed         | 14262         |
|    total_timesteps      | 1290240       |
| train/                  |               |
|    approx_kl            | 32.81346      |
|    clip_fraction        | 0.646         |
|    clip_range           | 0.2           |
|    entropy_loss         | -122          |
|    explained_variance   | -0.0419       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.14         |
|    n_updates            | 6290          |
|    policy_gradient_loss | 0.0746        |
|    reward               | 0.00036057242 |
|    std                  | 19.2          |
|    value_loss           | 4e-07         |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 446, ResetDay: 2126,Episode: 769
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 631          |
|    time_elapsed         | 14285        |
|    total_timesteps      | 1292288      |
| train/                  |              |
|    approx_kl            | 34.83345     |
|    clip_fraction        | 0.641        |
|    clip_range           | 0.2          |
|    entropy_loss         | -122         |
|    explained_variance   | -0.0714      |
|    learning_rate        | 0.00025      |
|    loss                 | -1.16        |
|    n_updates            | 6300         |
|    policy_gradient_loss | 0.0657       |
|    reward               | -1.74263e-05 |
|    std                  | 19.3         |
|    value_loss           | 5.51e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1805, ResetDay: 3485,Episode: 770
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 632          |
|    time_elapsed         | 14308        |
|    total_timesteps      | 1294336      |
| train/                  |              |
|    approx_kl            | 33.32184     |
|    clip_fraction        | 0.642        |
|    clip_range           | 0.2          |
|    entropy_loss         | -122         |
|    explained_variance   | -0.258       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.12        |
|    n_updates            | 6310         |
|    policy_gradient_loss | 0.0663       |
|    reward               | -0.000630983 |
|    std                  | 19.4         |
|    value_loss           | 4.61e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3485, episode: 770
begin_total_asset: 200.00
end_total_asset: 357.72
total_reward: 157.72
total_cost: 1.97
total_trades: 47033
Sharpe: 0.537
=================================
Reseting Environment StartDay: 1641, ResetDay: 3321,Episode: 771
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2226, ResetDay: 3906,Episode: 772
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 633            |
|    time_elapsed         | 14330          |
|    total_timesteps      | 1296384        |
| train/                  |                |
|    approx_kl            | 33.554512      |
|    clip_fraction        | 0.63           |
|    clip_range           | 0.2            |
|    entropy_loss         | -122           |
|    explained_variance   | -0.0693        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.14          |
|    n_updates            | 6320           |
|    policy_gradient_loss | 0.0642         |
|    reward               | -5.1692964e-06 |
|    std                  | 19.5           |
|    value_loss           | 5.39e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2717, ResetDay: 4397,Episode: 773
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 634           |
|    time_elapsed         | 14353         |
|    total_timesteps      | 1298432       |
| train/                  |               |
|    approx_kl            | 35.18296      |
|    clip_fraction        | 0.632         |
|    clip_range           | 0.2           |
|    entropy_loss         | -122          |
|    explained_variance   | 0.0771        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.16         |
|    n_updates            | 6330          |
|    policy_gradient_loss | 0.0642        |
|    reward               | 0.00040275155 |
|    std                  | 19.5          |
|    value_loss           | 3.04e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2632, ResetDay: 4312,Episode: 774
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 635           |
|    time_elapsed         | 14376         |
|    total_timesteps      | 1300480       |
| train/                  |               |
|    approx_kl            | 34.504463     |
|    clip_fraction        | 0.644         |
|    clip_range           | 0.2           |
|    entropy_loss         | -122          |
|    explained_variance   | 0.11          |
|    learning_rate        | 0.00025       |
|    loss                 | -1.12         |
|    n_updates            | 6340          |
|    policy_gradient_loss | 0.0696        |
|    reward               | -4.165306e-05 |
|    std                  | 19.6          |
|    value_loss           | 1.62e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2033, ResetDay: 3713,Episode: 775
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 636          |
|    time_elapsed         | 14399        |
|    total_timesteps      | 1302528      |
| train/                  |              |
|    approx_kl            | 35.867897    |
|    clip_fraction        | 0.629        |
|    clip_range           | 0.2          |
|    entropy_loss         | -122         |
|    explained_variance   | 0.0932       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.19        |
|    n_updates            | 6350         |
|    policy_gradient_loss | 0.0606       |
|    reward               | 2.233429e-05 |
|    std                  | 19.8         |
|    value_loss           | 4.52e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3713, episode: 775
begin_total_asset: 200.00
end_total_asset: 217.89
total_reward: 17.89
total_cost: 1.88
total_trades: 47033
Sharpe: 0.184
=================================
Reseting Environment StartDay: 1664, ResetDay: 3344,Episode: 776
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2801, ResetDay: 4481,Episode: 777
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 637          |
|    time_elapsed         | 14421        |
|    total_timesteps      | 1304576      |
| train/                  |              |
|    approx_kl            | 36.309536    |
|    clip_fraction        | 0.639        |
|    clip_range           | 0.2          |
|    entropy_loss         | -123         |
|    explained_variance   | 0.123        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.14        |
|    n_updates            | 6360         |
|    policy_gradient_loss | 0.0643       |
|    reward               | -9.74968e-05 |
|    std                  | 19.8         |
|    value_loss           | 4.38e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1350, ResetDay: 3030,Episode: 778
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 638          |
|    time_elapsed         | 14444        |
|    total_timesteps      | 1306624      |
| train/                  |              |
|    approx_kl            | 36.4295      |
|    clip_fraction        | 0.638        |
|    clip_range           | 0.2          |
|    entropy_loss         | -123         |
|    explained_variance   | 0.117        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.14        |
|    n_updates            | 6370         |
|    policy_gradient_loss | 0.057        |
|    reward               | 3.890457e-05 |
|    std                  | 19.9         |
|    value_loss           | 2.96e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2081, ResetDay: 3761,Episode: 779
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 639           |
|    time_elapsed         | 14467         |
|    total_timesteps      | 1308672       |
| train/                  |               |
|    approx_kl            | 35.715954     |
|    clip_fraction        | 0.62          |
|    clip_range           | 0.2           |
|    entropy_loss         | -123          |
|    explained_variance   | 0.0449        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.18         |
|    n_updates            | 6380          |
|    policy_gradient_loss | 0.0557        |
|    reward               | 0.00011738567 |
|    std                  | 19.9          |
|    value_loss           | 8.59e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1830, ResetDay: 3510,Episode: 780
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 640           |
|    time_elapsed         | 14489         |
|    total_timesteps      | 1310720       |
| train/                  |               |
|    approx_kl            | 34.69463      |
|    clip_fraction        | 0.64          |
|    clip_range           | 0.2           |
|    entropy_loss         | -123          |
|    explained_variance   | -0.25         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.17         |
|    n_updates            | 6390          |
|    policy_gradient_loss | 0.0626        |
|    reward               | 0.00015945129 |
|    std                  | 20            |
|    value_loss           | 1.6e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3510, episode: 780
begin_total_asset: 200.00
end_total_asset: 241.00
total_reward: 41.00
total_cost: 1.95
total_trades: 47033
Sharpe: 0.271
=================================
Reseting Environment StartDay: 2779, ResetDay: 4459,Episode: 781
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 641          |
|    time_elapsed         | 14512        |
|    total_timesteps      | 1312768      |
| train/                  |              |
|    approx_kl            | 36.564148    |
|    clip_fraction        | 0.64         |
|    clip_range           | 0.2          |
|    entropy_loss         | -123         |
|    explained_variance   | 0.0616       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.13        |
|    n_updates            | 6400         |
|    policy_gradient_loss | 0.0622       |
|    reward               | 6.477966e-05 |
|    std                  | 20.1         |
|    value_loss           | 5.9e-07      |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1647, ResetDay: 3327,Episode: 782
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 98, ResetDay: 1778,Episode: 783
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 642            |
|    time_elapsed         | 14534          |
|    total_timesteps      | 1314816        |
| train/                  |                |
|    approx_kl            | 35.792187      |
|    clip_fraction        | 0.638          |
|    clip_range           | 0.2            |
|    entropy_loss         | -123           |
|    explained_variance   | 0.0261         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.16          |
|    n_updates            | 6410           |
|    policy_gradient_loss | 0.0636         |
|    reward               | -0.00028481564 |
|    std                  | 20.3           |
|    value_loss           | 4.11e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1827, ResetDay: 3507,Episode: 784
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 643           |
|    time_elapsed         | 14557         |
|    total_timesteps      | 1316864       |
| train/                  |               |
|    approx_kl            | 38.256        |
|    clip_fraction        | 0.624         |
|    clip_range           | 0.2           |
|    entropy_loss         | -123          |
|    explained_variance   | -0.44         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.2          |
|    n_updates            | 6420          |
|    policy_gradient_loss | 0.0614        |
|    reward               | -3.911762e-05 |
|    std                  | 20.3          |
|    value_loss           | 5.49e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1139, ResetDay: 2819,Episode: 785
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 644           |
|    time_elapsed         | 14580         |
|    total_timesteps      | 1318912       |
| train/                  |               |
|    approx_kl            | 36.58419      |
|    clip_fraction        | 0.612         |
|    clip_range           | 0.2           |
|    entropy_loss         | -123          |
|    explained_variance   | -0.207        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.23         |
|    n_updates            | 6430          |
|    policy_gradient_loss | 0.0483        |
|    reward               | 0.00026902714 |
|    std                  | 20.4          |
|    value_loss           | 3.88e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2819, episode: 785
begin_total_asset: 200.00
end_total_asset: 179.52
total_reward: -20.48
total_cost: 2.26
total_trades: 47034
Sharpe: 0.118
=================================
Reseting Environment StartDay: 126, ResetDay: 1806,Episode: 786
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 645           |
|    time_elapsed         | 14602         |
|    total_timesteps      | 1320960       |
| train/                  |               |
|    approx_kl            | 36.25722      |
|    clip_fraction        | 0.618         |
|    clip_range           | 0.2           |
|    entropy_loss         | -123          |
|    explained_variance   | -0.0304       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.2          |
|    n_updates            | 6440          |
|    policy_gradient_loss | 0.0422        |
|    reward               | 0.00012481518 |
|    std                  | 20.5          |
|    value_loss           | 7.47e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1680, ResetDay: 3360,Episode: 787
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2696, ResetDay: 4376,Episode: 788
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 646           |
|    time_elapsed         | 14625         |
|    total_timesteps      | 1323008       |
| train/                  |               |
|    approx_kl            | 36.68457      |
|    clip_fraction        | 0.631         |
|    clip_range           | 0.2           |
|    entropy_loss         | -124          |
|    explained_variance   | -0.199        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.25         |
|    n_updates            | 6450          |
|    policy_gradient_loss | 0.0448        |
|    reward               | 4.1226576e-05 |
|    std                  | 20.6          |
|    value_loss           | 5.34e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 129, ResetDay: 1809,Episode: 789
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 647            |
|    time_elapsed         | 14647          |
|    total_timesteps      | 1325056        |
| train/                  |                |
|    approx_kl            | 36.9158        |
|    clip_fraction        | 0.626          |
|    clip_range           | 0.2            |
|    entropy_loss         | -124           |
|    explained_variance   | 0.0182         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.17          |
|    n_updates            | 6460           |
|    policy_gradient_loss | 0.0656         |
|    reward               | -5.2444506e-05 |
|    std                  | 20.7           |
|    value_loss           | 8.81e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 249, ResetDay: 1929,Episode: 790
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 648           |
|    time_elapsed         | 14675         |
|    total_timesteps      | 1327104       |
| train/                  |               |
|    approx_kl            | 37.169434     |
|    clip_fraction        | 0.609         |
|    clip_range           | 0.2           |
|    entropy_loss         | -124          |
|    explained_variance   | -0.137        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.15         |
|    n_updates            | 6470          |
|    policy_gradient_loss | 0.0523        |
|    reward               | 0.00038364297 |
|    std                  | 20.8          |
|    value_loss           | 7.26e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 1929, episode: 790
begin_total_asset: 200.00
end_total_asset: 250.18
total_reward: 50.18
total_cost: 1.97
total_trades: 47031
Sharpe: 0.261
=================================
Reseting Environment StartDay: 335, ResetDay: 2015,Episode: 791
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 649           |
|    time_elapsed         | 14697         |
|    total_timesteps      | 1329152       |
| train/                  |               |
|    approx_kl            | 38.372494     |
|    clip_fraction        | 0.619         |
|    clip_range           | 0.2           |
|    entropy_loss         | -124          |
|    explained_variance   | -0.384        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.19         |
|    n_updates            | 6480          |
|    policy_gradient_loss | 0.0696        |
|    reward               | 0.00019746227 |
|    std                  | 20.8          |
|    value_loss           | 4.98e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1572, ResetDay: 3252,Episode: 792
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 650           |
|    time_elapsed         | 14720         |
|    total_timesteps      | 1331200       |
| train/                  |               |
|    approx_kl            | 37.20763      |
|    clip_fraction        | 0.623         |
|    clip_range           | 0.2           |
|    entropy_loss         | -124          |
|    explained_variance   | 0.0784        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.21         |
|    n_updates            | 6490          |
|    policy_gradient_loss | 0.0571        |
|    reward               | -0.0005388895 |
|    std                  | 20.9          |
|    value_loss           | 7.25e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 251, ResetDay: 1931,Episode: 793
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1583, ResetDay: 3263,Episode: 794
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 651           |
|    time_elapsed         | 14742         |
|    total_timesteps      | 1333248       |
| train/                  |               |
|    approx_kl            | 37.577454     |
|    clip_fraction        | 0.623         |
|    clip_range           | 0.2           |
|    entropy_loss         | -124          |
|    explained_variance   | -0.0702       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.25         |
|    n_updates            | 6500          |
|    policy_gradient_loss | 0.0537        |
|    reward               | 0.00015091115 |
|    std                  | 21            |
|    value_loss           | 5.95e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1516, ResetDay: 3196,Episode: 795
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 652           |
|    time_elapsed         | 14765         |
|    total_timesteps      | 1335296       |
| train/                  |               |
|    approx_kl            | 39.182606     |
|    clip_fraction        | 0.623         |
|    clip_range           | 0.2           |
|    entropy_loss         | -124          |
|    explained_variance   | -0.191        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.2          |
|    n_updates            | 6510          |
|    policy_gradient_loss | 0.0633        |
|    reward               | 0.00014666215 |
|    std                  | 21            |
|    value_loss           | 4.79e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3196, episode: 795
begin_total_asset: 200.00
end_total_asset: 248.90
total_reward: 48.90
total_cost: 2.57
total_trades: 47037
Sharpe: 0.292
=================================
Reseting Environment StartDay: 2612, ResetDay: 4292,Episode: 796
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 653           |
|    time_elapsed         | 14787         |
|    total_timesteps      | 1337344       |
| train/                  |               |
|    approx_kl            | 38.692398     |
|    clip_fraction        | 0.63          |
|    clip_range           | 0.2           |
|    entropy_loss         | -124          |
|    explained_variance   | -0.00411      |
|    learning_rate        | 0.00025       |
|    loss                 | -1.23         |
|    n_updates            | 6520          |
|    policy_gradient_loss | 0.0654        |
|    reward               | 0.00012225723 |
|    std                  | 21.1          |
|    value_loss           | 6.37e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2532, ResetDay: 4212,Episode: 797
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 654           |
|    time_elapsed         | 14810         |
|    total_timesteps      | 1339392       |
| train/                  |               |
|    approx_kl            | 38.094395     |
|    clip_fraction        | 0.624         |
|    clip_range           | 0.2           |
|    entropy_loss         | -124          |
|    explained_variance   | 0.0819        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.26         |
|    n_updates            | 6530          |
|    policy_gradient_loss | 0.0544        |
|    reward               | 2.4970246e-05 |
|    std                  | 21.2          |
|    value_loss           | 2.75e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2406, ResetDay: 4086,Episode: 798
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 906, ResetDay: 2586,Episode: 799
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 655            |
|    time_elapsed         | 14833          |
|    total_timesteps      | 1341440        |
| train/                  |                |
|    approx_kl            | 39.38544       |
|    clip_fraction        | 0.623          |
|    clip_range           | 0.2            |
|    entropy_loss         | -124           |
|    explained_variance   | 0.056          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.21          |
|    n_updates            | 6540           |
|    policy_gradient_loss | 0.0565         |
|    reward               | -0.00017284878 |
|    std                  | 21.3           |
|    value_loss           | 4.46e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1390, ResetDay: 3070,Episode: 800
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 656          |
|    time_elapsed         | 14855        |
|    total_timesteps      | 1343488      |
| train/                  |              |
|    approx_kl            | 39.706123    |
|    clip_fraction        | 0.62         |
|    clip_range           | 0.2          |
|    entropy_loss         | -125         |
|    explained_variance   | 0.0841       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.2         |
|    n_updates            | 6550         |
|    policy_gradient_loss | 0.0451       |
|    reward               | 0.0001609743 |
|    std                  | 21.4         |
|    value_loss           | 5.13e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3070, episode: 800
begin_total_asset: 200.00
end_total_asset: 240.45
total_reward: 40.45
total_cost: 3.15
total_trades: 47034
Sharpe: 0.263
=================================
Reseting Environment StartDay: 1798, ResetDay: 3478,Episode: 801
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 657          |
|    time_elapsed         | 14878        |
|    total_timesteps      | 1345536      |
| train/                  |              |
|    approx_kl            | 38.360565    |
|    clip_fraction        | 0.617        |
|    clip_range           | 0.2          |
|    entropy_loss         | -125         |
|    explained_variance   | -0.635       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.17        |
|    n_updates            | 6560         |
|    policy_gradient_loss | 0.0553       |
|    reward               | 9.934044e-06 |
|    std                  | 21.5         |
|    value_loss           | 3.53e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1066, ResetDay: 2746,Episode: 802
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 658           |
|    time_elapsed         | 14900         |
|    total_timesteps      | 1347584       |
| train/                  |               |
|    approx_kl            | 39.650677     |
|    clip_fraction        | 0.619         |
|    clip_range           | 0.2           |
|    entropy_loss         | -125          |
|    explained_variance   | -0.162        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.18         |
|    n_updates            | 6570          |
|    policy_gradient_loss | 0.0565        |
|    reward               | 0.00012992954 |
|    std                  | 21.5          |
|    value_loss           | 3.57e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 362, ResetDay: 2042,Episode: 803
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 659            |
|    time_elapsed         | 14923          |
|    total_timesteps      | 1349632        |
| train/                  |                |
|    approx_kl            | 39.463234      |
|    clip_fraction        | 0.632          |
|    clip_range           | 0.2            |
|    entropy_loss         | -125           |
|    explained_variance   | -0.138         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.21          |
|    n_updates            | 6580           |
|    policy_gradient_loss | 0.0581         |
|    reward               | -0.00010424862 |
|    std                  | 21.6           |
|    value_loss           | 4.43e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1742, ResetDay: 3422,Episode: 804
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1139, ResetDay: 2819,Episode: 805
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 660           |
|    time_elapsed         | 14946         |
|    total_timesteps      | 1351680       |
| train/                  |               |
|    approx_kl            | 40.058968     |
|    clip_fraction        | 0.599         |
|    clip_range           | 0.2           |
|    entropy_loss         | -125          |
|    explained_variance   | -0.453        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.19         |
|    n_updates            | 6590          |
|    policy_gradient_loss | 0.0652        |
|    reward               | -8.094253e-05 |
|    std                  | 21.8          |
|    value_loss           | 4.15e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2819, episode: 805
begin_total_asset: 200.00
end_total_asset: 182.29
total_reward: -17.71
total_cost: 3.07
total_trades: 47033
Sharpe: 0.102
=================================
Reseting Environment StartDay: 1377, ResetDay: 3057,Episode: 806
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 661            |
|    time_elapsed         | 14968          |
|    total_timesteps      | 1353728        |
| train/                  |                |
|    approx_kl            | 40.10668       |
|    clip_fraction        | 0.605          |
|    clip_range           | 0.2            |
|    entropy_loss         | -125           |
|    explained_variance   | 0.0229         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.22          |
|    n_updates            | 6600           |
|    policy_gradient_loss | 0.0439         |
|    reward               | 0.000113280104 |
|    std                  | 21.8           |
|    value_loss           | 6.35e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 145, ResetDay: 1825,Episode: 807
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 662          |
|    time_elapsed         | 14991        |
|    total_timesteps      | 1355776      |
| train/                  |              |
|    approx_kl            | 39.89787     |
|    clip_fraction        | 0.599        |
|    clip_range           | 0.2          |
|    entropy_loss         | -125         |
|    explained_variance   | -0.0856      |
|    learning_rate        | 0.00025      |
|    loss                 | -1.16        |
|    n_updates            | 6610         |
|    policy_gradient_loss | 0.0534       |
|    reward               | 5.508709e-06 |
|    std                  | 21.9         |
|    value_loss           | 3.34e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1733, ResetDay: 3413,Episode: 808
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 663           |
|    time_elapsed         | 15013         |
|    total_timesteps      | 1357824       |
| train/                  |               |
|    approx_kl            | 40.29158      |
|    clip_fraction        | 0.622         |
|    clip_range           | 0.2           |
|    entropy_loss         | -125          |
|    explained_variance   | -0.16         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.16         |
|    n_updates            | 6620          |
|    policy_gradient_loss | 0.0557        |
|    reward               | 0.00041301423 |
|    std                  | 22            |
|    value_loss           | 5.16e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1613, ResetDay: 3293,Episode: 809
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 664            |
|    time_elapsed         | 15036          |
|    total_timesteps      | 1359872        |
| train/                  |                |
|    approx_kl            | 40.652893      |
|    clip_fraction        | 0.594          |
|    clip_range           | 0.2            |
|    entropy_loss         | -126           |
|    explained_variance   | -0.00825       |
|    learning_rate        | 0.00025        |
|    loss                 | -1.22          |
|    n_updates            | 6630           |
|    policy_gradient_loss | 0.0565         |
|    reward               | -0.00066582183 |
|    std                  | 22             |
|    value_loss           | 6.45e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 678, ResetDay: 2358,Episode: 810
Environment reached Terminal state as number of trading days reached limit!!
day: 2358, episode: 810
begin_total_asset: 200.00
end_total_asset: 216.61
total_reward: 16.61
total_cost: 2.50
total_trades: 47035
Sharpe: 0.214
=================================
Reseting Environment StartDay: 648, ResetDay: 2328,Episode: 811
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 665           |
|    time_elapsed         | 15058         |
|    total_timesteps      | 1361920       |
| train/                  |               |
|    approx_kl            | 40.979187     |
|    clip_fraction        | 0.616         |
|    clip_range           | 0.2           |
|    entropy_loss         | -126          |
|    explained_variance   | -0.0477       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.18         |
|    n_updates            | 6640          |
|    policy_gradient_loss | 0.0497        |
|    reward               | 5.3349497e-05 |
|    std                  | 22.1          |
|    value_loss           | 6.95e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1351, ResetDay: 3031,Episode: 812
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 666           |
|    time_elapsed         | 15081         |
|    total_timesteps      | 1363968       |
| train/                  |               |
|    approx_kl            | 41.406986     |
|    clip_fraction        | 0.605         |
|    clip_range           | 0.2           |
|    entropy_loss         | -126          |
|    explained_variance   | -0.259        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.21         |
|    n_updates            | 6650          |
|    policy_gradient_loss | 0.0519        |
|    reward               | 0.00018236418 |
|    std                  | 22.2          |
|    value_loss           | 4.12e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 470, ResetDay: 2150,Episode: 813
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 667          |
|    time_elapsed         | 15103        |
|    total_timesteps      | 1366016      |
| train/                  |              |
|    approx_kl            | 40.816383    |
|    clip_fraction        | 0.603        |
|    clip_range           | 0.2          |
|    entropy_loss         | -126         |
|    explained_variance   | -0.133       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.21        |
|    n_updates            | 6660         |
|    policy_gradient_loss | 0.0696       |
|    reward               | 3.935957e-05 |
|    std                  | 22.3         |
|    value_loss           | 4.08e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1250, ResetDay: 2930,Episode: 814
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 668          |
|    time_elapsed         | 15126        |
|    total_timesteps      | 1368064      |
| train/                  |              |
|    approx_kl            | 41.69184     |
|    clip_fraction        | 0.607        |
|    clip_range           | 0.2          |
|    entropy_loss         | -126         |
|    explained_variance   | -0.225       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.22        |
|    n_updates            | 6670         |
|    policy_gradient_loss | 0.0514       |
|    reward               | 7.982578e-05 |
|    std                  | 22.5         |
|    value_loss           | 3.89e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1812, ResetDay: 3492,Episode: 815
Environment reached Terminal state as number of trading days reached limit!!
day: 3492, episode: 815
begin_total_asset: 200.00
end_total_asset: 257.58
total_reward: 57.58
total_cost: 1.95
total_trades: 47038
Sharpe: 0.304
=================================
Reseting Environment StartDay: 2667, ResetDay: 4347,Episode: 816
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 669          |
|    time_elapsed         | 15149        |
|    total_timesteps      | 1370112      |
| train/                  |              |
|    approx_kl            | 41.576324    |
|    clip_fraction        | 0.603        |
|    clip_range           | 0.2          |
|    entropy_loss         | -126         |
|    explained_variance   | -0.157       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.24        |
|    n_updates            | 6680         |
|    policy_gradient_loss | 0.0465       |
|    reward               | 5.665474e-05 |
|    std                  | 22.6         |
|    value_loss           | 4.24e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 279, ResetDay: 1959,Episode: 817
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 670            |
|    time_elapsed         | 15171          |
|    total_timesteps      | 1372160        |
| train/                  |                |
|    approx_kl            | 43.113197      |
|    clip_fraction        | 0.62           |
|    clip_range           | 0.2            |
|    entropy_loss         | -126           |
|    explained_variance   | 0.00638        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.22          |
|    n_updates            | 6690           |
|    policy_gradient_loss | 0.0576         |
|    reward               | -0.00013368492 |
|    std                  | 22.7           |
|    value_loss           | 4.64e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1048, ResetDay: 2728,Episode: 818
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 671            |
|    time_elapsed         | 15194          |
|    total_timesteps      | 1374208        |
| train/                  |                |
|    approx_kl            | 42.590164      |
|    clip_fraction        | 0.619          |
|    clip_range           | 0.2            |
|    entropy_loss         | -126           |
|    explained_variance   | -0.206         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.2           |
|    n_updates            | 6700           |
|    policy_gradient_loss | 0.0524         |
|    reward               | -0.00027083972 |
|    std                  | 22.8           |
|    value_loss           | 4.07e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 874, ResetDay: 2554,Episode: 819
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 672           |
|    time_elapsed         | 15216         |
|    total_timesteps      | 1376256       |
| train/                  |               |
|    approx_kl            | 42.999287     |
|    clip_fraction        | 0.603         |
|    clip_range           | 0.2           |
|    entropy_loss         | -126          |
|    explained_variance   | -0.5          |
|    learning_rate        | 0.00025       |
|    loss                 | -1.17         |
|    n_updates            | 6710          |
|    policy_gradient_loss | 0.0471        |
|    reward               | 0.00015726662 |
|    std                  | 22.8          |
|    value_loss           | 2.68e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1002, ResetDay: 2682,Episode: 820
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 673            |
|    time_elapsed         | 15239          |
|    total_timesteps      | 1378304        |
| train/                  |                |
|    approx_kl            | 42.926758      |
|    clip_fraction        | 0.619          |
|    clip_range           | 0.2            |
|    entropy_loss         | -127           |
|    explained_variance   | 0.0605         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.23          |
|    n_updates            | 6720           |
|    policy_gradient_loss | 0.0504         |
|    reward               | -0.00026880493 |
|    std                  | 22.9           |
|    value_loss           | 1.12e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2682, episode: 820
begin_total_asset: 200.00
end_total_asset: 260.40
total_reward: 60.40
total_cost: 2.47
total_trades: 47033
Sharpe: 0.326
=================================
Reseting Environment StartDay: 324, ResetDay: 2004,Episode: 821
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 735, ResetDay: 2415,Episode: 822
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 674           |
|    time_elapsed         | 15262         |
|    total_timesteps      | 1380352       |
| train/                  |               |
|    approx_kl            | 43.138107     |
|    clip_fraction        | 0.608         |
|    clip_range           | 0.2           |
|    entropy_loss         | -127          |
|    explained_variance   | -0.0421       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.21         |
|    n_updates            | 6730          |
|    policy_gradient_loss | 0.0607        |
|    reward               | -8.873613e-05 |
|    std                  | 23            |
|    value_loss           | 4.27e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1357, ResetDay: 3037,Episode: 823
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 675          |
|    time_elapsed         | 15284        |
|    total_timesteps      | 1382400      |
| train/                  |              |
|    approx_kl            | 42.960064    |
|    clip_fraction        | 0.613        |
|    clip_range           | 0.2          |
|    entropy_loss         | -127         |
|    explained_variance   | -0.0544      |
|    learning_rate        | 0.00025      |
|    loss                 | -1.18        |
|    n_updates            | 6740         |
|    policy_gradient_loss | 0.0481       |
|    reward               | 0.0002981514 |
|    std                  | 23.1         |
|    value_loss           | 5.17e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2394, ResetDay: 4074,Episode: 824
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 676           |
|    time_elapsed         | 15307         |
|    total_timesteps      | 1384448       |
| train/                  |               |
|    approx_kl            | 43.111805     |
|    clip_fraction        | 0.597         |
|    clip_range           | 0.2           |
|    entropy_loss         | -127          |
|    explained_variance   | -0.213        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.21         |
|    n_updates            | 6750          |
|    policy_gradient_loss | 0.0531        |
|    reward               | 0.00020527572 |
|    std                  | 23.2          |
|    value_loss           | 3.01e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 696, ResetDay: 2376,Episode: 825
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 677           |
|    time_elapsed         | 15330         |
|    total_timesteps      | 1386496       |
| train/                  |               |
|    approx_kl            | 43.021027     |
|    clip_fraction        | 0.595         |
|    clip_range           | 0.2           |
|    entropy_loss         | -127          |
|    explained_variance   | -0.0893       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.23         |
|    n_updates            | 6760          |
|    policy_gradient_loss | 0.0468        |
|    reward               | 6.0892107e-06 |
|    std                  | 23.3          |
|    value_loss           | 3.63e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2376, episode: 825
begin_total_asset: 200.00
end_total_asset: 140.64
total_reward: -59.36
total_cost: 2.98
total_trades: 47033
Sharpe: 0.090
=================================
Reseting Environment StartDay: 297, ResetDay: 1977,Episode: 826
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2340, ResetDay: 4020,Episode: 827
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 678          |
|    time_elapsed         | 15352        |
|    total_timesteps      | 1388544      |
| train/                  |              |
|    approx_kl            | 45.263958    |
|    clip_fraction        | 0.617        |
|    clip_range           | 0.2          |
|    entropy_loss         | -127         |
|    explained_variance   | -0.139       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.19        |
|    n_updates            | 6770         |
|    policy_gradient_loss | 0.055        |
|    reward               | 7.818222e-06 |
|    std                  | 23.4         |
|    value_loss           | 7.91e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 696, ResetDay: 2376,Episode: 828
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 679           |
|    time_elapsed         | 15375         |
|    total_timesteps      | 1390592       |
| train/                  |               |
|    approx_kl            | 44.790337     |
|    clip_fraction        | 0.598         |
|    clip_range           | 0.2           |
|    entropy_loss         | -127          |
|    explained_variance   | -0.135        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.21         |
|    n_updates            | 6780          |
|    policy_gradient_loss | 0.04          |
|    reward               | -8.194199e-05 |
|    std                  | 23.5          |
|    value_loss           | 4.94e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1147, ResetDay: 2827,Episode: 829
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 680            |
|    time_elapsed         | 15397          |
|    total_timesteps      | 1392640        |
| train/                  |                |
|    approx_kl            | 46.14953       |
|    clip_fraction        | 0.59           |
|    clip_range           | 0.2            |
|    entropy_loss         | -127           |
|    explained_variance   | 0.00433        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.26          |
|    n_updates            | 6790           |
|    policy_gradient_loss | 0.047          |
|    reward               | -0.00012099657 |
|    std                  | 23.5           |
|    value_loss           | 3.02e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 384, ResetDay: 2064,Episode: 830
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 681            |
|    time_elapsed         | 15420          |
|    total_timesteps      | 1394688        |
| train/                  |                |
|    approx_kl            | 45.399338      |
|    clip_fraction        | 0.596          |
|    clip_range           | 0.2            |
|    entropy_loss         | -127           |
|    explained_variance   | -0.569         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.25          |
|    n_updates            | 6800           |
|    policy_gradient_loss | 0.049          |
|    reward               | -5.5783938e-05 |
|    std                  | 23.6           |
|    value_loss           | 4.18e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2064, episode: 830
begin_total_asset: 200.00
end_total_asset: 214.28
total_reward: 14.28
total_cost: 3.83
total_trades: 47037
Sharpe: 0.211
=================================
Reseting Environment StartDay: 501, ResetDay: 2181,Episode: 831
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 682           |
|    time_elapsed         | 15443         |
|    total_timesteps      | 1396736       |
| train/                  |               |
|    approx_kl            | 45.615936     |
|    clip_fraction        | 0.582         |
|    clip_range           | 0.2           |
|    entropy_loss         | -128          |
|    explained_variance   | 0.0184        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.25         |
|    n_updates            | 6810          |
|    policy_gradient_loss | 0.0483        |
|    reward               | 0.00036697043 |
|    std                  | 23.7          |
|    value_loss           | 3.67e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1465, ResetDay: 3145,Episode: 832
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1290, ResetDay: 2970,Episode: 833
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 683          |
|    time_elapsed         | 15465        |
|    total_timesteps      | 1398784      |
| train/                  |              |
|    approx_kl            | 45.24291     |
|    clip_fraction        | 0.599        |
|    clip_range           | 0.2          |
|    entropy_loss         | -128         |
|    explained_variance   | -0.0288      |
|    learning_rate        | 0.00025      |
|    loss                 | -1.22        |
|    n_updates            | 6820         |
|    policy_gradient_loss | 0.0511       |
|    reward               | 6.737976e-05 |
|    std                  | 23.8         |
|    value_loss           | 3.51e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 320, ResetDay: 2000,Episode: 834
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 684          |
|    time_elapsed         | 15488        |
|    total_timesteps      | 1400832      |
| train/                  |              |
|    approx_kl            | 46.484253    |
|    clip_fraction        | 0.586        |
|    clip_range           | 0.2          |
|    entropy_loss         | -128         |
|    explained_variance   | 0.0172       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.23        |
|    n_updates            | 6830         |
|    policy_gradient_loss | 0.0424       |
|    reward               | 6.699648e-05 |
|    std                  | 23.9         |
|    value_loss           | 3.44e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 310, ResetDay: 1990,Episode: 835
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 685           |
|    time_elapsed         | 15510         |
|    total_timesteps      | 1402880       |
| train/                  |               |
|    approx_kl            | 45.88901      |
|    clip_fraction        | 0.592         |
|    clip_range           | 0.2           |
|    entropy_loss         | -128          |
|    explained_variance   | -0.11         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.26         |
|    n_updates            | 6840          |
|    policy_gradient_loss | 0.0487        |
|    reward               | 8.9821246e-05 |
|    std                  | 24            |
|    value_loss           | 3.83e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 1990, episode: 835
begin_total_asset: 200.00
end_total_asset: 209.77
total_reward: 9.77
total_cost: 2.75
total_trades: 47039
Sharpe: 0.153
=================================
Reseting Environment StartDay: 2102, ResetDay: 3782,Episode: 836
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 686            |
|    time_elapsed         | 15533          |
|    total_timesteps      | 1404928        |
| train/                  |                |
|    approx_kl            | 46.02021       |
|    clip_fraction        | 0.617          |
|    clip_range           | 0.2            |
|    entropy_loss         | -128           |
|    explained_variance   | -0.0764        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.25          |
|    n_updates            | 6850           |
|    policy_gradient_loss | 0.0553         |
|    reward               | -0.00013300285 |
|    std                  | 24.1           |
|    value_loss           | 4.17e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 861, ResetDay: 2541,Episode: 837
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 687          |
|    time_elapsed         | 15555        |
|    total_timesteps      | 1406976      |
| train/                  |              |
|    approx_kl            | 46.739265    |
|    clip_fraction        | 0.583        |
|    clip_range           | 0.2          |
|    entropy_loss         | -128         |
|    explained_variance   | 0.0149       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.26        |
|    n_updates            | 6860         |
|    policy_gradient_loss | 0.0376       |
|    reward               | 6.991844e-05 |
|    std                  | 24.2         |
|    value_loss           | 5.89e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1730, ResetDay: 3410,Episode: 838
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2666, ResetDay: 4346,Episode: 839
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 688           |
|    time_elapsed         | 15578         |
|    total_timesteps      | 1409024       |
| train/                  |               |
|    approx_kl            | 48.574593     |
|    clip_fraction        | 0.607         |
|    clip_range           | 0.2           |
|    entropy_loss         | -128          |
|    explained_variance   | -0.0495       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.22         |
|    n_updates            | 6870          |
|    policy_gradient_loss | 0.0491        |
|    reward               | -9.164524e-05 |
|    std                  | 24.3          |
|    value_loss           | 1.03e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 804, ResetDay: 2484,Episode: 840
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 689           |
|    time_elapsed         | 15600         |
|    total_timesteps      | 1411072       |
| train/                  |               |
|    approx_kl            | 47.735847     |
|    clip_fraction        | 0.585         |
|    clip_range           | 0.2           |
|    entropy_loss         | -128          |
|    explained_variance   | -0.301        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.19         |
|    n_updates            | 6880          |
|    policy_gradient_loss | 0.0442        |
|    reward               | -0.0001291155 |
|    std                  | 24.4          |
|    value_loss           | 3.63e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2484, episode: 840
begin_total_asset: 200.00
end_total_asset: 163.06
total_reward: -36.94
total_cost: 2.97
total_trades: 47028
Sharpe: 0.121
=================================
Reseting Environment StartDay: 1001, ResetDay: 2681,Episode: 841
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 690          |
|    time_elapsed         | 15623        |
|    total_timesteps      | 1413120      |
| train/                  |              |
|    approx_kl            | 48.080986    |
|    clip_fraction        | 0.593        |
|    clip_range           | 0.2          |
|    entropy_loss         | -128         |
|    explained_variance   | -0.089       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.22        |
|    n_updates            | 6890         |
|    policy_gradient_loss | 0.0494       |
|    reward               | 9.057636e-05 |
|    std                  | 24.5         |
|    value_loss           | 5.27e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2458, ResetDay: 4138,Episode: 842
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 691           |
|    time_elapsed         | 15645         |
|    total_timesteps      | 1415168       |
| train/                  |               |
|    approx_kl            | 48.192863     |
|    clip_fraction        | 0.591         |
|    clip_range           | 0.2           |
|    entropy_loss         | -129          |
|    explained_variance   | -0.481        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.21         |
|    n_updates            | 6900          |
|    policy_gradient_loss | 0.0548        |
|    reward               | 0.00043597296 |
|    std                  | 24.6          |
|    value_loss           | 3.21e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2393, ResetDay: 4073,Episode: 843
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2436, ResetDay: 4116,Episode: 844
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 692           |
|    time_elapsed         | 15668         |
|    total_timesteps      | 1417216       |
| train/                  |               |
|    approx_kl            | 48.93641      |
|    clip_fraction        | 0.578         |
|    clip_range           | 0.2           |
|    entropy_loss         | -129          |
|    explained_variance   | -0.00237      |
|    learning_rate        | 0.00025       |
|    loss                 | -1.23         |
|    n_updates            | 6910          |
|    policy_gradient_loss | 0.0388        |
|    reward               | 0.00015058708 |
|    std                  | 24.7          |
|    value_loss           | 6.45e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2751, ResetDay: 4431,Episode: 845
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 693           |
|    time_elapsed         | 15691         |
|    total_timesteps      | 1419264       |
| train/                  |               |
|    approx_kl            | 50.71415      |
|    clip_fraction        | 0.573         |
|    clip_range           | 0.2           |
|    entropy_loss         | -129          |
|    explained_variance   | -0.053        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.25         |
|    n_updates            | 6920          |
|    policy_gradient_loss | 0.0518        |
|    reward               | 2.3680115e-05 |
|    std                  | 24.8          |
|    value_loss           | 7.48e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4431, episode: 845
begin_total_asset: 200.00
end_total_asset: 189.28
total_reward: -10.72
total_cost: 1.85
total_trades: 47025
Sharpe: 0.087
=================================
Reseting Environment StartDay: 318, ResetDay: 1998,Episode: 846
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 694           |
|    time_elapsed         | 15713         |
|    total_timesteps      | 1421312       |
| train/                  |               |
|    approx_kl            | 49.360916     |
|    clip_fraction        | 0.597         |
|    clip_range           | 0.2           |
|    entropy_loss         | -129          |
|    explained_variance   | 0.0531        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.21         |
|    n_updates            | 6930          |
|    policy_gradient_loss | 0.0552        |
|    reward               | -3.849802e-05 |
|    std                  | 24.9          |
|    value_loss           | 8.85e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1405, ResetDay: 3085,Episode: 847
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 695            |
|    time_elapsed         | 15736          |
|    total_timesteps      | 1423360        |
| train/                  |                |
|    approx_kl            | 50.422703      |
|    clip_fraction        | 0.59           |
|    clip_range           | 0.2            |
|    entropy_loss         | -129           |
|    explained_variance   | -0.638         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.27          |
|    n_updates            | 6940           |
|    policy_gradient_loss | 0.0487         |
|    reward               | -0.00019006652 |
|    std                  | 25             |
|    value_loss           | 3.97e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 372, ResetDay: 2052,Episode: 848
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 696           |
|    time_elapsed         | 15758         |
|    total_timesteps      | 1425408       |
| train/                  |               |
|    approx_kl            | 50.159195     |
|    clip_fraction        | 0.583         |
|    clip_range           | 0.2           |
|    entropy_loss         | -129          |
|    explained_variance   | -0.144        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.2          |
|    n_updates            | 6950          |
|    policy_gradient_loss | 0.0577        |
|    reward               | 0.00018569813 |
|    std                  | 25.1          |
|    value_loss           | 3.19e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1584, ResetDay: 3264,Episode: 849
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2055, ResetDay: 3735,Episode: 850
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 697           |
|    time_elapsed         | 15781         |
|    total_timesteps      | 1427456       |
| train/                  |               |
|    approx_kl            | 50.716896     |
|    clip_fraction        | 0.598         |
|    clip_range           | 0.2           |
|    entropy_loss         | -129          |
|    explained_variance   | -0.0435       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.22         |
|    n_updates            | 6960          |
|    policy_gradient_loss | 0.0467        |
|    reward               | 9.6380616e-05 |
|    std                  | 25.2          |
|    value_loss           | 5.28e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3735, episode: 850
begin_total_asset: 200.00
end_total_asset: 261.39
total_reward: 61.39
total_cost: 3.95
total_trades: 47015
Sharpe: 0.308
=================================
Reseting Environment StartDay: 1481, ResetDay: 3161,Episode: 851
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 698           |
|    time_elapsed         | 15803         |
|    total_timesteps      | 1429504       |
| train/                  |               |
|    approx_kl            | 51.909447     |
|    clip_fraction        | 0.583         |
|    clip_range           | 0.2           |
|    entropy_loss         | -129          |
|    explained_variance   | 0.0165        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.26         |
|    n_updates            | 6970          |
|    policy_gradient_loss | 0.049         |
|    reward               | -6.793613e-05 |
|    std                  | 25.3          |
|    value_loss           | 6.09e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 948, ResetDay: 2628,Episode: 852
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 699           |
|    time_elapsed         | 15826         |
|    total_timesteps      | 1431552       |
| train/                  |               |
|    approx_kl            | 51.267487     |
|    clip_fraction        | 0.597         |
|    clip_range           | 0.2           |
|    entropy_loss         | -129          |
|    explained_variance   | -0.0632       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.27         |
|    n_updates            | 6980          |
|    policy_gradient_loss | 0.0381        |
|    reward               | 7.0814895e-05 |
|    std                  | 25.4          |
|    value_loss           | 5.14e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 280, ResetDay: 1960,Episode: 853
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 700          |
|    time_elapsed         | 15848        |
|    total_timesteps      | 1433600      |
| train/                  |              |
|    approx_kl            | 52.48663     |
|    clip_fraction        | 0.58         |
|    clip_range           | 0.2          |
|    entropy_loss         | -130         |
|    explained_variance   | -0.225       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.28        |
|    n_updates            | 6990         |
|    policy_gradient_loss | 0.0469       |
|    reward               | 0.0002960741 |
|    std                  | 25.5         |
|    value_loss           | 2.54e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 811, ResetDay: 2491,Episode: 854
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 26, ResetDay: 1706,Episode: 855
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 701          |
|    time_elapsed         | 15871        |
|    total_timesteps      | 1435648      |
| train/                  |              |
|    approx_kl            | 51.603397    |
|    clip_fraction        | 0.575        |
|    clip_range           | 0.2          |
|    entropy_loss         | -130         |
|    explained_variance   | -0.0251      |
|    learning_rate        | 0.00025      |
|    loss                 | -1.33        |
|    n_updates            | 7000         |
|    policy_gradient_loss | 0.0385       |
|    reward               | -9.34174e-06 |
|    std                  | 25.6         |
|    value_loss           | 4.63e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 1706, episode: 855
begin_total_asset: 200.00
end_total_asset: 103.09
total_reward: -96.91
total_cost: 2.42
total_trades: 47023
Sharpe: -0.052
=================================
Reseting Environment StartDay: 1549, ResetDay: 3229,Episode: 856
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 702           |
|    time_elapsed         | 15893         |
|    total_timesteps      | 1437696       |
| train/                  |               |
|    approx_kl            | 52.965794     |
|    clip_fraction        | 0.591         |
|    clip_range           | 0.2           |
|    entropy_loss         | -130          |
|    explained_variance   | -0.0252       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.17         |
|    n_updates            | 7010          |
|    policy_gradient_loss | 0.0495        |
|    reward               | 0.00036179513 |
|    std                  | 25.7          |
|    value_loss           | 7.9e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2251, ResetDay: 3931,Episode: 857
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 703           |
|    time_elapsed         | 15916         |
|    total_timesteps      | 1439744       |
| train/                  |               |
|    approx_kl            | 52.90827      |
|    clip_fraction        | 0.581         |
|    clip_range           | 0.2           |
|    entropy_loss         | -130          |
|    explained_variance   | -0.46         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.26         |
|    n_updates            | 7020          |
|    policy_gradient_loss | 0.046         |
|    reward               | 2.9851151e-05 |
|    std                  | 25.8          |
|    value_loss           | 4.47e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1503, ResetDay: 3183,Episode: 858
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 704          |
|    time_elapsed         | 15938        |
|    total_timesteps      | 1441792      |
| train/                  |              |
|    approx_kl            | 52.847378    |
|    clip_fraction        | 0.573        |
|    clip_range           | 0.2          |
|    entropy_loss         | -130         |
|    explained_variance   | 0.0343       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.28        |
|    n_updates            | 7030         |
|    policy_gradient_loss | 0.0428       |
|    reward               | 0.0003221327 |
|    std                  | 25.8         |
|    value_loss           | 1.3e-06      |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2803, ResetDay: 4483,Episode: 859
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 705            |
|    time_elapsed         | 15961          |
|    total_timesteps      | 1443840        |
| train/                  |                |
|    approx_kl            | 53.61137       |
|    clip_fraction        | 0.586          |
|    clip_range           | 0.2            |
|    entropy_loss         | -130           |
|    explained_variance   | -0.0263        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.28          |
|    n_updates            | 7040           |
|    policy_gradient_loss | 0.0423         |
|    reward               | -0.00011857872 |
|    std                  | 25.9           |
|    value_loss           | 7.75e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 597, ResetDay: 2277,Episode: 860
Environment reached Terminal state as number of trading days reached limit!!
day: 2277, episode: 860
begin_total_asset: 200.00
end_total_asset: 190.85
total_reward: -9.15
total_cost: 3.03
total_trades: 47026
Sharpe: 0.201
=================================
Reseting Environment StartDay: 1257, ResetDay: 2937,Episode: 861
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 706            |
|    time_elapsed         | 15983          |
|    total_timesteps      | 1445888        |
| train/                  |                |
|    approx_kl            | 53.812943      |
|    clip_fraction        | 0.564          |
|    clip_range           | 0.2            |
|    entropy_loss         | -130           |
|    explained_variance   | 0.0197         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.29          |
|    n_updates            | 7050           |
|    policy_gradient_loss | 0.034          |
|    reward               | -0.00025250044 |
|    std                  | 26.1           |
|    value_loss           | 9.56e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 744, ResetDay: 2424,Episode: 862
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 707            |
|    time_elapsed         | 16006          |
|    total_timesteps      | 1447936        |
| train/                  |                |
|    approx_kl            | 56.060204      |
|    clip_fraction        | 0.569          |
|    clip_range           | 0.2            |
|    entropy_loss         | -130           |
|    explained_variance   | -0.649         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.28          |
|    n_updates            | 7060           |
|    policy_gradient_loss | 0.0345         |
|    reward               | -0.00022815156 |
|    std                  | 26.2           |
|    value_loss           | 6.13e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1769, ResetDay: 3449,Episode: 863
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 708           |
|    time_elapsed         | 16028         |
|    total_timesteps      | 1449984       |
| train/                  |               |
|    approx_kl            | 54.806778     |
|    clip_fraction        | 0.567         |
|    clip_range           | 0.2           |
|    entropy_loss         | -130          |
|    explained_variance   | 0.0904        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.27         |
|    n_updates            | 7070          |
|    policy_gradient_loss | 0.0412        |
|    reward               | -0.0003176071 |
|    std                  | 26.2          |
|    value_loss           | 4.14e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2466, ResetDay: 4146,Episode: 864
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 709          |
|    time_elapsed         | 16051        |
|    total_timesteps      | 1452032      |
| train/                  |              |
|    approx_kl            | 54.58548     |
|    clip_fraction        | 0.561        |
|    clip_range           | 0.2          |
|    entropy_loss         | -130         |
|    explained_variance   | 0.113        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.25        |
|    n_updates            | 7080         |
|    policy_gradient_loss | 0.0347       |
|    reward               | 0.0006417053 |
|    std                  | 26.3         |
|    value_loss           | 3.98e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 105, ResetDay: 1785,Episode: 865
Environment reached Terminal state as number of trading days reached limit!!
day: 1785, episode: 865
begin_total_asset: 200.00
end_total_asset: 227.01
total_reward: 27.01
total_cost: 4.11
total_trades: 47023
Sharpe: 0.304
=================================
Reseting Environment StartDay: 2142, ResetDay: 3822,Episode: 866
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 710           |
|    time_elapsed         | 16074         |
|    total_timesteps      | 1454080       |
| train/                  |               |
|    approx_kl            | 54.744972     |
|    clip_fraction        | 0.581         |
|    clip_range           | 0.2           |
|    entropy_loss         | -130          |
|    explained_variance   | -0.0484       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.23         |
|    n_updates            | 7090          |
|    policy_gradient_loss | 0.0517        |
|    reward               | 0.00015038624 |
|    std                  | 26.4          |
|    value_loss           | 4.14e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 418, ResetDay: 2098,Episode: 867
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 711           |
|    time_elapsed         | 16096         |
|    total_timesteps      | 1456128       |
| train/                  |               |
|    approx_kl            | 56.234814     |
|    clip_fraction        | 0.56          |
|    clip_range           | 0.2           |
|    entropy_loss         | -131          |
|    explained_variance   | -0.265        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.26         |
|    n_updates            | 7100          |
|    policy_gradient_loss | 0.0345        |
|    reward               | 0.00035631293 |
|    std                  | 26.5          |
|    value_loss           | 9.05e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1829, ResetDay: 3509,Episode: 868
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 712            |
|    time_elapsed         | 16119          |
|    total_timesteps      | 1458176        |
| train/                  |                |
|    approx_kl            | 56.216103      |
|    clip_fraction        | 0.567          |
|    clip_range           | 0.2            |
|    entropy_loss         | -131           |
|    explained_variance   | -0.0492        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.28          |
|    n_updates            | 7110           |
|    policy_gradient_loss | 0.034          |
|    reward               | -0.00082869147 |
|    std                  | 26.6           |
|    value_loss           | 1.6e-06        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1996, ResetDay: 3676,Episode: 869
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 713           |
|    time_elapsed         | 16141         |
|    total_timesteps      | 1460224       |
| train/                  |               |
|    approx_kl            | 55.976162     |
|    clip_fraction        | 0.577         |
|    clip_range           | 0.2           |
|    entropy_loss         | -131          |
|    explained_variance   | -0.401        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.25         |
|    n_updates            | 7120          |
|    policy_gradient_loss | 0.0429        |
|    reward               | -0.0003504076 |
|    std                  | 26.8          |
|    value_loss           | 5.46e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 965, ResetDay: 2645,Episode: 870
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 714            |
|    time_elapsed         | 16164          |
|    total_timesteps      | 1462272        |
| train/                  |                |
|    approx_kl            | 57.234573      |
|    clip_fraction        | 0.576          |
|    clip_range           | 0.2            |
|    entropy_loss         | -131           |
|    explained_variance   | -0.0199        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.29          |
|    n_updates            | 7130           |
|    policy_gradient_loss | 0.0396         |
|    reward               | -0.00027767924 |
|    std                  | 26.9           |
|    value_loss           | 5.39e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2645, episode: 870
begin_total_asset: 200.00
end_total_asset: 322.98
total_reward: 122.98
total_cost: 4.86
total_trades: 47010
Sharpe: 0.451
=================================
Reseting Environment StartDay: 1879, ResetDay: 3559,Episode: 871
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1309, ResetDay: 2989,Episode: 872
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 715           |
|    time_elapsed         | 16187         |
|    total_timesteps      | 1464320       |
| train/                  |               |
|    approx_kl            | 57.608295     |
|    clip_fraction        | 0.589         |
|    clip_range           | 0.2           |
|    entropy_loss         | -131          |
|    explained_variance   | -0.122        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.28         |
|    n_updates            | 7140          |
|    policy_gradient_loss | 0.0601        |
|    reward               | -7.891846e-06 |
|    std                  | 27            |
|    value_loss           | 5.4e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 537, ResetDay: 2217,Episode: 873
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 716            |
|    time_elapsed         | 16209          |
|    total_timesteps      | 1466368        |
| train/                  |                |
|    approx_kl            | 57.15361       |
|    clip_fraction        | 0.568          |
|    clip_range           | 0.2            |
|    entropy_loss         | -131           |
|    explained_variance   | 0.00568        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.29          |
|    n_updates            | 7150           |
|    policy_gradient_loss | 0.0353         |
|    reward               | -0.00024318819 |
|    std                  | 27.2           |
|    value_loss           | 5.22e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2263, ResetDay: 3943,Episode: 874
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 717           |
|    time_elapsed         | 16231         |
|    total_timesteps      | 1468416       |
| train/                  |               |
|    approx_kl            | 58.213318     |
|    clip_fraction        | 0.56          |
|    clip_range           | 0.2           |
|    entropy_loss         | -131          |
|    explained_variance   | -0.0838       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.29         |
|    n_updates            | 7160          |
|    policy_gradient_loss | 0.0495        |
|    reward               | 5.9798433e-05 |
|    std                  | 27.3          |
|    value_loss           | 3.87e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 687, ResetDay: 2367,Episode: 875
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 718          |
|    time_elapsed         | 16254        |
|    total_timesteps      | 1470464      |
| train/                  |              |
|    approx_kl            | 58.3878      |
|    clip_fraction        | 0.559        |
|    clip_range           | 0.2          |
|    entropy_loss         | -131         |
|    explained_variance   | 0.107        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.26        |
|    n_updates            | 7170         |
|    policy_gradient_loss | 0.0583       |
|    reward               | 6.580295e-05 |
|    std                  | 27.3         |
|    value_loss           | 4.03e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2367, episode: 875
begin_total_asset: 200.00
end_total_asset: 162.40
total_reward: -37.60
total_cost: 2.99
total_trades: 47011
Sharpe: 0.133
=================================
Reseting Environment StartDay: 970, ResetDay: 2650,Episode: 876
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 719           |
|    time_elapsed         | 16277         |
|    total_timesteps      | 1472512       |
| train/                  |               |
|    approx_kl            | 58.91464      |
|    clip_fraction        | 0.55          |
|    clip_range           | 0.2           |
|    entropy_loss         | -132          |
|    explained_variance   | -0.0688       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.3          |
|    n_updates            | 7180          |
|    policy_gradient_loss | 0.0397        |
|    reward               | 0.00052982103 |
|    std                  | 27.5          |
|    value_loss           | 9.02e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 250, ResetDay: 1930,Episode: 877
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 824, ResetDay: 2504,Episode: 878
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 720           |
|    time_elapsed         | 16299         |
|    total_timesteps      | 1474560       |
| train/                  |               |
|    approx_kl            | 59.147346     |
|    clip_fraction        | 0.578         |
|    clip_range           | 0.2           |
|    entropy_loss         | -132          |
|    explained_variance   | -0.0607       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.27         |
|    n_updates            | 7190          |
|    policy_gradient_loss | 0.0321        |
|    reward               | -0.0002179554 |
|    std                  | 27.6          |
|    value_loss           | 3.75e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2118, ResetDay: 3798,Episode: 879
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 721            |
|    time_elapsed         | 16322          |
|    total_timesteps      | 1476608        |
| train/                  |                |
|    approx_kl            | 60.305466      |
|    clip_fraction        | 0.544          |
|    clip_range           | 0.2            |
|    entropy_loss         | -132           |
|    explained_variance   | -0.155         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.32          |
|    n_updates            | 7200           |
|    policy_gradient_loss | 0.0378         |
|    reward               | -1.9937515e-06 |
|    std                  | 27.6           |
|    value_loss           | 5.49e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 799, ResetDay: 2479,Episode: 880
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 722           |
|    time_elapsed         | 16344         |
|    total_timesteps      | 1478656       |
| train/                  |               |
|    approx_kl            | 60.704597     |
|    clip_fraction        | 0.564         |
|    clip_range           | 0.2           |
|    entropy_loss         | -132          |
|    explained_variance   | -0.0549       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.29         |
|    n_updates            | 7210          |
|    policy_gradient_loss | 0.046         |
|    reward               | 0.00032487937 |
|    std                  | 27.7          |
|    value_loss           | 5.9e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2479, episode: 880
begin_total_asset: 200.00
end_total_asset: 354.66
total_reward: 154.66
total_cost: 6.80
total_trades: 46998
Sharpe: 0.468
=================================
Reseting Environment StartDay: 2142, ResetDay: 3822,Episode: 881
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 723            |
|    time_elapsed         | 16367          |
|    total_timesteps      | 1480704        |
| train/                  |                |
|    approx_kl            | 60.492905      |
|    clip_fraction        | 0.54           |
|    clip_range           | 0.2            |
|    entropy_loss         | -132           |
|    explained_variance   | -0.1           |
|    learning_rate        | 0.00025        |
|    loss                 | -1.29          |
|    n_updates            | 7220           |
|    policy_gradient_loss | 0.048          |
|    reward               | -2.7947997e-05 |
|    std                  | 27.8           |
|    value_loss           | 7.96e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 428, ResetDay: 2108,Episode: 882
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2774, ResetDay: 4454,Episode: 883
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 724           |
|    time_elapsed         | 16389         |
|    total_timesteps      | 1482752       |
| train/                  |               |
|    approx_kl            | 60.90744      |
|    clip_fraction        | 0.556         |
|    clip_range           | 0.2           |
|    entropy_loss         | -132          |
|    explained_variance   | -0.103        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.29         |
|    n_updates            | 7230          |
|    policy_gradient_loss | 0.0357        |
|    reward               | -2.658558e-05 |
|    std                  | 27.8          |
|    value_loss           | 6.73e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 175, ResetDay: 1855,Episode: 884
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 725            |
|    time_elapsed         | 16412          |
|    total_timesteps      | 1484800        |
| train/                  |                |
|    approx_kl            | 60.43097       |
|    clip_fraction        | 0.569          |
|    clip_range           | 0.2            |
|    entropy_loss         | -132           |
|    explained_variance   | -0.135         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.29          |
|    n_updates            | 7240           |
|    policy_gradient_loss | 0.0394         |
|    reward               | -0.00026857996 |
|    std                  | 27.9           |
|    value_loss           | 1.04e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1504, ResetDay: 3184,Episode: 885
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 726           |
|    time_elapsed         | 16434         |
|    total_timesteps      | 1486848       |
| train/                  |               |
|    approx_kl            | 60.91519      |
|    clip_fraction        | 0.525         |
|    clip_range           | 0.2           |
|    entropy_loss         | -132          |
|    explained_variance   | -0.0496       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.29         |
|    n_updates            | 7250          |
|    policy_gradient_loss | 0.0398        |
|    reward               | 0.00057624915 |
|    std                  | 28.1          |
|    value_loss           | 1.71e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3184, episode: 885
begin_total_asset: 200.00
end_total_asset: 457.74
total_reward: 257.74
total_cost: 6.64
total_trades: 46996
Sharpe: 0.748
=================================
Reseting Environment StartDay: 2018, ResetDay: 3698,Episode: 886
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 727            |
|    time_elapsed         | 16457          |
|    total_timesteps      | 1488896        |
| train/                  |                |
|    approx_kl            | 62.14793       |
|    clip_fraction        | 0.558          |
|    clip_range           | 0.2            |
|    entropy_loss         | -132           |
|    explained_variance   | -0.571         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.29          |
|    n_updates            | 7260           |
|    policy_gradient_loss | 0.0333         |
|    reward               | 0.000107356645 |
|    std                  | 28.1           |
|    value_loss           | 3.58e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1704, ResetDay: 3384,Episode: 887
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 728           |
|    time_elapsed         | 16480         |
|    total_timesteps      | 1490944       |
| train/                  |               |
|    approx_kl            | 62.494865     |
|    clip_fraction        | 0.556         |
|    clip_range           | 0.2           |
|    entropy_loss         | -132          |
|    explained_variance   | 0.0169        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.3          |
|    n_updates            | 7270          |
|    policy_gradient_loss | 0.0277        |
|    reward               | 0.00022330017 |
|    std                  | 28.2          |
|    value_loss           | 6.44e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2254, ResetDay: 3934,Episode: 888
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1435, ResetDay: 3115,Episode: 889
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 729            |
|    time_elapsed         | 16503          |
|    total_timesteps      | 1492992        |
| train/                  |                |
|    approx_kl            | 62.88446       |
|    clip_fraction        | 0.548          |
|    clip_range           | 0.2            |
|    entropy_loss         | -132           |
|    explained_variance   | 0.0257         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.27          |
|    n_updates            | 7280           |
|    policy_gradient_loss | 0.0456         |
|    reward               | -4.3541146e-05 |
|    std                  | 28.3           |
|    value_loss           | 1.11e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1077, ResetDay: 2757,Episode: 890
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 730           |
|    time_elapsed         | 16525         |
|    total_timesteps      | 1495040       |
| train/                  |               |
|    approx_kl            | 63.164013     |
|    clip_fraction        | 0.563         |
|    clip_range           | 0.2           |
|    entropy_loss         | -132          |
|    explained_variance   | -0.0107       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.3          |
|    n_updates            | 7290          |
|    policy_gradient_loss | 0.0454        |
|    reward               | -9.665203e-06 |
|    std                  | 28.4          |
|    value_loss           | 7.84e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2757, episode: 890
begin_total_asset: 200.00
end_total_asset: 206.05
total_reward: 6.05
total_cost: 2.67
total_trades: 46999
Sharpe: 0.233
=================================
Reseting Environment StartDay: 2307, ResetDay: 3987,Episode: 891
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 731            |
|    time_elapsed         | 16547          |
|    total_timesteps      | 1497088        |
| train/                  |                |
|    approx_kl            | 61.766792      |
|    clip_fraction        | 0.542          |
|    clip_range           | 0.2            |
|    entropy_loss         | -133           |
|    explained_variance   | -0.192         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.32          |
|    n_updates            | 7300           |
|    policy_gradient_loss | 0.0315         |
|    reward               | -0.00016653175 |
|    std                  | 28.6           |
|    value_loss           | 2.81e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1922, ResetDay: 3602,Episode: 892
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 732            |
|    time_elapsed         | 16570          |
|    total_timesteps      | 1499136        |
| train/                  |                |
|    approx_kl            | 63.545223      |
|    clip_fraction        | 0.538          |
|    clip_range           | 0.2            |
|    entropy_loss         | -133           |
|    explained_variance   | 0.0893         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.33          |
|    n_updates            | 7310           |
|    policy_gradient_loss | 0.0392         |
|    reward               | -0.00013976441 |
|    std                  | 28.7           |
|    value_loss           | 3.25e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2320, ResetDay: 4000,Episode: 893
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 633, ResetDay: 2313,Episode: 894
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 733          |
|    time_elapsed         | 16592        |
|    total_timesteps      | 1501184      |
| train/                  |              |
|    approx_kl            | 64.7812      |
|    clip_fraction        | 0.533        |
|    clip_range           | 0.2          |
|    entropy_loss         | -133         |
|    explained_variance   | 0.0277       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.28        |
|    n_updates            | 7320         |
|    policy_gradient_loss | 0.0264       |
|    reward               | 4.565358e-05 |
|    std                  | 28.9         |
|    value_loss           | 9.38e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1565, ResetDay: 3245,Episode: 895
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 734            |
|    time_elapsed         | 16615          |
|    total_timesteps      | 1503232        |
| train/                  |                |
|    approx_kl            | 64.97497       |
|    clip_fraction        | 0.535          |
|    clip_range           | 0.2            |
|    entropy_loss         | -133           |
|    explained_variance   | 0.0494         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.33          |
|    n_updates            | 7330           |
|    policy_gradient_loss | 0.033          |
|    reward               | -0.00010932179 |
|    std                  | 29             |
|    value_loss           | 1.14e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3245, episode: 895
begin_total_asset: 200.00
end_total_asset: 327.08
total_reward: 127.08
total_cost: 5.59
total_trades: 46993
Sharpe: 0.455
=================================
Reseting Environment StartDay: 145, ResetDay: 1825,Episode: 896
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 735            |
|    time_elapsed         | 16638          |
|    total_timesteps      | 1505280        |
| train/                  |                |
|    approx_kl            | 64.85225       |
|    clip_fraction        | 0.547          |
|    clip_range           | 0.2            |
|    entropy_loss         | -133           |
|    explained_variance   | -0.744         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.3           |
|    n_updates            | 7340           |
|    policy_gradient_loss | 0.0342         |
|    reward               | -0.00014601307 |
|    std                  | 29.1           |
|    value_loss           | 3.38e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2771, ResetDay: 4451,Episode: 897
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 736            |
|    time_elapsed         | 16660          |
|    total_timesteps      | 1507328        |
| train/                  |                |
|    approx_kl            | 64.881004      |
|    clip_fraction        | 0.559          |
|    clip_range           | 0.2            |
|    entropy_loss         | -133           |
|    explained_variance   | -0.169         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.3           |
|    n_updates            | 7350           |
|    policy_gradient_loss | 0.0401         |
|    reward               | -0.00012511901 |
|    std                  | 29.2           |
|    value_loss           | 4.91e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 895, ResetDay: 2575,Episode: 898
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 737           |
|    time_elapsed         | 16683         |
|    total_timesteps      | 1509376       |
| train/                  |               |
|    approx_kl            | 65.67723      |
|    clip_fraction        | 0.536         |
|    clip_range           | 0.2           |
|    entropy_loss         | -133          |
|    explained_variance   | -0.0141       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.29         |
|    n_updates            | 7360          |
|    policy_gradient_loss | 0.0344        |
|    reward               | 0.00044816532 |
|    std                  | 29.3          |
|    value_loss           | 1.36e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1266, ResetDay: 2946,Episode: 899
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 503, ResetDay: 2183,Episode: 900
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 738            |
|    time_elapsed         | 16705          |
|    total_timesteps      | 1511424        |
| train/                  |                |
|    approx_kl            | 67.89442       |
|    clip_fraction        | 0.544          |
|    clip_range           | 0.2            |
|    entropy_loss         | -133           |
|    explained_variance   | -0.224         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.34          |
|    n_updates            | 7370           |
|    policy_gradient_loss | 0.0493         |
|    reward               | -3.1765794e-05 |
|    std                  | 29.4           |
|    value_loss           | 1.18e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2183, episode: 900
begin_total_asset: 200.00
end_total_asset: 220.76
total_reward: 20.76
total_cost: 3.82
total_trades: 46983
Sharpe: 0.228
=================================
Reseting Environment StartDay: 1086, ResetDay: 2766,Episode: 901
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 739           |
|    time_elapsed         | 16728         |
|    total_timesteps      | 1513472       |
| train/                  |               |
|    approx_kl            | 66.88926      |
|    clip_fraction        | 0.546         |
|    clip_range           | 0.2           |
|    entropy_loss         | -134          |
|    explained_variance   | -0.163        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.29         |
|    n_updates            | 7380          |
|    policy_gradient_loss | 0.0515        |
|    reward               | 0.00025961924 |
|    std                  | 29.5          |
|    value_loss           | 4.99e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2502, ResetDay: 4182,Episode: 902
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 740           |
|    time_elapsed         | 16751         |
|    total_timesteps      | 1515520       |
| train/                  |               |
|    approx_kl            | 66.65347      |
|    clip_fraction        | 0.548         |
|    clip_range           | 0.2           |
|    entropy_loss         | -134          |
|    explained_variance   | -0.0149       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.29         |
|    n_updates            | 7390          |
|    policy_gradient_loss | 0.0376        |
|    reward               | -0.0001424572 |
|    std                  | 29.5          |
|    value_loss           | 4.95e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 202, ResetDay: 1882,Episode: 903
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 741            |
|    time_elapsed         | 16774          |
|    total_timesteps      | 1517568        |
| train/                  |                |
|    approx_kl            | 66.38078       |
|    clip_fraction        | 0.534          |
|    clip_range           | 0.2            |
|    entropy_loss         | -134           |
|    explained_variance   | -0.112         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.31          |
|    n_updates            | 7400           |
|    policy_gradient_loss | 0.0419         |
|    reward               | -2.6215172e-05 |
|    std                  | 29.7           |
|    value_loss           | 7.56e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2401, ResetDay: 4081,Episode: 904
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 742            |
|    time_elapsed         | 16796          |
|    total_timesteps      | 1519616        |
| train/                  |                |
|    approx_kl            | 68.79825       |
|    clip_fraction        | 0.575          |
|    clip_range           | 0.2            |
|    entropy_loss         | -134           |
|    explained_variance   | -0.16          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.31          |
|    n_updates            | 7410           |
|    policy_gradient_loss | 0.0374         |
|    reward               | -0.00021264076 |
|    std                  | 29.8           |
|    value_loss           | 9.55e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2293, ResetDay: 3973,Episode: 905
Environment reached Terminal state as number of trading days reached limit!!
day: 3973, episode: 905
begin_total_asset: 200.00
end_total_asset: 259.39
total_reward: 59.39
total_cost: 7.19
total_trades: 46976
Sharpe: 0.289
=================================
Reseting Environment StartDay: 2594, ResetDay: 4274,Episode: 906
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 743           |
|    time_elapsed         | 16819         |
|    total_timesteps      | 1521664       |
| train/                  |               |
|    approx_kl            | 68.43309      |
|    clip_fraction        | 0.541         |
|    clip_range           | 0.2           |
|    entropy_loss         | -134          |
|    explained_variance   | 0.0717        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.31         |
|    n_updates            | 7420          |
|    policy_gradient_loss | 0.0374        |
|    reward               | -9.388733e-05 |
|    std                  | 29.9          |
|    value_loss           | 1.57e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1533, ResetDay: 3213,Episode: 907
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 744           |
|    time_elapsed         | 16841         |
|    total_timesteps      | 1523712       |
| train/                  |               |
|    approx_kl            | 70.44953      |
|    clip_fraction        | 0.568         |
|    clip_range           | 0.2           |
|    entropy_loss         | -134          |
|    explained_variance   | 0.0296        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.33         |
|    n_updates            | 7430          |
|    policy_gradient_loss | 0.0381        |
|    reward               | -4.964447e-06 |
|    std                  | 30.1          |
|    value_loss           | 6.71e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1278, ResetDay: 2958,Episode: 908
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 745            |
|    time_elapsed         | 16864          |
|    total_timesteps      | 1525760        |
| train/                  |                |
|    approx_kl            | 69.76016       |
|    clip_fraction        | 0.545          |
|    clip_range           | 0.2            |
|    entropy_loss         | -134           |
|    explained_variance   | -0.0238        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.31          |
|    n_updates            | 7440           |
|    policy_gradient_loss | 0.0302         |
|    reward               | -8.3568575e-06 |
|    std                  | 30.2           |
|    value_loss           | 1e-06          |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1399, ResetDay: 3079,Episode: 909
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 746           |
|    time_elapsed         | 16886         |
|    total_timesteps      | 1527808       |
| train/                  |               |
|    approx_kl            | 71.5648       |
|    clip_fraction        | 0.553         |
|    clip_range           | 0.2           |
|    entropy_loss         | -134          |
|    explained_variance   | -0.304        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.28         |
|    n_updates            | 7450          |
|    policy_gradient_loss | 0.0394        |
|    reward               | -7.705803e-05 |
|    std                  | 30.3          |
|    value_loss           | 3.26e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2466, ResetDay: 4146,Episode: 910
Environment reached Terminal state as number of trading days reached limit!!
day: 4146, episode: 910
begin_total_asset: 200.00
end_total_asset: 313.65
total_reward: 113.65
total_cost: 3.98
total_trades: 46960
Sharpe: 0.401
=================================
Reseting Environment StartDay: 1985, ResetDay: 3665,Episode: 911
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 747           |
|    time_elapsed         | 16909         |
|    total_timesteps      | 1529856       |
| train/                  |               |
|    approx_kl            | 71.05838      |
|    clip_fraction        | 0.532         |
|    clip_range           | 0.2           |
|    entropy_loss         | -134          |
|    explained_variance   | 0.0701        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.3          |
|    n_updates            | 7460          |
|    policy_gradient_loss | 0.0369        |
|    reward               | 0.00018687468 |
|    std                  | 30.4          |
|    value_loss           | 4.78e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2801, ResetDay: 4481,Episode: 912
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 748            |
|    time_elapsed         | 16932          |
|    total_timesteps      | 1531904        |
| train/                  |                |
|    approx_kl            | 72.05766       |
|    clip_fraction        | 0.546          |
|    clip_range           | 0.2            |
|    entropy_loss         | -134           |
|    explained_variance   | -0.00925       |
|    learning_rate        | 0.00025        |
|    loss                 | -1.32          |
|    n_updates            | 7470           |
|    policy_gradient_loss | 0.0287         |
|    reward               | -0.00022414436 |
|    std                  | 30.4           |
|    value_loss           | 9.7e-07        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1459, ResetDay: 3139,Episode: 913
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 749            |
|    time_elapsed         | 16954          |
|    total_timesteps      | 1533952        |
| train/                  |                |
|    approx_kl            | 71.345535      |
|    clip_fraction        | 0.525          |
|    clip_range           | 0.2            |
|    entropy_loss         | -134           |
|    explained_variance   | -0.177         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.34          |
|    n_updates            | 7480           |
|    policy_gradient_loss | 0.0356         |
|    reward               | -0.00024986535 |
|    std                  | 30.5           |
|    value_loss           | 3.76e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1181, ResetDay: 2861,Episode: 914
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 750           |
|    time_elapsed         | 16977         |
|    total_timesteps      | 1536000       |
| train/                  |               |
|    approx_kl            | 72.06315      |
|    clip_fraction        | 0.523         |
|    clip_range           | 0.2           |
|    entropy_loss         | -135          |
|    explained_variance   | -0.0354       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.28         |
|    n_updates            | 7490          |
|    policy_gradient_loss | 0.0432        |
|    reward               | 0.00041015548 |
|    std                  | 30.5          |
|    value_loss           | 1.04e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 982, ResetDay: 2662,Episode: 915
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 751            |
|    time_elapsed         | 16999          |
|    total_timesteps      | 1538048        |
| train/                  |                |
|    approx_kl            | 71.75353       |
|    clip_fraction        | 0.537          |
|    clip_range           | 0.2            |
|    entropy_loss         | -135           |
|    explained_variance   | -0.21          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.33          |
|    n_updates            | 7500           |
|    policy_gradient_loss | 0.0275         |
|    reward               | -4.9191283e-05 |
|    std                  | 30.6           |
|    value_loss           | 3e-07          |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2662, episode: 915
begin_total_asset: 200.00
end_total_asset: 234.71
total_reward: 34.71
total_cost: 5.79
total_trades: 46952
Sharpe: 0.254
=================================
Reseting Environment StartDay: 298, ResetDay: 1978,Episode: 916
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 538, ResetDay: 2218,Episode: 917
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 752           |
|    time_elapsed         | 17022         |
|    total_timesteps      | 1540096       |
| train/                  |               |
|    approx_kl            | 70.83298      |
|    clip_fraction        | 0.538         |
|    clip_range           | 0.2           |
|    entropy_loss         | -135          |
|    explained_variance   | -0.0243       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.34         |
|    n_updates            | 7510          |
|    policy_gradient_loss | 0.0268        |
|    reward               | 0.00017874947 |
|    std                  | 30.7          |
|    value_loss           | 3.81e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2060, ResetDay: 3740,Episode: 918
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 753          |
|    time_elapsed         | 17044        |
|    total_timesteps      | 1542144      |
| train/                  |              |
|    approx_kl            | 71.66481     |
|    clip_fraction        | 0.535        |
|    clip_range           | 0.2          |
|    entropy_loss         | -135         |
|    explained_variance   | -0.111       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.34        |
|    n_updates            | 7520         |
|    policy_gradient_loss | 0.0286       |
|    reward               | 7.389469e-05 |
|    std                  | 30.8         |
|    value_loss           | 5.8e-07      |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 288, ResetDay: 1968,Episode: 919
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 754            |
|    time_elapsed         | 17067          |
|    total_timesteps      | 1544192        |
| train/                  |                |
|    approx_kl            | 73.70491       |
|    clip_fraction        | 0.524          |
|    clip_range           | 0.2            |
|    entropy_loss         | -135           |
|    explained_variance   | -0.0368        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.3           |
|    n_updates            | 7530           |
|    policy_gradient_loss | 0.0273         |
|    reward               | -5.4218294e-06 |
|    std                  | 30.8           |
|    value_loss           | 4.24e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2125, ResetDay: 3805,Episode: 920
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 755           |
|    time_elapsed         | 17090         |
|    total_timesteps      | 1546240       |
| train/                  |               |
|    approx_kl            | 72.7932       |
|    clip_fraction        | 0.519         |
|    clip_range           | 0.2           |
|    entropy_loss         | -135          |
|    explained_variance   | -0.116        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.31         |
|    n_updates            | 7540          |
|    policy_gradient_loss | 0.0354        |
|    reward               | 0.00014706726 |
|    std                  | 30.8          |
|    value_loss           | 5.4e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3805, episode: 920
begin_total_asset: 200.00
end_total_asset: 538.17
total_reward: 338.17
total_cost: 12.56
total_trades: 46949
Sharpe: 0.782
=================================
Reseting Environment StartDay: 2345, ResetDay: 4025,Episode: 921
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2520, ResetDay: 4200,Episode: 922
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 756          |
|    time_elapsed         | 17112        |
|    total_timesteps      | 1548288      |
| train/                  |              |
|    approx_kl            | 73.13668     |
|    clip_fraction        | 0.522        |
|    clip_range           | 0.2          |
|    entropy_loss         | -135         |
|    explained_variance   | 0.0692       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.33        |
|    n_updates            | 7550         |
|    policy_gradient_loss | 0.0424       |
|    reward               | 7.241211e-05 |
|    std                  | 30.9         |
|    value_loss           | 8.67e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2365, ResetDay: 4045,Episode: 923
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 757           |
|    time_elapsed         | 17135         |
|    total_timesteps      | 1550336       |
| train/                  |               |
|    approx_kl            | 74.31261      |
|    clip_fraction        | 0.539         |
|    clip_range           | 0.2           |
|    entropy_loss         | -135          |
|    explained_variance   | -0.0199       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.33         |
|    n_updates            | 7560          |
|    policy_gradient_loss | 0.0333        |
|    reward               | 0.00015732784 |
|    std                  | 31            |
|    value_loss           | 2.82e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1881, ResetDay: 3561,Episode: 924
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 758          |
|    time_elapsed         | 17158        |
|    total_timesteps      | 1552384      |
| train/                  |              |
|    approx_kl            | 73.604385    |
|    clip_fraction        | 0.535        |
|    clip_range           | 0.2          |
|    entropy_loss         | -135         |
|    explained_variance   | -0.118       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.34        |
|    n_updates            | 7570         |
|    policy_gradient_loss | 0.0265       |
|    reward               | 6.877842e-05 |
|    std                  | 31.1         |
|    value_loss           | 5.12e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 176, ResetDay: 1856,Episode: 925
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 759            |
|    time_elapsed         | 17180          |
|    total_timesteps      | 1554432        |
| train/                  |                |
|    approx_kl            | 73.64024       |
|    clip_fraction        | 0.525          |
|    clip_range           | 0.2            |
|    entropy_loss         | -135           |
|    explained_variance   | 0.0425         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.3           |
|    n_updates            | 7580           |
|    policy_gradient_loss | 0.0299         |
|    reward               | -7.9026126e-05 |
|    std                  | 31.1           |
|    value_loss           | 7.19e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 1856, episode: 925
begin_total_asset: 200.00
end_total_asset: 231.36
total_reward: 31.36
total_cost: 5.33
total_trades: 46953
Sharpe: 0.288
=================================
Reseting Environment StartDay: 889, ResetDay: 2569,Episode: 926
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 760          |
|    time_elapsed         | 17203        |
|    total_timesteps      | 1556480      |
| train/                  |              |
|    approx_kl            | 73.992805    |
|    clip_fraction        | 0.527        |
|    clip_range           | 0.2          |
|    entropy_loss         | -135         |
|    explained_variance   | -0.187       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.32        |
|    n_updates            | 7590         |
|    policy_gradient_loss | 0.0251       |
|    reward               | -0.000620454 |
|    std                  | 31.2         |
|    value_loss           | 5.75e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1877, ResetDay: 3557,Episode: 927
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1827, ResetDay: 3507,Episode: 928
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 761          |
|    time_elapsed         | 17225        |
|    total_timesteps      | 1558528      |
| train/                  |              |
|    approx_kl            | 73.9669      |
|    clip_fraction        | 0.497        |
|    clip_range           | 0.2          |
|    entropy_loss         | -135         |
|    explained_variance   | 0.079        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.33        |
|    n_updates            | 7600         |
|    policy_gradient_loss | 0.0237       |
|    reward               | -0.000151886 |
|    std                  | 31.4         |
|    value_loss           | 4.72e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1559, ResetDay: 3239,Episode: 929
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 762           |
|    time_elapsed         | 17248         |
|    total_timesteps      | 1560576       |
| train/                  |               |
|    approx_kl            | 75.18464      |
|    clip_fraction        | 0.528         |
|    clip_range           | 0.2           |
|    entropy_loss         | -135          |
|    explained_variance   | -0.0442       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.29         |
|    n_updates            | 7610          |
|    policy_gradient_loss | 0.0274        |
|    reward               | -9.220123e-07 |
|    std                  | 31.5          |
|    value_loss           | 9.67e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 679, ResetDay: 2359,Episode: 930
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 763          |
|    time_elapsed         | 17270        |
|    total_timesteps      | 1562624      |
| train/                  |              |
|    approx_kl            | 75.64891     |
|    clip_fraction        | 0.519        |
|    clip_range           | 0.2          |
|    entropy_loss         | -135         |
|    explained_variance   | 0.0681       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.34        |
|    n_updates            | 7620         |
|    policy_gradient_loss | 0.0194       |
|    reward               | 0.0003304324 |
|    std                  | 31.6         |
|    value_loss           | 5.27e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2359, episode: 930
begin_total_asset: 200.00
end_total_asset: 218.70
total_reward: 18.70
total_cost: 3.92
total_trades: 46954
Sharpe: 0.249
=================================
Reseting Environment StartDay: 78, ResetDay: 1758,Episode: 931
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 764          |
|    time_elapsed         | 17293        |
|    total_timesteps      | 1564672      |
| train/                  |              |
|    approx_kl            | 75.59208     |
|    clip_fraction        | 0.508        |
|    clip_range           | 0.2          |
|    entropy_loss         | -136         |
|    explained_variance   | -0.0346      |
|    learning_rate        | 0.00025      |
|    loss                 | -1.35        |
|    n_updates            | 7630         |
|    policy_gradient_loss | 0.0304       |
|    reward               | 0.0006747328 |
|    std                  | 31.8         |
|    value_loss           | 4.51e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 343, ResetDay: 2023,Episode: 932
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 518, ResetDay: 2198,Episode: 933
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 765            |
|    time_elapsed         | 17315          |
|    total_timesteps      | 1566720        |
| train/                  |                |
|    approx_kl            | 76.26926       |
|    clip_fraction        | 0.517          |
|    clip_range           | 0.2            |
|    entropy_loss         | -136           |
|    explained_variance   | -0.0109        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.34          |
|    n_updates            | 7640           |
|    policy_gradient_loss | 0.0316         |
|    reward               | -2.8570653e-06 |
|    std                  | 31.9           |
|    value_loss           | 8.1e-07        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 480, ResetDay: 2160,Episode: 934
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 766           |
|    time_elapsed         | 17338         |
|    total_timesteps      | 1568768       |
| train/                  |               |
|    approx_kl            | 77.93896      |
|    clip_fraction        | 0.509         |
|    clip_range           | 0.2           |
|    entropy_loss         | -136          |
|    explained_variance   | 0.0996        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.35         |
|    n_updates            | 7650          |
|    policy_gradient_loss | 0.0273        |
|    reward               | -0.0005049159 |
|    std                  | 32            |
|    value_loss           | 8.71e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2460, ResetDay: 4140,Episode: 935
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 767            |
|    time_elapsed         | 17360          |
|    total_timesteps      | 1570816        |
| train/                  |                |
|    approx_kl            | 78.563324      |
|    clip_fraction        | 0.527          |
|    clip_range           | 0.2            |
|    entropy_loss         | -136           |
|    explained_variance   | 0.0187         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.31          |
|    n_updates            | 7660           |
|    policy_gradient_loss | 0.0339         |
|    reward               | -4.2565156e-05 |
|    std                  | 32             |
|    value_loss           | 4.79e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4140, episode: 935
begin_total_asset: 200.00
end_total_asset: 445.82
total_reward: 245.82
total_cost: 4.66
total_trades: 46928
Sharpe: 0.629
=================================
Reseting Environment StartDay: 595, ResetDay: 2275,Episode: 936
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 768           |
|    time_elapsed         | 17383         |
|    total_timesteps      | 1572864       |
| train/                  |               |
|    approx_kl            | 78.018265     |
|    clip_fraction        | 0.51          |
|    clip_range           | 0.2           |
|    entropy_loss         | -136          |
|    explained_variance   | -0.226        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.34         |
|    n_updates            | 7670          |
|    policy_gradient_loss | 0.0287        |
|    reward               | 0.00015059242 |
|    std                  | 32.1          |
|    value_loss           | 3.62e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2336, ResetDay: 4016,Episode: 937
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 769           |
|    time_elapsed         | 17405         |
|    total_timesteps      | 1574912       |
| train/                  |               |
|    approx_kl            | 77.96948      |
|    clip_fraction        | 0.513         |
|    clip_range           | 0.2           |
|    entropy_loss         | -136          |
|    explained_variance   | 0.00224       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.35         |
|    n_updates            | 7680          |
|    policy_gradient_loss | 0.025         |
|    reward               | 0.00013675155 |
|    std                  | 32.2          |
|    value_loss           | 2.05e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 610, ResetDay: 2290,Episode: 938
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1850, ResetDay: 3530,Episode: 939
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 770           |
|    time_elapsed         | 17428         |
|    total_timesteps      | 1576960       |
| train/                  |               |
|    approx_kl            | 78.895355     |
|    clip_fraction        | 0.515         |
|    clip_range           | 0.2           |
|    entropy_loss         | -136          |
|    explained_variance   | 0.0374        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.35         |
|    n_updates            | 7690          |
|    policy_gradient_loss | 0.0226        |
|    reward               | 6.1643885e-05 |
|    std                  | 32.3          |
|    value_loss           | 9.84e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 889, ResetDay: 2569,Episode: 940
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 771            |
|    time_elapsed         | 17451          |
|    total_timesteps      | 1579008        |
| train/                  |                |
|    approx_kl            | 79.64643       |
|    clip_fraction        | 0.51           |
|    clip_range           | 0.2            |
|    entropy_loss         | -136           |
|    explained_variance   | -0.259         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.35          |
|    n_updates            | 7700           |
|    policy_gradient_loss | 0.0303         |
|    reward               | -6.1646744e-05 |
|    std                  | 32.4           |
|    value_loss           | 5.98e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2569, episode: 940
begin_total_asset: 200.00
end_total_asset: 329.54
total_reward: 129.54
total_cost: 8.25
total_trades: 46960
Sharpe: 0.456
=================================
Reseting Environment StartDay: 761, ResetDay: 2441,Episode: 941
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 772           |
|    time_elapsed         | 17473         |
|    total_timesteps      | 1581056       |
| train/                  |               |
|    approx_kl            | 79.34117      |
|    clip_fraction        | 0.52          |
|    clip_range           | 0.2           |
|    entropy_loss         | -136          |
|    explained_variance   | -0.000171     |
|    learning_rate        | 0.00025       |
|    loss                 | -1.34         |
|    n_updates            | 7710          |
|    policy_gradient_loss | 0.028         |
|    reward               | 1.1580372e-05 |
|    std                  | 32.6          |
|    value_loss           | 7.06e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 831, ResetDay: 2511,Episode: 942
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 773            |
|    time_elapsed         | 17496          |
|    total_timesteps      | 1583104        |
| train/                  |                |
|    approx_kl            | 80.01979       |
|    clip_fraction        | 0.52           |
|    clip_range           | 0.2            |
|    entropy_loss         | -136           |
|    explained_variance   | 0.0916         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.36          |
|    n_updates            | 7720           |
|    policy_gradient_loss | 0.0267         |
|    reward               | -6.7108536e-05 |
|    std                  | 32.7           |
|    value_loss           | 4.34e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2604, ResetDay: 4284,Episode: 943
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 774            |
|    time_elapsed         | 17518          |
|    total_timesteps      | 1585152        |
| train/                  |                |
|    approx_kl            | 80.85896       |
|    clip_fraction        | 0.516          |
|    clip_range           | 0.2            |
|    entropy_loss         | -137           |
|    explained_variance   | 0.196          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.37          |
|    n_updates            | 7730           |
|    policy_gradient_loss | 0.041          |
|    reward               | -0.00073134305 |
|    std                  | 32.8           |
|    value_loss           | 6.69e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1315, ResetDay: 2995,Episode: 944
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1506, ResetDay: 3186,Episode: 945
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 775           |
|    time_elapsed         | 17541         |
|    total_timesteps      | 1587200       |
| train/                  |               |
|    approx_kl            | 80.46105      |
|    clip_fraction        | 0.489         |
|    clip_range           | 0.2           |
|    entropy_loss         | -137          |
|    explained_variance   | -0.014        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.35         |
|    n_updates            | 7740          |
|    policy_gradient_loss | 0.0246        |
|    reward               | -4.952116e-05 |
|    std                  | 32.9          |
|    value_loss           | 1.68e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3186, episode: 945
begin_total_asset: 200.00
end_total_asset: 309.78
total_reward: 109.78
total_cost: 9.48
total_trades: 46924
Sharpe: 0.420
=================================
Reseting Environment StartDay: 462, ResetDay: 2142,Episode: 946
-----------------------------------------
| time/                   |             |
|    fps                  | 90          |
|    iterations           | 776         |
|    time_elapsed         | 17563       |
|    total_timesteps      | 1589248     |
| train/                  |             |
|    approx_kl            | 82.84252    |
|    clip_fraction        | 0.495       |
|    clip_range           | 0.2         |
|    entropy_loss         | -137        |
|    explained_variance   | -0.607      |
|    learning_rate        | 0.00025     |
|    loss                 | -1.36       |
|    n_updates            | 7750        |
|    policy_gradient_loss | 0.0188      |
|    reward               | 0.000236343 |
|    std                  | 33          |
|    value_loss           | 5e-07       |
-----------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2649, ResetDay: 4329,Episode: 947
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 777           |
|    time_elapsed         | 17586         |
|    total_timesteps      | 1591296       |
| train/                  |               |
|    approx_kl            | 82.09791      |
|    clip_fraction        | 0.513         |
|    clip_range           | 0.2           |
|    entropy_loss         | -137          |
|    explained_variance   | -0.0709       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.33         |
|    n_updates            | 7760          |
|    policy_gradient_loss | 0.0318        |
|    reward               | 0.00023428879 |
|    std                  | 33            |
|    value_loss           | 4.91e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2197, ResetDay: 3877,Episode: 948
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 778           |
|    time_elapsed         | 17608         |
|    total_timesteps      | 1593344       |
| train/                  |               |
|    approx_kl            | 82.60413      |
|    clip_fraction        | 0.524         |
|    clip_range           | 0.2           |
|    entropy_loss         | -137          |
|    explained_variance   | 0.0659        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.29         |
|    n_updates            | 7770          |
|    policy_gradient_loss | 0.0404        |
|    reward               | 0.00014763184 |
|    std                  | 33.1          |
|    value_loss           | 8.41e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2465, ResetDay: 4145,Episode: 949
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 911, ResetDay: 2591,Episode: 950
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 779            |
|    time_elapsed         | 17631          |
|    total_timesteps      | 1595392        |
| train/                  |                |
|    approx_kl            | 83.41489       |
|    clip_fraction        | 0.523          |
|    clip_range           | 0.2            |
|    entropy_loss         | -137           |
|    explained_variance   | -0.0351        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.36          |
|    n_updates            | 7780           |
|    policy_gradient_loss | 0.019          |
|    reward               | -0.00015010223 |
|    std                  | 33.2           |
|    value_loss           | 2.82e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2591, episode: 950
begin_total_asset: 200.00
end_total_asset: 273.90
total_reward: 73.90
total_cost: 4.39
total_trades: 46910
Sharpe: 0.413
=================================
Reseting Environment StartDay: 146, ResetDay: 1826,Episode: 951
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 780           |
|    time_elapsed         | 17653         |
|    total_timesteps      | 1597440       |
| train/                  |               |
|    approx_kl            | 82.74498      |
|    clip_fraction        | 0.51          |
|    clip_range           | 0.2           |
|    entropy_loss         | -137          |
|    explained_variance   | -0.0229       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.36         |
|    n_updates            | 7790          |
|    policy_gradient_loss | 0.0368        |
|    reward               | -3.402481e-05 |
|    std                  | 33.3          |
|    value_loss           | 1.44e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1382, ResetDay: 3062,Episode: 952
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 781           |
|    time_elapsed         | 17676         |
|    total_timesteps      | 1599488       |
| train/                  |               |
|    approx_kl            | 83.192345     |
|    clip_fraction        | 0.517         |
|    clip_range           | 0.2           |
|    entropy_loss         | -137          |
|    explained_variance   | -1.12         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.36         |
|    n_updates            | 7800          |
|    policy_gradient_loss | 0.0317        |
|    reward               | 0.00015450668 |
|    std                  | 33.4          |
|    value_loss           | 4.76e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 114, ResetDay: 1794,Episode: 953
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 782          |
|    time_elapsed         | 17699        |
|    total_timesteps      | 1601536      |
| train/                  |              |
|    approx_kl            | 83.05796     |
|    clip_fraction        | 0.496        |
|    clip_range           | 0.2          |
|    entropy_loss         | -137         |
|    explained_variance   | 0.104        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.35        |
|    n_updates            | 7810         |
|    policy_gradient_loss | 0.0283       |
|    reward               | 3.497791e-05 |
|    std                  | 33.5         |
|    value_loss           | 7.14e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2447, ResetDay: 4127,Episode: 954
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 783           |
|    time_elapsed         | 17721         |
|    total_timesteps      | 1603584       |
| train/                  |               |
|    approx_kl            | 83.19572      |
|    clip_fraction        | 0.508         |
|    clip_range           | 0.2           |
|    entropy_loss         | -137          |
|    explained_variance   | -0.0522       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.34         |
|    n_updates            | 7820          |
|    policy_gradient_loss | 0.037         |
|    reward               | 0.00058729935 |
|    std                  | 33.7          |
|    value_loss           | 6.59e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 96, ResetDay: 1776,Episode: 955
Environment reached Terminal state as number of trading days reached limit!!
day: 1776, episode: 955
begin_total_asset: 200.00
end_total_asset: 266.30
total_reward: 66.30
total_cost: 3.56
total_trades: 46921
Sharpe: 0.379
=================================
Reseting Environment StartDay: 903, ResetDay: 2583,Episode: 956
-----------------------------------------
| time/                   |             |
|    fps                  | 90          |
|    iterations           | 784         |
|    time_elapsed         | 17744       |
|    total_timesteps      | 1605632     |
| train/                  |             |
|    approx_kl            | 84.24895    |
|    clip_fraction        | 0.509       |
|    clip_range           | 0.2         |
|    entropy_loss         | -137        |
|    explained_variance   | 0.0244      |
|    learning_rate        | 0.00025     |
|    loss                 | -1.36       |
|    n_updates            | 7830        |
|    policy_gradient_loss | 0.0174      |
|    reward               | 2.37607e-05 |
|    std                  | 33.8        |
|    value_loss           | 2.33e-06    |
-----------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2354, ResetDay: 4034,Episode: 957
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 785            |
|    time_elapsed         | 17766          |
|    total_timesteps      | 1607680        |
| train/                  |                |
|    approx_kl            | 87.22351       |
|    clip_fraction        | 0.496          |
|    clip_range           | 0.2            |
|    entropy_loss         | -138           |
|    explained_variance   | -0.451         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.35          |
|    n_updates            | 7840           |
|    policy_gradient_loss | 0.0325         |
|    reward               | -0.00011155834 |
|    std                  | 33.9           |
|    value_loss           | 7.81e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 16, ResetDay: 1696,Episode: 958
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 786           |
|    time_elapsed         | 17789         |
|    total_timesteps      | 1609728       |
| train/                  |               |
|    approx_kl            | 85.337006     |
|    clip_fraction        | 0.489         |
|    clip_range           | 0.2           |
|    entropy_loss         | -138          |
|    explained_variance   | 0.0286        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.37         |
|    n_updates            | 7850          |
|    policy_gradient_loss | 0.0261        |
|    reward               | 9.5172785e-05 |
|    std                  | 34            |
|    value_loss           | 5.49e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1317, ResetDay: 2997,Episode: 959
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 787           |
|    time_elapsed         | 17811         |
|    total_timesteps      | 1611776       |
| train/                  |               |
|    approx_kl            | 86.39302      |
|    clip_fraction        | 0.49          |
|    clip_range           | 0.2           |
|    entropy_loss         | -138          |
|    explained_variance   | -0.0695       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.4          |
|    n_updates            | 7860          |
|    policy_gradient_loss | 0.0149        |
|    reward               | 0.00042712936 |
|    std                  | 34.1          |
|    value_loss           | 1.58e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 429, ResetDay: 2109,Episode: 960
Environment reached Terminal state as number of trading days reached limit!!
day: 2109, episode: 960
begin_total_asset: 200.00
end_total_asset: 184.99
total_reward: -15.01
total_cost: 4.61
total_trades: 46903
Sharpe: 0.170
=================================
Reseting Environment StartDay: 954, ResetDay: 2634,Episode: 961
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 788          |
|    time_elapsed         | 17834        |
|    total_timesteps      | 1613824      |
| train/                  |              |
|    approx_kl            | 87.14499     |
|    clip_fraction        | 0.492        |
|    clip_range           | 0.2          |
|    entropy_loss         | -138         |
|    explained_variance   | -0.066       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.37        |
|    n_updates            | 7870         |
|    policy_gradient_loss | 0.0402       |
|    reward               | -7.15064e-05 |
|    std                  | 34.3         |
|    value_loss           | 5.58e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1923, ResetDay: 3603,Episode: 962
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 789           |
|    time_elapsed         | 17856         |
|    total_timesteps      | 1615872       |
| train/                  |               |
|    approx_kl            | 86.96022      |
|    clip_fraction        | 0.496         |
|    clip_range           | 0.2           |
|    entropy_loss         | -138          |
|    explained_variance   | -0.0698       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.37         |
|    n_updates            | 7880          |
|    policy_gradient_loss | 0.0205        |
|    reward               | -8.630962e-05 |
|    std                  | 34.4          |
|    value_loss           | 8.03e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2004, ResetDay: 3684,Episode: 963
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 790           |
|    time_elapsed         | 17879         |
|    total_timesteps      | 1617920       |
| train/                  |               |
|    approx_kl            | 88.23541      |
|    clip_fraction        | 0.509         |
|    clip_range           | 0.2           |
|    entropy_loss         | -138          |
|    explained_variance   | 0.0253        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.38         |
|    n_updates            | 7890          |
|    policy_gradient_loss | 0.0327        |
|    reward               | 3.1615447e-05 |
|    std                  | 34.6          |
|    value_loss           | 4.1e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 982, ResetDay: 2662,Episode: 964
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 791           |
|    time_elapsed         | 17901         |
|    total_timesteps      | 1619968       |
| train/                  |               |
|    approx_kl            | 89.522        |
|    clip_fraction        | 0.496         |
|    clip_range           | 0.2           |
|    entropy_loss         | -138          |
|    explained_variance   | 0.0748        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.37         |
|    n_updates            | 7900          |
|    policy_gradient_loss | 0.0299        |
|    reward               | 0.00076457654 |
|    std                  | 34.6          |
|    value_loss           | 4.88e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2318, ResetDay: 3998,Episode: 965
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 792          |
|    time_elapsed         | 17924        |
|    total_timesteps      | 1622016      |
| train/                  |              |
|    approx_kl            | 89.25351     |
|    clip_fraction        | 0.482        |
|    clip_range           | 0.2          |
|    entropy_loss         | -138         |
|    explained_variance   | 0.0294       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.34        |
|    n_updates            | 7910         |
|    policy_gradient_loss | 0.0306       |
|    reward               | 0.0006011223 |
|    std                  | 34.8         |
|    value_loss           | 1.31e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3998, episode: 965
begin_total_asset: 200.00
end_total_asset: 392.35
total_reward: 192.35
total_cost: 15.81
total_trades: 46873
Sharpe: 0.568
=================================
Reseting Environment StartDay: 2653, ResetDay: 4333,Episode: 966
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 815, ResetDay: 2495,Episode: 967
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 793           |
|    time_elapsed         | 17947         |
|    total_timesteps      | 1624064       |
| train/                  |               |
|    approx_kl            | 89.96849      |
|    clip_fraction        | 0.485         |
|    clip_range           | 0.2           |
|    entropy_loss         | -138          |
|    explained_variance   | 0.0545        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.38         |
|    n_updates            | 7920          |
|    policy_gradient_loss | 0.0181        |
|    reward               | 0.00010489359 |
|    std                  | 35            |
|    value_loss           | 9.47e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2629, ResetDay: 4309,Episode: 968
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 794           |
|    time_elapsed         | 17969         |
|    total_timesteps      | 1626112       |
| train/                  |               |
|    approx_kl            | 91.92136      |
|    clip_fraction        | 0.5           |
|    clip_range           | 0.2           |
|    entropy_loss         | -138          |
|    explained_variance   | -0.0704       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.37         |
|    n_updates            | 7930          |
|    policy_gradient_loss | 0.0314        |
|    reward               | 0.00024633866 |
|    std                  | 35.1          |
|    value_loss           | 1.45e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2595, ResetDay: 4275,Episode: 969
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 795            |
|    time_elapsed         | 17992          |
|    total_timesteps      | 1628160        |
| train/                  |                |
|    approx_kl            | 91.59128       |
|    clip_fraction        | 0.506          |
|    clip_range           | 0.2            |
|    entropy_loss         | -139           |
|    explained_variance   | -0.836         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.39          |
|    n_updates            | 7940           |
|    policy_gradient_loss | 0.0258         |
|    reward               | -0.00013194504 |
|    std                  | 35.2           |
|    value_loss           | 4.3e-07        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 387, ResetDay: 2067,Episode: 970
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 796          |
|    time_elapsed         | 18015        |
|    total_timesteps      | 1630208      |
| train/                  |              |
|    approx_kl            | 92.56181     |
|    clip_fraction        | 0.481        |
|    clip_range           | 0.2          |
|    entropy_loss         | -139         |
|    explained_variance   | -0.00245     |
|    learning_rate        | 0.00025      |
|    loss                 | -1.37        |
|    n_updates            | 7950         |
|    policy_gradient_loss | 0.03         |
|    reward               | 7.189732e-05 |
|    std                  | 35.3         |
|    value_loss           | 1.8e-06      |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2067, episode: 970
begin_total_asset: 200.00
end_total_asset: 206.57
total_reward: 6.57
total_cost: 7.44
total_trades: 46850
Sharpe: 0.259
=================================
Reseting Environment StartDay: 2226, ResetDay: 3906,Episode: 971
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2339, ResetDay: 4019,Episode: 972
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 797            |
|    time_elapsed         | 18037          |
|    total_timesteps      | 1632256        |
| train/                  |                |
|    approx_kl            | 93.71936       |
|    clip_fraction        | 0.494          |
|    clip_range           | 0.2            |
|    entropy_loss         | -139           |
|    explained_variance   | -0.456         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.34          |
|    n_updates            | 7960           |
|    policy_gradient_loss | 0.0329         |
|    reward               | -2.7795219e-05 |
|    std                  | 35.4           |
|    value_loss           | 6.96e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 234, ResetDay: 1914,Episode: 973
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 798            |
|    time_elapsed         | 18060          |
|    total_timesteps      | 1634304        |
| train/                  |                |
|    approx_kl            | 92.70473       |
|    clip_fraction        | 0.481          |
|    clip_range           | 0.2            |
|    entropy_loss         | -139           |
|    explained_variance   | 0.0146         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.38          |
|    n_updates            | 7970           |
|    policy_gradient_loss | 0.0191         |
|    reward               | -0.00024226648 |
|    std                  | 35.5           |
|    value_loss           | 1.53e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1578, ResetDay: 3258,Episode: 974
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 799          |
|    time_elapsed         | 18082        |
|    total_timesteps      | 1636352      |
| train/                  |              |
|    approx_kl            | 94.85736     |
|    clip_fraction        | 0.491        |
|    clip_range           | 0.2          |
|    entropy_loss         | -139         |
|    explained_variance   | -0.0464      |
|    learning_rate        | 0.00025      |
|    loss                 | -1.35        |
|    n_updates            | 7980         |
|    policy_gradient_loss | 0.0217       |
|    reward               | 4.162178e-05 |
|    std                  | 35.7         |
|    value_loss           | 7.9e-07      |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2539, ResetDay: 4219,Episode: 975
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 800            |
|    time_elapsed         | 18105          |
|    total_timesteps      | 1638400        |
| train/                  |                |
|    approx_kl            | 94.46561       |
|    clip_fraction        | 0.496          |
|    clip_range           | 0.2            |
|    entropy_loss         | -139           |
|    explained_variance   | -0.0122        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.36          |
|    n_updates            | 7990           |
|    policy_gradient_loss | 0.0255         |
|    reward               | -0.00030173798 |
|    std                  | 35.8           |
|    value_loss           | 4.12e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4219, episode: 975
begin_total_asset: 200.00
end_total_asset: 363.77
total_reward: 163.77
total_cost: 6.07
total_trades: 46815
Sharpe: 0.498
=================================
Reseting Environment StartDay: 973, ResetDay: 2653,Episode: 976
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 801           |
|    time_elapsed         | 18127         |
|    total_timesteps      | 1640448       |
| train/                  |               |
|    approx_kl            | 95.442184     |
|    clip_fraction        | 0.477         |
|    clip_range           | 0.2           |
|    entropy_loss         | -139          |
|    explained_variance   | 0.0314        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.38         |
|    n_updates            | 8000          |
|    policy_gradient_loss | 0.0254        |
|    reward               | 0.00047180481 |
|    std                  | 35.9          |
|    value_loss           | 8.96e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 533, ResetDay: 2213,Episode: 977
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1300, ResetDay: 2980,Episode: 978
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 802          |
|    time_elapsed         | 18150        |
|    total_timesteps      | 1642496      |
| train/                  |              |
|    approx_kl            | 95.55657     |
|    clip_fraction        | 0.478        |
|    clip_range           | 0.2          |
|    entropy_loss         | -139         |
|    explained_variance   | -0.31        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.36        |
|    n_updates            | 8010         |
|    policy_gradient_loss | 0.0333       |
|    reward               | 6.585903e-05 |
|    std                  | 36           |
|    value_loss           | 9.22e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2189, ResetDay: 3869,Episode: 979
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 803            |
|    time_elapsed         | 18172          |
|    total_timesteps      | 1644544        |
| train/                  |                |
|    approx_kl            | 97.14801       |
|    clip_fraction        | 0.489          |
|    clip_range           | 0.2            |
|    entropy_loss         | -139           |
|    explained_variance   | 0.0368         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.38          |
|    n_updates            | 8020           |
|    policy_gradient_loss | 0.0286         |
|    reward               | -0.00044458485 |
|    std                  | 36             |
|    value_loss           | 5.27e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 859, ResetDay: 2539,Episode: 980
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 804          |
|    time_elapsed         | 18195        |
|    total_timesteps      | 1646592      |
| train/                  |              |
|    approx_kl            | 96.090126    |
|    clip_fraction        | 0.466        |
|    clip_range           | 0.2          |
|    entropy_loss         | -139         |
|    explained_variance   | 0.0189       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.38        |
|    n_updates            | 8030         |
|    policy_gradient_loss | 0.0262       |
|    reward               | 8.617859e-05 |
|    std                  | 36.2         |
|    value_loss           | 3.73e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2539, episode: 980
begin_total_asset: 200.00
end_total_asset: 428.24
total_reward: 228.24
total_cost: 10.40
total_trades: 46805
Sharpe: 0.544
=================================
Reseting Environment StartDay: 73, ResetDay: 1753,Episode: 981
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 805           |
|    time_elapsed         | 18218         |
|    total_timesteps      | 1648640       |
| train/                  |               |
|    approx_kl            | 97.336296     |
|    clip_fraction        | 0.471         |
|    clip_range           | 0.2           |
|    entropy_loss         | -139          |
|    explained_variance   | 0.0568        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.4          |
|    n_updates            | 8040          |
|    policy_gradient_loss | 0.0299        |
|    reward               | -3.594179e-05 |
|    std                  | 36.3          |
|    value_loss           | 1.46e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 578, ResetDay: 2258,Episode: 982
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 806            |
|    time_elapsed         | 18240          |
|    total_timesteps      | 1650688        |
| train/                  |                |
|    approx_kl            | 97.056496      |
|    clip_fraction        | 0.507          |
|    clip_range           | 0.2            |
|    entropy_loss         | -140           |
|    explained_variance   | -0.0181        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.37          |
|    n_updates            | 8050           |
|    policy_gradient_loss | 0.0283         |
|    reward               | -0.00017245598 |
|    std                  | 36.4           |
|    value_loss           | 1.02e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 395, ResetDay: 2075,Episode: 983
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2190, ResetDay: 3870,Episode: 984
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 807            |
|    time_elapsed         | 18263          |
|    total_timesteps      | 1652736        |
| train/                  |                |
|    approx_kl            | 97.36638       |
|    clip_fraction        | 0.485          |
|    clip_range           | 0.2            |
|    entropy_loss         | -140           |
|    explained_variance   | 0.032          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.36          |
|    n_updates            | 8060           |
|    policy_gradient_loss | 0.0338         |
|    reward               | -0.00038836288 |
|    std                  | 36.5           |
|    value_loss           | 7.25e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1583, ResetDay: 3263,Episode: 985
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 808           |
|    time_elapsed         | 18285         |
|    total_timesteps      | 1654784       |
| train/                  |               |
|    approx_kl            | 99.756424     |
|    clip_fraction        | 0.481         |
|    clip_range           | 0.2           |
|    entropy_loss         | -140          |
|    explained_variance   | 0.0578        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.36         |
|    n_updates            | 8070          |
|    policy_gradient_loss | 0.0265        |
|    reward               | 0.00016501312 |
|    std                  | 36.6          |
|    value_loss           | 8.93e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3263, episode: 985
begin_total_asset: 200.00
end_total_asset: 284.30
total_reward: 84.30
total_cost: 4.36
total_trades: 46797
Sharpe: 0.363
=================================
Reseting Environment StartDay: 2278, ResetDay: 3958,Episode: 986
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 809           |
|    time_elapsed         | 18308         |
|    total_timesteps      | 1656832       |
| train/                  |               |
|    approx_kl            | 98.36623      |
|    clip_fraction        | 0.465         |
|    clip_range           | 0.2           |
|    entropy_loss         | -140          |
|    explained_variance   | -0.0475       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.39         |
|    n_updates            | 8080          |
|    policy_gradient_loss | 0.0238        |
|    reward               | -0.0003041622 |
|    std                  | 36.7          |
|    value_loss           | 2.08e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 514, ResetDay: 2194,Episode: 987
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 810            |
|    time_elapsed         | 18330          |
|    total_timesteps      | 1658880        |
| train/                  |                |
|    approx_kl            | 98.80502       |
|    clip_fraction        | 0.475          |
|    clip_range           | 0.2            |
|    entropy_loss         | -140           |
|    explained_variance   | -0.000592      |
|    learning_rate        | 0.00025        |
|    loss                 | -1.36          |
|    n_updates            | 8090           |
|    policy_gradient_loss | 0.0279         |
|    reward               | -0.00014852657 |
|    std                  | 36.8           |
|    value_loss           | 5.17e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1876, ResetDay: 3556,Episode: 988
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2717, ResetDay: 4397,Episode: 989
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 811            |
|    time_elapsed         | 18353          |
|    total_timesteps      | 1660928        |
| train/                  |                |
|    approx_kl            | 99.94734       |
|    clip_fraction        | 0.468          |
|    clip_range           | 0.2            |
|    entropy_loss         | -140           |
|    explained_variance   | -0.0156        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.37          |
|    n_updates            | 8100           |
|    policy_gradient_loss | 0.0213         |
|    reward               | -3.3341217e-05 |
|    std                  | 37             |
|    value_loss           | 1.44e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2481, ResetDay: 4161,Episode: 990
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 812            |
|    time_elapsed         | 18376          |
|    total_timesteps      | 1662976        |
| train/                  |                |
|    approx_kl            | 100.812004     |
|    clip_fraction        | 0.482          |
|    clip_range           | 0.2            |
|    entropy_loss         | -140           |
|    explained_variance   | -0.1           |
|    learning_rate        | 0.00025        |
|    loss                 | -1.37          |
|    n_updates            | 8110           |
|    policy_gradient_loss | 0.0237         |
|    reward               | -9.4838906e-05 |
|    std                  | 37.1           |
|    value_loss           | 1.16e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4161, episode: 990
begin_total_asset: 200.00
end_total_asset: 316.43
total_reward: 116.43
total_cost: 6.05
total_trades: 46748
Sharpe: 0.396
=================================
Reseting Environment StartDay: 2658, ResetDay: 4338,Episode: 991
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 813           |
|    time_elapsed         | 18398         |
|    total_timesteps      | 1665024       |
| train/                  |               |
|    approx_kl            | 102.21788     |
|    clip_fraction        | 0.491         |
|    clip_range           | 0.2           |
|    entropy_loss         | -140          |
|    explained_variance   | -0.0415       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.4          |
|    n_updates            | 8120          |
|    policy_gradient_loss | 0.0212        |
|    reward               | 0.00042860946 |
|    std                  | 37.2          |
|    value_loss           | 1.21e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 619, ResetDay: 2299,Episode: 992
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 814            |
|    time_elapsed         | 18421          |
|    total_timesteps      | 1667072        |
| train/                  |                |
|    approx_kl            | 101.404785     |
|    clip_fraction        | 0.478          |
|    clip_range           | 0.2            |
|    entropy_loss         | -140           |
|    explained_variance   | 0.0245         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.37          |
|    n_updates            | 8130           |
|    policy_gradient_loss | 0.0259         |
|    reward               | -0.00055655953 |
|    std                  | 37.4           |
|    value_loss           | 1.03e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2428, ResetDay: 4108,Episode: 993
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 815           |
|    time_elapsed         | 18443         |
|    total_timesteps      | 1669120       |
| train/                  |               |
|    approx_kl            | 104.94856     |
|    clip_fraction        | 0.47          |
|    clip_range           | 0.2           |
|    entropy_loss         | -140          |
|    explained_variance   | -0.0618       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.39         |
|    n_updates            | 8140          |
|    policy_gradient_loss | 0.0273        |
|    reward               | 5.9986114e-06 |
|    std                  | 37.5          |
|    value_loss           | 1.12e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1205, ResetDay: 2885,Episode: 994
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1597, ResetDay: 3277,Episode: 995
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 816           |
|    time_elapsed         | 18466         |
|    total_timesteps      | 1671168       |
| train/                  |               |
|    approx_kl            | 104.39732     |
|    clip_fraction        | 0.479         |
|    clip_range           | 0.2           |
|    entropy_loss         | -140          |
|    explained_variance   | 0.0456        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.39         |
|    n_updates            | 8150          |
|    policy_gradient_loss | 0.021         |
|    reward               | 5.9971237e-05 |
|    std                  | 37.6          |
|    value_loss           | 1.14e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3277, episode: 995
begin_total_asset: 200.00
end_total_asset: 356.92
total_reward: 156.92
total_cost: 7.61
total_trades: 46756
Sharpe: 0.502
=================================
Reseting Environment StartDay: 57, ResetDay: 1737,Episode: 996
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 817           |
|    time_elapsed         | 18488         |
|    total_timesteps      | 1673216       |
| train/                  |               |
|    approx_kl            | 105.32272     |
|    clip_fraction        | 0.465         |
|    clip_range           | 0.2           |
|    entropy_loss         | -141          |
|    explained_variance   | -0.338        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.29         |
|    n_updates            | 8160          |
|    policy_gradient_loss | 0.0313        |
|    reward               | 6.0261536e-05 |
|    std                  | 37.7          |
|    value_loss           | 3.5e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2451, ResetDay: 4131,Episode: 997
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 818           |
|    time_elapsed         | 18511         |
|    total_timesteps      | 1675264       |
| train/                  |               |
|    approx_kl            | 105.88461     |
|    clip_fraction        | 0.469         |
|    clip_range           | 0.2           |
|    entropy_loss         | -141          |
|    explained_variance   | -0.062        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.37         |
|    n_updates            | 8170          |
|    policy_gradient_loss | 0.027         |
|    reward               | 0.00070041086 |
|    std                  | 37.8          |
|    value_loss           | 5.79e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2122, ResetDay: 3802,Episode: 998
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 819           |
|    time_elapsed         | 18534         |
|    total_timesteps      | 1677312       |
| train/                  |               |
|    approx_kl            | 106.26523     |
|    clip_fraction        | 0.474         |
|    clip_range           | 0.2           |
|    entropy_loss         | -141          |
|    explained_variance   | 0.0789        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.38         |
|    n_updates            | 8180          |
|    policy_gradient_loss | 0.0249        |
|    reward               | 0.00052128296 |
|    std                  | 37.9          |
|    value_loss           | 1.55e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 371, ResetDay: 2051,Episode: 999
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 826, ResetDay: 2506,Episode: 1000
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 820           |
|    time_elapsed         | 18556         |
|    total_timesteps      | 1679360       |
| train/                  |               |
|    approx_kl            | 106.29974     |
|    clip_fraction        | 0.472         |
|    clip_range           | 0.2           |
|    entropy_loss         | -141          |
|    explained_variance   | 0.0331        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.36         |
|    n_updates            | 8190          |
|    policy_gradient_loss | 0.028         |
|    reward               | 0.00021790862 |
|    std                  | 38            |
|    value_loss           | 2.51e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2506, episode: 1000
begin_total_asset: 200.00
end_total_asset: 404.00
total_reward: 204.00
total_cost: 11.11
total_trades: 46739
Sharpe: 0.529
=================================
Reseting Environment StartDay: 1870, ResetDay: 3550,Episode: 1001
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 821          |
|    time_elapsed         | 18579        |
|    total_timesteps      | 1681408      |
| train/                  |              |
|    approx_kl            | 107.10675    |
|    clip_fraction        | 0.475        |
|    clip_range           | 0.2          |
|    entropy_loss         | -141         |
|    explained_variance   | -0.63        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.38        |
|    n_updates            | 8200         |
|    policy_gradient_loss | 0.0272       |
|    reward               | 2.356739e-05 |
|    std                  | 38.2         |
|    value_loss           | 9.33e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 714, ResetDay: 2394,Episode: 1002
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 822           |
|    time_elapsed         | 18601         |
|    total_timesteps      | 1683456       |
| train/                  |               |
|    approx_kl            | 107.324486    |
|    clip_fraction        | 0.473         |
|    clip_range           | 0.2           |
|    entropy_loss         | -141          |
|    explained_variance   | 0.0448        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.41         |
|    n_updates            | 8210          |
|    policy_gradient_loss | 0.0207        |
|    reward               | -8.216133e-05 |
|    std                  | 38.3          |
|    value_loss           | 5.33e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1529, ResetDay: 3209,Episode: 1003
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 823            |
|    time_elapsed         | 18624          |
|    total_timesteps      | 1685504        |
| train/                  |                |
|    approx_kl            | 108.11131      |
|    clip_fraction        | 0.473          |
|    clip_range           | 0.2            |
|    entropy_loss         | -141           |
|    explained_variance   | -0.0142        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.39          |
|    n_updates            | 8220           |
|    policy_gradient_loss | 0.0347         |
|    reward               | -0.00019004325 |
|    std                  | 38.4           |
|    value_loss           | 8.53e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1185, ResetDay: 2865,Episode: 1004
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 824            |
|    time_elapsed         | 18647          |
|    total_timesteps      | 1687552        |
| train/                  |                |
|    approx_kl            | 108.66374      |
|    clip_fraction        | 0.475          |
|    clip_range           | 0.2            |
|    entropy_loss         | -141           |
|    explained_variance   | -0.00371       |
|    learning_rate        | 0.00025        |
|    loss                 | -1.4           |
|    n_updates            | 8230           |
|    policy_gradient_loss | 0.014          |
|    reward               | -0.00032363337 |
|    std                  | 38.6           |
|    value_loss           | 3.42e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 436, ResetDay: 2116,Episode: 1005
Environment reached Terminal state as number of trading days reached limit!!
day: 2116, episode: 1005
begin_total_asset: 200.00
end_total_asset: 254.10
total_reward: 54.10
total_cost: 8.18
total_trades: 46708
Sharpe: 0.290
=================================
Reseting Environment StartDay: 129, ResetDay: 1809,Episode: 1006
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 825            |
|    time_elapsed         | 18670          |
|    total_timesteps      | 1689600        |
| train/                  |                |
|    approx_kl            | 109.387764     |
|    clip_fraction        | 0.463          |
|    clip_range           | 0.2            |
|    entropy_loss         | -141           |
|    explained_variance   | 0.0733         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.43          |
|    n_updates            | 8240           |
|    policy_gradient_loss | 0.026          |
|    reward               | -0.00014425568 |
|    std                  | 38.7           |
|    value_loss           | 4.03e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2391, ResetDay: 4071,Episode: 1007
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 826            |
|    time_elapsed         | 18692          |
|    total_timesteps      | 1691648        |
| train/                  |                |
|    approx_kl            | 110.03897      |
|    clip_fraction        | 0.452          |
|    clip_range           | 0.2            |
|    entropy_loss         | -141           |
|    explained_variance   | 0.106          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.42          |
|    n_updates            | 8250           |
|    policy_gradient_loss | 0.0161         |
|    reward               | -0.00013388156 |
|    std                  | 38.8           |
|    value_loss           | 8.54e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2474, ResetDay: 4154,Episode: 1008
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 827            |
|    time_elapsed         | 18715          |
|    total_timesteps      | 1693696        |
| train/                  |                |
|    approx_kl            | 109.543884     |
|    clip_fraction        | 0.462          |
|    clip_range           | 0.2            |
|    entropy_loss         | -141           |
|    explained_variance   | 0.0403         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.4           |
|    n_updates            | 8260           |
|    policy_gradient_loss | 0.0229         |
|    reward               | -0.00028063508 |
|    std                  | 38.9           |
|    value_loss           | 1.41e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1877, ResetDay: 3557,Episode: 1009
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 828           |
|    time_elapsed         | 18737         |
|    total_timesteps      | 1695744       |
| train/                  |               |
|    approx_kl            | 111.162766    |
|    clip_fraction        | 0.467         |
|    clip_range           | 0.2           |
|    entropy_loss         | -141          |
|    explained_variance   | 0.0106        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.39         |
|    n_updates            | 8270          |
|    policy_gradient_loss | 0.0209        |
|    reward               | 0.00014799042 |
|    std                  | 39            |
|    value_loss           | 4.38e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 108, ResetDay: 1788,Episode: 1010
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 829            |
|    time_elapsed         | 18760          |
|    total_timesteps      | 1697792        |
| train/                  |                |
|    approx_kl            | 112.82702      |
|    clip_fraction        | 0.456          |
|    clip_range           | 0.2            |
|    entropy_loss         | -142           |
|    explained_variance   | -0.12          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.41          |
|    n_updates            | 8280           |
|    policy_gradient_loss | 0.0184         |
|    reward               | -0.00018947382 |
|    std                  | 39.2           |
|    value_loss           | 1.05e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 1788, episode: 1010
begin_total_asset: 200.00
end_total_asset: 374.58
total_reward: 174.58
total_cost: 6.15
total_trades: 46674
Sharpe: 0.488
=================================
Reseting Environment StartDay: 1094, ResetDay: 2774,Episode: 1011
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 850, ResetDay: 2530,Episode: 1012
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 830            |
|    time_elapsed         | 18783          |
|    total_timesteps      | 1699840        |
| train/                  |                |
|    approx_kl            | 113.588936     |
|    clip_fraction        | 0.467          |
|    clip_range           | 0.2            |
|    entropy_loss         | -142           |
|    explained_variance   | -0.0354        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.39          |
|    n_updates            | 8290           |
|    policy_gradient_loss | 0.0196         |
|    reward               | -3.9044455e-05 |
|    std                  | 39.3           |
|    value_loss           | 1.06e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2259, ResetDay: 3939,Episode: 1013
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 831          |
|    time_elapsed         | 18805        |
|    total_timesteps      | 1701888      |
| train/                  |              |
|    approx_kl            | 112.75391    |
|    clip_fraction        | 0.454        |
|    clip_range           | 0.2          |
|    entropy_loss         | -142         |
|    explained_variance   | -0.0591      |
|    learning_rate        | 0.00025      |
|    loss                 | -1.41        |
|    n_updates            | 8300         |
|    policy_gradient_loss | 0.0322       |
|    reward               | 8.668881e-05 |
|    std                  | 39.5         |
|    value_loss           | 8.74e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 152, ResetDay: 1832,Episode: 1014
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 832           |
|    time_elapsed         | 18828         |
|    total_timesteps      | 1703936       |
| train/                  |               |
|    approx_kl            | 114.47963     |
|    clip_fraction        | 0.465         |
|    clip_range           | 0.2           |
|    entropy_loss         | -142          |
|    explained_variance   | 0.117         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.43         |
|    n_updates            | 8310          |
|    policy_gradient_loss | 0.0247        |
|    reward               | 6.7542984e-05 |
|    std                  | 39.6          |
|    value_loss           | 5.33e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1843, ResetDay: 3523,Episode: 1015
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 833           |
|    time_elapsed         | 18851         |
|    total_timesteps      | 1705984       |
| train/                  |               |
|    approx_kl            | 115.16049     |
|    clip_fraction        | 0.459         |
|    clip_range           | 0.2           |
|    entropy_loss         | -142          |
|    explained_variance   | -0.0212       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.4          |
|    n_updates            | 8320          |
|    policy_gradient_loss | 0.0222        |
|    reward               | 0.00043943978 |
|    std                  | 39.8          |
|    value_loss           | 1.5e-06       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3523, episode: 1015
begin_total_asset: 200.00
end_total_asset: 358.97
total_reward: 158.97
total_cost: 3.56
total_trades: 46645
Sharpe: 0.607
=================================
Reseting Environment StartDay: 1094, ResetDay: 2774,Episode: 1016
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2737, ResetDay: 4417,Episode: 1017
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 834           |
|    time_elapsed         | 18873         |
|    total_timesteps      | 1708032       |
| train/                  |               |
|    approx_kl            | 116.07323     |
|    clip_fraction        | 0.448         |
|    clip_range           | 0.2           |
|    entropy_loss         | -142          |
|    explained_variance   | -0.0206       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.37         |
|    n_updates            | 8330          |
|    policy_gradient_loss | 0.0218        |
|    reward               | 0.00013104783 |
|    std                  | 39.9          |
|    value_loss           | 5.9e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2591, ResetDay: 4271,Episode: 1018
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 835            |
|    time_elapsed         | 18896          |
|    total_timesteps      | 1710080        |
| train/                  |                |
|    approx_kl            | 118.321434     |
|    clip_fraction        | 0.456          |
|    clip_range           | 0.2            |
|    entropy_loss         | -142           |
|    explained_variance   | 0.0262         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.42          |
|    n_updates            | 8340           |
|    policy_gradient_loss | 0.0264         |
|    reward               | -3.3178712e-05 |
|    std                  | 40             |
|    value_loss           | 5.07e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1922, ResetDay: 3602,Episode: 1019
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 836            |
|    time_elapsed         | 18918          |
|    total_timesteps      | 1712128        |
| train/                  |                |
|    approx_kl            | 117.08118      |
|    clip_fraction        | 0.456          |
|    clip_range           | 0.2            |
|    entropy_loss         | -142           |
|    explained_variance   | -0.0141        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.43          |
|    n_updates            | 8350           |
|    policy_gradient_loss | 0.0198         |
|    reward               | -0.00016374435 |
|    std                  | 40.2           |
|    value_loss           | 1.64e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2452, ResetDay: 4132,Episode: 1020
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 837           |
|    time_elapsed         | 18941         |
|    total_timesteps      | 1714176       |
| train/                  |               |
|    approx_kl            | 119.65161     |
|    clip_fraction        | 0.445         |
|    clip_range           | 0.2           |
|    entropy_loss         | -142          |
|    explained_variance   | -0.00735      |
|    learning_rate        | 0.00025       |
|    loss                 | -1.36         |
|    n_updates            | 8360          |
|    policy_gradient_loss | 0.0255        |
|    reward               | 0.00037948493 |
|    std                  | 40.3          |
|    value_loss           | 1.24e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4132, episode: 1020
begin_total_asset: 200.00
end_total_asset: 349.55
total_reward: 149.55
total_cost: 7.43
total_trades: 46666
Sharpe: 0.473
=================================
Reseting Environment StartDay: 2307, ResetDay: 3987,Episode: 1021
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 838          |
|    time_elapsed         | 18964        |
|    total_timesteps      | 1716224      |
| train/                  |              |
|    approx_kl            | 118.78727    |
|    clip_fraction        | 0.415        |
|    clip_range           | 0.2          |
|    entropy_loss         | -142         |
|    explained_variance   | -0.171       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.41        |
|    n_updates            | 8370         |
|    policy_gradient_loss | 0.0198       |
|    reward               | -0.000163385 |
|    std                  | 40.4         |
|    value_loss           | 5.62e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1656, ResetDay: 3336,Episode: 1022
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 787, ResetDay: 2467,Episode: 1023
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 839          |
|    time_elapsed         | 18986        |
|    total_timesteps      | 1718272      |
| train/                  |              |
|    approx_kl            | 121.3928     |
|    clip_fraction        | 0.432        |
|    clip_range           | 0.2          |
|    entropy_loss         | -142         |
|    explained_variance   | 0.0556       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.41        |
|    n_updates            | 8380         |
|    policy_gradient_loss | 0.0203       |
|    reward               | 0.0001683464 |
|    std                  | 40.5         |
|    value_loss           | 9.31e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 930, ResetDay: 2610,Episode: 1024
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 840           |
|    time_elapsed         | 19009         |
|    total_timesteps      | 1720320       |
| train/                  |               |
|    approx_kl            | 121.04147     |
|    clip_fraction        | 0.443         |
|    clip_range           | 0.2           |
|    entropy_loss         | -143          |
|    explained_variance   | -0.313        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.41         |
|    n_updates            | 8390          |
|    policy_gradient_loss | 0.0265        |
|    reward               | 0.00025158454 |
|    std                  | 40.6          |
|    value_loss           | 5.24e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 888, ResetDay: 2568,Episode: 1025
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 841          |
|    time_elapsed         | 19031        |
|    total_timesteps      | 1722368      |
| train/                  |              |
|    approx_kl            | 121.53197    |
|    clip_fraction        | 0.442        |
|    clip_range           | 0.2          |
|    entropy_loss         | -143         |
|    explained_variance   | -0.0331      |
|    learning_rate        | 0.00025      |
|    loss                 | -1.4         |
|    n_updates            | 8400         |
|    policy_gradient_loss | 0.0242       |
|    reward               | -0.000378197 |
|    std                  | 40.6         |
|    value_loss           | 3.91e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2568, episode: 1025
begin_total_asset: 200.00
end_total_asset: 424.94
total_reward: 224.94
total_cost: 7.52
total_trades: 46625
Sharpe: 0.555
=================================
Reseting Environment StartDay: 57, ResetDay: 1737,Episode: 1026
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 842           |
|    time_elapsed         | 19054         |
|    total_timesteps      | 1724416       |
| train/                  |               |
|    approx_kl            | 121.747       |
|    clip_fraction        | 0.445         |
|    clip_range           | 0.2           |
|    entropy_loss         | -143          |
|    explained_variance   | 0.172         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.41         |
|    n_updates            | 8410          |
|    policy_gradient_loss | 0.0226        |
|    reward               | -9.096737e-05 |
|    std                  | 40.7          |
|    value_loss           | 7.45e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 928, ResetDay: 2608,Episode: 1027
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 509, ResetDay: 2189,Episode: 1028
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 843            |
|    time_elapsed         | 19076          |
|    total_timesteps      | 1726464        |
| train/                  |                |
|    approx_kl            | 121.43057      |
|    clip_fraction        | 0.447          |
|    clip_range           | 0.2            |
|    entropy_loss         | -143           |
|    explained_variance   | 0.0428         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.41          |
|    n_updates            | 8420           |
|    policy_gradient_loss | 0.0159         |
|    reward               | -0.00047452675 |
|    std                  | 40.9           |
|    value_loss           | 1.31e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 603, ResetDay: 2283,Episode: 1029
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 844           |
|    time_elapsed         | 19099         |
|    total_timesteps      | 1728512       |
| train/                  |               |
|    approx_kl            | 125.03984     |
|    clip_fraction        | 0.427         |
|    clip_range           | 0.2           |
|    entropy_loss         | -143          |
|    explained_variance   | 0.0788        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.4          |
|    n_updates            | 8430          |
|    policy_gradient_loss | 0.0195        |
|    reward               | -4.358578e-06 |
|    std                  | 40.9          |
|    value_loss           | 1.22e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2202, ResetDay: 3882,Episode: 1030
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 845            |
|    time_elapsed         | 19121          |
|    total_timesteps      | 1730560        |
| train/                  |                |
|    approx_kl            | 123.048935     |
|    clip_fraction        | 0.439          |
|    clip_range           | 0.2            |
|    entropy_loss         | -143           |
|    explained_variance   | -0.0026        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.44          |
|    n_updates            | 8440           |
|    policy_gradient_loss | 0.0239         |
|    reward               | -0.00026426392 |
|    std                  | 41             |
|    value_loss           | 8.84e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3882, episode: 1030
begin_total_asset: 200.00
end_total_asset: 345.17
total_reward: 145.17
total_cost: 7.43
total_trades: 46580
Sharpe: 0.454
=================================
Reseting Environment StartDay: 1340, ResetDay: 3020,Episode: 1031
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 846           |
|    time_elapsed         | 19144         |
|    total_timesteps      | 1732608       |
| train/                  |               |
|    approx_kl            | 124.44        |
|    clip_fraction        | 0.436         |
|    clip_range           | 0.2           |
|    entropy_loss         | -143          |
|    explained_variance   | -0.0639       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.38         |
|    n_updates            | 8450          |
|    policy_gradient_loss | 0.0277        |
|    reward               | 1.0678864e-05 |
|    std                  | 41.2          |
|    value_loss           | 4.05e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 250, ResetDay: 1930,Episode: 1032
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 847            |
|    time_elapsed         | 19166          |
|    total_timesteps      | 1734656        |
| train/                  |                |
|    approx_kl            | 125.1851       |
|    clip_fraction        | 0.425          |
|    clip_range           | 0.2            |
|    entropy_loss         | -143           |
|    explained_variance   | 0.0048         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.4           |
|    n_updates            | 8460           |
|    policy_gradient_loss | 0.0171         |
|    reward               | -0.00017323313 |
|    std                  | 41.4           |
|    value_loss           | 2.24e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2266, ResetDay: 3946,Episode: 1033
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 711, ResetDay: 2391,Episode: 1034
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 848            |
|    time_elapsed         | 19189          |
|    total_timesteps      | 1736704        |
| train/                  |                |
|    approx_kl            | 127.04965      |
|    clip_fraction        | 0.434          |
|    clip_range           | 0.2            |
|    entropy_loss         | -143           |
|    explained_variance   | -0.111         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.42          |
|    n_updates            | 8470           |
|    policy_gradient_loss | 0.0114         |
|    reward               | -1.2568951e-06 |
|    std                  | 41.5           |
|    value_loss           | 5.7e-07        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1561, ResetDay: 3241,Episode: 1035
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 849           |
|    time_elapsed         | 19211         |
|    total_timesteps      | 1738752       |
| train/                  |               |
|    approx_kl            | 127.51177     |
|    clip_fraction        | 0.46          |
|    clip_range           | 0.2           |
|    entropy_loss         | -143          |
|    explained_variance   | 0.0498        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.42         |
|    n_updates            | 8480          |
|    policy_gradient_loss | 0.0213        |
|    reward               | 6.5253065e-05 |
|    std                  | 41.5          |
|    value_loss           | 3.05e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3241, episode: 1035
begin_total_asset: 200.00
end_total_asset: 364.79
total_reward: 164.79
total_cost: 5.92
total_trades: 46529
Sharpe: 0.503
=================================
Reseting Environment StartDay: 1462, ResetDay: 3142,Episode: 1036
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 850           |
|    time_elapsed         | 19234         |
|    total_timesteps      | 1740800       |
| train/                  |               |
|    approx_kl            | 127.439804    |
|    clip_fraction        | 0.428         |
|    clip_range           | 0.2           |
|    entropy_loss         | -143          |
|    explained_variance   | -0.508        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.4          |
|    n_updates            | 8490          |
|    policy_gradient_loss | 0.0262        |
|    reward               | -6.045742e-05 |
|    std                  | 41.6          |
|    value_loss           | 4.6e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1345, ResetDay: 3025,Episode: 1037
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 851          |
|    time_elapsed         | 19256        |
|    total_timesteps      | 1742848      |
| train/                  |              |
|    approx_kl            | 127.094826   |
|    clip_fraction        | 0.435        |
|    clip_range           | 0.2          |
|    entropy_loss         | -143         |
|    explained_variance   | 0.055        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.38        |
|    n_updates            | 8500         |
|    policy_gradient_loss | 0.0256       |
|    reward               | 0.0001359478 |
|    std                  | 41.7         |
|    value_loss           | 5.16e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2684, ResetDay: 4364,Episode: 1038
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2580, ResetDay: 4260,Episode: 1039
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 852           |
|    time_elapsed         | 19279         |
|    total_timesteps      | 1744896       |
| train/                  |               |
|    approx_kl            | 127.16632     |
|    clip_fraction        | 0.431         |
|    clip_range           | 0.2           |
|    entropy_loss         | -143          |
|    explained_variance   | 0.00415       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.4          |
|    n_updates            | 8510          |
|    policy_gradient_loss | 0.0228        |
|    reward               | 0.00020602073 |
|    std                  | 41.8          |
|    value_loss           | 3.21e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2396, ResetDay: 4076,Episode: 1040
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 853           |
|    time_elapsed         | 19301         |
|    total_timesteps      | 1746944       |
| train/                  |               |
|    approx_kl            | 128.45181     |
|    clip_fraction        | 0.453         |
|    clip_range           | 0.2           |
|    entropy_loss         | -143          |
|    explained_variance   | 0.00722       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.41         |
|    n_updates            | 8520          |
|    policy_gradient_loss | 0.0142        |
|    reward               | 2.1730042e-05 |
|    std                  | 42            |
|    value_loss           | 1.46e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4076, episode: 1040
begin_total_asset: 200.00
end_total_asset: 318.09
total_reward: 118.09
total_cost: 6.86
total_trades: 46498
Sharpe: 0.394
=================================
Reseting Environment StartDay: 1754, ResetDay: 3434,Episode: 1041
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 854            |
|    time_elapsed         | 19324          |
|    total_timesteps      | 1748992        |
| train/                  |                |
|    approx_kl            | 129.84082      |
|    clip_fraction        | 0.438          |
|    clip_range           | 0.2            |
|    entropy_loss         | -144           |
|    explained_variance   | 0.0416         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.43          |
|    n_updates            | 8530           |
|    policy_gradient_loss | 0.017          |
|    reward               | -8.0322265e-05 |
|    std                  | 42.2           |
|    value_loss           | 1.02e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2798, ResetDay: 4478,Episode: 1042
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 855            |
|    time_elapsed         | 19346          |
|    total_timesteps      | 1751040        |
| train/                  |                |
|    approx_kl            | 130.72964      |
|    clip_fraction        | 0.442          |
|    clip_range           | 0.2            |
|    entropy_loss         | -144           |
|    explained_variance   | -0.0401        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.41          |
|    n_updates            | 8540           |
|    policy_gradient_loss | 0.0278         |
|    reward               | -3.9457704e-05 |
|    std                  | 42.3           |
|    value_loss           | 1.06e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 245, ResetDay: 1925,Episode: 1043
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 856           |
|    time_elapsed         | 19369         |
|    total_timesteps      | 1753088       |
| train/                  |               |
|    approx_kl            | 130.45673     |
|    clip_fraction        | 0.428         |
|    clip_range           | 0.2           |
|    entropy_loss         | -144          |
|    explained_variance   | 0.0494        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.42         |
|    n_updates            | 8550          |
|    policy_gradient_loss | 0.0164        |
|    reward               | 0.00033279342 |
|    std                  | 42.5          |
|    value_loss           | 8.09e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2028, ResetDay: 3708,Episode: 1044
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 900, ResetDay: 2580,Episode: 1045
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 857           |
|    time_elapsed         | 19391         |
|    total_timesteps      | 1755136       |
| train/                  |               |
|    approx_kl            | 132.76987     |
|    clip_fraction        | 0.44          |
|    clip_range           | 0.2           |
|    entropy_loss         | -144          |
|    explained_variance   | -0.179        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.41         |
|    n_updates            | 8560          |
|    policy_gradient_loss | 0.0261        |
|    reward               | 5.9509945e-05 |
|    std                  | 42.6          |
|    value_loss           | 9.76e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2580, episode: 1045
begin_total_asset: 200.00
end_total_asset: 253.20
total_reward: 53.20
total_cost: 10.66
total_trades: 46498
Sharpe: 0.315
=================================
Reseting Environment StartDay: 1948, ResetDay: 3628,Episode: 1046
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 858            |
|    time_elapsed         | 19420          |
|    total_timesteps      | 1757184        |
| train/                  |                |
|    approx_kl            | 133.4003       |
|    clip_fraction        | 0.412          |
|    clip_range           | 0.2            |
|    entropy_loss         | -144           |
|    explained_variance   | -0.0179        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.42          |
|    n_updates            | 8570           |
|    policy_gradient_loss | 0.0164         |
|    reward               | -2.1600152e-05 |
|    std                  | 42.8           |
|    value_loss           | 2.82e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1274, ResetDay: 2954,Episode: 1047
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 859            |
|    time_elapsed         | 19443          |
|    total_timesteps      | 1759232        |
| train/                  |                |
|    approx_kl            | 134.90347      |
|    clip_fraction        | 0.43           |
|    clip_range           | 0.2            |
|    entropy_loss         | -144           |
|    explained_variance   | -0.245         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.4           |
|    n_updates            | 8580           |
|    policy_gradient_loss | 0.0224         |
|    reward               | -3.3195876e-05 |
|    std                  | 42.9           |
|    value_loss           | 4.8e-07        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2242, ResetDay: 3922,Episode: 1048
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 860            |
|    time_elapsed         | 19466          |
|    total_timesteps      | 1761280        |
| train/                  |                |
|    approx_kl            | 135.07932      |
|    clip_fraction        | 0.43           |
|    clip_range           | 0.2            |
|    entropy_loss         | -144           |
|    explained_variance   | 0.00738        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.42          |
|    n_updates            | 8590           |
|    policy_gradient_loss | 0.0157         |
|    reward               | -0.00014193726 |
|    std                  | 43.1           |
|    value_loss           | 9.67e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2265, ResetDay: 3945,Episode: 1049
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 861           |
|    time_elapsed         | 19488         |
|    total_timesteps      | 1763328       |
| train/                  |               |
|    approx_kl            | 135.76901     |
|    clip_fraction        | 0.423         |
|    clip_range           | 0.2           |
|    entropy_loss         | -144          |
|    explained_variance   | 0.042         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.43         |
|    n_updates            | 8600          |
|    policy_gradient_loss | 0.0172        |
|    reward               | 0.00016820297 |
|    std                  | 43.2          |
|    value_loss           | 6.91e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2768, ResetDay: 4448,Episode: 1050
Environment reached Terminal state as number of trading days reached limit!!
day: 4448, episode: 1050
begin_total_asset: 200.00
end_total_asset: 261.90
total_reward: 61.90
total_cost: 8.50
total_trades: 46434
Sharpe: 0.290
=================================
Reseting Environment StartDay: 734, ResetDay: 2414,Episode: 1051
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 862           |
|    time_elapsed         | 19511         |
|    total_timesteps      | 1765376       |
| train/                  |               |
|    approx_kl            | 136.31308     |
|    clip_fraction        | 0.418         |
|    clip_range           | 0.2           |
|    entropy_loss         | -144          |
|    explained_variance   | 0.0304        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.45         |
|    n_updates            | 8610          |
|    policy_gradient_loss | 0.0102        |
|    reward               | 4.3198157e-05 |
|    std                  | 43.3          |
|    value_loss           | 2.03e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 539, ResetDay: 2219,Episode: 1052
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 863            |
|    time_elapsed         | 19534          |
|    total_timesteps      | 1767424        |
| train/                  |                |
|    approx_kl            | 137.95836      |
|    clip_fraction        | 0.426          |
|    clip_range           | 0.2            |
|    entropy_loss         | -144           |
|    explained_variance   | -0.145         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.4           |
|    n_updates            | 8620           |
|    policy_gradient_loss | 0.0282         |
|    reward               | -0.00023525793 |
|    std                  | 43.4           |
|    value_loss           | 1.21e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2792, ResetDay: 4472,Episode: 1053
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 864            |
|    time_elapsed         | 19556          |
|    total_timesteps      | 1769472        |
| train/                  |                |
|    approx_kl            | 138.10455      |
|    clip_fraction        | 0.408          |
|    clip_range           | 0.2            |
|    entropy_loss         | -144           |
|    explained_variance   | -0.965         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.44          |
|    n_updates            | 8630           |
|    policy_gradient_loss | 0.024          |
|    reward               | -0.00035250396 |
|    std                  | 43.6           |
|    value_loss           | 3.06e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 492, ResetDay: 2172,Episode: 1054
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 865            |
|    time_elapsed         | 19579          |
|    total_timesteps      | 1771520        |
| train/                  |                |
|    approx_kl            | 138.93248      |
|    clip_fraction        | 0.41           |
|    clip_range           | 0.2            |
|    entropy_loss         | -145           |
|    explained_variance   | 0.0618         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.41          |
|    n_updates            | 8640           |
|    policy_gradient_loss | 0.0157         |
|    reward               | -4.2950345e-05 |
|    std                  | 43.6           |
|    value_loss           | 8.09e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1055, ResetDay: 2735,Episode: 1055
Environment reached Terminal state as number of trading days reached limit!!
day: 2735, episode: 1055
begin_total_asset: 200.00
end_total_asset: 277.20
total_reward: 77.20
total_cost: 10.07
total_trades: 46453
Sharpe: 0.356
=================================
Reseting Environment StartDay: 1949, ResetDay: 3629,Episode: 1056
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 866            |
|    time_elapsed         | 19601          |
|    total_timesteps      | 1773568        |
| train/                  |                |
|    approx_kl            | 137.81488      |
|    clip_fraction        | 0.433          |
|    clip_range           | 0.2            |
|    entropy_loss         | -145           |
|    explained_variance   | 0.0085         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.44          |
|    n_updates            | 8650           |
|    policy_gradient_loss | 0.0238         |
|    reward               | -0.00016842574 |
|    std                  | 43.8           |
|    value_loss           | 9.99e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1569, ResetDay: 3249,Episode: 1057
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 867           |
|    time_elapsed         | 19623         |
|    total_timesteps      | 1775616       |
| train/                  |               |
|    approx_kl            | 140.16122     |
|    clip_fraction        | 0.411         |
|    clip_range           | 0.2           |
|    entropy_loss         | -145          |
|    explained_variance   | -0.0131       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.42         |
|    n_updates            | 8660          |
|    policy_gradient_loss | 0.0257        |
|    reward               | -0.0002096199 |
|    std                  | 43.8          |
|    value_loss           | 8.2e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1798, ResetDay: 3478,Episode: 1058
-----------------------------------------
| time/                   |             |
|    fps                  | 90          |
|    iterations           | 868         |
|    time_elapsed         | 19646       |
|    total_timesteps      | 1777664     |
| train/                  |             |
|    approx_kl            | 141.18874   |
|    clip_fraction        | 0.424       |
|    clip_range           | 0.2         |
|    entropy_loss         | -145        |
|    explained_variance   | 0.00251     |
|    learning_rate        | 0.00025     |
|    loss                 | -1.46       |
|    n_updates            | 8670        |
|    policy_gradient_loss | 0.0206      |
|    reward               | 9.63356e-05 |
|    std                  | 43.9        |
|    value_loss           | 1.67e-06    |
-----------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 73, ResetDay: 1753,Episode: 1059
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 869          |
|    time_elapsed         | 19668        |
|    total_timesteps      | 1779712      |
| train/                  |              |
|    approx_kl            | 141.75238    |
|    clip_fraction        | 0.414        |
|    clip_range           | 0.2          |
|    entropy_loss         | -145         |
|    explained_variance   | -0.0147      |
|    learning_rate        | 0.00025      |
|    loss                 | -1.47        |
|    n_updates            | 8680         |
|    policy_gradient_loss | 0.0266       |
|    reward               | 0.0005410898 |
|    std                  | 44           |
|    value_loss           | 3.65e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2318, ResetDay: 3998,Episode: 1060
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 870           |
|    time_elapsed         | 19691         |
|    total_timesteps      | 1781760       |
| train/                  |               |
|    approx_kl            | 142.0188      |
|    clip_fraction        | 0.421         |
|    clip_range           | 0.2           |
|    entropy_loss         | -145          |
|    explained_variance   | 0.0189        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.47         |
|    n_updates            | 8690          |
|    policy_gradient_loss | 0.0178        |
|    reward               | 0.00080307655 |
|    std                  | 44.2          |
|    value_loss           | 1.2e-06       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3998, episode: 1060
begin_total_asset: 200.00
end_total_asset: 636.43
total_reward: 436.43
total_cost: 15.76
total_trades: 46368
Sharpe: 0.654
=================================
Reseting Environment StartDay: 808, ResetDay: 2488,Episode: 1061
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1858, ResetDay: 3538,Episode: 1062
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 871           |
|    time_elapsed         | 19714         |
|    total_timesteps      | 1783808       |
| train/                  |               |
|    approx_kl            | 143.2537      |
|    clip_fraction        | 0.418         |
|    clip_range           | 0.2           |
|    entropy_loss         | -145          |
|    explained_variance   | 0.039         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.45         |
|    n_updates            | 8700          |
|    policy_gradient_loss | 0.0139        |
|    reward               | 0.00011555195 |
|    std                  | 44.4          |
|    value_loss           | 2.92e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1303, ResetDay: 2983,Episode: 1063
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 872           |
|    time_elapsed         | 19736         |
|    total_timesteps      | 1785856       |
| train/                  |               |
|    approx_kl            | 144.69756     |
|    clip_fraction        | 0.419         |
|    clip_range           | 0.2           |
|    entropy_loss         | -145          |
|    explained_variance   | -0.554        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.4          |
|    n_updates            | 8710          |
|    policy_gradient_loss | 0.0287        |
|    reward               | 0.00015875683 |
|    std                  | 44.6          |
|    value_loss           | 8.14e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 97, ResetDay: 1777,Episode: 1064
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 873            |
|    time_elapsed         | 19759          |
|    total_timesteps      | 1787904        |
| train/                  |                |
|    approx_kl            | 144.99414      |
|    clip_fraction        | 0.424          |
|    clip_range           | 0.2            |
|    entropy_loss         | -145           |
|    explained_variance   | 0.167          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.41          |
|    n_updates            | 8720           |
|    policy_gradient_loss | 0.0123         |
|    reward               | -0.00021552281 |
|    std                  | 44.7           |
|    value_loss           | 9.31e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2250, ResetDay: 3930,Episode: 1065
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 874           |
|    time_elapsed         | 19781         |
|    total_timesteps      | 1789952       |
| train/                  |               |
|    approx_kl            | 145.85797     |
|    clip_fraction        | 0.418         |
|    clip_range           | 0.2           |
|    entropy_loss         | -145          |
|    explained_variance   | -0.139        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.43         |
|    n_updates            | 8730          |
|    policy_gradient_loss | 0.0174        |
|    reward               | -0.0043614223 |
|    std                  | 44.7          |
|    value_loss           | 9.54e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3930, episode: 1065
begin_total_asset: 200.00
end_total_asset: 584.31
total_reward: 384.31
total_cost: 23.76
total_trades: 46363
Sharpe: 0.634
=================================
Reseting Environment StartDay: 1931, ResetDay: 3611,Episode: 1066
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 592, ResetDay: 2272,Episode: 1067
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 875            |
|    time_elapsed         | 19804          |
|    total_timesteps      | 1792000        |
| train/                  |                |
|    approx_kl            | 146.37538      |
|    clip_fraction        | 0.412          |
|    clip_range           | 0.2            |
|    entropy_loss         | -145           |
|    explained_variance   | 0.0192         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.45          |
|    n_updates            | 8740           |
|    policy_gradient_loss | 0.0158         |
|    reward               | -2.8972625e-05 |
|    std                  | 44.9           |
|    value_loss           | 3.11e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 772, ResetDay: 2452,Episode: 1068
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 876          |
|    time_elapsed         | 19827        |
|    total_timesteps      | 1794048      |
| train/                  |              |
|    approx_kl            | 145.61276    |
|    clip_fraction        | 0.412        |
|    clip_range           | 0.2          |
|    entropy_loss         | -145         |
|    explained_variance   | -0.0171      |
|    learning_rate        | 0.00025      |
|    loss                 | -1.43        |
|    n_updates            | 8750         |
|    policy_gradient_loss | 0.0184       |
|    reward               | 0.0002084508 |
|    std                  | 45.2         |
|    value_loss           | 3.31e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 915, ResetDay: 2595,Episode: 1069
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 877           |
|    time_elapsed         | 19849         |
|    total_timesteps      | 1796096       |
| train/                  |               |
|    approx_kl            | 148.67404     |
|    clip_fraction        | 0.414         |
|    clip_range           | 0.2           |
|    entropy_loss         | -146          |
|    explained_variance   | -0.869        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.42         |
|    n_updates            | 8760          |
|    policy_gradient_loss | 0.0151        |
|    reward               | 0.00020756492 |
|    std                  | 45.4          |
|    value_loss           | 4.35e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1311, ResetDay: 2991,Episode: 1070
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 878           |
|    time_elapsed         | 19872         |
|    total_timesteps      | 1798144       |
| train/                  |               |
|    approx_kl            | 151.48561     |
|    clip_fraction        | 0.397         |
|    clip_range           | 0.2           |
|    entropy_loss         | -146          |
|    explained_variance   | 0.0757        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.45         |
|    n_updates            | 8770          |
|    policy_gradient_loss | 0.0117        |
|    reward               | 0.00016679191 |
|    std                  | 45.5          |
|    value_loss           | 3.96e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2991, episode: 1070
begin_total_asset: 200.00
end_total_asset: 232.93
total_reward: 32.93
total_cost: 6.35
total_trades: 46244
Sharpe: 0.249
=================================
Reseting Environment StartDay: 2483, ResetDay: 4163,Episode: 1071
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 879           |
|    time_elapsed         | 19894         |
|    total_timesteps      | 1800192       |
| train/                  |               |
|    approx_kl            | 151.21136     |
|    clip_fraction        | 0.39          |
|    clip_range           | 0.2           |
|    entropy_loss         | -146          |
|    explained_variance   | 0.0995        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.45         |
|    n_updates            | 8780          |
|    policy_gradient_loss | 0.00599       |
|    reward               | 0.00069240836 |
|    std                  | 45.6          |
|    value_loss           | 3.81e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 295, ResetDay: 1975,Episode: 1072
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 281, ResetDay: 1961,Episode: 1073
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 880           |
|    time_elapsed         | 19917         |
|    total_timesteps      | 1802240       |
| train/                  |               |
|    approx_kl            | 153.27728     |
|    clip_fraction        | 0.398         |
|    clip_range           | 0.2           |
|    entropy_loss         | -146          |
|    explained_variance   | -0.0588       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.43         |
|    n_updates            | 8790          |
|    policy_gradient_loss | 0.0192        |
|    reward               | -0.0002030325 |
|    std                  | 45.7          |
|    value_loss           | 9.79e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2250, ResetDay: 3930,Episode: 1074
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 881            |
|    time_elapsed         | 19939          |
|    total_timesteps      | 1804288        |
| train/                  |                |
|    approx_kl            | 152.3599       |
|    clip_fraction        | 0.411          |
|    clip_range           | 0.2            |
|    entropy_loss         | -146           |
|    explained_variance   | -0.228         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.42          |
|    n_updates            | 8800           |
|    policy_gradient_loss | 0.0142         |
|    reward               | -0.00010809403 |
|    std                  | 45.7           |
|    value_loss           | 1.18e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 87, ResetDay: 1767,Episode: 1075
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 882           |
|    time_elapsed         | 19962         |
|    total_timesteps      | 1806336       |
| train/                  |               |
|    approx_kl            | 152.36703     |
|    clip_fraction        | 0.413         |
|    clip_range           | 0.2           |
|    entropy_loss         | -146          |
|    explained_variance   | 0.143         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.48         |
|    n_updates            | 8810          |
|    policy_gradient_loss | 0.0101        |
|    reward               | 0.00050459174 |
|    std                  | 45.9          |
|    value_loss           | 1.32e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 1767, episode: 1075
begin_total_asset: 200.00
end_total_asset: 579.38
total_reward: 379.38
total_cost: 10.28
total_trades: 46347
Sharpe: 0.641
=================================
Reseting Environment StartDay: 355, ResetDay: 2035,Episode: 1076
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 883           |
|    time_elapsed         | 19984         |
|    total_timesteps      | 1808384       |
| train/                  |               |
|    approx_kl            | 154.45323     |
|    clip_fraction        | 0.394         |
|    clip_range           | 0.2           |
|    entropy_loss         | -146          |
|    explained_variance   | 0.0092        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.45         |
|    n_updates            | 8820          |
|    policy_gradient_loss | 0.0247        |
|    reward               | 0.00024347658 |
|    std                  | 46.1          |
|    value_loss           | 3.04e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1899, ResetDay: 3579,Episode: 1077
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 884           |
|    time_elapsed         | 20007         |
|    total_timesteps      | 1810432       |
| train/                  |               |
|    approx_kl            | 153.9618      |
|    clip_fraction        | 0.416         |
|    clip_range           | 0.2           |
|    entropy_loss         | -146          |
|    explained_variance   | 0.0812        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.48         |
|    n_updates            | 8830          |
|    policy_gradient_loss | 0.0142        |
|    reward               | -0.0013450196 |
|    std                  | 46.2          |
|    value_loss           | 1.85e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2038, ResetDay: 3718,Episode: 1078
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 285, ResetDay: 1965,Episode: 1079
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 885            |
|    time_elapsed         | 20029          |
|    total_timesteps      | 1812480        |
| train/                  |                |
|    approx_kl            | 155.34653      |
|    clip_fraction        | 0.394          |
|    clip_range           | 0.2            |
|    entropy_loss         | -146           |
|    explained_variance   | 0.0986         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.44          |
|    n_updates            | 8840           |
|    policy_gradient_loss | 0.0126         |
|    reward               | -0.00019671879 |
|    std                  | 46.3           |
|    value_loss           | 1.42e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 479, ResetDay: 2159,Episode: 1080
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 886           |
|    time_elapsed         | 20052         |
|    total_timesteps      | 1814528       |
| train/                  |               |
|    approx_kl            | 155.35138     |
|    clip_fraction        | 0.408         |
|    clip_range           | 0.2           |
|    entropy_loss         | -146          |
|    explained_variance   | -0.0355       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.46         |
|    n_updates            | 8850          |
|    policy_gradient_loss | 0.0153        |
|    reward               | 0.00043838425 |
|    std                  | 46.6          |
|    value_loss           | 9.25e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2159, episode: 1080
begin_total_asset: 200.00
end_total_asset: 306.28
total_reward: 106.28
total_cost: 14.69
total_trades: 46285
Sharpe: 0.377
=================================
Reseting Environment StartDay: 2743, ResetDay: 4423,Episode: 1081
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 887           |
|    time_elapsed         | 20074         |
|    total_timesteps      | 1816576       |
| train/                  |               |
|    approx_kl            | 160.4671      |
|    clip_fraction        | 0.394         |
|    clip_range           | 0.2           |
|    entropy_loss         | -146          |
|    explained_variance   | -0.0182       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.48         |
|    n_updates            | 8860          |
|    policy_gradient_loss | 0.00985       |
|    reward               | -0.0005060333 |
|    std                  | 46.6          |
|    value_loss           | 1.32e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2512, ResetDay: 4192,Episode: 1082
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 888          |
|    time_elapsed         | 20097        |
|    total_timesteps      | 1818624      |
| train/                  |              |
|    approx_kl            | 157.8309     |
|    clip_fraction        | 0.407        |
|    clip_range           | 0.2          |
|    entropy_loss         | -146         |
|    explained_variance   | 0.0453       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.43        |
|    n_updates            | 8870         |
|    policy_gradient_loss | 0.0177       |
|    reward               | 9.433479e-05 |
|    std                  | 46.7         |
|    value_loss           | 1.35e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 884, ResetDay: 2564,Episode: 1083
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 428, ResetDay: 2108,Episode: 1084
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 889            |
|    time_elapsed         | 20120          |
|    total_timesteps      | 1820672        |
| train/                  |                |
|    approx_kl            | 159.44504      |
|    clip_fraction        | 0.406          |
|    clip_range           | 0.2            |
|    entropy_loss         | -147           |
|    explained_variance   | 0.0182         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.46          |
|    n_updates            | 8880           |
|    policy_gradient_loss | 0.00593        |
|    reward               | -0.00027793698 |
|    std                  | 46.9           |
|    value_loss           | 1.8e-06        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1578, ResetDay: 3258,Episode: 1085
---------------------------------------
| time/                   |           |
|    fps                  | 90        |
|    iterations           | 890       |
|    time_elapsed         | 20142     |
|    total_timesteps      | 1822720   |
| train/                  |           |
|    approx_kl            | 159.88437 |
|    clip_fraction        | 0.403     |
|    clip_range           | 0.2       |
|    entropy_loss         | -147      |
|    explained_variance   | -0.562    |
|    learning_rate        | 0.00025   |
|    loss                 | -1.41     |
|    n_updates            | 8890      |
|    policy_gradient_loss | 0.0217    |
|    reward               | 0.0       |
|    std                  | 46.9      |
|    value_loss           | 7.8e-07   |
---------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3258, episode: 1085
begin_total_asset: 200.00
end_total_asset: 430.47
total_reward: 230.47
total_cost: 7.19
total_trades: 46173
Sharpe: 0.596
=================================
Reseting Environment StartDay: 488, ResetDay: 2168,Episode: 1086
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 891          |
|    time_elapsed         | 20165        |
|    total_timesteps      | 1824768      |
| train/                  |              |
|    approx_kl            | 159.9722     |
|    clip_fraction        | 0.4          |
|    clip_range           | 0.2          |
|    entropy_loss         | -147         |
|    explained_variance   | 0.12         |
|    learning_rate        | 0.00025      |
|    loss                 | -1.46        |
|    n_updates            | 8900         |
|    policy_gradient_loss | 0.0196       |
|    reward               | 9.739113e-06 |
|    std                  | 47.1         |
|    value_loss           | 7.8e-07      |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1066, ResetDay: 2746,Episode: 1087
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 892           |
|    time_elapsed         | 20187         |
|    total_timesteps      | 1826816       |
| train/                  |               |
|    approx_kl            | 161.32133     |
|    clip_fraction        | 0.395         |
|    clip_range           | 0.2           |
|    entropy_loss         | -147          |
|    explained_variance   | 0.0978        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.48         |
|    n_updates            | 8910          |
|    policy_gradient_loss | 0.0132        |
|    reward               | -7.168846e-05 |
|    std                  | 47.3          |
|    value_loss           | 9.55e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 684, ResetDay: 2364,Episode: 1088
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 893            |
|    time_elapsed         | 20210          |
|    total_timesteps      | 1828864        |
| train/                  |                |
|    approx_kl            | 162.4241       |
|    clip_fraction        | 0.391          |
|    clip_range           | 0.2            |
|    entropy_loss         | -147           |
|    explained_variance   | 0.0173         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.47          |
|    n_updates            | 8920           |
|    policy_gradient_loss | 0.0194         |
|    reward               | -0.00011404038 |
|    std                  | 47.5           |
|    value_loss           | 4.68e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2146, ResetDay: 3826,Episode: 1089
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2313, ResetDay: 3993,Episode: 1090
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 894            |
|    time_elapsed         | 20233          |
|    total_timesteps      | 1830912        |
| train/                  |                |
|    approx_kl            | 164.1076       |
|    clip_fraction        | 0.39           |
|    clip_range           | 0.2            |
|    entropy_loss         | -147           |
|    explained_variance   | 0.158          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.44          |
|    n_updates            | 8930           |
|    policy_gradient_loss | 0.0181         |
|    reward               | -0.00036894492 |
|    std                  | 47.6           |
|    value_loss           | 1.11e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3993, episode: 1090
begin_total_asset: 200.00
end_total_asset: 286.77
total_reward: 86.77
total_cost: 7.92
total_trades: 46102
Sharpe: 0.344
=================================
Reseting Environment StartDay: 1640, ResetDay: 3320,Episode: 1091
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 895           |
|    time_elapsed         | 20255         |
|    total_timesteps      | 1832960       |
| train/                  |               |
|    approx_kl            | 164.59428     |
|    clip_fraction        | 0.399         |
|    clip_range           | 0.2           |
|    entropy_loss         | -147          |
|    explained_variance   | 0.0326        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.46         |
|    n_updates            | 8940          |
|    policy_gradient_loss | 0.0108        |
|    reward               | 9.1235735e-05 |
|    std                  | 47.7          |
|    value_loss           | 2.35e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2120, ResetDay: 3800,Episode: 1092
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 896           |
|    time_elapsed         | 20278         |
|    total_timesteps      | 1835008       |
| train/                  |               |
|    approx_kl            | 166.1741      |
|    clip_fraction        | 0.385         |
|    clip_range           | 0.2           |
|    entropy_loss         | -147          |
|    explained_variance   | 0.0333        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.44         |
|    n_updates            | 8950          |
|    policy_gradient_loss | 0.0151        |
|    reward               | 0.00016639271 |
|    std                  | 47.7          |
|    value_loss           | 9.13e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 164, ResetDay: 1844,Episode: 1093
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 897           |
|    time_elapsed         | 20300         |
|    total_timesteps      | 1837056       |
| train/                  |               |
|    approx_kl            | 165.07338     |
|    clip_fraction        | 0.392         |
|    clip_range           | 0.2           |
|    entropy_loss         | -147          |
|    explained_variance   | 0.0226        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.48         |
|    n_updates            | 8960          |
|    policy_gradient_loss | 0.0154        |
|    reward               | -0.0002021224 |
|    std                  | 47.9          |
|    value_loss           | 3.62e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1375, ResetDay: 3055,Episode: 1094
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2046, ResetDay: 3726,Episode: 1095
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 898           |
|    time_elapsed         | 20323         |
|    total_timesteps      | 1839104       |
| train/                  |               |
|    approx_kl            | 166.1769      |
|    clip_fraction        | 0.384         |
|    clip_range           | 0.2           |
|    entropy_loss         | -147          |
|    explained_variance   | 0.00324       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.47         |
|    n_updates            | 8970          |
|    policy_gradient_loss | 0.0224        |
|    reward               | -6.061592e-05 |
|    std                  | 48            |
|    value_loss           | 1.6e-06       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3726, episode: 1095
begin_total_asset: 200.00
end_total_asset: 390.50
total_reward: 190.50
total_cost: 8.88
total_trades: 46169
Sharpe: 0.572
=================================
Reseting Environment StartDay: 630, ResetDay: 2310,Episode: 1096
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 899           |
|    time_elapsed         | 20345         |
|    total_timesteps      | 1841152       |
| train/                  |               |
|    approx_kl            | 166.30907     |
|    clip_fraction        | 0.417         |
|    clip_range           | 0.2           |
|    entropy_loss         | -147          |
|    explained_variance   | 0.0588        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.47         |
|    n_updates            | 8980          |
|    policy_gradient_loss | 0.0215        |
|    reward               | 3.1765176e-05 |
|    std                  | 48.2          |
|    value_loss           | 9.61e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 997, ResetDay: 2677,Episode: 1097
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 900          |
|    time_elapsed         | 20368        |
|    total_timesteps      | 1843200      |
| train/                  |              |
|    approx_kl            | 168.30939    |
|    clip_fraction        | 0.39         |
|    clip_range           | 0.2          |
|    entropy_loss         | -147         |
|    explained_variance   | 0.0588       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.48        |
|    n_updates            | 8990         |
|    policy_gradient_loss | 0.0181       |
|    reward               | 0.0001748066 |
|    std                  | 48.3         |
|    value_loss           | 9.62e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 928, ResetDay: 2608,Episode: 1098
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 901            |
|    time_elapsed         | 20391          |
|    total_timesteps      | 1845248        |
| train/                  |                |
|    approx_kl            | 168.26263      |
|    clip_fraction        | 0.397          |
|    clip_range           | 0.2            |
|    entropy_loss         | -147           |
|    explained_variance   | -0.0149        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.47          |
|    n_updates            | 9000           |
|    policy_gradient_loss | 0.0172         |
|    reward               | -0.00019647065 |
|    std                  | 48.4           |
|    value_loss           | 4.65e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2050, ResetDay: 3730,Episode: 1099
---------------------------------------------
| time/                   |                 |
|    fps                  | 90              |
|    iterations           | 902             |
|    time_elapsed         | 20413           |
|    total_timesteps      | 1847296         |
| train/                  |                 |
|    approx_kl            | 171.15683       |
|    clip_fraction        | 0.385           |
|    clip_range           | 0.2             |
|    entropy_loss         | -148            |
|    explained_variance   | 0.164           |
|    learning_rate        | 0.00025         |
|    loss                 | -1.41           |
|    n_updates            | 9010            |
|    policy_gradient_loss | 0.0219          |
|    reward               | -0.000100015255 |
|    std                  | 48.4            |
|    value_loss           | 9.26e-07        |
---------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 569, ResetDay: 2249,Episode: 1100
Environment reached Terminal state as number of trading days reached limit!!
day: 2249, episode: 1100
begin_total_asset: 200.00
end_total_asset: 182.18
total_reward: -17.82
total_cost: 8.73
total_trades: 46076
Sharpe: 0.150
=================================
Reseting Environment StartDay: 166, ResetDay: 1846,Episode: 1101
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 903           |
|    time_elapsed         | 20436         |
|    total_timesteps      | 1849344       |
| train/                  |               |
|    approx_kl            | 169.83719     |
|    clip_fraction        | 0.392         |
|    clip_range           | 0.2           |
|    entropy_loss         | -148          |
|    explained_variance   | 0.116         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.46         |
|    n_updates            | 9020          |
|    policy_gradient_loss | 0.0166        |
|    reward               | 0.00018587858 |
|    std                  | 48.6          |
|    value_loss           | 7.67e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1064, ResetDay: 2744,Episode: 1102
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 904           |
|    time_elapsed         | 20459         |
|    total_timesteps      | 1851392       |
| train/                  |               |
|    approx_kl            | 172.18382     |
|    clip_fraction        | 0.387         |
|    clip_range           | 0.2           |
|    entropy_loss         | -148          |
|    explained_variance   | -0.448        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.47         |
|    n_updates            | 9030          |
|    policy_gradient_loss | 0.00812       |
|    reward               | -6.611061e-05 |
|    std                  | 48.7          |
|    value_loss           | 5.44e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 461, ResetDay: 2141,Episode: 1103
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 905          |
|    time_elapsed         | 20481        |
|    total_timesteps      | 1853440      |
| train/                  |              |
|    approx_kl            | 170.96527    |
|    clip_fraction        | 0.373        |
|    clip_range           | 0.2          |
|    entropy_loss         | -148         |
|    explained_variance   | 0.0768       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.48        |
|    n_updates            | 9040         |
|    policy_gradient_loss | 0.014        |
|    reward               | 8.142872e-05 |
|    std                  | 48.9         |
|    value_loss           | 2.12e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1778, ResetDay: 3458,Episode: 1104
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 906           |
|    time_elapsed         | 20504         |
|    total_timesteps      | 1855488       |
| train/                  |               |
|    approx_kl            | 172.08139     |
|    clip_fraction        | 0.387         |
|    clip_range           | 0.2           |
|    entropy_loss         | -148          |
|    explained_variance   | -0.0587       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.48         |
|    n_updates            | 9050          |
|    policy_gradient_loss | 0.0188        |
|    reward               | 0.00016565647 |
|    std                  | 49.2          |
|    value_loss           | 1.22e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 749, ResetDay: 2429,Episode: 1105
Environment reached Terminal state as number of trading days reached limit!!
day: 2429, episode: 1105
begin_total_asset: 200.00
end_total_asset: 211.97
total_reward: 11.97
total_cost: 10.29
total_trades: 46126
Sharpe: 0.222
=================================
Reseting Environment StartDay: 417, ResetDay: 2097,Episode: 1106
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 907           |
|    time_elapsed         | 20526         |
|    total_timesteps      | 1857536       |
| train/                  |               |
|    approx_kl            | 177.05304     |
|    clip_fraction        | 0.383         |
|    clip_range           | 0.2           |
|    entropy_loss         | -148          |
|    explained_variance   | 0.121         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.49         |
|    n_updates            | 9060          |
|    policy_gradient_loss | 0.0112        |
|    reward               | 0.00012912435 |
|    std                  | 49.2          |
|    value_loss           | 7.14e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2582, ResetDay: 4262,Episode: 1107
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 908            |
|    time_elapsed         | 20549          |
|    total_timesteps      | 1859584        |
| train/                  |                |
|    approx_kl            | 176.58797      |
|    clip_fraction        | 0.387          |
|    clip_range           | 0.2            |
|    entropy_loss         | -148           |
|    explained_variance   | 0.00624        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.44          |
|    n_updates            | 9070           |
|    policy_gradient_loss | 0.0197         |
|    reward               | -0.00022824688 |
|    std                  | 49.2           |
|    value_loss           | 9.73e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2427, ResetDay: 4107,Episode: 1108
-----------------------------------------
| time/                   |             |
|    fps                  | 90          |
|    iterations           | 909         |
|    time_elapsed         | 20571       |
|    total_timesteps      | 1861632     |
| train/                  |             |
|    approx_kl            | 176.10268   |
|    clip_fraction        | 0.364       |
|    clip_range           | 0.2         |
|    entropy_loss         | -148        |
|    explained_variance   | 0.101       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.44       |
|    n_updates            | 9080        |
|    policy_gradient_loss | 0.0173      |
|    reward               | 3.48217e-05 |
|    std                  | 49.3        |
|    value_loss           | 7.01e-07    |
-----------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1013, ResetDay: 2693,Episode: 1109
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 910            |
|    time_elapsed         | 20594          |
|    total_timesteps      | 1863680        |
| train/                  |                |
|    approx_kl            | 175.81413      |
|    clip_fraction        | 0.386          |
|    clip_range           | 0.2            |
|    entropy_loss         | -148           |
|    explained_variance   | 0.0203         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.47          |
|    n_updates            | 9090           |
|    policy_gradient_loss | 0.0103         |
|    reward               | -0.00020507621 |
|    std                  | 49.5           |
|    value_loss           | 2.91e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1011, ResetDay: 2691,Episode: 1110
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 911           |
|    time_elapsed         | 20616         |
|    total_timesteps      | 1865728       |
| train/                  |               |
|    approx_kl            | 177.58806     |
|    clip_fraction        | 0.374         |
|    clip_range           | 0.2           |
|    entropy_loss         | -148          |
|    explained_variance   | -0.22         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.48         |
|    n_updates            | 9100          |
|    policy_gradient_loss | 0.0141        |
|    reward               | -4.368782e-05 |
|    std                  | 49.6          |
|    value_loss           | 9.41e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2691, episode: 1110
begin_total_asset: 200.00
end_total_asset: 367.61
total_reward: 167.61
total_cost: 16.87
total_trades: 46046
Sharpe: 0.499
=================================
Reseting Environment StartDay: 2156, ResetDay: 3836,Episode: 1111
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1299, ResetDay: 2979,Episode: 1112
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 912           |
|    time_elapsed         | 20639         |
|    total_timesteps      | 1867776       |
| train/                  |               |
|    approx_kl            | 178.58545     |
|    clip_fraction        | 0.377         |
|    clip_range           | 0.2           |
|    entropy_loss         | -148          |
|    explained_variance   | 0.0784        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.46         |
|    n_updates            | 9110          |
|    policy_gradient_loss | 0.0127        |
|    reward               | -0.0001503582 |
|    std                  | 49.8          |
|    value_loss           | 5.67e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1049, ResetDay: 2729,Episode: 1113
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 913          |
|    time_elapsed         | 20662        |
|    total_timesteps      | 1869824      |
| train/                  |              |
|    approx_kl            | 179.6894     |
|    clip_fraction        | 0.385        |
|    clip_range           | 0.2          |
|    entropy_loss         | -148         |
|    explained_variance   | 0.06         |
|    learning_rate        | 0.00025      |
|    loss                 | -1.44        |
|    n_updates            | 9120         |
|    policy_gradient_loss | 0.0133       |
|    reward               | 0.0002666479 |
|    std                  | 50           |
|    value_loss           | 1.95e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 375, ResetDay: 2055,Episode: 1114
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 914           |
|    time_elapsed         | 20684         |
|    total_timesteps      | 1871872       |
| train/                  |               |
|    approx_kl            | 179.79092     |
|    clip_fraction        | 0.37          |
|    clip_range           | 0.2           |
|    entropy_loss         | -149          |
|    explained_variance   | -0.729        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.47         |
|    n_updates            | 9130          |
|    policy_gradient_loss | 0.0237        |
|    reward               | 0.00022561505 |
|    std                  | 50.1          |
|    value_loss           | 3.43e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 72, ResetDay: 1752,Episode: 1115
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 915          |
|    time_elapsed         | 20707        |
|    total_timesteps      | 1873920      |
| train/                  |              |
|    approx_kl            | 180.58855    |
|    clip_fraction        | 0.386        |
|    clip_range           | 0.2          |
|    entropy_loss         | -149         |
|    explained_variance   | 0.0872       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.47        |
|    n_updates            | 9140         |
|    policy_gradient_loss | 0.0142       |
|    reward               | -0.000567257 |
|    std                  | 50.3         |
|    value_loss           | 6.25e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 1752, episode: 1115
begin_total_asset: 200.00
end_total_asset: 608.65
total_reward: 408.65
total_cost: 13.86
total_trades: 46084
Sharpe: 0.681
=================================
Reseting Environment StartDay: 516, ResetDay: 2196,Episode: 1116
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 916            |
|    time_elapsed         | 20730          |
|    total_timesteps      | 1875968        |
| train/                  |                |
|    approx_kl            | 183.1467       |
|    clip_fraction        | 0.374          |
|    clip_range           | 0.2            |
|    entropy_loss         | -149           |
|    explained_variance   | 0.101          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.5           |
|    n_updates            | 9150           |
|    policy_gradient_loss | 0.00941        |
|    reward               | -0.00011788807 |
|    std                  | 50.4           |
|    value_loss           | 1.8e-06        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1075, ResetDay: 2755,Episode: 1117
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1430, ResetDay: 3110,Episode: 1118
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 917           |
|    time_elapsed         | 20753         |
|    total_timesteps      | 1878016       |
| train/                  |               |
|    approx_kl            | 183.20297     |
|    clip_fraction        | 0.365         |
|    clip_range           | 0.2           |
|    entropy_loss         | -149          |
|    explained_variance   | 0.129         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.5          |
|    n_updates            | 9160          |
|    policy_gradient_loss | 0.0184        |
|    reward               | -0.0002428957 |
|    std                  | 50.6          |
|    value_loss           | 2.78e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1158, ResetDay: 2838,Episode: 1119
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 918           |
|    time_elapsed         | 20775         |
|    total_timesteps      | 1880064       |
| train/                  |               |
|    approx_kl            | 184.19858     |
|    clip_fraction        | 0.386         |
|    clip_range           | 0.2           |
|    entropy_loss         | -149          |
|    explained_variance   | -0.356        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.47         |
|    n_updates            | 9170          |
|    policy_gradient_loss | 0.0252        |
|    reward               | -3.318443e-05 |
|    std                  | 50.9          |
|    value_loss           | 5.56e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 690, ResetDay: 2370,Episode: 1120
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 919            |
|    time_elapsed         | 20798          |
|    total_timesteps      | 1882112        |
| train/                  |                |
|    approx_kl            | 188.21167      |
|    clip_fraction        | 0.374          |
|    clip_range           | 0.2            |
|    entropy_loss         | -149           |
|    explained_variance   | -0.000961      |
|    learning_rate        | 0.00025        |
|    loss                 | -1.48          |
|    n_updates            | 9180           |
|    policy_gradient_loss | 0.0127         |
|    reward               | -4.8259353e-05 |
|    std                  | 51             |
|    value_loss           | 4.41e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2370, episode: 1120
begin_total_asset: 200.00
end_total_asset: 246.47
total_reward: 46.47
total_cost: 12.38
total_trades: 45948
Sharpe: 0.279
=================================
Reseting Environment StartDay: 1928, ResetDay: 3608,Episode: 1121
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 920          |
|    time_elapsed         | 20820        |
|    total_timesteps      | 1884160      |
| train/                  |              |
|    approx_kl            | 188.17792    |
|    clip_fraction        | 0.369        |
|    clip_range           | 0.2          |
|    entropy_loss         | -149         |
|    explained_variance   | 0.0167       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.5         |
|    n_updates            | 9190         |
|    policy_gradient_loss | 0.0158       |
|    reward               | 0.0011345139 |
|    std                  | 51.1         |
|    value_loss           | 5.49e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2252, ResetDay: 3932,Episode: 1122
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 516, ResetDay: 2196,Episode: 1123
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 921           |
|    time_elapsed         | 20843         |
|    total_timesteps      | 1886208       |
| train/                  |               |
|    approx_kl            | 189.40477     |
|    clip_fraction        | 0.355         |
|    clip_range           | 0.2           |
|    entropy_loss         | -149          |
|    explained_variance   | 0.076         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.47         |
|    n_updates            | 9200          |
|    policy_gradient_loss | 0.00442       |
|    reward               | 4.7244357e-05 |
|    std                  | 51.1          |
|    value_loss           | 6.73e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1359, ResetDay: 3039,Episode: 1124
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 922           |
|    time_elapsed         | 20865         |
|    total_timesteps      | 1888256       |
| train/                  |               |
|    approx_kl            | 188.90271     |
|    clip_fraction        | 0.375         |
|    clip_range           | 0.2           |
|    entropy_loss         | -149          |
|    explained_variance   | 0.0257        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.51         |
|    n_updates            | 9210          |
|    policy_gradient_loss | 0.0103        |
|    reward               | 0.00024086256 |
|    std                  | 51.3          |
|    value_loss           | 1.47e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1136, ResetDay: 2816,Episode: 1125
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 923           |
|    time_elapsed         | 20888         |
|    total_timesteps      | 1890304       |
| train/                  |               |
|    approx_kl            | 189.35802     |
|    clip_fraction        | 0.364         |
|    clip_range           | 0.2           |
|    entropy_loss         | -149          |
|    explained_variance   | -0.181        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.49         |
|    n_updates            | 9220          |
|    policy_gradient_loss | 0.0112        |
|    reward               | 6.3044834e-05 |
|    std                  | 51.5          |
|    value_loss           | 8.12e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2816, episode: 1125
begin_total_asset: 200.00
end_total_asset: 247.33
total_reward: 47.33
total_cost: 10.09
total_trades: 45915
Sharpe: 0.304
=================================
Reseting Environment StartDay: 2025, ResetDay: 3705,Episode: 1126
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 924           |
|    time_elapsed         | 20911         |
|    total_timesteps      | 1892352       |
| train/                  |               |
|    approx_kl            | 192.6177      |
|    clip_fraction        | 0.364         |
|    clip_range           | 0.2           |
|    entropy_loss         | -149          |
|    explained_variance   | 0.00682       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.48         |
|    n_updates            | 9230          |
|    policy_gradient_loss | 0.0141        |
|    reward               | 0.00045250473 |
|    std                  | 51.7          |
|    value_loss           | 4.55e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1701, ResetDay: 3381,Episode: 1127
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 925          |
|    time_elapsed         | 20933        |
|    total_timesteps      | 1894400      |
| train/                  |              |
|    approx_kl            | 192.93535    |
|    clip_fraction        | 0.378        |
|    clip_range           | 0.2          |
|    entropy_loss         | -149         |
|    explained_variance   | 0.141        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.5         |
|    n_updates            | 9240         |
|    policy_gradient_loss | 0.014        |
|    reward               | 0.0003515728 |
|    std                  | 51.9         |
|    value_loss           | 6.7e-07      |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1207, ResetDay: 2887,Episode: 1128
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1563, ResetDay: 3243,Episode: 1129
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 926           |
|    time_elapsed         | 20955         |
|    total_timesteps      | 1896448       |
| train/                  |               |
|    approx_kl            | 192.76544     |
|    clip_fraction        | 0.36          |
|    clip_range           | 0.2           |
|    entropy_loss         | -150          |
|    explained_variance   | 0.103         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.51         |
|    n_updates            | 9250          |
|    policy_gradient_loss | 0.0186        |
|    reward               | 0.00013174333 |
|    std                  | 52.2          |
|    value_loss           | 1.1e-06       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1754, ResetDay: 3434,Episode: 1130
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 927            |
|    time_elapsed         | 20978          |
|    total_timesteps      | 1898496        |
| train/                  |                |
|    approx_kl            | 198.52927      |
|    clip_fraction        | 0.356          |
|    clip_range           | 0.2            |
|    entropy_loss         | -150           |
|    explained_variance   | 0.128          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.5           |
|    n_updates            | 9260           |
|    policy_gradient_loss | 0.0213         |
|    reward               | 0.000102496146 |
|    std                  | 52.3           |
|    value_loss           | 4.51e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3434, episode: 1130
begin_total_asset: 200.00
end_total_asset: 246.65
total_reward: 46.65
total_cost: 4.38
total_trades: 45836
Sharpe: 0.299
=================================
Reseting Environment StartDay: 738, ResetDay: 2418,Episode: 1131
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 928           |
|    time_elapsed         | 21001         |
|    total_timesteps      | 1900544       |
| train/                  |               |
|    approx_kl            | 197.42621     |
|    clip_fraction        | 0.35          |
|    clip_range           | 0.2           |
|    entropy_loss         | -150          |
|    explained_variance   | 0.12          |
|    learning_rate        | 0.00025       |
|    loss                 | -1.51         |
|    n_updates            | 9270          |
|    policy_gradient_loss | 0.0127        |
|    reward               | -0.0002173378 |
|    std                  | 52.4          |
|    value_loss           | 5.77e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1964, ResetDay: 3644,Episode: 1132
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 929          |
|    time_elapsed         | 21024        |
|    total_timesteps      | 1902592      |
| train/                  |              |
|    approx_kl            | 198.7427     |
|    clip_fraction        | 0.359        |
|    clip_range           | 0.2          |
|    entropy_loss         | -150         |
|    explained_variance   | 0.0874       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.48        |
|    n_updates            | 9280         |
|    policy_gradient_loss | 0.0182       |
|    reward               | 0.0003221386 |
|    std                  | 52.6         |
|    value_loss           | 5.24e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 562, ResetDay: 2242,Episode: 1133
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 57, ResetDay: 1737,Episode: 1134
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 930           |
|    time_elapsed         | 21046         |
|    total_timesteps      | 1904640       |
| train/                  |               |
|    approx_kl            | 200.62927     |
|    clip_fraction        | 0.378         |
|    clip_range           | 0.2           |
|    entropy_loss         | -150          |
|    explained_variance   | 0.0706        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.45         |
|    n_updates            | 9290          |
|    policy_gradient_loss | 0.0109        |
|    reward               | -9.896419e-05 |
|    std                  | 52.8          |
|    value_loss           | 7.07e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2415, ResetDay: 4095,Episode: 1135
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 931          |
|    time_elapsed         | 21069        |
|    total_timesteps      | 1906688      |
| train/                  |              |
|    approx_kl            | 202.62979    |
|    clip_fraction        | 0.362        |
|    clip_range           | 0.2          |
|    entropy_loss         | -150         |
|    explained_variance   | 0.00216      |
|    learning_rate        | 0.00025      |
|    loss                 | -1.52        |
|    n_updates            | 9300         |
|    policy_gradient_loss | 0.0152       |
|    reward               | 0.0001870491 |
|    std                  | 52.9         |
|    value_loss           | 1.03e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4095, episode: 1135
begin_total_asset: 200.00
end_total_asset: 772.24
total_reward: 572.24
total_cost: 18.34
total_trades: 45835
Sharpe: 0.656
=================================
Reseting Environment StartDay: 352, ResetDay: 2032,Episode: 1136
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 932            |
|    time_elapsed         | 21091          |
|    total_timesteps      | 1908736        |
| train/                  |                |
|    approx_kl            | 203.19405      |
|    clip_fraction        | 0.361          |
|    clip_range           | 0.2            |
|    entropy_loss         | -150           |
|    explained_variance   | 0.0316         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.5           |
|    n_updates            | 9310           |
|    policy_gradient_loss | 0.0163         |
|    reward               | -0.00033151475 |
|    std                  | 52.9           |
|    value_loss           | 2.71e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1280, ResetDay: 2960,Episode: 1137
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 933           |
|    time_elapsed         | 21114         |
|    total_timesteps      | 1910784       |
| train/                  |               |
|    approx_kl            | 202.30878     |
|    clip_fraction        | 0.353         |
|    clip_range           | 0.2           |
|    entropy_loss         | -150          |
|    explained_variance   | 0.025         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.5          |
|    n_updates            | 9320          |
|    policy_gradient_loss | 0.0111        |
|    reward               | 4.1542244e-05 |
|    std                  | 53            |
|    value_loss           | 4.47e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2225, ResetDay: 3905,Episode: 1138
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 934          |
|    time_elapsed         | 21137        |
|    total_timesteps      | 1912832      |
| train/                  |              |
|    approx_kl            | 204.08997    |
|    clip_fraction        | 0.357        |
|    clip_range           | 0.2          |
|    entropy_loss         | -150         |
|    explained_variance   | -0.291       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.47        |
|    n_updates            | 9330         |
|    policy_gradient_loss | 0.016        |
|    reward               | 0.0017364166 |
|    std                  | 53           |
|    value_loss           | 9.56e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1739, ResetDay: 3419,Episode: 1139
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 105, ResetDay: 1785,Episode: 1140
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 935           |
|    time_elapsed         | 21160         |
|    total_timesteps      | 1914880       |
| train/                  |               |
|    approx_kl            | 200.52063     |
|    clip_fraction        | 0.353         |
|    clip_range           | 0.2           |
|    entropy_loss         | -150          |
|    explained_variance   | 0.0609        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.5          |
|    n_updates            | 9340          |
|    policy_gradient_loss | 0.0131        |
|    reward               | 5.1501607e-05 |
|    std                  | 53.3          |
|    value_loss           | 1.39e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 1785, episode: 1140
begin_total_asset: 200.00
end_total_asset: 379.56
total_reward: 179.56
total_cost: 9.67
total_trades: 45808
Sharpe: 0.499
=================================
Reseting Environment StartDay: 2673, ResetDay: 4353,Episode: 1141
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 936            |
|    time_elapsed         | 21182          |
|    total_timesteps      | 1916928        |
| train/                  |                |
|    approx_kl            | 204.4567       |
|    clip_fraction        | 0.338          |
|    clip_range           | 0.2            |
|    entropy_loss         | -150           |
|    explained_variance   | -0.129         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.43          |
|    n_updates            | 9350           |
|    policy_gradient_loss | 0.0243         |
|    reward               | -0.00029649658 |
|    std                  | 53.4           |
|    value_loss           | 9.21e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1455, ResetDay: 3135,Episode: 1142
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 937           |
|    time_elapsed         | 21205         |
|    total_timesteps      | 1918976       |
| train/                  |               |
|    approx_kl            | 207.1907      |
|    clip_fraction        | 0.358         |
|    clip_range           | 0.2           |
|    entropy_loss         | -150          |
|    explained_variance   | 0.111         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.49         |
|    n_updates            | 9360          |
|    policy_gradient_loss | 0.00677       |
|    reward               | -7.703209e-06 |
|    std                  | 53.5          |
|    value_loss           | 1.6e-06       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 962, ResetDay: 2642,Episode: 1143
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 938          |
|    time_elapsed         | 21228        |
|    total_timesteps      | 1921024      |
| train/                  |              |
|    approx_kl            | 208.40594    |
|    clip_fraction        | 0.358        |
|    clip_range           | 0.2          |
|    entropy_loss         | -150         |
|    explained_variance   | -0.0236      |
|    learning_rate        | 0.00025      |
|    loss                 | -1.49        |
|    n_updates            | 9370         |
|    policy_gradient_loss | 0.00982      |
|    reward               | 9.481506e-05 |
|    std                  | 53.6         |
|    value_loss           | 5.03e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1359, ResetDay: 3039,Episode: 1144
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2157, ResetDay: 3837,Episode: 1145
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 939           |
|    time_elapsed         | 21250         |
|    total_timesteps      | 1923072       |
| train/                  |               |
|    approx_kl            | 206.23846     |
|    clip_fraction        | 0.35          |
|    clip_range           | 0.2           |
|    entropy_loss         | -150          |
|    explained_variance   | -0.316        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.51         |
|    n_updates            | 9380          |
|    policy_gradient_loss | 0.0164        |
|    reward               | 2.9208373e-05 |
|    std                  | 53.8          |
|    value_loss           | 7.15e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3837, episode: 1145
begin_total_asset: 200.00
end_total_asset: 325.39
total_reward: 125.39
total_cost: 11.08
total_trades: 45749
Sharpe: 0.425
=================================
Reseting Environment StartDay: 338, ResetDay: 2018,Episode: 1146
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 940           |
|    time_elapsed         | 21273         |
|    total_timesteps      | 1925120       |
| train/                  |               |
|    approx_kl            | 207.8067      |
|    clip_fraction        | 0.353         |
|    clip_range           | 0.2           |
|    entropy_loss         | -151          |
|    explained_variance   | 0.126         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.49         |
|    n_updates            | 9390          |
|    policy_gradient_loss | 0.0159        |
|    reward               | 0.00025903096 |
|    std                  | 53.9          |
|    value_loss           | 8.18e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 939, ResetDay: 2619,Episode: 1147
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 941          |
|    time_elapsed         | 21295        |
|    total_timesteps      | 1927168      |
| train/                  |              |
|    approx_kl            | 209.4469     |
|    clip_fraction        | 0.335        |
|    clip_range           | 0.2          |
|    entropy_loss         | -151         |
|    explained_variance   | 0.0483       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.48        |
|    n_updates            | 9400         |
|    policy_gradient_loss | 0.00848      |
|    reward               | 9.840326e-05 |
|    std                  | 54           |
|    value_loss           | 1.25e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1750, ResetDay: 3430,Episode: 1148
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 942           |
|    time_elapsed         | 21318         |
|    total_timesteps      | 1929216       |
| train/                  |               |
|    approx_kl            | 209.09607     |
|    clip_fraction        | 0.342         |
|    clip_range           | 0.2           |
|    entropy_loss         | -151          |
|    explained_variance   | -0.106        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.49         |
|    n_updates            | 9410          |
|    policy_gradient_loss | 0.0198        |
|    reward               | -5.144005e-05 |
|    std                  | 54.2          |
|    value_loss           | 1.09e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1712, ResetDay: 3392,Episode: 1149
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 943          |
|    time_elapsed         | 21341        |
|    total_timesteps      | 1931264      |
| train/                  |              |
|    approx_kl            | 210.75839    |
|    clip_fraction        | 0.344        |
|    clip_range           | 0.2          |
|    entropy_loss         | -151         |
|    explained_variance   | 0.138        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.49        |
|    n_updates            | 9420         |
|    policy_gradient_loss | 0.0209       |
|    reward               | 0.0005133175 |
|    std                  | 54.5         |
|    value_loss           | 9.23e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 440, ResetDay: 2120,Episode: 1150
Environment reached Terminal state as number of trading days reached limit!!
day: 2120, episode: 1150
begin_total_asset: 200.00
end_total_asset: 271.30
total_reward: 71.30
total_cost: 12.50
total_trades: 45808
Sharpe: 0.349
=================================
Reseting Environment StartDay: 2701, ResetDay: 4381,Episode: 1151
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 944           |
|    time_elapsed         | 21363         |
|    total_timesteps      | 1933312       |
| train/                  |               |
|    approx_kl            | 214.83505     |
|    clip_fraction        | 0.346         |
|    clip_range           | 0.2           |
|    entropy_loss         | -151          |
|    explained_variance   | 0.0645        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.51         |
|    n_updates            | 9430          |
|    policy_gradient_loss | 0.0165        |
|    reward               | 0.00037038955 |
|    std                  | 54.7          |
|    value_loss           | 6.3e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2108, ResetDay: 3788,Episode: 1152
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 945           |
|    time_elapsed         | 21386         |
|    total_timesteps      | 1935360       |
| train/                  |               |
|    approx_kl            | 215.96661     |
|    clip_fraction        | 0.32          |
|    clip_range           | 0.2           |
|    entropy_loss         | -151          |
|    explained_variance   | 0.0597        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.5          |
|    n_updates            | 9440          |
|    policy_gradient_loss | 0.0195        |
|    reward               | -0.0002523031 |
|    std                  | 54.9          |
|    value_loss           | 8.36e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 461, ResetDay: 2141,Episode: 1153
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 946           |
|    time_elapsed         | 21409         |
|    total_timesteps      | 1937408       |
| train/                  |               |
|    approx_kl            | 215.84402     |
|    clip_fraction        | 0.315         |
|    clip_range           | 0.2           |
|    entropy_loss         | -151          |
|    explained_variance   | 0.0122        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.49         |
|    n_updates            | 9450          |
|    policy_gradient_loss | 0.00857       |
|    reward               | -3.852272e-06 |
|    std                  | 55            |
|    value_loss           | 3.27e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 45, ResetDay: 1725,Episode: 1154
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 947           |
|    time_elapsed         | 21431         |
|    total_timesteps      | 1939456       |
| train/                  |               |
|    approx_kl            | 219.40714     |
|    clip_fraction        | 0.332         |
|    clip_range           | 0.2           |
|    entropy_loss         | -151          |
|    explained_variance   | -0.121        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.47         |
|    n_updates            | 9460          |
|    policy_gradient_loss | 0.0144        |
|    reward               | 0.00038523588 |
|    std                  | 55            |
|    value_loss           | 1.06e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2480, ResetDay: 4160,Episode: 1155
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 948          |
|    time_elapsed         | 21454        |
|    total_timesteps      | 1941504      |
| train/                  |              |
|    approx_kl            | 218.93358    |
|    clip_fraction        | 0.334        |
|    clip_range           | 0.2          |
|    entropy_loss         | -151         |
|    explained_variance   | 0.0579       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.52        |
|    n_updates            | 9470         |
|    policy_gradient_loss | 0.00252      |
|    reward               | 0.0004907497 |
|    std                  | 55.1         |
|    value_loss           | 1.93e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4160, episode: 1155
begin_total_asset: 200.00
end_total_asset: 807.20
total_reward: 607.20
total_cost: 15.45
total_trades: 45733
Sharpe: 0.664
=================================
Reseting Environment StartDay: 2603, ResetDay: 4283,Episode: 1156
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1959, ResetDay: 3639,Episode: 1157
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 949           |
|    time_elapsed         | 21476         |
|    total_timesteps      | 1943552       |
| train/                  |               |
|    approx_kl            | 219.36078     |
|    clip_fraction        | 0.336         |
|    clip_range           | 0.2           |
|    entropy_loss         | -151          |
|    explained_variance   | -0.00682      |
|    learning_rate        | 0.00025       |
|    loss                 | -1.49         |
|    n_updates            | 9480          |
|    policy_gradient_loss | 0.00621       |
|    reward               | 1.6551208e-05 |
|    std                  | 55.3          |
|    value_loss           | 6.03e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 927, ResetDay: 2607,Episode: 1158
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 950           |
|    time_elapsed         | 21499         |
|    total_timesteps      | 1945600       |
| train/                  |               |
|    approx_kl            | 219.40964     |
|    clip_fraction        | 0.346         |
|    clip_range           | 0.2           |
|    entropy_loss         | -151          |
|    explained_variance   | -0.138        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.52         |
|    n_updates            | 9490          |
|    policy_gradient_loss | 0.0212        |
|    reward               | 3.7002565e-08 |
|    std                  | 55.5          |
|    value_loss           | 1.29e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1330, ResetDay: 3010,Episode: 1159
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 951            |
|    time_elapsed         | 21521          |
|    total_timesteps      | 1947648        |
| train/                  |                |
|    approx_kl            | 221.07939      |
|    clip_fraction        | 0.327          |
|    clip_range           | 0.2            |
|    entropy_loss         | -151           |
|    explained_variance   | -0.059         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.47          |
|    n_updates            | 9500           |
|    policy_gradient_loss | 0.0226         |
|    reward               | -6.1289975e-05 |
|    std                  | 55.7           |
|    value_loss           | 6.53e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1793, ResetDay: 3473,Episode: 1160
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 952            |
|    time_elapsed         | 21544          |
|    total_timesteps      | 1949696        |
| train/                  |                |
|    approx_kl            | 223.21243      |
|    clip_fraction        | 0.335          |
|    clip_range           | 0.2            |
|    entropy_loss         | -152           |
|    explained_variance   | 0.132          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.51          |
|    n_updates            | 9510           |
|    policy_gradient_loss | 0.0195         |
|    reward               | -0.00019782409 |
|    std                  | 55.7           |
|    value_loss           | 3.74e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3473, episode: 1160
begin_total_asset: 200.00
end_total_asset: 325.08
total_reward: 125.08
total_cost: 6.95
total_trades: 45617
Sharpe: 0.431
=================================
Reseting Environment StartDay: 1689, ResetDay: 3369,Episode: 1161
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2006, ResetDay: 3686,Episode: 1162
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 953           |
|    time_elapsed         | 21566         |
|    total_timesteps      | 1951744       |
| train/                  |               |
|    approx_kl            | 222.85        |
|    clip_fraction        | 0.333         |
|    clip_range           | 0.2           |
|    entropy_loss         | -152          |
|    explained_variance   | 0.0685        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.5          |
|    n_updates            | 9520          |
|    policy_gradient_loss | 0.0172        |
|    reward               | -8.956108e-05 |
|    std                  | 55.9          |
|    value_loss           | 4.24e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2579, ResetDay: 4259,Episode: 1163
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 954            |
|    time_elapsed         | 21589          |
|    total_timesteps      | 1953792        |
| train/                  |                |
|    approx_kl            | 224.54968      |
|    clip_fraction        | 0.33           |
|    clip_range           | 0.2            |
|    entropy_loss         | -152           |
|    explained_variance   | 0.0207         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.51          |
|    n_updates            | 9530           |
|    policy_gradient_loss | 0.0165         |
|    reward               | -4.6069144e-05 |
|    std                  | 56.1           |
|    value_loss           | 4.6e-07        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1571, ResetDay: 3251,Episode: 1164
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 955           |
|    time_elapsed         | 21612         |
|    total_timesteps      | 1955840       |
| train/                  |               |
|    approx_kl            | 227.80997     |
|    clip_fraction        | 0.306         |
|    clip_range           | 0.2           |
|    entropy_loss         | -152          |
|    explained_variance   | 0.078         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.5          |
|    n_updates            | 9540          |
|    policy_gradient_loss | 0.00446       |
|    reward               | 0.00016751519 |
|    std                  | 56            |
|    value_loss           | 7.89e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1310, ResetDay: 2990,Episode: 1165
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 956          |
|    time_elapsed         | 21634        |
|    total_timesteps      | 1957888      |
| train/                  |              |
|    approx_kl            | 224.388      |
|    clip_fraction        | 0.327        |
|    clip_range           | 0.2          |
|    entropy_loss         | -152         |
|    explained_variance   | 0.0182       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.51        |
|    n_updates            | 9550         |
|    policy_gradient_loss | 0.0134       |
|    reward               | 1.865158e-05 |
|    std                  | 56.2         |
|    value_loss           | 8.66e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2990, episode: 1165
begin_total_asset: 200.00
end_total_asset: 170.73
total_reward: -29.27
total_cost: 5.01
total_trades: 45649
Sharpe: 0.113
=================================
Reseting Environment StartDay: 732, ResetDay: 2412,Episode: 1166
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 957           |
|    time_elapsed         | 21657         |
|    total_timesteps      | 1959936       |
| train/                  |               |
|    approx_kl            | 228.50659     |
|    clip_fraction        | 0.328         |
|    clip_range           | 0.2           |
|    entropy_loss         | -152          |
|    explained_variance   | 0.0798        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.55         |
|    n_updates            | 9560          |
|    policy_gradient_loss | 0.0204        |
|    reward               | 0.00027537614 |
|    std                  | 56.4          |
|    value_loss           | 3.6e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1076, ResetDay: 2756,Episode: 1167
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 684, ResetDay: 2364,Episode: 1168
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 958           |
|    time_elapsed         | 21681         |
|    total_timesteps      | 1961984       |
| train/                  |               |
|    approx_kl            | 227.39804     |
|    clip_fraction        | 0.34          |
|    clip_range           | 0.2           |
|    entropy_loss         | -152          |
|    explained_variance   | 0.111         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.54         |
|    n_updates            | 9570          |
|    policy_gradient_loss | 0.00995       |
|    reward               | -2.216115e-05 |
|    std                  | 56.6          |
|    value_loss           | 7.48e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2549, ResetDay: 4229,Episode: 1169
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 959           |
|    time_elapsed         | 21704         |
|    total_timesteps      | 1964032       |
| train/                  |               |
|    approx_kl            | 227.0793      |
|    clip_fraction        | 0.335         |
|    clip_range           | 0.2           |
|    entropy_loss         | -152          |
|    explained_variance   | 0.0868        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.51         |
|    n_updates            | 9580          |
|    policy_gradient_loss | 0.0119        |
|    reward               | 1.8634797e-05 |
|    std                  | 56.8          |
|    value_loss           | 1.43e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2756, ResetDay: 4436,Episode: 1170
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 960           |
|    time_elapsed         | 21726         |
|    total_timesteps      | 1966080       |
| train/                  |               |
|    approx_kl            | 230.706       |
|    clip_fraction        | 0.325         |
|    clip_range           | 0.2           |
|    entropy_loss         | -152          |
|    explained_variance   | 0.073         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.51         |
|    n_updates            | 9590          |
|    policy_gradient_loss | 0.0146        |
|    reward               | 0.00030578842 |
|    std                  | 57.1          |
|    value_loss           | 5.19e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4436, episode: 1170
begin_total_asset: 200.00
end_total_asset: 279.96
total_reward: 79.96
total_cost: 5.34
total_trades: 45563
Sharpe: 0.326
=================================
Reseting Environment StartDay: 1498, ResetDay: 3178,Episode: 1171
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 961           |
|    time_elapsed         | 21749         |
|    total_timesteps      | 1968128       |
| train/                  |               |
|    approx_kl            | 235.90219     |
|    clip_fraction        | 0.34          |
|    clip_range           | 0.2           |
|    entropy_loss         | -152          |
|    explained_variance   | -0.0244       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.54         |
|    n_updates            | 9600          |
|    policy_gradient_loss | 0.0127        |
|    reward               | 4.5720673e-05 |
|    std                  | 57            |
|    value_loss           | 1.64e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 498, ResetDay: 2178,Episode: 1172
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2167, ResetDay: 3847,Episode: 1173
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 962          |
|    time_elapsed         | 21772        |
|    total_timesteps      | 1970176      |
| train/                  |              |
|    approx_kl            | 234.0662     |
|    clip_fraction        | 0.318        |
|    clip_range           | 0.2          |
|    entropy_loss         | -152         |
|    explained_variance   | -0.449       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.52        |
|    n_updates            | 9610         |
|    policy_gradient_loss | 0.0177       |
|    reward               | -7.88702e-05 |
|    std                  | 57.1         |
|    value_loss           | 9.67e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 498, ResetDay: 2178,Episode: 1174
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 963           |
|    time_elapsed         | 21795         |
|    total_timesteps      | 1972224       |
| train/                  |               |
|    approx_kl            | 234.36143     |
|    clip_fraction        | 0.326         |
|    clip_range           | 0.2           |
|    entropy_loss         | -152          |
|    explained_variance   | 0.0403        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.52         |
|    n_updates            | 9620          |
|    policy_gradient_loss | 0.0113        |
|    reward               | 0.00017304954 |
|    std                  | 57.3          |
|    value_loss           | 1.12e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 516, ResetDay: 2196,Episode: 1175
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 964           |
|    time_elapsed         | 21817         |
|    total_timesteps      | 1974272       |
| train/                  |               |
|    approx_kl            | 236.82265     |
|    clip_fraction        | 0.326         |
|    clip_range           | 0.2           |
|    entropy_loss         | -152          |
|    explained_variance   | 0.0233        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.54         |
|    n_updates            | 9630          |
|    policy_gradient_loss | 0.0106        |
|    reward               | 0.00019473996 |
|    std                  | 57.5          |
|    value_loss           | 2.28e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2196, episode: 1175
begin_total_asset: 200.00
end_total_asset: 244.48
total_reward: 44.48
total_cost: 12.76
total_trades: 45602
Sharpe: 0.267
=================================
Reseting Environment StartDay: 720, ResetDay: 2400,Episode: 1176
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 965           |
|    time_elapsed         | 21840         |
|    total_timesteps      | 1976320       |
| train/                  |               |
|    approx_kl            | 237.52084     |
|    clip_fraction        | 0.327         |
|    clip_range           | 0.2           |
|    entropy_loss         | -152          |
|    explained_variance   | -0.0754       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.52         |
|    n_updates            | 9640          |
|    policy_gradient_loss | 0.00632       |
|    reward               | 4.2889595e-05 |
|    std                  | 57.7          |
|    value_loss           | 8.38e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1205, ResetDay: 2885,Episode: 1177
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 966           |
|    time_elapsed         | 21862         |
|    total_timesteps      | 1978368       |
| train/                  |               |
|    approx_kl            | 240.59596     |
|    clip_fraction        | 0.331         |
|    clip_range           | 0.2           |
|    entropy_loss         | -153          |
|    explained_variance   | 0.288         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.53         |
|    n_updates            | 9650          |
|    policy_gradient_loss | 0.0133        |
|    reward               | -0.0009172716 |
|    std                  | 57.8          |
|    value_loss           | 5.86e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2556, ResetDay: 4236,Episode: 1178
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 448, ResetDay: 2128,Episode: 1179
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 967            |
|    time_elapsed         | 21885          |
|    total_timesteps      | 1980416        |
| train/                  |                |
|    approx_kl            | 238.22995      |
|    clip_fraction        | 0.315          |
|    clip_range           | 0.2            |
|    entropy_loss         | -153           |
|    explained_variance   | 0.105          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.53          |
|    n_updates            | 9660           |
|    policy_gradient_loss | 0.00707        |
|    reward               | -0.00012147255 |
|    std                  | 58             |
|    value_loss           | 7.52e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2275, ResetDay: 3955,Episode: 1180
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 968          |
|    time_elapsed         | 21908        |
|    total_timesteps      | 1982464      |
| train/                  |              |
|    approx_kl            | 243.08176    |
|    clip_fraction        | 0.328        |
|    clip_range           | 0.2          |
|    entropy_loss         | -153         |
|    explained_variance   | -0.0228      |
|    learning_rate        | 0.00025      |
|    loss                 | -1.51        |
|    n_updates            | 9670         |
|    policy_gradient_loss | 0.0155       |
|    reward               | 0.0001029831 |
|    std                  | 58.1         |
|    value_loss           | 2.18e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3955, episode: 1180
begin_total_asset: 200.00
end_total_asset: 431.63
total_reward: 231.63
total_cost: 16.19
total_trades: 45460
Sharpe: 0.592
=================================
Reseting Environment StartDay: 530, ResetDay: 2210,Episode: 1181
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 969            |
|    time_elapsed         | 21930          |
|    total_timesteps      | 1984512        |
| train/                  |                |
|    approx_kl            | 241.80751      |
|    clip_fraction        | 0.339          |
|    clip_range           | 0.2            |
|    entropy_loss         | -153           |
|    explained_variance   | -0.307         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.52          |
|    n_updates            | 9680           |
|    policy_gradient_loss | 0.0142         |
|    reward               | -0.00018996856 |
|    std                  | 58.3           |
|    value_loss           | 5.81e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 532, ResetDay: 2212,Episode: 1182
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 970           |
|    time_elapsed         | 21953         |
|    total_timesteps      | 1986560       |
| train/                  |               |
|    approx_kl            | 245.41806     |
|    clip_fraction        | 0.321         |
|    clip_range           | 0.2           |
|    entropy_loss         | -153          |
|    explained_variance   | 0.0654        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.54         |
|    n_updates            | 9690          |
|    policy_gradient_loss | 0.0123        |
|    reward               | 0.00035498542 |
|    std                  | 58.4          |
|    value_loss           | 2.05e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 439, ResetDay: 2119,Episode: 1183
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 971          |
|    time_elapsed         | 21976        |
|    total_timesteps      | 1988608      |
| train/                  |              |
|    approx_kl            | 245.8052     |
|    clip_fraction        | 0.322        |
|    clip_range           | 0.2          |
|    entropy_loss         | -153         |
|    explained_variance   | 0.206        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.51        |
|    n_updates            | 9700         |
|    policy_gradient_loss | 0.014        |
|    reward               | 0.0006243549 |
|    std                  | 58.4         |
|    value_loss           | 1.06e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1925, ResetDay: 3605,Episode: 1184
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1909, ResetDay: 3589,Episode: 1185
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 972            |
|    time_elapsed         | 21998          |
|    total_timesteps      | 1990656        |
| train/                  |                |
|    approx_kl            | 246.04558      |
|    clip_fraction        | 0.329          |
|    clip_range           | 0.2            |
|    entropy_loss         | -153           |
|    explained_variance   | 0.22           |
|    learning_rate        | 0.00025        |
|    loss                 | -1.49          |
|    n_updates            | 9710           |
|    policy_gradient_loss | 0.0194         |
|    reward               | -4.2728614e-05 |
|    std                  | 58.6           |
|    value_loss           | 1.42e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3589, episode: 1185
begin_total_asset: 200.00
end_total_asset: 463.94
total_reward: 263.94
total_cost: 10.77
total_trades: 45445
Sharpe: 0.682
=================================
Reseting Environment StartDay: 914, ResetDay: 2594,Episode: 1186
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 973           |
|    time_elapsed         | 22021         |
|    total_timesteps      | 1992704       |
| train/                  |               |
|    approx_kl            | 248.64227     |
|    clip_fraction        | 0.314         |
|    clip_range           | 0.2           |
|    entropy_loss         | -153          |
|    explained_variance   | 0.085         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.52         |
|    n_updates            | 9720          |
|    policy_gradient_loss | 0.00139       |
|    reward               | 0.00015486698 |
|    std                  | 58.7          |
|    value_loss           | 1.21e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2310, ResetDay: 3990,Episode: 1187
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 974           |
|    time_elapsed         | 22044         |
|    total_timesteps      | 1994752       |
| train/                  |               |
|    approx_kl            | 247.40149     |
|    clip_fraction        | 0.322         |
|    clip_range           | 0.2           |
|    entropy_loss         | -153          |
|    explained_variance   | 0.125         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.57         |
|    n_updates            | 9730          |
|    policy_gradient_loss | 0.00675       |
|    reward               | -4.189148e-05 |
|    std                  | 59            |
|    value_loss           | 8.26e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2520, ResetDay: 4200,Episode: 1188
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 975           |
|    time_elapsed         | 22066         |
|    total_timesteps      | 1996800       |
| train/                  |               |
|    approx_kl            | 251.7543      |
|    clip_fraction        | 0.318         |
|    clip_range           | 0.2           |
|    entropy_loss         | -153          |
|    explained_variance   | 0.215         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.53         |
|    n_updates            | 9740          |
|    policy_gradient_loss | 0.0102        |
|    reward               | 0.00024304962 |
|    std                  | 59.1          |
|    value_loss           | 6.2e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2526, ResetDay: 4206,Episode: 1189
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 587, ResetDay: 2267,Episode: 1190
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 976          |
|    time_elapsed         | 22089        |
|    total_timesteps      | 1998848      |
| train/                  |              |
|    approx_kl            | 251.83575    |
|    clip_fraction        | 0.33         |
|    clip_range           | 0.2          |
|    entropy_loss         | -153         |
|    explained_variance   | 0.105        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.54        |
|    n_updates            | 9750         |
|    policy_gradient_loss | 0.00515      |
|    reward               | 6.639235e-05 |
|    std                  | 59.2         |
|    value_loss           | 1.63e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2267, episode: 1190
begin_total_asset: 200.00
end_total_asset: 211.32
total_reward: 11.32
total_cost: 13.73
total_trades: 45440
Sharpe: 0.282
=================================
Reseting Environment StartDay: 2523, ResetDay: 4203,Episode: 1191
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 977            |
|    time_elapsed         | 22112          |
|    total_timesteps      | 2000896        |
| train/                  |                |
|    approx_kl            | 249.91805      |
|    clip_fraction        | 0.316          |
|    clip_range           | 0.2            |
|    entropy_loss         | -153           |
|    explained_variance   | -0.0141        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.53          |
|    n_updates            | 9760           |
|    policy_gradient_loss | 0.0107         |
|    reward               | -0.00020369205 |
|    std                  | 59.4           |
|    value_loss           | 1.65e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 800, ResetDay: 2480,Episode: 1192
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 978           |
|    time_elapsed         | 22134         |
|    total_timesteps      | 2002944       |
| train/                  |               |
|    approx_kl            | 253.05203     |
|    clip_fraction        | 0.315         |
|    clip_range           | 0.2           |
|    entropy_loss         | -153          |
|    explained_variance   | -0.202        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.51         |
|    n_updates            | 9770          |
|    policy_gradient_loss | 0.0116        |
|    reward               | -7.288942e-05 |
|    std                  | 59.6          |
|    value_loss           | 5.43e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2201, ResetDay: 3881,Episode: 1193
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 979          |
|    time_elapsed         | 22157        |
|    total_timesteps      | 2004992      |
| train/                  |              |
|    approx_kl            | 254.70946    |
|    clip_fraction        | 0.309        |
|    clip_range           | 0.2          |
|    entropy_loss         | -153         |
|    explained_variance   | 0.0758       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.54        |
|    n_updates            | 9780         |
|    policy_gradient_loss | 0.00176      |
|    reward               | 4.392624e-05 |
|    std                  | 59.9         |
|    value_loss           | 2.17e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2516, ResetDay: 4196,Episode: 1194
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 980           |
|    time_elapsed         | 22179         |
|    total_timesteps      | 2007040       |
| train/                  |               |
|    approx_kl            | 257.29398     |
|    clip_fraction        | 0.309         |
|    clip_range           | 0.2           |
|    entropy_loss         | -154          |
|    explained_variance   | 0.0578        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.5          |
|    n_updates            | 9790          |
|    policy_gradient_loss | 0.0118        |
|    reward               | -0.0001805729 |
|    std                  | 60            |
|    value_loss           | 7.06e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2073, ResetDay: 3753,Episode: 1195
Environment reached Terminal state as number of trading days reached limit!!
day: 3753, episode: 1195
begin_total_asset: 200.00
end_total_asset: 260.39
total_reward: 60.39
total_cost: 7.81
total_trades: 45371
Sharpe: 0.306
=================================
Reseting Environment StartDay: 41, ResetDay: 1721,Episode: 1196
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 981           |
|    time_elapsed         | 22202         |
|    total_timesteps      | 2009088       |
| train/                  |               |
|    approx_kl            | 259.88348     |
|    clip_fraction        | 0.301         |
|    clip_range           | 0.2           |
|    entropy_loss         | -154          |
|    explained_variance   | 0.0654        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.56         |
|    n_updates            | 9800          |
|    policy_gradient_loss | 0.00938       |
|    reward               | 0.00033998035 |
|    std                  | 60.2          |
|    value_loss           | 2.4e-06       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2498, ResetDay: 4178,Episode: 1197
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 982           |
|    time_elapsed         | 22225         |
|    total_timesteps      | 2011136       |
| train/                  |               |
|    approx_kl            | 258.08026     |
|    clip_fraction        | 0.298         |
|    clip_range           | 0.2           |
|    entropy_loss         | -154          |
|    explained_variance   | -0.354        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.54         |
|    n_updates            | 9810          |
|    policy_gradient_loss | 0.0101        |
|    reward               | 0.00010413437 |
|    std                  | 60.4          |
|    value_loss           | 1.18e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1596, ResetDay: 3276,Episode: 1198
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 983            |
|    time_elapsed         | 22247          |
|    total_timesteps      | 2013184        |
| train/                  |                |
|    approx_kl            | 261.3919       |
|    clip_fraction        | 0.323          |
|    clip_range           | 0.2            |
|    entropy_loss         | -154           |
|    explained_variance   | 0.0813         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.53          |
|    n_updates            | 9820           |
|    policy_gradient_loss | 0.008          |
|    reward               | -0.00035989494 |
|    std                  | 60.6           |
|    value_loss           | 2.96e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 170, ResetDay: 1850,Episode: 1199
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 984           |
|    time_elapsed         | 22270         |
|    total_timesteps      | 2015232       |
| train/                  |               |
|    approx_kl            | 262.9158      |
|    clip_fraction        | 0.29          |
|    clip_range           | 0.2           |
|    entropy_loss         | -154          |
|    explained_variance   | 0.0546        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.52         |
|    n_updates            | 9830          |
|    policy_gradient_loss | 0.0165        |
|    reward               | 2.1762466e-05 |
|    std                  | 60.7          |
|    value_loss           | 4.63e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1685, ResetDay: 3365,Episode: 1200
Environment reached Terminal state as number of trading days reached limit!!
day: 3365, episode: 1200
begin_total_asset: 200.00
end_total_asset: 469.72
total_reward: 269.72
total_cost: 10.33
total_trades: 45437
Sharpe: 0.702
=================================
Reseting Environment StartDay: 490, ResetDay: 2170,Episode: 1201
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 985            |
|    time_elapsed         | 22292          |
|    total_timesteps      | 2017280        |
| train/                  |                |
|    approx_kl            | 264.4344       |
|    clip_fraction        | 0.323          |
|    clip_range           | 0.2            |
|    entropy_loss         | -154           |
|    explained_variance   | -0.143         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.54          |
|    n_updates            | 9840           |
|    policy_gradient_loss | 0.00829        |
|    reward               | -5.1023173e-05 |
|    std                  | 60.8           |
|    value_loss           | 9.02e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2113, ResetDay: 3793,Episode: 1202
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 986            |
|    time_elapsed         | 22316          |
|    total_timesteps      | 2019328        |
| train/                  |                |
|    approx_kl            | 262.85565      |
|    clip_fraction        | 0.313          |
|    clip_range           | 0.2            |
|    entropy_loss         | -154           |
|    explained_variance   | 0.0984         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.53          |
|    n_updates            | 9850           |
|    policy_gradient_loss | 0.0169         |
|    reward               | -3.5230063e-05 |
|    std                  | 61.2           |
|    value_loss           | 1.07e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2643, ResetDay: 4323,Episode: 1203
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 987          |
|    time_elapsed         | 22338        |
|    total_timesteps      | 2021376      |
| train/                  |              |
|    approx_kl            | 269.3349     |
|    clip_fraction        | 0.298        |
|    clip_range           | 0.2          |
|    entropy_loss         | -154         |
|    explained_variance   | 0.0892       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.55        |
|    n_updates            | 9860         |
|    policy_gradient_loss | 0.0084       |
|    reward               | -0.001103537 |
|    std                  | 61.2         |
|    value_loss           | 9.86e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1076, ResetDay: 2756,Episode: 1204
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 988           |
|    time_elapsed         | 22361         |
|    total_timesteps      | 2023424       |
| train/                  |               |
|    approx_kl            | 270.02106     |
|    clip_fraction        | 0.301         |
|    clip_range           | 0.2           |
|    entropy_loss         | -154          |
|    explained_variance   | 0.0865        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.53         |
|    n_updates            | 9870          |
|    policy_gradient_loss | 0.00237       |
|    reward               | 0.00022616959 |
|    std                  | 61.2          |
|    value_loss           | 1.92e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2256, ResetDay: 3936,Episode: 1205
---------------------------------------------
| time/                   |                 |
|    fps                  | 90              |
|    iterations           | 989             |
|    time_elapsed         | 22384           |
|    total_timesteps      | 2025472         |
| train/                  |                 |
|    approx_kl            | 268.21613       |
|    clip_fraction        | 0.295           |
|    clip_range           | 0.2             |
|    entropy_loss         | -154            |
|    explained_variance   | -0.0609         |
|    learning_rate        | 0.00025         |
|    loss                 | -1.53           |
|    n_updates            | 9880            |
|    policy_gradient_loss | 0.0197          |
|    reward               | -0.000101047895 |
|    std                  | 61.4            |
|    value_loss           | 1.98e-06        |
---------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3936, episode: 1205
begin_total_asset: 200.00
end_total_asset: 442.85
total_reward: 242.85
total_cost: 10.04
total_trades: 45265
Sharpe: 0.603
=================================
Reseting Environment StartDay: 703, ResetDay: 2383,Episode: 1206
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1035, ResetDay: 2715,Episode: 1207
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 990           |
|    time_elapsed         | 22406         |
|    total_timesteps      | 2027520       |
| train/                  |               |
|    approx_kl            | 269.64648     |
|    clip_fraction        | 0.308         |
|    clip_range           | 0.2           |
|    entropy_loss         | -154          |
|    explained_variance   | 0.148         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.55         |
|    n_updates            | 9890          |
|    policy_gradient_loss | 0.00451       |
|    reward               | -9.632807e-05 |
|    std                  | 61.6          |
|    value_loss           | 2.07e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1661, ResetDay: 3341,Episode: 1208
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 991            |
|    time_elapsed         | 22429          |
|    total_timesteps      | 2029568        |
| train/                  |                |
|    approx_kl            | 271.2578       |
|    clip_fraction        | 0.302          |
|    clip_range           | 0.2            |
|    entropy_loss         | -154           |
|    explained_variance   | -0.524         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.53          |
|    n_updates            | 9900           |
|    policy_gradient_loss | 0.0101         |
|    reward               | -0.00022615814 |
|    std                  | 61.7           |
|    value_loss           | 9.51e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1717, ResetDay: 3397,Episode: 1209
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 992            |
|    time_elapsed         | 22451          |
|    total_timesteps      | 2031616        |
| train/                  |                |
|    approx_kl            | 270.24866      |
|    clip_fraction        | 0.3            |
|    clip_range           | 0.2            |
|    entropy_loss         | -154           |
|    explained_variance   | 0.171          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.53          |
|    n_updates            | 9910           |
|    policy_gradient_loss | 0.0048         |
|    reward               | -5.0126837e-05 |
|    std                  | 62             |
|    value_loss           | 7.95e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1526, ResetDay: 3206,Episode: 1210
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 993           |
|    time_elapsed         | 22474         |
|    total_timesteps      | 2033664       |
| train/                  |               |
|    approx_kl            | 275.33932     |
|    clip_fraction        | 0.292         |
|    clip_range           | 0.2           |
|    entropy_loss         | -155          |
|    explained_variance   | 0.138         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.53         |
|    n_updates            | 9920          |
|    policy_gradient_loss | 0.0124        |
|    reward               | 5.7157515e-05 |
|    std                  | 62            |
|    value_loss           | 6.8e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3206, episode: 1210
begin_total_asset: 200.00
end_total_asset: 239.29
total_reward: 39.29
total_cost: 5.38
total_trades: 45188
Sharpe: 0.288
=================================
Reseting Environment StartDay: 2336, ResetDay: 4016,Episode: 1211
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1221, ResetDay: 2901,Episode: 1212
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 994           |
|    time_elapsed         | 22496         |
|    total_timesteps      | 2035712       |
| train/                  |               |
|    approx_kl            | 274.03134     |
|    clip_fraction        | 0.288         |
|    clip_range           | 0.2           |
|    entropy_loss         | -155          |
|    explained_variance   | 0.157         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.53         |
|    n_updates            | 9930          |
|    policy_gradient_loss | 0.00232       |
|    reward               | 1.6651726e-05 |
|    std                  | 62.1          |
|    value_loss           | 6.83e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1824, ResetDay: 3504,Episode: 1213
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 995           |
|    time_elapsed         | 22519         |
|    total_timesteps      | 2037760       |
| train/                  |               |
|    approx_kl            | 276.04688     |
|    clip_fraction        | 0.28          |
|    clip_range           | 0.2           |
|    entropy_loss         | -155          |
|    explained_variance   | 0.132         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.53         |
|    n_updates            | 9940          |
|    policy_gradient_loss | 0.0116        |
|    reward               | 0.00018243256 |
|    std                  | 62.3          |
|    value_loss           | 8.06e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 785, ResetDay: 2465,Episode: 1214
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 996            |
|    time_elapsed         | 22541          |
|    total_timesteps      | 2039808        |
| train/                  |                |
|    approx_kl            | 277.451        |
|    clip_fraction        | 0.293          |
|    clip_range           | 0.2            |
|    entropy_loss         | -155           |
|    explained_variance   | -0.124         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.55          |
|    n_updates            | 9950           |
|    policy_gradient_loss | 0.0119         |
|    reward               | -0.00030447321 |
|    std                  | 62.6           |
|    value_loss           | 3.88e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2177, ResetDay: 3857,Episode: 1215
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 997          |
|    time_elapsed         | 22564        |
|    total_timesteps      | 2041856      |
| train/                  |              |
|    approx_kl            | 278.33966    |
|    clip_fraction        | 0.302        |
|    clip_range           | 0.2          |
|    entropy_loss         | -155         |
|    explained_variance   | 0.103        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.54        |
|    n_updates            | 9960         |
|    policy_gradient_loss | 0.00763      |
|    reward               | 0.0002857666 |
|    std                  | 62.8         |
|    value_loss           | 1.1e-06      |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3857, episode: 1215
begin_total_asset: 200.00
end_total_asset: 429.68
total_reward: 229.68
total_cost: 12.89
total_trades: 45204
Sharpe: 0.580
=================================
Reseting Environment StartDay: 1479, ResetDay: 3159,Episode: 1216
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 998           |
|    time_elapsed         | 22587         |
|    total_timesteps      | 2043904       |
| train/                  |               |
|    approx_kl            | 280.92026     |
|    clip_fraction        | 0.275         |
|    clip_range           | 0.2           |
|    entropy_loss         | -155          |
|    explained_variance   | 0.098         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.56         |
|    n_updates            | 9970          |
|    policy_gradient_loss | 0.00203       |
|    reward               | 2.2415543e-05 |
|    std                  | 63            |
|    value_loss           | 6.97e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 374, ResetDay: 2054,Episode: 1217
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 969, ResetDay: 2649,Episode: 1218
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 999          |
|    time_elapsed         | 22609        |
|    total_timesteps      | 2045952      |
| train/                  |              |
|    approx_kl            | 284.73572    |
|    clip_fraction        | 0.289        |
|    clip_range           | 0.2          |
|    entropy_loss         | -155         |
|    explained_variance   | 0.17         |
|    learning_rate        | 0.00025      |
|    loss                 | -1.55        |
|    n_updates            | 9980         |
|    policy_gradient_loss | 0.000939     |
|    reward               | 7.259045e-05 |
|    std                  | 63.1         |
|    value_loss           | 1.6e-06      |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 666, ResetDay: 2346,Episode: 1219
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1000          |
|    time_elapsed         | 22632         |
|    total_timesteps      | 2048000       |
| train/                  |               |
|    approx_kl            | 282.03867     |
|    clip_fraction        | 0.283         |
|    clip_range           | 0.2           |
|    entropy_loss         | -155          |
|    explained_variance   | 0.0965        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.55         |
|    n_updates            | 9990          |
|    policy_gradient_loss | 0.00711       |
|    reward               | 0.00026272336 |
|    std                  | 63.3          |
|    value_loss           | 1.09e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 703, ResetDay: 2383,Episode: 1220
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1001          |
|    time_elapsed         | 22654         |
|    total_timesteps      | 2050048       |
| train/                  |               |
|    approx_kl            | 283.1964      |
|    clip_fraction        | 0.292         |
|    clip_range           | 0.2           |
|    entropy_loss         | -155          |
|    explained_variance   | 0.0867        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.52         |
|    n_updates            | 10000         |
|    policy_gradient_loss | 0.0101        |
|    reward               | 0.00012189503 |
|    std                  | 63.7          |
|    value_loss           | 1.24e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2383, episode: 1220
begin_total_asset: 200.00
end_total_asset: 373.10
total_reward: 173.10
total_cost: 15.55
total_trades: 45100
Sharpe: 0.480
=================================
Reseting Environment StartDay: 925, ResetDay: 2605,Episode: 1221
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1002          |
|    time_elapsed         | 22677         |
|    total_timesteps      | 2052096       |
| train/                  |               |
|    approx_kl            | 290.44553     |
|    clip_fraction        | 0.292         |
|    clip_range           | 0.2           |
|    entropy_loss         | -155          |
|    explained_variance   | 0.0953        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.55         |
|    n_updates            | 10010         |
|    policy_gradient_loss | 0.0173        |
|    reward               | 0.00027980766 |
|    std                  | 63.8          |
|    value_loss           | 6.42e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 416, ResetDay: 2096,Episode: 1222
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1003          |
|    time_elapsed         | 22699         |
|    total_timesteps      | 2054144       |
| train/                  |               |
|    approx_kl            | 292.03906     |
|    clip_fraction        | 0.274         |
|    clip_range           | 0.2           |
|    entropy_loss         | -155          |
|    explained_variance   | 0.234         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.56         |
|    n_updates            | 10020         |
|    policy_gradient_loss | 0.00699       |
|    reward               | 0.00013055878 |
|    std                  | 63.9          |
|    value_loss           | 1.11e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 24, ResetDay: 1704,Episode: 1223
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1017, ResetDay: 2697,Episode: 1224
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1004           |
|    time_elapsed         | 22722          |
|    total_timesteps      | 2056192        |
| train/                  |                |
|    approx_kl            | 291.65085      |
|    clip_fraction        | 0.293          |
|    clip_range           | 0.2            |
|    entropy_loss         | -155           |
|    explained_variance   | 0.195          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.57          |
|    n_updates            | 10030          |
|    policy_gradient_loss | 0.00622        |
|    reward               | -5.0450133e-05 |
|    std                  | 64.3           |
|    value_loss           | 1.35e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 790, ResetDay: 2470,Episode: 1225
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1005         |
|    time_elapsed         | 22744        |
|    total_timesteps      | 2058240      |
| train/                  |              |
|    approx_kl            | 295.6075     |
|    clip_fraction        | 0.297        |
|    clip_range           | 0.2          |
|    entropy_loss         | -156         |
|    explained_variance   | -0.0366      |
|    learning_rate        | 0.00025      |
|    loss                 | -1.56        |
|    n_updates            | 10040        |
|    policy_gradient_loss | 0.00597      |
|    reward               | 9.032059e-06 |
|    std                  | 64.5         |
|    value_loss           | 4.54e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2470, episode: 1225
begin_total_asset: 200.00
end_total_asset: 375.98
total_reward: 175.98
total_cost: 12.77
total_trades: 44991
Sharpe: 0.461
=================================
Reseting Environment StartDay: 2470, ResetDay: 4150,Episode: 1226
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1006          |
|    time_elapsed         | 22767         |
|    total_timesteps      | 2060288       |
| train/                  |               |
|    approx_kl            | 296.62842     |
|    clip_fraction        | 0.271         |
|    clip_range           | 0.2           |
|    entropy_loss         | -156          |
|    explained_variance   | -0.306        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.55         |
|    n_updates            | 10050         |
|    policy_gradient_loss | 0.00982       |
|    reward               | 0.00021651306 |
|    std                  | 64.7          |
|    value_loss           | 1.84e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2336, ResetDay: 4016,Episode: 1227
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1007         |
|    time_elapsed         | 22790        |
|    total_timesteps      | 2062336      |
| train/                  |              |
|    approx_kl            | 299.2614     |
|    clip_fraction        | 0.274        |
|    clip_range           | 0.2          |
|    entropy_loss         | -156         |
|    explained_variance   | 0.158        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.56        |
|    n_updates            | 10060        |
|    policy_gradient_loss | 0.0035       |
|    reward               | 0.0008845894 |
|    std                  | 64.9         |
|    value_loss           | 9.96e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 373, ResetDay: 2053,Episode: 1228
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1036, ResetDay: 2716,Episode: 1229
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1008           |
|    time_elapsed         | 22814          |
|    total_timesteps      | 2064384        |
| train/                  |                |
|    approx_kl            | 300.65387      |
|    clip_fraction        | 0.273          |
|    clip_range           | 0.2            |
|    entropy_loss         | -156           |
|    explained_variance   | 0.0471         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.55          |
|    n_updates            | 10070          |
|    policy_gradient_loss | 0.00566        |
|    reward               | -0.00018604274 |
|    std                  | 65             |
|    value_loss           | 1.9e-06        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1589, ResetDay: 3269,Episode: 1230
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1009           |
|    time_elapsed         | 22837          |
|    total_timesteps      | 2066432        |
| train/                  |                |
|    approx_kl            | 300.8065       |
|    clip_fraction        | 0.276          |
|    clip_range           | 0.2            |
|    entropy_loss         | -156           |
|    explained_variance   | -0.647         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.54          |
|    n_updates            | 10080          |
|    policy_gradient_loss | 0.0059         |
|    reward               | -3.6880494e-05 |
|    std                  | 65.2           |
|    value_loss           | 1.01e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3269, episode: 1230
begin_total_asset: 200.00
end_total_asset: 371.83
total_reward: 171.83
total_cost: 8.05
total_trades: 44913
Sharpe: 0.505
=================================
Reseting Environment StartDay: 1973, ResetDay: 3653,Episode: 1231
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1010         |
|    time_elapsed         | 22859        |
|    total_timesteps      | 2068480      |
| train/                  |              |
|    approx_kl            | 305.9888     |
|    clip_fraction        | 0.274        |
|    clip_range           | 0.2          |
|    entropy_loss         | -156         |
|    explained_variance   | 0.13         |
|    learning_rate        | 0.00025      |
|    loss                 | -1.56        |
|    n_updates            | 10090        |
|    policy_gradient_loss | 0.0111       |
|    reward               | 5.178528e-05 |
|    std                  | 65.3         |
|    value_loss           | 8.28e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2110, ResetDay: 3790,Episode: 1232
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1011           |
|    time_elapsed         | 22882          |
|    total_timesteps      | 2070528        |
| train/                  |                |
|    approx_kl            | 305.54123      |
|    clip_fraction        | 0.274          |
|    clip_range           | 0.2            |
|    entropy_loss         | -156           |
|    explained_variance   | 0.147          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.56          |
|    n_updates            | 10100          |
|    policy_gradient_loss | 0.0133         |
|    reward               | -0.00027018433 |
|    std                  | 65.5           |
|    value_loss           | 7.13e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1260, ResetDay: 2940,Episode: 1233
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1012          |
|    time_elapsed         | 22905         |
|    total_timesteps      | 2072576       |
| train/                  |               |
|    approx_kl            | 306.1059      |
|    clip_fraction        | 0.278         |
|    clip_range           | 0.2           |
|    entropy_loss         | -156          |
|    explained_variance   | 0.14          |
|    learning_rate        | 0.00025       |
|    loss                 | -1.59         |
|    n_updates            | 10110         |
|    policy_gradient_loss | 0.00559       |
|    reward               | 5.7117463e-06 |
|    std                  | 65.7          |
|    value_loss           | 8.83e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 483, ResetDay: 2163,Episode: 1234
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 929, ResetDay: 2609,Episode: 1235
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1013           |
|    time_elapsed         | 22927          |
|    total_timesteps      | 2074624        |
| train/                  |                |
|    approx_kl            | 308.31006      |
|    clip_fraction        | 0.29           |
|    clip_range           | 0.2            |
|    entropy_loss         | -156           |
|    explained_variance   | 0.0212         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.52          |
|    n_updates            | 10120          |
|    policy_gradient_loss | 0.0221         |
|    reward               | -2.0530653e-05 |
|    std                  | 65.8           |
|    value_loss           | 1.56e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2609, episode: 1235
begin_total_asset: 200.00
end_total_asset: 198.74
total_reward: -1.26
total_cost: 12.30
total_trades: 45017
Sharpe: 0.215
=================================
Reseting Environment StartDay: 79, ResetDay: 1759,Episode: 1236
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1014           |
|    time_elapsed         | 22950          |
|    total_timesteps      | 2076672        |
| train/                  |                |
|    approx_kl            | 309.37555      |
|    clip_fraction        | 0.26           |
|    clip_range           | 0.2            |
|    entropy_loss         | -156           |
|    explained_variance   | -0.174         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.55          |
|    n_updates            | 10130          |
|    policy_gradient_loss | 0.00681        |
|    reward               | -0.00040607824 |
|    std                  | 66             |
|    value_loss           | 1.07e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 408, ResetDay: 2088,Episode: 1237
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1015          |
|    time_elapsed         | 22973         |
|    total_timesteps      | 2078720       |
| train/                  |               |
|    approx_kl            | 310.45328     |
|    clip_fraction        | 0.283         |
|    clip_range           | 0.2           |
|    entropy_loss         | -156          |
|    explained_variance   | -0.00536      |
|    learning_rate        | 0.00025       |
|    loss                 | -1.57         |
|    n_updates            | 10140         |
|    policy_gradient_loss | 0.00509       |
|    reward               | 0.00017704192 |
|    std                  | 66.3          |
|    value_loss           | 1.36e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1295, ResetDay: 2975,Episode: 1238
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1016           |
|    time_elapsed         | 22995          |
|    total_timesteps      | 2080768        |
| train/                  |                |
|    approx_kl            | 315.34778      |
|    clip_fraction        | 0.273          |
|    clip_range           | 0.2            |
|    entropy_loss         | -156           |
|    explained_variance   | 0.0818         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.58          |
|    n_updates            | 10150          |
|    policy_gradient_loss | 0.0102         |
|    reward               | -5.0917053e-05 |
|    std                  | 66.4           |
|    value_loss           | 4.4e-06        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 862, ResetDay: 2542,Episode: 1239
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2444, ResetDay: 4124,Episode: 1240
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1017           |
|    time_elapsed         | 23018          |
|    total_timesteps      | 2082816        |
| train/                  |                |
|    approx_kl            | 311.89957      |
|    clip_fraction        | 0.268          |
|    clip_range           | 0.2            |
|    entropy_loss         | -156           |
|    explained_variance   | 0.0563         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.58          |
|    n_updates            | 10160          |
|    policy_gradient_loss | 0.0113         |
|    reward               | -0.00051430473 |
|    std                  | 66.6           |
|    value_loss           | 1.8e-06        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4124, episode: 1240
begin_total_asset: 200.00
end_total_asset: 430.76
total_reward: 230.76
total_cost: 10.22
total_trades: 44787
Sharpe: 0.586
=================================
Reseting Environment StartDay: 1987, ResetDay: 3667,Episode: 1241
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1018          |
|    time_elapsed         | 23040         |
|    total_timesteps      | 2084864       |
| train/                  |               |
|    approx_kl            | 315.41315     |
|    clip_fraction        | 0.261         |
|    clip_range           | 0.2           |
|    entropy_loss         | -157          |
|    explained_variance   | -0.496        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.56         |
|    n_updates            | 10170         |
|    policy_gradient_loss | 0.00212       |
|    reward               | 0.00016751251 |
|    std                  | 66.8          |
|    value_loss           | 6.17e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1184, ResetDay: 2864,Episode: 1242
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1019          |
|    time_elapsed         | 23063         |
|    total_timesteps      | 2086912       |
| train/                  |               |
|    approx_kl            | 318.71942     |
|    clip_fraction        | 0.27          |
|    clip_range           | 0.2           |
|    entropy_loss         | -157          |
|    explained_variance   | 0.0846        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.57         |
|    n_updates            | 10180         |
|    policy_gradient_loss | 0.00218       |
|    reward               | 0.00017120561 |
|    std                  | 66.9          |
|    value_loss           | 1.5e-06       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1649, ResetDay: 3329,Episode: 1243
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1020          |
|    time_elapsed         | 23086         |
|    total_timesteps      | 2088960       |
| train/                  |               |
|    approx_kl            | 320.39856     |
|    clip_fraction        | 0.264         |
|    clip_range           | 0.2           |
|    entropy_loss         | -157          |
|    explained_variance   | 0.0915        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.55         |
|    n_updates            | 10190         |
|    policy_gradient_loss | 0.0112        |
|    reward               | 0.00029128112 |
|    std                  | 66.9          |
|    value_loss           | 7.72e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2283, ResetDay: 3963,Episode: 1244
-----------------------------------------
| time/                   |             |
|    fps                  | 90          |
|    iterations           | 1021        |
|    time_elapsed         | 23108       |
|    total_timesteps      | 2091008     |
| train/                  |             |
|    approx_kl            | 318.2008    |
|    clip_fraction        | 0.266       |
|    clip_range           | 0.2         |
|    entropy_loss         | -157        |
|    explained_variance   | 0.177       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.56       |
|    n_updates            | 10200       |
|    policy_gradient_loss | 0.0102      |
|    reward               | 0.000653199 |
|    std                  | 67.1        |
|    value_loss           | 4.08e-07    |
-----------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2248, ResetDay: 3928,Episode: 1245
Environment reached Terminal state as number of trading days reached limit!!
day: 3928, episode: 1245
begin_total_asset: 200.00
end_total_asset: 260.33
total_reward: 60.33
total_cost: 7.33
total_trades: 44860
Sharpe: 0.290
=================================
Reseting Environment StartDay: 548, ResetDay: 2228,Episode: 1246
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1022           |
|    time_elapsed         | 23131          |
|    total_timesteps      | 2093056        |
| train/                  |                |
|    approx_kl            | 320.4145       |
|    clip_fraction        | 0.256          |
|    clip_range           | 0.2            |
|    entropy_loss         | -157           |
|    explained_variance   | 0.0804         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.55          |
|    n_updates            | 10210          |
|    policy_gradient_loss | 0.00272        |
|    reward               | -0.00020972313 |
|    std                  | 67.4           |
|    value_loss           | 1.75e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 322, ResetDay: 2002,Episode: 1247
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1023           |
|    time_elapsed         | 23153          |
|    total_timesteps      | 2095104        |
| train/                  |                |
|    approx_kl            | 323.13678      |
|    clip_fraction        | 0.278          |
|    clip_range           | 0.2            |
|    entropy_loss         | -157           |
|    explained_variance   | 0.00606        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.54          |
|    n_updates            | 10220          |
|    policy_gradient_loss | 0.00428        |
|    reward               | -0.00037250257 |
|    std                  | 67.7           |
|    value_loss           | 1.34e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1311, ResetDay: 2991,Episode: 1248
---------------------------------------
| time/                   |           |
|    fps                  | 90        |
|    iterations           | 1024      |
|    time_elapsed         | 23176     |
|    total_timesteps      | 2097152   |
| train/                  |           |
|    approx_kl            | 327.60437 |
|    clip_fraction        | 0.238     |
|    clip_range           | 0.2       |
|    entropy_loss         | -157      |
|    explained_variance   | -0.154    |
|    learning_rate        | 0.00025   |
|    loss                 | -1.55     |
|    n_updates            | 10230     |
|    policy_gradient_loss | 0.00487   |
|    reward               | 0.0       |
|    std                  | 67.8      |
|    value_loss           | 1.1e-06   |
---------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1306, ResetDay: 2986,Episode: 1249
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1025           |
|    time_elapsed         | 23199          |
|    total_timesteps      | 2099200        |
| train/                  |                |
|    approx_kl            | 330.09656      |
|    clip_fraction        | 0.267          |
|    clip_range           | 0.2            |
|    entropy_loss         | -157           |
|    explained_variance   | 0.163          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.57          |
|    n_updates            | 10240          |
|    policy_gradient_loss | 0.00496        |
|    reward               | -0.00031490307 |
|    std                  | 68             |
|    value_loss           | 1.07e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 112, ResetDay: 1792,Episode: 1250
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1026          |
|    time_elapsed         | 23222         |
|    total_timesteps      | 2101248       |
| train/                  |               |
|    approx_kl            | 329.71677     |
|    clip_fraction        | 0.253         |
|    clip_range           | 0.2           |
|    entropy_loss         | -157          |
|    explained_variance   | -0.137        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.58         |
|    n_updates            | 10250         |
|    policy_gradient_loss | 0.00396       |
|    reward               | -0.0020511053 |
|    std                  | 68.2          |
|    value_loss           | 4.68e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 1792, episode: 1250
begin_total_asset: 200.00
end_total_asset: 477.89
total_reward: 277.89
total_cost: 14.70
total_trades: 44795
Sharpe: 0.569
=================================
Reseting Environment StartDay: 10, ResetDay: 1690,Episode: 1251
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 614, ResetDay: 2294,Episode: 1252
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1027          |
|    time_elapsed         | 23244         |
|    total_timesteps      | 2103296       |
| train/                  |               |
|    approx_kl            | 333.11957     |
|    clip_fraction        | 0.277         |
|    clip_range           | 0.2           |
|    entropy_loss         | -157          |
|    explained_variance   | 0.106         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.58         |
|    n_updates            | 10260         |
|    policy_gradient_loss | 0.00283       |
|    reward               | 5.2843523e-05 |
|    std                  | 68.3          |
|    value_loss           | 1.84e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2496, ResetDay: 4176,Episode: 1253
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1028         |
|    time_elapsed         | 23267        |
|    total_timesteps      | 2105344      |
| train/                  |              |
|    approx_kl            | 332.0986     |
|    clip_fraction        | 0.265        |
|    clip_range           | 0.2          |
|    entropy_loss         | -157         |
|    explained_variance   | -0.0157      |
|    learning_rate        | 0.00025      |
|    loss                 | -1.57        |
|    n_updates            | 10270        |
|    policy_gradient_loss | 0.00359      |
|    reward               | 0.0004535797 |
|    std                  | 68.5         |
|    value_loss           | 6.63e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1505, ResetDay: 3185,Episode: 1254
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1029          |
|    time_elapsed         | 23290         |
|    total_timesteps      | 2107392       |
| train/                  |               |
|    approx_kl            | 335.8079      |
|    clip_fraction        | 0.273         |
|    clip_range           | 0.2           |
|    entropy_loss         | -157          |
|    explained_variance   | -0.119        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.56         |
|    n_updates            | 10280         |
|    policy_gradient_loss | 0.017         |
|    reward               | 0.00011365586 |
|    std                  | 68.6          |
|    value_loss           | 1.46e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 571, ResetDay: 2251,Episode: 1255
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1030           |
|    time_elapsed         | 23312          |
|    total_timesteps      | 2109440        |
| train/                  |                |
|    approx_kl            | 337.01776      |
|    clip_fraction        | 0.262          |
|    clip_range           | 0.2            |
|    entropy_loss         | -157           |
|    explained_variance   | 0.0107         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.57          |
|    n_updates            | 10290          |
|    policy_gradient_loss | 0.00832        |
|    reward               | -1.1797333e-05 |
|    std                  | 68.7           |
|    value_loss           | 1.53e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2251, episode: 1255
begin_total_asset: 200.00
end_total_asset: 141.45
total_reward: -58.55
total_cost: 15.59
total_trades: 44859
Sharpe: 0.055
=================================
Reseting Environment StartDay: 1288, ResetDay: 2968,Episode: 1256
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2377, ResetDay: 4057,Episode: 1257
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1031          |
|    time_elapsed         | 23335         |
|    total_timesteps      | 2111488       |
| train/                  |               |
|    approx_kl            | 333.78302     |
|    clip_fraction        | 0.246         |
|    clip_range           | 0.2           |
|    entropy_loss         | -157          |
|    explained_variance   | -0.381        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.59         |
|    n_updates            | 10300         |
|    policy_gradient_loss | -0.000192     |
|    reward               | 0.00032760104 |
|    std                  | 69.1          |
|    value_loss           | 5.18e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 296, ResetDay: 1976,Episode: 1258
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1032           |
|    time_elapsed         | 23357          |
|    total_timesteps      | 2113536        |
| train/                  |                |
|    approx_kl            | 341.1486       |
|    clip_fraction        | 0.265          |
|    clip_range           | 0.2            |
|    entropy_loss         | -158           |
|    explained_variance   | 0.074          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.53          |
|    n_updates            | 10310          |
|    policy_gradient_loss | 0.0126         |
|    reward               | -0.00076229847 |
|    std                  | 69.3           |
|    value_loss           | 3.65e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1338, ResetDay: 3018,Episode: 1259
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1033          |
|    time_elapsed         | 23380         |
|    total_timesteps      | 2115584       |
| train/                  |               |
|    approx_kl            | 343.96967     |
|    clip_fraction        | 0.252         |
|    clip_range           | 0.2           |
|    entropy_loss         | -158          |
|    explained_variance   | 0.00604       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.55         |
|    n_updates            | 10320         |
|    policy_gradient_loss | 0.00685       |
|    reward               | -4.749527e-05 |
|    std                  | 69.5          |
|    value_loss           | 2.1e-06       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 600, ResetDay: 2280,Episode: 1260
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1034          |
|    time_elapsed         | 23402         |
|    total_timesteps      | 2117632       |
| train/                  |               |
|    approx_kl            | 343.05286     |
|    clip_fraction        | 0.258         |
|    clip_range           | 0.2           |
|    entropy_loss         | -158          |
|    explained_variance   | 0.0908        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.55         |
|    n_updates            | 10330         |
|    policy_gradient_loss | 0.00753       |
|    reward               | 2.4250221e-05 |
|    std                  | 69.6          |
|    value_loss           | 1.2e-06       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2280, episode: 1260
begin_total_asset: 200.00
end_total_asset: 296.45
total_reward: 96.45
total_cost: 21.95
total_trades: 44758
Sharpe: 0.357
=================================
Reseting Environment StartDay: 1531, ResetDay: 3211,Episode: 1261
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1035          |
|    time_elapsed         | 23425         |
|    total_timesteps      | 2119680       |
| train/                  |               |
|    approx_kl            | 347.3581      |
|    clip_fraction        | 0.262         |
|    clip_range           | 0.2           |
|    entropy_loss         | -158          |
|    explained_variance   | 0.148         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.58         |
|    n_updates            | 10340         |
|    policy_gradient_loss | 0.00495       |
|    reward               | 0.00012791443 |
|    std                  | 69.7          |
|    value_loss           | 7.15e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2312, ResetDay: 3992,Episode: 1262
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2801, ResetDay: 4481,Episode: 1263
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1036          |
|    time_elapsed         | 23448         |
|    total_timesteps      | 2121728       |
| train/                  |               |
|    approx_kl            | 347.55124     |
|    clip_fraction        | 0.25          |
|    clip_range           | 0.2           |
|    entropy_loss         | -158          |
|    explained_variance   | 0.109         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.57         |
|    n_updates            | 10350         |
|    policy_gradient_loss | 0.00126       |
|    reward               | 1.6910553e-05 |
|    std                  | 69.8          |
|    value_loss           | 6.86e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 232, ResetDay: 1912,Episode: 1264
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1037           |
|    time_elapsed         | 23470          |
|    total_timesteps      | 2123776        |
| train/                  |                |
|    approx_kl            | 347.60883      |
|    clip_fraction        | 0.251          |
|    clip_range           | 0.2            |
|    entropy_loss         | -158           |
|    explained_variance   | 0.0936         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.52          |
|    n_updates            | 10360          |
|    policy_gradient_loss | 0.0139         |
|    reward               | -0.00015438117 |
|    std                  | 70             |
|    value_loss           | 1.47e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2607, ResetDay: 4287,Episode: 1265
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1038          |
|    time_elapsed         | 23493         |
|    total_timesteps      | 2125824       |
| train/                  |               |
|    approx_kl            | 351.727       |
|    clip_fraction        | 0.249         |
|    clip_range           | 0.2           |
|    entropy_loss         | -158          |
|    explained_variance   | -0.0504       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.59         |
|    n_updates            | 10370         |
|    policy_gradient_loss | 0.0106        |
|    reward               | -0.0009791146 |
|    std                  | 70.3          |
|    value_loss           | 1.18e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4287, episode: 1265
begin_total_asset: 200.00
end_total_asset: 721.27
total_reward: 521.27
total_cost: 17.21
total_trades: 44606
Sharpe: 0.650
=================================
Reseting Environment StartDay: 722, ResetDay: 2402,Episode: 1266
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1039         |
|    time_elapsed         | 23515        |
|    total_timesteps      | 2127872      |
| train/                  |              |
|    approx_kl            | 355.0931     |
|    clip_fraction        | 0.248        |
|    clip_range           | 0.2          |
|    entropy_loss         | -158         |
|    explained_variance   | 0.0794       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.58        |
|    n_updates            | 10380        |
|    policy_gradient_loss | -0.000578    |
|    reward               | 3.564606e-05 |
|    std                  | 70.5         |
|    value_loss           | 2.28e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2284, ResetDay: 3964,Episode: 1267
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2765, ResetDay: 4445,Episode: 1268
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1040          |
|    time_elapsed         | 23538         |
|    total_timesteps      | 2129920       |
| train/                  |               |
|    approx_kl            | 354.36188     |
|    clip_fraction        | 0.238         |
|    clip_range           | 0.2           |
|    entropy_loss         | -158          |
|    explained_variance   | -0.0316       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.59         |
|    n_updates            | 10390         |
|    policy_gradient_loss | 0.0015        |
|    reward               | -9.797668e-06 |
|    std                  | 70.7          |
|    value_loss           | 3.31e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 910, ResetDay: 2590,Episode: 1269
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1041          |
|    time_elapsed         | 23560         |
|    total_timesteps      | 2131968       |
| train/                  |               |
|    approx_kl            | 357.21506     |
|    clip_fraction        | 0.231         |
|    clip_range           | 0.2           |
|    entropy_loss         | -158          |
|    explained_variance   | 0.0645        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.59         |
|    n_updates            | 10400         |
|    policy_gradient_loss | 0.0039        |
|    reward               | 3.3576011e-06 |
|    std                  | 70.8          |
|    value_loss           | 2.02e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 703, ResetDay: 2383,Episode: 1270
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1042         |
|    time_elapsed         | 23584        |
|    total_timesteps      | 2134016      |
| train/                  |              |
|    approx_kl            | 358.4466     |
|    clip_fraction        | 0.26         |
|    clip_range           | 0.2          |
|    entropy_loss         | -158         |
|    explained_variance   | -0.227       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.59        |
|    n_updates            | 10410        |
|    policy_gradient_loss | 0.00619      |
|    reward               | 4.622488e-05 |
|    std                  | 71           |
|    value_loss           | 7.75e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2383, episode: 1270
begin_total_asset: 200.00
end_total_asset: 175.50
total_reward: -24.50
total_cost: 10.46
total_trades: 44447
Sharpe: 0.156
=================================
Reseting Environment StartDay: 1072, ResetDay: 2752,Episode: 1271
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1043          |
|    time_elapsed         | 23607         |
|    total_timesteps      | 2136064       |
| train/                  |               |
|    approx_kl            | 361.97845     |
|    clip_fraction        | 0.242         |
|    clip_range           | 0.2           |
|    entropy_loss         | -158          |
|    explained_variance   | 0.0809        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.59         |
|    n_updates            | 10420         |
|    policy_gradient_loss | 0.00494       |
|    reward               | -8.363533e-05 |
|    std                  | 71.1          |
|    value_loss           | 6.51e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1278, ResetDay: 2958,Episode: 1272
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1044          |
|    time_elapsed         | 23630         |
|    total_timesteps      | 2138112       |
| train/                  |               |
|    approx_kl            | 362.2585      |
|    clip_fraction        | 0.241         |
|    clip_range           | 0.2           |
|    entropy_loss         | -158          |
|    explained_variance   | 0.158         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.58         |
|    n_updates            | 10430         |
|    policy_gradient_loss | 0.00943       |
|    reward               | 0.00011758118 |
|    std                  | 71.3          |
|    value_loss           | 4.49e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 557, ResetDay: 2237,Episode: 1273
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1032, ResetDay: 2712,Episode: 1274
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1045           |
|    time_elapsed         | 23653          |
|    total_timesteps      | 2140160        |
| train/                  |                |
|    approx_kl            | 365.11658      |
|    clip_fraction        | 0.253          |
|    clip_range           | 0.2            |
|    entropy_loss         | -158           |
|    explained_variance   | 0.159          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.59          |
|    n_updates            | 10440          |
|    policy_gradient_loss | 0.00116        |
|    reward               | -0.00036441957 |
|    std                  | 71.3           |
|    value_loss           | 5.24e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2622, ResetDay: 4302,Episode: 1275
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1046         |
|    time_elapsed         | 23676        |
|    total_timesteps      | 2142208      |
| train/                  |              |
|    approx_kl            | 362.7657     |
|    clip_fraction        | 0.248        |
|    clip_range           | 0.2          |
|    entropy_loss         | -158         |
|    explained_variance   | 0.139        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.6         |
|    n_updates            | 10450        |
|    policy_gradient_loss | 0.00559      |
|    reward               | 0.0001460495 |
|    std                  | 71.4         |
|    value_loss           | 7.76e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4302, episode: 1275
begin_total_asset: 200.00
end_total_asset: 486.61
total_reward: 286.61
total_cost: 13.21
total_trades: 44440
Sharpe: 0.647
=================================
Reseting Environment StartDay: 2195, ResetDay: 3875,Episode: 1276
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1047           |
|    time_elapsed         | 23698          |
|    total_timesteps      | 2144256        |
| train/                  |                |
|    approx_kl            | 365.99957      |
|    clip_fraction        | 0.245          |
|    clip_range           | 0.2            |
|    entropy_loss         | -158           |
|    explained_variance   | 0.154          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.61          |
|    n_updates            | 10460          |
|    policy_gradient_loss | 0.000359       |
|    reward               | -0.00023022766 |
|    std                  | 71.5           |
|    value_loss           | 5.87e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1995, ResetDay: 3675,Episode: 1277
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1048         |
|    time_elapsed         | 23721        |
|    total_timesteps      | 2146304      |
| train/                  |              |
|    approx_kl            | 365.78064    |
|    clip_fraction        | 0.246        |
|    clip_range           | 0.2          |
|    entropy_loss         | -158         |
|    explained_variance   | 0.0555       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.57        |
|    n_updates            | 10470        |
|    policy_gradient_loss | 0.0053       |
|    reward               | 0.0007051483 |
|    std                  | 71.6         |
|    value_loss           | 2.73e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 219, ResetDay: 1899,Episode: 1278
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2363, ResetDay: 4043,Episode: 1279
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1049         |
|    time_elapsed         | 23744        |
|    total_timesteps      | 2148352      |
| train/                  |              |
|    approx_kl            | 365.95737    |
|    clip_fraction        | 0.25         |
|    clip_range           | 0.2          |
|    entropy_loss         | -158         |
|    explained_variance   | 0.0656       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.55        |
|    n_updates            | 10480        |
|    policy_gradient_loss | 0.00331      |
|    reward               | 0.0004300129 |
|    std                  | 71.8         |
|    value_loss           | 8.05e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 874, ResetDay: 2554,Episode: 1280
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1050           |
|    time_elapsed         | 23766          |
|    total_timesteps      | 2150400        |
| train/                  |                |
|    approx_kl            | 367.89716      |
|    clip_fraction        | 0.252          |
|    clip_range           | 0.2            |
|    entropy_loss         | -159           |
|    explained_variance   | 0.115          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.59          |
|    n_updates            | 10490          |
|    policy_gradient_loss | 0.00877        |
|    reward               | -6.1683655e-05 |
|    std                  | 72             |
|    value_loss           | 1.91e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2554, episode: 1280
begin_total_asset: 200.00
end_total_asset: 363.71
total_reward: 163.71
total_cost: 14.19
total_trades: 44431
Sharpe: 0.486
=================================
Reseting Environment StartDay: 1497, ResetDay: 3177,Episode: 1281
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1051         |
|    time_elapsed         | 23789        |
|    total_timesteps      | 2152448      |
| train/                  |              |
|    approx_kl            | 368.1103     |
|    clip_fraction        | 0.251        |
|    clip_range           | 0.2          |
|    entropy_loss         | -159         |
|    explained_variance   | 0.0643       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.56        |
|    n_updates            | 10500        |
|    policy_gradient_loss | 0.0109       |
|    reward               | 0.0006614685 |
|    std                  | 72.4         |
|    value_loss           | 4.51e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1749, ResetDay: 3429,Episode: 1282
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1052           |
|    time_elapsed         | 23812          |
|    total_timesteps      | 2154496        |
| train/                  |                |
|    approx_kl            | 374.21832      |
|    clip_fraction        | 0.252          |
|    clip_range           | 0.2            |
|    entropy_loss         | -159           |
|    explained_variance   | -0.246         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.58          |
|    n_updates            | 10510          |
|    policy_gradient_loss | 0.00594        |
|    reward               | -3.9189148e-05 |
|    std                  | 72.6           |
|    value_loss           | 1.12e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1235, ResetDay: 2915,Episode: 1283
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1053          |
|    time_elapsed         | 23835         |
|    total_timesteps      | 2156544       |
| train/                  |               |
|    approx_kl            | 376.69427     |
|    clip_fraction        | 0.248         |
|    clip_range           | 0.2           |
|    entropy_loss         | -159          |
|    explained_variance   | 0.0675        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.58         |
|    n_updates            | 10520         |
|    policy_gradient_loss | 0.000867      |
|    reward               | 0.00040971965 |
|    std                  | 72.8          |
|    value_loss           | 5.69e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2023, ResetDay: 3703,Episode: 1284
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1646, ResetDay: 3326,Episode: 1285
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1054           |
|    time_elapsed         | 23857          |
|    total_timesteps      | 2158592        |
| train/                  |                |
|    approx_kl            | 380.53827      |
|    clip_fraction        | 0.246          |
|    clip_range           | 0.2            |
|    entropy_loss         | -159           |
|    explained_variance   | 0.124          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.6           |
|    n_updates            | 10530          |
|    policy_gradient_loss | 0.0048         |
|    reward               | -0.00021974526 |
|    std                  | 73             |
|    value_loss           | 6.15e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3326, episode: 1285
begin_total_asset: 200.00
end_total_asset: 278.36
total_reward: 78.36
total_cost: 5.86
total_trades: 44334
Sharpe: 0.354
=================================
Reseting Environment StartDay: 2040, ResetDay: 3720,Episode: 1286
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1055          |
|    time_elapsed         | 23880         |
|    total_timesteps      | 2160640       |
| train/                  |               |
|    approx_kl            | 379.28552     |
|    clip_fraction        | 0.231         |
|    clip_range           | 0.2           |
|    entropy_loss         | -159          |
|    explained_variance   | 0.143         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.61         |
|    n_updates            | 10540         |
|    policy_gradient_loss | 0.00306       |
|    reward               | 0.00026518496 |
|    std                  | 73.2          |
|    value_loss           | 1.35e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2469, ResetDay: 4149,Episode: 1287
---------------------------------------------
| time/                   |                 |
|    fps                  | 90              |
|    iterations           | 1056            |
|    time_elapsed         | 23902           |
|    total_timesteps      | 2162688         |
| train/                  |                 |
|    approx_kl            | 385.38312       |
|    clip_fraction        | 0.242           |
|    clip_range           | 0.2             |
|    entropy_loss         | -159            |
|    explained_variance   | -0.0472         |
|    learning_rate        | 0.00025         |
|    loss                 | -1.59           |
|    n_updates            | 10550           |
|    policy_gradient_loss | 0.00616         |
|    reward               | -0.000109957124 |
|    std                  | 73.2            |
|    value_loss           | 3.77e-07        |
---------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1500, ResetDay: 3180,Episode: 1288
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1057          |
|    time_elapsed         | 23925         |
|    total_timesteps      | 2164736       |
| train/                  |               |
|    approx_kl            | 384.66824     |
|    clip_fraction        | 0.23          |
|    clip_range           | 0.2           |
|    entropy_loss         | -159          |
|    explained_variance   | 0.18          |
|    learning_rate        | 0.00025       |
|    loss                 | -1.59         |
|    n_updates            | 10560         |
|    policy_gradient_loss | 0.00094       |
|    reward               | -0.0002662077 |
|    std                  | 73.4          |
|    value_loss           | 9.93e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 447, ResetDay: 2127,Episode: 1289
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1058         |
|    time_elapsed         | 23948        |
|    total_timesteps      | 2166784      |
| train/                  |              |
|    approx_kl            | 386.9666     |
|    clip_fraction        | 0.238        |
|    clip_range           | 0.2          |
|    entropy_loss         | -159         |
|    explained_variance   | 0.0148       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.57        |
|    n_updates            | 10570        |
|    policy_gradient_loss | 0.00397      |
|    reward               | 9.358463e-05 |
|    std                  | 73.5         |
|    value_loss           | 1.12e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 709, ResetDay: 2389,Episode: 1290
Environment reached Terminal state as number of trading days reached limit!!
day: 2389, episode: 1290
begin_total_asset: 200.00
end_total_asset: 256.73
total_reward: 56.73
total_cost: 16.55
total_trades: 44370
Sharpe: 0.308
=================================
Reseting Environment StartDay: 357, ResetDay: 2037,Episode: 1291
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1059           |
|    time_elapsed         | 23970          |
|    total_timesteps      | 2168832        |
| train/                  |                |
|    approx_kl            | 386.48932      |
|    clip_fraction        | 0.253          |
|    clip_range           | 0.2            |
|    entropy_loss         | -159           |
|    explained_variance   | -0.174         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.57          |
|    n_updates            | 10580          |
|    policy_gradient_loss | 0.0065         |
|    reward               | -7.5509546e-05 |
|    std                  | 73.5           |
|    value_loss           | 4.91e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1798, ResetDay: 3478,Episode: 1292
---------------------------------------
| time/                   |           |
|    fps                  | 90        |
|    iterations           | 1060      |
|    time_elapsed         | 23993     |
|    total_timesteps      | 2170880   |
| train/                  |           |
|    approx_kl            | 384.53217 |
|    clip_fraction        | 0.247     |
|    clip_range           | 0.2       |
|    entropy_loss         | -159      |
|    explained_variance   | 0.151     |
|    learning_rate        | 0.00025   |
|    loss                 | -1.59     |
|    n_updates            | 10590     |
|    policy_gradient_loss | 0.000923  |
|    reward               | 0.0       |
|    std                  | 73.8      |
|    value_loss           | 8.2e-07   |
---------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 128, ResetDay: 1808,Episode: 1293
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1061           |
|    time_elapsed         | 24015          |
|    total_timesteps      | 2172928        |
| train/                  |                |
|    approx_kl            | 385.0987       |
|    clip_fraction        | 0.245          |
|    clip_range           | 0.2            |
|    entropy_loss         | -159           |
|    explained_variance   | 0.309          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.56          |
|    n_updates            | 10600          |
|    policy_gradient_loss | 0.0126         |
|    reward               | -0.00021320085 |
|    std                  | 74.1           |
|    value_loss           | 9.82e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 130, ResetDay: 1810,Episode: 1294
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1062          |
|    time_elapsed         | 24038         |
|    total_timesteps      | 2174976       |
| train/                  |               |
|    approx_kl            | 388.05084     |
|    clip_fraction        | 0.238         |
|    clip_range           | 0.2           |
|    entropy_loss         | -159          |
|    explained_variance   | 0.0642        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.6          |
|    n_updates            | 10610         |
|    policy_gradient_loss | 0.00623       |
|    reward               | 4.8367405e-05 |
|    std                  | 74.4          |
|    value_loss           | 1.21e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2790, ResetDay: 4470,Episode: 1295
Environment reached Terminal state as number of trading days reached limit!!
day: 4470, episode: 1295
begin_total_asset: 200.00
end_total_asset: 686.22
total_reward: 486.22
total_cost: 17.19
total_trades: 44108
Sharpe: 0.649
=================================
Reseting Environment StartDay: 2151, ResetDay: 3831,Episode: 1296
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1063           |
|    time_elapsed         | 24061          |
|    total_timesteps      | 2177024        |
| train/                  |                |
|    approx_kl            | 394.79703      |
|    clip_fraction        | 0.248          |
|    clip_range           | 0.2            |
|    entropy_loss         | -160           |
|    explained_variance   | 0.146          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.58          |
|    n_updates            | 10620          |
|    policy_gradient_loss | 0.0109         |
|    reward               | -1.0649109e-05 |
|    std                  | 74.5           |
|    value_loss           | 3.32e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2243, ResetDay: 3923,Episode: 1297
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1064           |
|    time_elapsed         | 24083          |
|    total_timesteps      | 2179072        |
| train/                  |                |
|    approx_kl            | 395.6249       |
|    clip_fraction        | 0.245          |
|    clip_range           | 0.2            |
|    entropy_loss         | -160           |
|    explained_variance   | 0.0157         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.61          |
|    n_updates            | 10630          |
|    policy_gradient_loss | 0.00249        |
|    reward               | -1.6836166e-05 |
|    std                  | 74.7           |
|    value_loss           | 7.24e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1668, ResetDay: 3348,Episode: 1298
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1065          |
|    time_elapsed         | 24106         |
|    total_timesteps      | 2181120       |
| train/                  |               |
|    approx_kl            | 397.4179      |
|    clip_fraction        | 0.239         |
|    clip_range           | 0.2           |
|    entropy_loss         | -160          |
|    explained_variance   | -0.225        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.57         |
|    n_updates            | 10640         |
|    policy_gradient_loss | 0.00816       |
|    reward               | -4.385986e-05 |
|    std                  | 74.9          |
|    value_loss           | 1.06e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 153, ResetDay: 1833,Episode: 1299
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1066          |
|    time_elapsed         | 24128         |
|    total_timesteps      | 2183168       |
| train/                  |               |
|    approx_kl            | 401.89746     |
|    clip_fraction        | 0.242         |
|    clip_range           | 0.2           |
|    entropy_loss         | -160          |
|    explained_variance   | 0.101         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.56         |
|    n_updates            | 10650         |
|    policy_gradient_loss | 0.00822       |
|    reward               | -0.0003756137 |
|    std                  | 75            |
|    value_loss           | 1.13e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2147, ResetDay: 3827,Episode: 1300
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1067           |
|    time_elapsed         | 24151          |
|    total_timesteps      | 2185216        |
| train/                  |                |
|    approx_kl            | 402.6385       |
|    clip_fraction        | 0.236          |
|    clip_range           | 0.2            |
|    entropy_loss         | -160           |
|    explained_variance   | -0.0874        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.59          |
|    n_updates            | 10660          |
|    policy_gradient_loss | 0.0036         |
|    reward               | -0.00050961913 |
|    std                  | 75.1           |
|    value_loss           | 1.13e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3827, episode: 1300
begin_total_asset: 200.00
end_total_asset: 668.90
total_reward: 468.90
total_cost: 21.21
total_trades: 44240
Sharpe: 0.804
=================================
Reseting Environment StartDay: 2375, ResetDay: 4055,Episode: 1301
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2449, ResetDay: 4129,Episode: 1302
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1068          |
|    time_elapsed         | 24173         |
|    total_timesteps      | 2187264       |
| train/                  |               |
|    approx_kl            | 401.9796      |
|    clip_fraction        | 0.223         |
|    clip_range           | 0.2           |
|    entropy_loss         | -160          |
|    explained_variance   | 0.0887        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.58         |
|    n_updates            | 10670         |
|    policy_gradient_loss | 0.00399       |
|    reward               | 1.9244384e-05 |
|    std                  | 75.4          |
|    value_loss           | 3.12e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 764, ResetDay: 2444,Episode: 1303
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1069          |
|    time_elapsed         | 24196         |
|    total_timesteps      | 2189312       |
| train/                  |               |
|    approx_kl            | 405.96906     |
|    clip_fraction        | 0.243         |
|    clip_range           | 0.2           |
|    entropy_loss         | -160          |
|    explained_variance   | 0.0913        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.6          |
|    n_updates            | 10680         |
|    policy_gradient_loss | 0.0165        |
|    reward               | 4.7372818e-05 |
|    std                  | 75.4          |
|    value_loss           | 2.01e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1584, ResetDay: 3264,Episode: 1304
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1070         |
|    time_elapsed         | 24219        |
|    total_timesteps      | 2191360      |
| train/                  |              |
|    approx_kl            | 406.8791     |
|    clip_fraction        | 0.238        |
|    clip_range           | 0.2          |
|    entropy_loss         | -160         |
|    explained_variance   | -0.302       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.59        |
|    n_updates            | 10690        |
|    policy_gradient_loss | 0.00866      |
|    reward               | 8.524017e-05 |
|    std                  | 75.5         |
|    value_loss           | 1.13e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1159, ResetDay: 2839,Episode: 1305
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1071          |
|    time_elapsed         | 24241         |
|    total_timesteps      | 2193408       |
| train/                  |               |
|    approx_kl            | 405.2849      |
|    clip_fraction        | 0.234         |
|    clip_range           | 0.2           |
|    entropy_loss         | -160          |
|    explained_variance   | -0.131        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.61         |
|    n_updates            | 10700         |
|    policy_gradient_loss | 0.00249       |
|    reward               | 0.00026315765 |
|    std                  | 75.7          |
|    value_loss           | 3.6e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2839, episode: 1305
begin_total_asset: 200.00
end_total_asset: 199.57
total_reward: -0.43
total_cost: 9.62
total_trades: 44247
Sharpe: 0.176
=================================
Reseting Environment StartDay: 1157, ResetDay: 2837,Episode: 1306
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2800, ResetDay: 4480,Episode: 1307
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1072          |
|    time_elapsed         | 24264         |
|    total_timesteps      | 2195456       |
| train/                  |               |
|    approx_kl            | 410.85214     |
|    clip_fraction        | 0.228         |
|    clip_range           | 0.2           |
|    entropy_loss         | -160          |
|    explained_variance   | 0.174         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.59         |
|    n_updates            | 10710         |
|    policy_gradient_loss | 0.00682       |
|    reward               | 5.5623244e-05 |
|    std                  | 75.9          |
|    value_loss           | 5.14e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1013, ResetDay: 2693,Episode: 1308
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1073          |
|    time_elapsed         | 24286         |
|    total_timesteps      | 2197504       |
| train/                  |               |
|    approx_kl            | 412.16605     |
|    clip_fraction        | 0.227         |
|    clip_range           | 0.2           |
|    entropy_loss         | -160          |
|    explained_variance   | 0.103         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.59         |
|    n_updates            | 10720         |
|    policy_gradient_loss | 0.00578       |
|    reward               | 0.00018579388 |
|    std                  | 75.8          |
|    value_loss           | 4.91e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1585, ResetDay: 3265,Episode: 1309
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1074          |
|    time_elapsed         | 24309         |
|    total_timesteps      | 2199552       |
| train/                  |               |
|    approx_kl            | 409.9588      |
|    clip_fraction        | 0.244         |
|    clip_range           | 0.2           |
|    entropy_loss         | -160          |
|    explained_variance   | 0.0113        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.6          |
|    n_updates            | 10730         |
|    policy_gradient_loss | 0.00635       |
|    reward               | 0.00035240364 |
|    std                  | 76.1          |
|    value_loss           | 1.93e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2082, ResetDay: 3762,Episode: 1310
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1075          |
|    time_elapsed         | 24332         |
|    total_timesteps      | 2201600       |
| train/                  |               |
|    approx_kl            | 409.40845     |
|    clip_fraction        | 0.239         |
|    clip_range           | 0.2           |
|    entropy_loss         | -160          |
|    explained_variance   | -0.0254       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.6          |
|    n_updates            | 10740         |
|    policy_gradient_loss | 0.00851       |
|    reward               | 0.00031612854 |
|    std                  | 76.3          |
|    value_loss           | 3.86e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3762, episode: 1310
begin_total_asset: 200.00
end_total_asset: 247.80
total_reward: 47.80
total_cost: 8.90
total_trades: 44198
Sharpe: 0.260
=================================
Reseting Environment StartDay: 1862, ResetDay: 3542,Episode: 1311
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1076          |
|    time_elapsed         | 24355         |
|    total_timesteps      | 2203648       |
| train/                  |               |
|    approx_kl            | 415.55884     |
|    clip_fraction        | 0.228         |
|    clip_range           | 0.2           |
|    entropy_loss         | -160          |
|    explained_variance   | 0.119         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.62         |
|    n_updates            | 10750         |
|    policy_gradient_loss | 0.00728       |
|    reward               | 0.00010996971 |
|    std                  | 76.3          |
|    value_loss           | 5.8e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2422, ResetDay: 4102,Episode: 1312
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 22, ResetDay: 1702,Episode: 1313
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1077           |
|    time_elapsed         | 24377          |
|    total_timesteps      | 2205696        |
| train/                  |                |
|    approx_kl            | 414.04913      |
|    clip_fraction        | 0.224          |
|    clip_range           | 0.2            |
|    entropy_loss         | -160           |
|    explained_variance   | 0.0996         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.6           |
|    n_updates            | 10760          |
|    policy_gradient_loss | 0.00455        |
|    reward               | -0.00010838946 |
|    std                  | 76.5           |
|    value_loss           | 2.05e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1555, ResetDay: 3235,Episode: 1314
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1078           |
|    time_elapsed         | 24400          |
|    total_timesteps      | 2207744        |
| train/                  |                |
|    approx_kl            | 413.38907      |
|    clip_fraction        | 0.236          |
|    clip_range           | 0.2            |
|    entropy_loss         | -160           |
|    explained_variance   | -0.0173        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.61          |
|    n_updates            | 10770          |
|    policy_gradient_loss | 0.00393        |
|    reward               | -0.00017806473 |
|    std                  | 76.9           |
|    value_loss           | 1.2e-06        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1219, ResetDay: 2899,Episode: 1315
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1079         |
|    time_elapsed         | 24422        |
|    total_timesteps      | 2209792      |
| train/                  |              |
|    approx_kl            | 419.64178    |
|    clip_fraction        | 0.215        |
|    clip_range           | 0.2          |
|    entropy_loss         | -161         |
|    explained_variance   | 0.0707       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.61        |
|    n_updates            | 10780        |
|    policy_gradient_loss | 0.0046       |
|    reward               | 0.0001256898 |
|    std                  | 77.1         |
|    value_loss           | 1.26e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2899, episode: 1315
begin_total_asset: 200.00
end_total_asset: 189.86
total_reward: -10.14
total_cost: 10.98
total_trades: 44094
Sharpe: 0.176
=================================
Reseting Environment StartDay: 1734, ResetDay: 3414,Episode: 1316
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1080           |
|    time_elapsed         | 24445          |
|    total_timesteps      | 2211840        |
| train/                  |                |
|    approx_kl            | 423.69025      |
|    clip_fraction        | 0.225          |
|    clip_range           | 0.2            |
|    entropy_loss         | -161           |
|    explained_variance   | 0.097          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.61          |
|    n_updates            | 10790          |
|    policy_gradient_loss | -0.00271       |
|    reward               | -3.7689973e-05 |
|    std                  | 77.3           |
|    value_loss           | 1.48e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1695, ResetDay: 3375,Episode: 1317
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2285, ResetDay: 3965,Episode: 1318
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1081          |
|    time_elapsed         | 24467         |
|    total_timesteps      | 2213888       |
| train/                  |               |
|    approx_kl            | 424.63342     |
|    clip_fraction        | 0.234         |
|    clip_range           | 0.2           |
|    entropy_loss         | -161          |
|    explained_variance   | 0.135         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.62         |
|    n_updates            | 10800         |
|    policy_gradient_loss | 0.00189       |
|    reward               | 2.5009156e-06 |
|    std                  | 77.5          |
|    value_loss           | 5.77e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1577, ResetDay: 3257,Episode: 1319
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1082           |
|    time_elapsed         | 24490          |
|    total_timesteps      | 2215936        |
| train/                  |                |
|    approx_kl            | 428.0161       |
|    clip_fraction        | 0.214          |
|    clip_range           | 0.2            |
|    entropy_loss         | -161           |
|    explained_variance   | 0.17           |
|    learning_rate        | 0.00025        |
|    loss                 | -1.64          |
|    n_updates            | 10810          |
|    policy_gradient_loss | -0.00234       |
|    reward               | -9.7305965e-05 |
|    std                  | 77.6           |
|    value_loss           | 6.3e-07        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1498, ResetDay: 3178,Episode: 1320
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1083          |
|    time_elapsed         | 24513         |
|    total_timesteps      | 2217984       |
| train/                  |               |
|    approx_kl            | 427.07077     |
|    clip_fraction        | 0.215         |
|    clip_range           | 0.2           |
|    entropy_loss         | -161          |
|    explained_variance   | 0.116         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.59         |
|    n_updates            | 10820         |
|    policy_gradient_loss | 0.00605       |
|    reward               | -7.236633e-05 |
|    std                  | 77.8          |
|    value_loss           | 1.37e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3178, episode: 1320
begin_total_asset: 200.00
end_total_asset: 238.19
total_reward: 38.19
total_cost: 5.23
total_trades: 43964
Sharpe: 0.269
=================================
Reseting Environment StartDay: 2737, ResetDay: 4417,Episode: 1321
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1084           |
|    time_elapsed         | 24536          |
|    total_timesteps      | 2220032        |
| train/                  |                |
|    approx_kl            | 429.4513       |
|    clip_fraction        | 0.218          |
|    clip_range           | 0.2            |
|    entropy_loss         | -161           |
|    explained_variance   | -0.0122        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.61          |
|    n_updates            | 10830          |
|    policy_gradient_loss | 0.00437        |
|    reward               | -0.00040186234 |
|    std                  | 78             |
|    value_loss           | 4.46e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 358, ResetDay: 2038,Episode: 1322
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1085          |
|    time_elapsed         | 24558         |
|    total_timesteps      | 2222080       |
| train/                  |               |
|    approx_kl            | 434.1698      |
|    clip_fraction        | 0.236         |
|    clip_range           | 0.2           |
|    entropy_loss         | -161          |
|    explained_variance   | 0.14          |
|    learning_rate        | 0.00025       |
|    loss                 | -1.62         |
|    n_updates            | 10840         |
|    policy_gradient_loss | 0.00246       |
|    reward               | 3.4604644e-05 |
|    std                  | 78.2          |
|    value_loss           | 9.54e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2478, ResetDay: 4158,Episode: 1323
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 658, ResetDay: 2338,Episode: 1324
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1086           |
|    time_elapsed         | 24581          |
|    total_timesteps      | 2224128        |
| train/                  |                |
|    approx_kl            | 436.34845      |
|    clip_fraction        | 0.217          |
|    clip_range           | 0.2            |
|    entropy_loss         | -161           |
|    explained_variance   | -0.11          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.63          |
|    n_updates            | 10850          |
|    policy_gradient_loss | -0.00387       |
|    reward               | -0.00026372095 |
|    std                  | 78.4           |
|    value_loss           | 1.69e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1547, ResetDay: 3227,Episode: 1325
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1087           |
|    time_elapsed         | 24603          |
|    total_timesteps      | 2226176        |
| train/                  |                |
|    approx_kl            | 435.91785      |
|    clip_fraction        | 0.231          |
|    clip_range           | 0.2            |
|    entropy_loss         | -161           |
|    explained_variance   | 0.0385         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.61          |
|    n_updates            | 10860          |
|    policy_gradient_loss | 0.00708        |
|    reward               | -1.1878968e-05 |
|    std                  | 78.7           |
|    value_loss           | 3.56e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3227, episode: 1325
begin_total_asset: 200.00
end_total_asset: 288.90
total_reward: 88.90
total_cost: 6.13
total_trades: 43977
Sharpe: 0.364
=================================
Reseting Environment StartDay: 2701, ResetDay: 4381,Episode: 1326
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1088         |
|    time_elapsed         | 24626        |
|    total_timesteps      | 2228224      |
| train/                  |              |
|    approx_kl            | 443.72943    |
|    clip_fraction        | 0.215        |
|    clip_range           | 0.2          |
|    entropy_loss         | -161         |
|    explained_variance   | -0.751       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.62        |
|    n_updates            | 10870        |
|    policy_gradient_loss | 0.00288      |
|    reward               | 0.0001658764 |
|    std                  | 78.8         |
|    value_loss           | 6.01e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 68, ResetDay: 1748,Episode: 1327
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1089         |
|    time_elapsed         | 24649        |
|    total_timesteps      | 2230272      |
| train/                  |              |
|    approx_kl            | 441.8169     |
|    clip_fraction        | 0.221        |
|    clip_range           | 0.2          |
|    entropy_loss         | -161         |
|    explained_variance   | 0.0657       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.61        |
|    n_updates            | 10880        |
|    policy_gradient_loss | -0.000472    |
|    reward               | 0.0005945996 |
|    std                  | 79.1         |
|    value_loss           | 4.43e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1180, ResetDay: 2860,Episode: 1328
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1090         |
|    time_elapsed         | 24671        |
|    total_timesteps      | 2232320      |
| train/                  |              |
|    approx_kl            | 448.15292    |
|    clip_fraction        | 0.211        |
|    clip_range           | 0.2          |
|    entropy_loss         | -161         |
|    explained_variance   | -0.0182      |
|    learning_rate        | 0.00025      |
|    loss                 | -1.62        |
|    n_updates            | 10890        |
|    policy_gradient_loss | 0.00502      |
|    reward               | 4.854126e-05 |
|    std                  | 79.3         |
|    value_loss           | 1.43e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1499, ResetDay: 3179,Episode: 1329
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2272, ResetDay: 3952,Episode: 1330
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1091          |
|    time_elapsed         | 24694         |
|    total_timesteps      | 2234368       |
| train/                  |               |
|    approx_kl            | 450.69122     |
|    clip_fraction        | 0.225         |
|    clip_range           | 0.2           |
|    entropy_loss         | -161          |
|    explained_variance   | 0.0945        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.59         |
|    n_updates            | 10900         |
|    policy_gradient_loss | 0.00603       |
|    reward               | -8.839111e-05 |
|    std                  | 79.4          |
|    value_loss           | 7.96e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3952, episode: 1330
begin_total_asset: 200.00
end_total_asset: 334.76
total_reward: 134.76
total_cost: 16.61
total_trades: 43907
Sharpe: 0.424
=================================
Reseting Environment StartDay: 489, ResetDay: 2169,Episode: 1331
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1092           |
|    time_elapsed         | 24717          |
|    total_timesteps      | 2236416        |
| train/                  |                |
|    approx_kl            | 451.05914      |
|    clip_fraction        | 0.228          |
|    clip_range           | 0.2            |
|    entropy_loss         | -161           |
|    explained_variance   | 0.148          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.6           |
|    n_updates            | 10910          |
|    policy_gradient_loss | 0.0119         |
|    reward               | -3.5795878e-05 |
|    std                  | 79.7           |
|    value_loss           | 5.4e-07        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 620, ResetDay: 2300,Episode: 1332
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1093         |
|    time_elapsed         | 24739        |
|    total_timesteps      | 2238464      |
| train/                  |              |
|    approx_kl            | 454.88       |
|    clip_fraction        | 0.227        |
|    clip_range           | 0.2          |
|    entropy_loss         | -161         |
|    explained_variance   | 0.0739       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.6         |
|    n_updates            | 10920        |
|    policy_gradient_loss | 0.00632      |
|    reward               | -4.70212e-05 |
|    std                  | 79.9         |
|    value_loss           | 1.62e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 733, ResetDay: 2413,Episode: 1333
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1094          |
|    time_elapsed         | 24762         |
|    total_timesteps      | 2240512       |
| train/                  |               |
|    approx_kl            | 456.36688     |
|    clip_fraction        | 0.218         |
|    clip_range           | 0.2           |
|    entropy_loss         | -162          |
|    explained_variance   | 0.105         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.59         |
|    n_updates            | 10930         |
|    policy_gradient_loss | 0.00291       |
|    reward               | 9.4265175e-05 |
|    std                  | 80.2          |
|    value_loss           | 7.95e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1177, ResetDay: 2857,Episode: 1334
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1955, ResetDay: 3635,Episode: 1335
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1095          |
|    time_elapsed         | 24785         |
|    total_timesteps      | 2242560       |
| train/                  |               |
|    approx_kl            | 457.0142      |
|    clip_fraction        | 0.224         |
|    clip_range           | 0.2           |
|    entropy_loss         | -162          |
|    explained_variance   | 0.205         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.6          |
|    n_updates            | 10940         |
|    policy_gradient_loss | 0.00449       |
|    reward               | -7.669983e-05 |
|    std                  | 80.5          |
|    value_loss           | 6.02e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3635, episode: 1335
begin_total_asset: 200.00
end_total_asset: 364.86
total_reward: 164.86
total_cost: 13.83
total_trades: 43735
Sharpe: 0.498
=================================
Reseting Environment StartDay: 546, ResetDay: 2226,Episode: 1336
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1096          |
|    time_elapsed         | 24807         |
|    total_timesteps      | 2244608       |
| train/                  |               |
|    approx_kl            | 466.06818     |
|    clip_fraction        | 0.223         |
|    clip_range           | 0.2           |
|    entropy_loss         | -162          |
|    explained_variance   | 0.185         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.62         |
|    n_updates            | 10950         |
|    policy_gradient_loss | -8.22e-05     |
|    reward               | -0.0002111996 |
|    std                  | 80.6          |
|    value_loss           | 3.67e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 594, ResetDay: 2274,Episode: 1337
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1097          |
|    time_elapsed         | 24830         |
|    total_timesteps      | 2246656       |
| train/                  |               |
|    approx_kl            | 464.57544     |
|    clip_fraction        | 0.217         |
|    clip_range           | 0.2           |
|    entropy_loss         | -162          |
|    explained_variance   | 0.105         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.62         |
|    n_updates            | 10960         |
|    policy_gradient_loss | 0.000244      |
|    reward               | 0.00012230706 |
|    std                  | 80.8          |
|    value_loss           | 1.05e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2322, ResetDay: 4002,Episode: 1338
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1098          |
|    time_elapsed         | 24853         |
|    total_timesteps      | 2248704       |
| train/                  |               |
|    approx_kl            | 465.43384     |
|    clip_fraction        | 0.205         |
|    clip_range           | 0.2           |
|    entropy_loss         | -162          |
|    explained_variance   | 0.0532        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.62         |
|    n_updates            | 10970         |
|    policy_gradient_loss | 0.00945       |
|    reward               | -0.0002762146 |
|    std                  | 81.1          |
|    value_loss           | 6.44e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2792, ResetDay: 4472,Episode: 1339
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1099           |
|    time_elapsed         | 24875          |
|    total_timesteps      | 2250752        |
| train/                  |                |
|    approx_kl            | 469.20032      |
|    clip_fraction        | 0.224          |
|    clip_range           | 0.2            |
|    entropy_loss         | -162           |
|    explained_variance   | 0.224          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.61          |
|    n_updates            | 10980          |
|    policy_gradient_loss | 0.00686        |
|    reward               | -0.00012974853 |
|    std                  | 81.2           |
|    value_loss           | 9.43e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 437, ResetDay: 2117,Episode: 1340
Environment reached Terminal state as number of trading days reached limit!!
day: 2117, episode: 1340
begin_total_asset: 200.00
end_total_asset: 316.11
total_reward: 116.11
total_cost: 26.25
total_trades: 43931
Sharpe: 0.417
=================================
Reseting Environment StartDay: 1908, ResetDay: 3588,Episode: 1341
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1100         |
|    time_elapsed         | 24898        |
|    total_timesteps      | 2252800      |
| train/                  |              |
|    approx_kl            | 467.16287    |
|    clip_fraction        | 0.211        |
|    clip_range           | 0.2          |
|    entropy_loss         | -162         |
|    explained_variance   | 0.0979       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.62        |
|    n_updates            | 10990        |
|    policy_gradient_loss | 0.00713      |
|    reward               | 0.0003291851 |
|    std                  | 81.6         |
|    value_loss           | 1.66e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 75, ResetDay: 1755,Episode: 1342
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1101          |
|    time_elapsed         | 24921         |
|    total_timesteps      | 2254848       |
| train/                  |               |
|    approx_kl            | 475.12534     |
|    clip_fraction        | 0.203         |
|    clip_range           | 0.2           |
|    entropy_loss         | -162          |
|    explained_variance   | -0.527        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.63         |
|    n_updates            | 11000         |
|    policy_gradient_loss | 0.00043       |
|    reward               | -0.0007739488 |
|    std                  | 82            |
|    value_loss           | 1.18e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 978, ResetDay: 2658,Episode: 1343
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1102           |
|    time_elapsed         | 24943          |
|    total_timesteps      | 2256896        |
| train/                  |                |
|    approx_kl            | 484.46637      |
|    clip_fraction        | 0.211          |
|    clip_range           | 0.2            |
|    entropy_loss         | -162           |
|    explained_variance   | 0.0528         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.63          |
|    n_updates            | 11010          |
|    policy_gradient_loss | -0.000491      |
|    reward               | -1.4629364e-05 |
|    std                  | 82             |
|    value_loss           | 1.31e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 799, ResetDay: 2479,Episode: 1344
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1103         |
|    time_elapsed         | 24966        |
|    total_timesteps      | 2258944      |
| train/                  |              |
|    approx_kl            | 481.20007    |
|    clip_fraction        | 0.206        |
|    clip_range           | 0.2          |
|    entropy_loss         | -162         |
|    explained_variance   | 0.161        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.64        |
|    n_updates            | 11020        |
|    policy_gradient_loss | 0.0047       |
|    reward               | 0.0001466362 |
|    std                  | 82.2         |
|    value_loss           | 1.31e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2769, ResetDay: 4449,Episode: 1345
Environment reached Terminal state as number of trading days reached limit!!
day: 4449, episode: 1345
begin_total_asset: 200.00
end_total_asset: 403.40
total_reward: 203.40
total_cost: 11.75
total_trades: 43529
Sharpe: 0.537
=================================
Reseting Environment StartDay: 690, ResetDay: 2370,Episode: 1346
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1104          |
|    time_elapsed         | 24989         |
|    total_timesteps      | 2260992       |
| train/                  |               |
|    approx_kl            | 484.25848     |
|    clip_fraction        | 0.2           |
|    clip_range           | 0.2           |
|    entropy_loss         | -162          |
|    explained_variance   | 0.0867        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.61         |
|    n_updates            | 11030         |
|    policy_gradient_loss | 0.000565      |
|    reward               | -8.274624e-05 |
|    std                  | 82.5          |
|    value_loss           | 1.02e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2435, ResetDay: 4115,Episode: 1347
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1105          |
|    time_elapsed         | 25011         |
|    total_timesteps      | 2263040       |
| train/                  |               |
|    approx_kl            | 489.03174     |
|    clip_fraction        | 0.206         |
|    clip_range           | 0.2           |
|    entropy_loss         | -162          |
|    explained_variance   | 0.0208        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.63         |
|    n_updates            | 11040         |
|    policy_gradient_loss | -0.00279      |
|    reward               | 5.8787537e-05 |
|    std                  | 82.6          |
|    value_loss           | 1.98e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 907, ResetDay: 2587,Episode: 1348
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1106           |
|    time_elapsed         | 25034          |
|    total_timesteps      | 2265088        |
| train/                  |                |
|    approx_kl            | 486.61328      |
|    clip_fraction        | 0.208          |
|    clip_range           | 0.2            |
|    entropy_loss         | -162           |
|    explained_variance   | -0.728         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.62          |
|    n_updates            | 11050          |
|    policy_gradient_loss | 0.0029         |
|    reward               | -0.00032416935 |
|    std                  | 82.9           |
|    value_loss           | 3.45e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2443, ResetDay: 4123,Episode: 1349
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1107           |
|    time_elapsed         | 25057          |
|    total_timesteps      | 2267136        |
| train/                  |                |
|    approx_kl            | 492.33124      |
|    clip_fraction        | 0.198          |
|    clip_range           | 0.2            |
|    entropy_loss         | -163           |
|    explained_variance   | 0.105          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.64          |
|    n_updates            | 11060          |
|    policy_gradient_loss | -0.00279       |
|    reward               | 0.000107601925 |
|    std                  | 83.2           |
|    value_loss           | 1.53e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2014, ResetDay: 3694,Episode: 1350
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1108           |
|    time_elapsed         | 25079          |
|    total_timesteps      | 2269184        |
| train/                  |                |
|    approx_kl            | 496.37527      |
|    clip_fraction        | 0.208          |
|    clip_range           | 0.2            |
|    entropy_loss         | -163           |
|    explained_variance   | 0.174          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.6           |
|    n_updates            | 11070          |
|    policy_gradient_loss | 0.00664        |
|    reward               | -0.00016572876 |
|    std                  | 83.4           |
|    value_loss           | 8.6e-07        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3694, episode: 1350
begin_total_asset: 200.00
end_total_asset: 246.72
total_reward: 46.72
total_cost: 7.90
total_trades: 43553
Sharpe: 0.287
=================================
Reseting Environment StartDay: 1695, ResetDay: 3375,Episode: 1351
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1369, ResetDay: 3049,Episode: 1352
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1109           |
|    time_elapsed         | 25102          |
|    total_timesteps      | 2271232        |
| train/                  |                |
|    approx_kl            | 501.23123      |
|    clip_fraction        | 0.208          |
|    clip_range           | 0.2            |
|    entropy_loss         | -163           |
|    explained_variance   | 0.13           |
|    learning_rate        | 0.00025        |
|    loss                 | -1.64          |
|    n_updates            | 11080          |
|    policy_gradient_loss | -0.00329       |
|    reward               | -0.00020095207 |
|    std                  | 83.4           |
|    value_loss           | 1.54e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1240, ResetDay: 2920,Episode: 1353
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1110          |
|    time_elapsed         | 25124         |
|    total_timesteps      | 2273280       |
| train/                  |               |
|    approx_kl            | 500.64874     |
|    clip_fraction        | 0.193         |
|    clip_range           | 0.2           |
|    entropy_loss         | -163          |
|    explained_variance   | -0.0631       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.63         |
|    n_updates            | 11090         |
|    policy_gradient_loss | -0.000574     |
|    reward               | 4.3052673e-06 |
|    std                  | 83.6          |
|    value_loss           | 7.88e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2297, ResetDay: 3977,Episode: 1354
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1111           |
|    time_elapsed         | 25147          |
|    total_timesteps      | 2275328        |
| train/                  |                |
|    approx_kl            | 501.9361       |
|    clip_fraction        | 0.203          |
|    clip_range           | 0.2            |
|    entropy_loss         | -163           |
|    explained_variance   | 0.127          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.63          |
|    n_updates            | 11100          |
|    policy_gradient_loss | -0.000534      |
|    reward               | 0.000109960936 |
|    std                  | 83.7           |
|    value_loss           | 4.2e-07        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2505, ResetDay: 4185,Episode: 1355
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1112          |
|    time_elapsed         | 25170         |
|    total_timesteps      | 2277376       |
| train/                  |               |
|    approx_kl            | 500.8037      |
|    clip_fraction        | 0.209         |
|    clip_range           | 0.2           |
|    entropy_loss         | -163          |
|    explained_variance   | 0.168         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.62         |
|    n_updates            | 11110         |
|    policy_gradient_loss | -0.000579     |
|    reward               | 0.00027009964 |
|    std                  | 84            |
|    value_loss           | 3.35e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4185, episode: 1355
begin_total_asset: 200.00
end_total_asset: 383.46
total_reward: 183.46
total_cost: 7.24
total_trades: 43490
Sharpe: 0.501
=================================
Reseting Environment StartDay: 2711, ResetDay: 4391,Episode: 1356
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1113         |
|    time_elapsed         | 25192        |
|    total_timesteps      | 2279424      |
| train/                  |              |
|    approx_kl            | 505.67773    |
|    clip_fraction        | 0.198        |
|    clip_range           | 0.2          |
|    entropy_loss         | -163         |
|    explained_variance   | 0.132        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.63        |
|    n_updates            | 11120        |
|    policy_gradient_loss | 0.00256      |
|    reward               | -0.000167099 |
|    std                  | 84.3         |
|    value_loss           | 1.74e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 309, ResetDay: 1989,Episode: 1357
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1462, ResetDay: 3142,Episode: 1358
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1114          |
|    time_elapsed         | 25215         |
|    total_timesteps      | 2281472       |
| train/                  |               |
|    approx_kl            | 510.43652     |
|    clip_fraction        | 0.179         |
|    clip_range           | 0.2           |
|    entropy_loss         | -163          |
|    explained_variance   | 0.0224        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.64         |
|    n_updates            | 11130         |
|    policy_gradient_loss | 0.00482       |
|    reward               | 2.8699875e-05 |
|    std                  | 84.4          |
|    value_loss           | 1.29e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2391, ResetDay: 4071,Episode: 1359
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1115         |
|    time_elapsed         | 25238        |
|    total_timesteps      | 2283520      |
| train/                  |              |
|    approx_kl            | 512.6054     |
|    clip_fraction        | 0.201        |
|    clip_range           | 0.2          |
|    entropy_loss         | -163         |
|    explained_variance   | -0.358       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.62        |
|    n_updates            | 11140        |
|    policy_gradient_loss | 0.00579      |
|    reward               | 0.0002781332 |
|    std                  | 84.8         |
|    value_loss           | 1.29e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1314, ResetDay: 2994,Episode: 1360
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1116         |
|    time_elapsed         | 25260        |
|    total_timesteps      | 2285568      |
| train/                  |              |
|    approx_kl            | 520.5851     |
|    clip_fraction        | 0.185        |
|    clip_range           | 0.2          |
|    entropy_loss         | -163         |
|    explained_variance   | 0.17         |
|    learning_rate        | 0.00025      |
|    loss                 | -1.63        |
|    n_updates            | 11150        |
|    policy_gradient_loss | 0.000647     |
|    reward               | -4.32312e-05 |
|    std                  | 84.9         |
|    value_loss           | 5.18e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2994, episode: 1360
begin_total_asset: 200.00
end_total_asset: 113.33
total_reward: -86.67
total_cost: 8.80
total_trades: 43522
Sharpe: 0.028
=================================
Reseting Environment StartDay: 367, ResetDay: 2047,Episode: 1361
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1117           |
|    time_elapsed         | 25283          |
|    total_timesteps      | 2287616        |
| train/                  |                |
|    approx_kl            | 521.25446      |
|    clip_fraction        | 0.203          |
|    clip_range           | 0.2            |
|    entropy_loss         | -163           |
|    explained_variance   | 0.0624         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.62          |
|    n_updates            | 11160          |
|    policy_gradient_loss | 0.0109         |
|    reward               | -0.00012915803 |
|    std                  | 84.9           |
|    value_loss           | 1.08e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1132, ResetDay: 2812,Episode: 1362
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 75, ResetDay: 1755,Episode: 1363
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1118          |
|    time_elapsed         | 25314         |
|    total_timesteps      | 2289664       |
| train/                  |               |
|    approx_kl            | 520.2606      |
|    clip_fraction        | 0.193         |
|    clip_range           | 0.2           |
|    entropy_loss         | -163          |
|    explained_variance   | 0.0629        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.63         |
|    n_updates            | 11170         |
|    policy_gradient_loss | 0.00391       |
|    reward               | -0.0001496748 |
|    std                  | 85            |
|    value_loss           | 7.02e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 958, ResetDay: 2638,Episode: 1364
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1119         |
|    time_elapsed         | 25336        |
|    total_timesteps      | 2291712      |
| train/                  |              |
|    approx_kl            | 515.5758     |
|    clip_fraction        | 0.193        |
|    clip_range           | 0.2          |
|    entropy_loss         | -163         |
|    explained_variance   | 0.0699       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.63        |
|    n_updates            | 11180        |
|    policy_gradient_loss | 0.00916      |
|    reward               | 3.038807e-05 |
|    std                  | 85.3         |
|    value_loss           | 7.53e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1658, ResetDay: 3338,Episode: 1365
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1120         |
|    time_elapsed         | 25359        |
|    total_timesteps      | 2293760      |
| train/                  |              |
|    approx_kl            | 525.4453     |
|    clip_fraction        | 0.201        |
|    clip_range           | 0.2          |
|    entropy_loss         | -163         |
|    explained_variance   | 0.201        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.64        |
|    n_updates            | 11190        |
|    policy_gradient_loss | 0.0029       |
|    reward               | 4.934063e-05 |
|    std                  | 85.4         |
|    value_loss           | 1.46e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3338, episode: 1365
begin_total_asset: 200.00
end_total_asset: 339.14
total_reward: 139.14
total_cost: 10.24
total_trades: 43363
Sharpe: 0.450
=================================
Reseting Environment StartDay: 1795, ResetDay: 3475,Episode: 1366
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1121           |
|    time_elapsed         | 25382          |
|    total_timesteps      | 2295808        |
| train/                  |                |
|    approx_kl            | 522.3093       |
|    clip_fraction        | 0.201          |
|    clip_range           | 0.2            |
|    entropy_loss         | -163           |
|    explained_variance   | 0.139          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.63          |
|    n_updates            | 11200          |
|    policy_gradient_loss | -0.000163      |
|    reward               | -1.3398742e-05 |
|    std                  | 85.8           |
|    value_loss           | 1.29e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1636, ResetDay: 3316,Episode: 1367
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1122           |
|    time_elapsed         | 25405          |
|    total_timesteps      | 2297856        |
| train/                  |                |
|    approx_kl            | 529.0674       |
|    clip_fraction        | 0.201          |
|    clip_range           | 0.2            |
|    entropy_loss         | -163           |
|    explained_variance   | -0.0215        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.65          |
|    n_updates            | 11210          |
|    policy_gradient_loss | 0.00161        |
|    reward               | -0.00019070892 |
|    std                  | 86.2           |
|    value_loss           | 6.42e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1181, ResetDay: 2861,Episode: 1368
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 768, ResetDay: 2448,Episode: 1369
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1123         |
|    time_elapsed         | 25427        |
|    total_timesteps      | 2299904      |
| train/                  |              |
|    approx_kl            | 534.2085     |
|    clip_fraction        | 0.192        |
|    clip_range           | 0.2          |
|    entropy_loss         | -164         |
|    explained_variance   | 0.18         |
|    learning_rate        | 0.00025      |
|    loss                 | -1.63        |
|    n_updates            | 11220        |
|    policy_gradient_loss | -0.000333    |
|    reward               | 8.658219e-06 |
|    std                  | 86.5         |
|    value_loss           | 5.96e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1225, ResetDay: 2905,Episode: 1370
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1124          |
|    time_elapsed         | 25450         |
|    total_timesteps      | 2301952       |
| train/                  |               |
|    approx_kl            | 535.27356     |
|    clip_fraction        | 0.194         |
|    clip_range           | 0.2           |
|    entropy_loss         | -164          |
|    explained_variance   | 0.0259        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.65         |
|    n_updates            | 11230         |
|    policy_gradient_loss | 0.000908      |
|    reward               | 0.00011101656 |
|    std                  | 86.8          |
|    value_loss           | 4.18e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2905, episode: 1370
begin_total_asset: 200.00
end_total_asset: 174.34
total_reward: -25.66
total_cost: 11.58
total_trades: 43154
Sharpe: 0.098
=================================
Reseting Environment StartDay: 1963, ResetDay: 3643,Episode: 1371
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1125          |
|    time_elapsed         | 25473         |
|    total_timesteps      | 2304000       |
| train/                  |               |
|    approx_kl            | 540.893       |
|    clip_fraction        | 0.191         |
|    clip_range           | 0.2           |
|    entropy_loss         | -164          |
|    explained_variance   | 0.296         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.65         |
|    n_updates            | 11240         |
|    policy_gradient_loss | 0.0049        |
|    reward               | 0.00029144154 |
|    std                  | 87.2          |
|    value_loss           | 3.71e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1812, ResetDay: 3492,Episode: 1372
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1126          |
|    time_elapsed         | 25495         |
|    total_timesteps      | 2306048       |
| train/                  |               |
|    approx_kl            | 545.6884      |
|    clip_fraction        | 0.188         |
|    clip_range           | 0.2           |
|    entropy_loss         | -164          |
|    explained_variance   | 0.0594        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.65         |
|    n_updates            | 11250         |
|    policy_gradient_loss | 0.000414      |
|    reward               | 2.0455933e-05 |
|    std                  | 87.5          |
|    value_loss           | 3.96e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1509, ResetDay: 3189,Episode: 1373
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 297, ResetDay: 1977,Episode: 1374
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1127         |
|    time_elapsed         | 25519        |
|    total_timesteps      | 2308096      |
| train/                  |              |
|    approx_kl            | 551.58936    |
|    clip_fraction        | 0.182        |
|    clip_range           | 0.2          |
|    entropy_loss         | -164         |
|    explained_variance   | 0.158        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.66        |
|    n_updates            | 11260        |
|    policy_gradient_loss | 0.000334     |
|    reward               | 7.184096e-05 |
|    std                  | 87.7         |
|    value_loss           | 1.31e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 44, ResetDay: 1724,Episode: 1375
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1128          |
|    time_elapsed         | 25542         |
|    total_timesteps      | 2310144       |
| train/                  |               |
|    approx_kl            | 553.5291      |
|    clip_fraction        | 0.18          |
|    clip_range           | 0.2           |
|    entropy_loss         | -164          |
|    explained_variance   | 0.1           |
|    learning_rate        | 0.00025       |
|    loss                 | -1.63         |
|    n_updates            | 11270         |
|    policy_gradient_loss | 0.00563       |
|    reward               | 5.6331253e-05 |
|    std                  | 87.9          |
|    value_loss           | 6.79e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 1724, episode: 1375
begin_total_asset: 200.00
end_total_asset: 549.50
total_reward: 349.50
total_cost: 34.73
total_trades: 43405
Sharpe: 0.615
=================================
Reseting Environment StartDay: 677, ResetDay: 2357,Episode: 1376
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1129          |
|    time_elapsed         | 25564         |
|    total_timesteps      | 2312192       |
| train/                  |               |
|    approx_kl            | 555.1554      |
|    clip_fraction        | 0.179         |
|    clip_range           | 0.2           |
|    entropy_loss         | -164          |
|    explained_variance   | 0.0365        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.64         |
|    n_updates            | 11280         |
|    policy_gradient_loss | -0.000986     |
|    reward               | 1.6136551e-05 |
|    std                  | 88.1          |
|    value_loss           | 1.25e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1377, ResetDay: 3057,Episode: 1377
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1130          |
|    time_elapsed         | 25587         |
|    total_timesteps      | 2314240       |
| train/                  |               |
|    approx_kl            | 556.6341      |
|    clip_fraction        | 0.196         |
|    clip_range           | 0.2           |
|    entropy_loss         | -164          |
|    explained_variance   | 0.232         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.64         |
|    n_updates            | 11290         |
|    policy_gradient_loss | 0.0107        |
|    reward               | -0.0003383463 |
|    std                  | 88.2          |
|    value_loss           | 2.53e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1656, ResetDay: 3336,Episode: 1378
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1131           |
|    time_elapsed         | 25609          |
|    total_timesteps      | 2316288        |
| train/                  |                |
|    approx_kl            | 561.2537       |
|    clip_fraction        | 0.182          |
|    clip_range           | 0.2            |
|    entropy_loss         | -164           |
|    explained_variance   | -0.00418       |
|    learning_rate        | 0.00025        |
|    loss                 | -1.63          |
|    n_updates            | 11300          |
|    policy_gradient_loss | 0.00304        |
|    reward               | -4.7747802e-05 |
|    std                  | 88.2           |
|    value_loss           | 5.85e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2285, ResetDay: 3965,Episode: 1379
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1974, ResetDay: 3654,Episode: 1380
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1132           |
|    time_elapsed         | 25632          |
|    total_timesteps      | 2318336        |
| train/                  |                |
|    approx_kl            | 557.6456       |
|    clip_fraction        | 0.181          |
|    clip_range           | 0.2            |
|    entropy_loss         | -164           |
|    explained_variance   | 0.131          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.63          |
|    n_updates            | 11310          |
|    policy_gradient_loss | -0.00282       |
|    reward               | -1.5828133e-05 |
|    std                  | 88.5           |
|    value_loss           | 4.62e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3654, episode: 1380
begin_total_asset: 200.00
end_total_asset: 311.79
total_reward: 111.79
total_cost: 8.09
total_trades: 43148
Sharpe: 0.407
=================================
Reseting Environment StartDay: 2449, ResetDay: 4129,Episode: 1381
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1133          |
|    time_elapsed         | 25655         |
|    total_timesteps      | 2320384       |
| train/                  |               |
|    approx_kl            | 558.9306      |
|    clip_fraction        | 0.188         |
|    clip_range           | 0.2           |
|    entropy_loss         | -164          |
|    explained_variance   | 0.126         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.62         |
|    n_updates            | 11320         |
|    policy_gradient_loss | 0.00752       |
|    reward               | -0.0002010126 |
|    std                  | 88.9          |
|    value_loss           | 1.97e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2579, ResetDay: 4259,Episode: 1382
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1134           |
|    time_elapsed         | 25677          |
|    total_timesteps      | 2322432        |
| train/                  |                |
|    approx_kl            | 570.836        |
|    clip_fraction        | 0.178          |
|    clip_range           | 0.2            |
|    entropy_loss         | -164           |
|    explained_variance   | 0.212          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.65          |
|    n_updates            | 11330          |
|    policy_gradient_loss | 0.000605       |
|    reward               | -0.00029403306 |
|    std                  | 88.8           |
|    value_loss           | 7.44e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 266, ResetDay: 1946,Episode: 1383
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1135          |
|    time_elapsed         | 25700         |
|    total_timesteps      | 2324480       |
| train/                  |               |
|    approx_kl            | 567.4984      |
|    clip_fraction        | 0.169         |
|    clip_range           | 0.2           |
|    entropy_loss         | -164          |
|    explained_variance   | 0.174         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.66         |
|    n_updates            | 11340         |
|    policy_gradient_loss | -0.00219      |
|    reward               | 0.00010471029 |
|    std                  | 88.9          |
|    value_loss           | 7.84e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 476, ResetDay: 2156,Episode: 1384
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1089, ResetDay: 2769,Episode: 1385
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1136           |
|    time_elapsed         | 25723          |
|    total_timesteps      | 2326528        |
| train/                  |                |
|    approx_kl            | 564.31177      |
|    clip_fraction        | 0.191          |
|    clip_range           | 0.2            |
|    entropy_loss         | -164           |
|    explained_variance   | -0.183         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.64          |
|    n_updates            | 11350          |
|    policy_gradient_loss | 0.00403        |
|    reward               | -0.00022751355 |
|    std                  | 89.2           |
|    value_loss           | 1.1e-06        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2769, episode: 1385
begin_total_asset: 200.00
end_total_asset: 184.57
total_reward: -15.43
total_cost: 17.19
total_trades: 43154
Sharpe: 0.144
=================================
Reseting Environment StartDay: 2088, ResetDay: 3768,Episode: 1386
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1137          |
|    time_elapsed         | 25745         |
|    total_timesteps      | 2328576       |
| train/                  |               |
|    approx_kl            | 571.0931      |
|    clip_fraction        | 0.192         |
|    clip_range           | 0.2           |
|    entropy_loss         | -164          |
|    explained_variance   | 0.26          |
|    learning_rate        | 0.00025       |
|    loss                 | -1.65         |
|    n_updates            | 11360         |
|    policy_gradient_loss | 0.0042        |
|    reward               | 0.00039873162 |
|    std                  | 89.4          |
|    value_loss           | 9.16e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1729, ResetDay: 3409,Episode: 1387
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1138         |
|    time_elapsed         | 25768        |
|    total_timesteps      | 2330624      |
| train/                  |              |
|    approx_kl            | 573.7909     |
|    clip_fraction        | 0.187        |
|    clip_range           | 0.2          |
|    entropy_loss         | -165         |
|    explained_variance   | -0.0258      |
|    learning_rate        | 0.00025      |
|    loss                 | -1.66        |
|    n_updates            | 11370        |
|    policy_gradient_loss | -0.00264     |
|    reward               | 9.793415e-05 |
|    std                  | 89.6         |
|    value_loss           | 4.6e-07      |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 162, ResetDay: 1842,Episode: 1388
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1139          |
|    time_elapsed         | 25791         |
|    total_timesteps      | 2332672       |
| train/                  |               |
|    approx_kl            | 578.9969      |
|    clip_fraction        | 0.172         |
|    clip_range           | 0.2           |
|    entropy_loss         | -165          |
|    explained_variance   | 0.0538        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.64         |
|    n_updates            | 11380         |
|    policy_gradient_loss | 0.00201       |
|    reward               | 0.00041779142 |
|    std                  | 89.8          |
|    value_loss           | 1.78e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 809, ResetDay: 2489,Episode: 1389
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1140          |
|    time_elapsed         | 25813         |
|    total_timesteps      | 2334720       |
| train/                  |               |
|    approx_kl            | 577.8989      |
|    clip_fraction        | 0.182         |
|    clip_range           | 0.2           |
|    entropy_loss         | -165          |
|    explained_variance   | -0.0721       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.66         |
|    n_updates            | 11390         |
|    policy_gradient_loss | -0.000982     |
|    reward               | -8.362961e-05 |
|    std                  | 90.2          |
|    value_loss           | 1.06e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2412, ResetDay: 4092,Episode: 1390
Environment reached Terminal state as number of trading days reached limit!!
day: 4092, episode: 1390
begin_total_asset: 200.00
end_total_asset: 461.68
total_reward: 261.68
total_cost: 10.36
total_trades: 42947
Sharpe: 0.610
=================================
Reseting Environment StartDay: 2751, ResetDay: 4431,Episode: 1391
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1141           |
|    time_elapsed         | 25836          |
|    total_timesteps      | 2336768        |
| train/                  |                |
|    approx_kl            | 589.1331       |
|    clip_fraction        | 0.178          |
|    clip_range           | 0.2            |
|    entropy_loss         | -165           |
|    explained_variance   | 0.299          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.65          |
|    n_updates            | 11400          |
|    policy_gradient_loss | 0.00282        |
|    reward               | -0.00010396077 |
|    std                  | 90.4           |
|    value_loss           | 7.33e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2062, ResetDay: 3742,Episode: 1392
-----------------------------------------
| time/                   |             |
|    fps                  | 90          |
|    iterations           | 1142        |
|    time_elapsed         | 25859       |
|    total_timesteps      | 2338816     |
| train/                  |             |
|    approx_kl            | 585.2686    |
|    clip_fraction        | 0.185       |
|    clip_range           | 0.2         |
|    entropy_loss         | -165        |
|    explained_variance   | -0.0205     |
|    learning_rate        | 0.00025     |
|    loss                 | -1.63       |
|    n_updates            | 11410       |
|    policy_gradient_loss | 0.00247     |
|    reward               | 0.000208358 |
|    std                  | 90.8        |
|    value_loss           | 2.02e-06    |
-----------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1350, ResetDay: 3030,Episode: 1393
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1143          |
|    time_elapsed         | 25881         |
|    total_timesteps      | 2340864       |
| train/                  |               |
|    approx_kl            | 591.2454      |
|    clip_fraction        | 0.178         |
|    clip_range           | 0.2           |
|    entropy_loss         | -165          |
|    explained_variance   | 0.0278        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.65         |
|    n_updates            | 11420         |
|    policy_gradient_loss | 0.00573       |
|    reward               | -0.0001583107 |
|    std                  | 91.2          |
|    value_loss           | 8.33e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1542, ResetDay: 3222,Episode: 1394
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1144           |
|    time_elapsed         | 25904          |
|    total_timesteps      | 2342912        |
| train/                  |                |
|    approx_kl            | 597.9738       |
|    clip_fraction        | 0.168          |
|    clip_range           | 0.2            |
|    entropy_loss         | -165           |
|    explained_variance   | 0.0944         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.67          |
|    n_updates            | 11430          |
|    policy_gradient_loss | -0.00247       |
|    reward               | -0.00020066986 |
|    std                  | 91.6           |
|    value_loss           | 7.34e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2425, ResetDay: 4105,Episode: 1395
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1145          |
|    time_elapsed         | 25926         |
|    total_timesteps      | 2344960       |
| train/                  |               |
|    approx_kl            | 605.77496     |
|    clip_fraction        | 0.174         |
|    clip_range           | 0.2           |
|    entropy_loss         | -165          |
|    explained_variance   | 0.195         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.68         |
|    n_updates            | 11440         |
|    policy_gradient_loss | -6.37e-05     |
|    reward               | 0.00024574396 |
|    std                  | 91.8          |
|    value_loss           | 4.12e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4105, episode: 1395
begin_total_asset: 200.00
end_total_asset: 365.83
total_reward: 165.83
total_cost: 11.20
total_trades: 42866
Sharpe: 0.474
=================================
Reseting Environment StartDay: 136, ResetDay: 1816,Episode: 1396
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 648, ResetDay: 2328,Episode: 1397
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1146           |
|    time_elapsed         | 25949          |
|    total_timesteps      | 2347008        |
| train/                  |                |
|    approx_kl            | 607.2408       |
|    clip_fraction        | 0.163          |
|    clip_range           | 0.2            |
|    entropy_loss         | -165           |
|    explained_variance   | 0.108          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.64          |
|    n_updates            | 11450          |
|    policy_gradient_loss | 0.00135        |
|    reward               | -0.00034500373 |
|    std                  | 92.1           |
|    value_loss           | 1.09e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2028, ResetDay: 3708,Episode: 1398
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1147           |
|    time_elapsed         | 25972          |
|    total_timesteps      | 2349056        |
| train/                  |                |
|    approx_kl            | 612.93567      |
|    clip_fraction        | 0.182          |
|    clip_range           | 0.2            |
|    entropy_loss         | -165           |
|    explained_variance   | -0.207         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.64          |
|    n_updates            | 11460          |
|    policy_gradient_loss | 0.000873       |
|    reward               | -0.00022370568 |
|    std                  | 92.4           |
|    value_loss           | 1.35e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2451, ResetDay: 4131,Episode: 1399
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1148          |
|    time_elapsed         | 25994         |
|    total_timesteps      | 2351104       |
| train/                  |               |
|    approx_kl            | 618.7436      |
|    clip_fraction        | 0.164         |
|    clip_range           | 0.2           |
|    entropy_loss         | -165          |
|    explained_variance   | 0.143         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.65         |
|    n_updates            | 11470         |
|    policy_gradient_loss | 0.00777       |
|    reward               | -0.0006374954 |
|    std                  | 92.6          |
|    value_loss           | 5.66e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2783, ResetDay: 4463,Episode: 1400
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1149          |
|    time_elapsed         | 26017         |
|    total_timesteps      | 2353152       |
| train/                  |               |
|    approx_kl            | 625.146       |
|    clip_fraction        | 0.165         |
|    clip_range           | 0.2           |
|    entropy_loss         | -165          |
|    explained_variance   | -0.0252       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.65         |
|    n_updates            | 11480         |
|    policy_gradient_loss | 0.01          |
|    reward               | 0.00020680428 |
|    std                  | 92.6          |
|    value_loss           | 1.4e-06       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4463, episode: 1400
begin_total_asset: 200.00
end_total_asset: 245.85
total_reward: 45.85
total_cost: 11.13
total_trades: 42931
Sharpe: 0.260
=================================
Reseting Environment StartDay: 15, ResetDay: 1695,Episode: 1401
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2043, ResetDay: 3723,Episode: 1402
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1150          |
|    time_elapsed         | 26040         |
|    total_timesteps      | 2355200       |
| train/                  |               |
|    approx_kl            | 616.85535     |
|    clip_fraction        | 0.19          |
|    clip_range           | 0.2           |
|    entropy_loss         | -166          |
|    explained_variance   | 0.113         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.67         |
|    n_updates            | 11490         |
|    policy_gradient_loss | 0.00477       |
|    reward               | -0.0001417326 |
|    std                  | 93.1          |
|    value_loss           | 9.82e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1437, ResetDay: 3117,Episode: 1403
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1151          |
|    time_elapsed         | 26063         |
|    total_timesteps      | 2357248       |
| train/                  |               |
|    approx_kl            | 627.9026      |
|    clip_fraction        | 0.178         |
|    clip_range           | 0.2           |
|    entropy_loss         | -166          |
|    explained_variance   | -0.126        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.65         |
|    n_updates            | 11500         |
|    policy_gradient_loss | 0.00636       |
|    reward               | 0.00015759573 |
|    std                  | 93.2          |
|    value_loss           | 2.39e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 874, ResetDay: 2554,Episode: 1404
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1152          |
|    time_elapsed         | 26085         |
|    total_timesteps      | 2359296       |
| train/                  |               |
|    approx_kl            | 626.144       |
|    clip_fraction        | 0.167         |
|    clip_range           | 0.2           |
|    entropy_loss         | -166          |
|    explained_variance   | 0.0232        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.64         |
|    n_updates            | 11510         |
|    policy_gradient_loss | 0.00164       |
|    reward               | 0.00021373873 |
|    std                  | 93.3          |
|    value_loss           | 2.73e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2344, ResetDay: 4024,Episode: 1405
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1153          |
|    time_elapsed         | 26108         |
|    total_timesteps      | 2361344       |
| train/                  |               |
|    approx_kl            | 631.577       |
|    clip_fraction        | 0.173         |
|    clip_range           | 0.2           |
|    entropy_loss         | -166          |
|    explained_variance   | -0.0669       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.65         |
|    n_updates            | 11520         |
|    policy_gradient_loss | 0.00532       |
|    reward               | 0.00027799682 |
|    std                  | 93.3          |
|    value_loss           | 5.06e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4024, episode: 1405
begin_total_asset: 200.00
end_total_asset: 407.57
total_reward: 207.57
total_cost: 15.97
total_trades: 42770
Sharpe: 0.557
=================================
Reseting Environment StartDay: 54, ResetDay: 1734,Episode: 1406
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1154         |
|    time_elapsed         | 26131        |
|    total_timesteps      | 2363392      |
| train/                  |              |
|    approx_kl            | 631.06775    |
|    clip_fraction        | 0.172        |
|    clip_range           | 0.2          |
|    entropy_loss         | -166         |
|    explained_variance   | 0.22         |
|    learning_rate        | 0.00025      |
|    loss                 | -1.67        |
|    n_updates            | 11530        |
|    policy_gradient_loss | 0.00465      |
|    reward               | 0.0010886359 |
|    std                  | 93.5         |
|    value_loss           | 7.19e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1389, ResetDay: 3069,Episode: 1407
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 569, ResetDay: 2249,Episode: 1408
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1155          |
|    time_elapsed         | 26153         |
|    total_timesteps      | 2365440       |
| train/                  |               |
|    approx_kl            | 630.59265     |
|    clip_fraction        | 0.185         |
|    clip_range           | 0.2           |
|    entropy_loss         | -166          |
|    explained_variance   | 0.104         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.66         |
|    n_updates            | 11540         |
|    policy_gradient_loss | -0.000255     |
|    reward               | 0.00043085776 |
|    std                  | 93.8          |
|    value_loss           | 2.5e-06       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2797, ResetDay: 4477,Episode: 1409
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1156          |
|    time_elapsed         | 26176         |
|    total_timesteps      | 2367488       |
| train/                  |               |
|    approx_kl            | 636.33167     |
|    clip_fraction        | 0.17          |
|    clip_range           | 0.2           |
|    entropy_loss         | -166          |
|    explained_variance   | -0.0421       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.65         |
|    n_updates            | 11550         |
|    policy_gradient_loss | 0.00171       |
|    reward               | -0.0002152626 |
|    std                  | 93.9          |
|    value_loss           | 1.08e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1877, ResetDay: 3557,Episode: 1410
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1157           |
|    time_elapsed         | 26199          |
|    total_timesteps      | 2369536        |
| train/                  |                |
|    approx_kl            | 637.18604      |
|    clip_fraction        | 0.16           |
|    clip_range           | 0.2            |
|    entropy_loss         | -166           |
|    explained_variance   | 0.185          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.64          |
|    n_updates            | 11560          |
|    policy_gradient_loss | -0.00428       |
|    reward               | -2.4493218e-05 |
|    std                  | 94.2           |
|    value_loss           | 5.43e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3557, episode: 1410
begin_total_asset: 200.00
end_total_asset: 254.31
total_reward: 54.31
total_cost: 5.42
total_trades: 42686
Sharpe: 0.341
=================================
Reseting Environment StartDay: 1789, ResetDay: 3469,Episode: 1411
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1158          |
|    time_elapsed         | 26222         |
|    total_timesteps      | 2371584       |
| train/                  |               |
|    approx_kl            | 637.65265     |
|    clip_fraction        | 0.184         |
|    clip_range           | 0.2           |
|    entropy_loss         | -166          |
|    explained_variance   | 0.0491        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.63         |
|    n_updates            | 11570         |
|    policy_gradient_loss | 0.00218       |
|    reward               | 5.9687616e-05 |
|    std                  | 94.5          |
|    value_loss           | 1.93e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 809, ResetDay: 2489,Episode: 1412
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1193, ResetDay: 2873,Episode: 1413
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1159           |
|    time_elapsed         | 26244          |
|    total_timesteps      | 2373632        |
| train/                  |                |
|    approx_kl            | 647.0194       |
|    clip_fraction        | 0.153          |
|    clip_range           | 0.2            |
|    entropy_loss         | -166           |
|    explained_variance   | 0.111          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.68          |
|    n_updates            | 11580          |
|    policy_gradient_loss | 8.93e-05       |
|    reward               | -4.9659633e-05 |
|    std                  | 94.6           |
|    value_loss           | 4.8e-07        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1938, ResetDay: 3618,Episode: 1414
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1160           |
|    time_elapsed         | 26267          |
|    total_timesteps      | 2375680        |
| train/                  |                |
|    approx_kl            | 643.8461       |
|    clip_fraction        | 0.164          |
|    clip_range           | 0.2            |
|    entropy_loss         | -166           |
|    explained_variance   | 0.0771         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.66          |
|    n_updates            | 11590          |
|    policy_gradient_loss | 0.0133         |
|    reward               | -0.00014709473 |
|    std                  | 94.9           |
|    value_loss           | 5.95e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 396, ResetDay: 2076,Episode: 1415
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1161          |
|    time_elapsed         | 26290         |
|    total_timesteps      | 2377728       |
| train/                  |               |
|    approx_kl            | 650.13684     |
|    clip_fraction        | 0.163         |
|    clip_range           | 0.2           |
|    entropy_loss         | -166          |
|    explained_variance   | 0.0574        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.67         |
|    n_updates            | 11600         |
|    policy_gradient_loss | -0.00582      |
|    reward               | 0.00015432277 |
|    std                  | 95.2          |
|    value_loss           | 2.36e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2076, episode: 1415
begin_total_asset: 200.00
end_total_asset: 162.83
total_reward: -37.17
total_cost: 22.43
total_trades: 42828
Sharpe: 0.149
=================================
Reseting Environment StartDay: 2560, ResetDay: 4240,Episode: 1416
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1162         |
|    time_elapsed         | 26313        |
|    total_timesteps      | 2379776      |
| train/                  |              |
|    approx_kl            | 650.21216    |
|    clip_fraction        | 0.174        |
|    clip_range           | 0.2          |
|    entropy_loss         | -166         |
|    explained_variance   | 0.0671       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.67        |
|    n_updates            | 11610        |
|    policy_gradient_loss | -0.00052     |
|    reward               | 0.0009173584 |
|    std                  | 95.3         |
|    value_loss           | 1.47e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2586, ResetDay: 4266,Episode: 1417
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1163           |
|    time_elapsed         | 26335          |
|    total_timesteps      | 2381824        |
| train/                  |                |
|    approx_kl            | 654.4728       |
|    clip_fraction        | 0.167          |
|    clip_range           | 0.2            |
|    entropy_loss         | -166           |
|    explained_variance   | 0.148          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.68          |
|    n_updates            | 11620          |
|    policy_gradient_loss | -0.0045        |
|    reward               | -0.00021401519 |
|    std                  | 95.5           |
|    value_loss           | 1.96e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 43, ResetDay: 1723,Episode: 1418
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1721, ResetDay: 3401,Episode: 1419
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1164          |
|    time_elapsed         | 26358         |
|    total_timesteps      | 2383872       |
| train/                  |               |
|    approx_kl            | 656.0768      |
|    clip_fraction        | 0.153         |
|    clip_range           | 0.2           |
|    entropy_loss         | -166          |
|    explained_variance   | 0.0388        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.66         |
|    n_updates            | 11630         |
|    policy_gradient_loss | -0.0122       |
|    reward               | 0.00027654972 |
|    std                  | 95.7          |
|    value_loss           | 2.36e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2704, ResetDay: 4384,Episode: 1420
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1165          |
|    time_elapsed         | 26381         |
|    total_timesteps      | 2385920       |
| train/                  |               |
|    approx_kl            | 657.2809      |
|    clip_fraction        | 0.167         |
|    clip_range           | 0.2           |
|    entropy_loss         | -166          |
|    explained_variance   | -0.187        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.67         |
|    n_updates            | 11640         |
|    policy_gradient_loss | -0.00362      |
|    reward               | -4.243088e-05 |
|    std                  | 95.9          |
|    value_loss           | 2.49e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4384, episode: 1420
begin_total_asset: 200.00
end_total_asset: 311.42
total_reward: 111.42
total_cost: 8.04
total_trades: 42693
Sharpe: 0.381
=================================
Reseting Environment StartDay: 804, ResetDay: 2484,Episode: 1421
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1166           |
|    time_elapsed         | 26403          |
|    total_timesteps      | 2387968        |
| train/                  |                |
|    approx_kl            | 660.9739       |
|    clip_fraction        | 0.159          |
|    clip_range           | 0.2            |
|    entropy_loss         | -166           |
|    explained_variance   | -0.0868        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.67          |
|    n_updates            | 11650          |
|    policy_gradient_loss | -0.00104       |
|    reward               | -0.00010365248 |
|    std                  | 96             |
|    value_loss           | 1.46e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 965, ResetDay: 2645,Episode: 1422
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1167           |
|    time_elapsed         | 26426          |
|    total_timesteps      | 2390016        |
| train/                  |                |
|    approx_kl            | 663.19495      |
|    clip_fraction        | 0.161          |
|    clip_range           | 0.2            |
|    entropy_loss         | -166           |
|    explained_variance   | -0.0948        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.68          |
|    n_updates            | 11660          |
|    policy_gradient_loss | -0.00174       |
|    reward               | -2.1298218e-05 |
|    std                  | 96.2           |
|    value_loss           | 1.73e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1594, ResetDay: 3274,Episode: 1423
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1864, ResetDay: 3544,Episode: 1424
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1168         |
|    time_elapsed         | 26450        |
|    total_timesteps      | 2392064      |
| train/                  |              |
|    approx_kl            | 664.4448     |
|    clip_fraction        | 0.15         |
|    clip_range           | 0.2          |
|    entropy_loss         | -167         |
|    explained_variance   | 0.134        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.67        |
|    n_updates            | 11670        |
|    policy_gradient_loss | 0.00207      |
|    reward               | -0.007405781 |
|    std                  | 96.5         |
|    value_loss           | 5.65e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 285, ResetDay: 1965,Episode: 1425
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1169          |
|    time_elapsed         | 26472         |
|    total_timesteps      | 2394112       |
| train/                  |               |
|    approx_kl            | 672.6184      |
|    clip_fraction        | 0.158         |
|    clip_range           | 0.2           |
|    entropy_loss         | -167          |
|    explained_variance   | 0.135         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.69         |
|    n_updates            | 11680         |
|    policy_gradient_loss | 0.000588      |
|    reward               | 0.00011845131 |
|    std                  | 96.6          |
|    value_loss           | 9.07e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 1965, episode: 1425
begin_total_asset: 200.00
end_total_asset: 178.08
total_reward: -21.92
total_cost: 32.42
total_trades: 42841
Sharpe: 0.190
=================================
Reseting Environment StartDay: 2703, ResetDay: 4383,Episode: 1426
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1170         |
|    time_elapsed         | 26495        |
|    total_timesteps      | 2396160      |
| train/                  |              |
|    approx_kl            | 667.45605    |
|    clip_fraction        | 0.166        |
|    clip_range           | 0.2          |
|    entropy_loss         | -167         |
|    explained_variance   | 0.0641       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.67        |
|    n_updates            | 11690        |
|    policy_gradient_loss | -0.00122     |
|    reward               | 0.0013574639 |
|    std                  | 96.9         |
|    value_loss           | 7.86e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 706, ResetDay: 2386,Episode: 1427
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1171         |
|    time_elapsed         | 26518        |
|    total_timesteps      | 2398208      |
| train/                  |              |
|    approx_kl            | 670.82635    |
|    clip_fraction        | 0.163        |
|    clip_range           | 0.2          |
|    entropy_loss         | -167         |
|    explained_variance   | 0.198        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.66        |
|    n_updates            | 11700        |
|    policy_gradient_loss | -0.00288     |
|    reward               | 5.022812e-06 |
|    std                  | 97.3         |
|    value_loss           | 1.38e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2561, ResetDay: 4241,Episode: 1428
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1172          |
|    time_elapsed         | 26541         |
|    total_timesteps      | 2400256       |
| train/                  |               |
|    approx_kl            | 675.6703      |
|    clip_fraction        | 0.161         |
|    clip_range           | 0.2           |
|    entropy_loss         | -167          |
|    explained_variance   | 0.0646        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.68         |
|    n_updates            | 11710         |
|    policy_gradient_loss | 0.00438       |
|    reward               | -0.0003244915 |
|    std                  | 97.7          |
|    value_loss           | 5.45e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 969, ResetDay: 2649,Episode: 1429
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 843, ResetDay: 2523,Episode: 1430
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1173         |
|    time_elapsed         | 26564        |
|    total_timesteps      | 2402304      |
| train/                  |              |
|    approx_kl            | 686.3327     |
|    clip_fraction        | 0.16         |
|    clip_range           | 0.2          |
|    entropy_loss         | -167         |
|    explained_variance   | 0.0982       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.64        |
|    n_updates            | 11720        |
|    policy_gradient_loss | 0.00107      |
|    reward               | -6.19853e-05 |
|    std                  | 98           |
|    value_loss           | 1.5e-06      |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2523, episode: 1430
begin_total_asset: 200.00
end_total_asset: 98.28
total_reward: -101.72
total_cost: 16.72
total_trades: 42604
Sharpe: -0.090
=================================
Reseting Environment StartDay: 1043, ResetDay: 2723,Episode: 1431
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1174           |
|    time_elapsed         | 26586          |
|    total_timesteps      | 2404352        |
| train/                  |                |
|    approx_kl            | 683.25665      |
|    clip_fraction        | 0.156          |
|    clip_range           | 0.2            |
|    entropy_loss         | -167           |
|    explained_variance   | 0.0393         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.67          |
|    n_updates            | 11730          |
|    policy_gradient_loss | 0.00512        |
|    reward               | -4.5246125e-05 |
|    std                  | 98.4           |
|    value_loss           | 9.52e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2422, ResetDay: 4102,Episode: 1432
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1175           |
|    time_elapsed         | 26609          |
|    total_timesteps      | 2406400        |
| train/                  |                |
|    approx_kl            | 694.3517       |
|    clip_fraction        | 0.144          |
|    clip_range           | 0.2            |
|    entropy_loss         | -167           |
|    explained_variance   | 0.0648         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.66          |
|    n_updates            | 11740          |
|    policy_gradient_loss | 0.0054         |
|    reward               | -0.00024160653 |
|    std                  | 98.6           |
|    value_loss           | 3.13e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 694, ResetDay: 2374,Episode: 1433
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1176           |
|    time_elapsed         | 26633          |
|    total_timesteps      | 2408448        |
| train/                  |                |
|    approx_kl            | 700.75024      |
|    clip_fraction        | 0.149          |
|    clip_range           | 0.2            |
|    entropy_loss         | -167           |
|    explained_variance   | 0.117          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.66          |
|    n_updates            | 11750          |
|    policy_gradient_loss | -0.00345       |
|    reward               | -4.3897533e-05 |
|    std                  | 98.9           |
|    value_loss           | 4.36e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 483, ResetDay: 2163,Episode: 1434
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1177           |
|    time_elapsed         | 26656          |
|    total_timesteps      | 2410496        |
| train/                  |                |
|    approx_kl            | 700.2677       |
|    clip_fraction        | 0.149          |
|    clip_range           | 0.2            |
|    entropy_loss         | -167           |
|    explained_variance   | 0.0389         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.69          |
|    n_updates            | 11760          |
|    policy_gradient_loss | 0.00123        |
|    reward               | -1.4860153e-05 |
|    std                  | 99.4           |
|    value_loss           | 1.73e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2612, ResetDay: 4292,Episode: 1435
Environment reached Terminal state as number of trading days reached limit!!
day: 4292, episode: 1435
begin_total_asset: 200.00
end_total_asset: 507.19
total_reward: 307.19
total_cost: 10.83
total_trades: 42229
Sharpe: 0.666
=================================
Reseting Environment StartDay: 489, ResetDay: 2169,Episode: 1436
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1178           |
|    time_elapsed         | 26678          |
|    total_timesteps      | 2412544        |
| train/                  |                |
|    approx_kl            | 711.9311       |
|    clip_fraction        | 0.142          |
|    clip_range           | 0.2            |
|    entropy_loss         | -167           |
|    explained_variance   | 0.0224         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.67          |
|    n_updates            | 11770          |
|    policy_gradient_loss | 0.00647        |
|    reward               | -3.3986475e-05 |
|    std                  | 99.4           |
|    value_loss           | 5.12e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 772, ResetDay: 2452,Episode: 1437
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1179          |
|    time_elapsed         | 26701         |
|    total_timesteps      | 2414592       |
| train/                  |               |
|    approx_kl            | 713.0111      |
|    clip_fraction        | 0.149         |
|    clip_range           | 0.2           |
|    entropy_loss         | -167          |
|    explained_variance   | 0.0624        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.7          |
|    n_updates            | 11780         |
|    policy_gradient_loss | -0.000986     |
|    reward               | -7.045269e-06 |
|    std                  | 99.6          |
|    value_loss           | 2.78e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 19, ResetDay: 1699,Episode: 1438
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1180          |
|    time_elapsed         | 26724         |
|    total_timesteps      | 2416640       |
| train/                  |               |
|    approx_kl            | 712.1125      |
|    clip_fraction        | 0.152         |
|    clip_range           | 0.2           |
|    entropy_loss         | -168          |
|    explained_variance   | -0.426        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.68         |
|    n_updates            | 11790         |
|    policy_gradient_loss | -0.00313      |
|    reward               | 0.00039197426 |
|    std                  | 99.9          |
|    value_loss           | 6.2e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2584, ResetDay: 4264,Episode: 1439
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1181          |
|    time_elapsed         | 26747         |
|    total_timesteps      | 2418688       |
| train/                  |               |
|    approx_kl            | 720.8903      |
|    clip_fraction        | 0.142         |
|    clip_range           | 0.2           |
|    entropy_loss         | -168          |
|    explained_variance   | 0.178         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.66         |
|    n_updates            | 11800         |
|    policy_gradient_loss | 0.000946      |
|    reward               | 0.00060856476 |
|    std                  | 99.9          |
|    value_loss           | 1.5e-06       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 418, ResetDay: 2098,Episode: 1440
Environment reached Terminal state as number of trading days reached limit!!
day: 2098, episode: 1440
begin_total_asset: 200.00
end_total_asset: 221.33
total_reward: 21.33
total_cost: 30.25
total_trades: 42540
Sharpe: 0.299
=================================
Reseting Environment StartDay: 663, ResetDay: 2343,Episode: 1441
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1182           |
|    time_elapsed         | 26769          |
|    total_timesteps      | 2420736        |
| train/                  |                |
|    approx_kl            | 717.94635      |
|    clip_fraction        | 0.145          |
|    clip_range           | 0.2            |
|    entropy_loss         | -168           |
|    explained_variance   | 0.038          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.68          |
|    n_updates            | 11810          |
|    policy_gradient_loss | -0.000412      |
|    reward               | -0.00014693318 |
|    std                  | 100            |
|    value_loss           | 7.55e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2135, ResetDay: 3815,Episode: 1442
--------------------------------------
| time/                   |          |
|    fps                  | 90       |
|    iterations           | 1183     |
|    time_elapsed         | 26791    |
|    total_timesteps      | 2422784  |
| train/                  |          |
|    approx_kl            | 718.7965 |
|    clip_fraction        | 0.159    |
|    clip_range           | 0.2      |
|    entropy_loss         | -168     |
|    explained_variance   | -0.352   |
|    learning_rate        | 0.00025  |
|    loss                 | -1.69    |
|    n_updates            | 11820    |
|    policy_gradient_loss | 0.0211   |
|    reward               | 0.0      |
|    std                  | 100      |
|    value_loss           | 2.43e-06 |
--------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1346, ResetDay: 3026,Episode: 1443
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1184          |
|    time_elapsed         | 26814         |
|    total_timesteps      | 2424832       |
| train/                  |               |
|    approx_kl            | 719.8309      |
|    clip_fraction        | 0.154         |
|    clip_range           | 0.2           |
|    entropy_loss         | -168          |
|    explained_variance   | 0.196         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.65         |
|    n_updates            | 11830         |
|    policy_gradient_loss | 0.00562       |
|    reward               | -7.107592e-05 |
|    std                  | 101           |
|    value_loss           | 4.95e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2511, ResetDay: 4191,Episode: 1444
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1185          |
|    time_elapsed         | 26837         |
|    total_timesteps      | 2426880       |
| train/                  |               |
|    approx_kl            | 727.4795      |
|    clip_fraction        | 0.146         |
|    clip_range           | 0.2           |
|    entropy_loss         | -168          |
|    explained_variance   | 0.0511        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.69         |
|    n_updates            | 11840         |
|    policy_gradient_loss | -0.000718     |
|    reward               | 0.00046979066 |
|    std                  | 101           |
|    value_loss           | 1.98e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1469, ResetDay: 3149,Episode: 1445
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1186          |
|    time_elapsed         | 26859         |
|    total_timesteps      | 2428928       |
| train/                  |               |
|    approx_kl            | 736.57904     |
|    clip_fraction        | 0.137         |
|    clip_range           | 0.2           |
|    entropy_loss         | -168          |
|    explained_variance   | 0.169         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.68         |
|    n_updates            | 11850         |
|    policy_gradient_loss | -0.00296      |
|    reward               | -8.372307e-06 |
|    std                  | 102           |
|    value_loss           | 7.65e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3149, episode: 1445
begin_total_asset: 200.00
end_total_asset: 153.71
total_reward: -46.29
total_cost: 11.47
total_trades: 42185
Sharpe: 0.089
=================================
Reseting Environment StartDay: 2558, ResetDay: 4238,Episode: 1446
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 31, ResetDay: 1711,Episode: 1447
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1187          |
|    time_elapsed         | 26882         |
|    total_timesteps      | 2430976       |
| train/                  |               |
|    approx_kl            | 737.9796      |
|    clip_fraction        | 0.134         |
|    clip_range           | 0.2           |
|    entropy_loss         | -168          |
|    explained_variance   | 0.0397        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.7          |
|    n_updates            | 11860         |
|    policy_gradient_loss | -0.00317      |
|    reward               | 2.8460598e-05 |
|    std                  | 102           |
|    value_loss           | 8.74e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 66, ResetDay: 1746,Episode: 1448
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1188          |
|    time_elapsed         | 26905         |
|    total_timesteps      | 2433024       |
| train/                  |               |
|    approx_kl            | 739.01697     |
|    clip_fraction        | 0.138         |
|    clip_range           | 0.2           |
|    entropy_loss         | -168          |
|    explained_variance   | 0.0968        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.7          |
|    n_updates            | 11870         |
|    policy_gradient_loss | -0.00136      |
|    reward               | -0.0010500047 |
|    std                  | 102           |
|    value_loss           | 2.07e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 978, ResetDay: 2658,Episode: 1449
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1189          |
|    time_elapsed         | 26927         |
|    total_timesteps      | 2435072       |
| train/                  |               |
|    approx_kl            | 741.54315     |
|    clip_fraction        | 0.158         |
|    clip_range           | 0.2           |
|    entropy_loss         | -168          |
|    explained_variance   | 0.00041       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.68         |
|    n_updates            | 11880         |
|    policy_gradient_loss | 0.000301      |
|    reward               | 5.8534242e-05 |
|    std                  | 103           |
|    value_loss           | 1.07e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 455, ResetDay: 2135,Episode: 1450
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1190          |
|    time_elapsed         | 26950         |
|    total_timesteps      | 2437120       |
| train/                  |               |
|    approx_kl            | 745.716       |
|    clip_fraction        | 0.153         |
|    clip_range           | 0.2           |
|    entropy_loss         | -168          |
|    explained_variance   | 0.287         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.71         |
|    n_updates            | 11890         |
|    policy_gradient_loss | -0.00883      |
|    reward               | -0.0003185898 |
|    std                  | 103           |
|    value_loss           | 2.04e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2135, episode: 1450
begin_total_asset: 200.00
end_total_asset: 217.48
total_reward: 17.48
total_cost: 36.55
total_trades: 42316
Sharpe: 0.225
=================================
Reseting Environment StartDay: 2547, ResetDay: 4227,Episode: 1451
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2750, ResetDay: 4430,Episode: 1452
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1191          |
|    time_elapsed         | 26972         |
|    total_timesteps      | 2439168       |
| train/                  |               |
|    approx_kl            | 753.3087      |
|    clip_fraction        | 0.14          |
|    clip_range           | 0.2           |
|    entropy_loss         | -169          |
|    explained_variance   | 0.209         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.7          |
|    n_updates            | 11900         |
|    policy_gradient_loss | -0.00283      |
|    reward               | -8.853817e-05 |
|    std                  | 104           |
|    value_loss           | 9.53e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2577, ResetDay: 4257,Episode: 1453
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1192          |
|    time_elapsed         | 26995         |
|    total_timesteps      | 2441216       |
| train/                  |               |
|    approx_kl            | 772.40906     |
|    clip_fraction        | 0.144         |
|    clip_range           | 0.2           |
|    entropy_loss         | -169          |
|    explained_variance   | 0.065         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.7          |
|    n_updates            | 11910         |
|    policy_gradient_loss | 0.00335       |
|    reward               | 0.00022585067 |
|    std                  | 104           |
|    value_loss           | 1.7e-06       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1867, ResetDay: 3547,Episode: 1454
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1193          |
|    time_elapsed         | 27018         |
|    total_timesteps      | 2443264       |
| train/                  |               |
|    approx_kl            | 763.8977      |
|    clip_fraction        | 0.131         |
|    clip_range           | 0.2           |
|    entropy_loss         | -169          |
|    explained_variance   | 0.0825        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.7          |
|    n_updates            | 11920         |
|    policy_gradient_loss | -0.00353      |
|    reward               | 5.5246353e-05 |
|    std                  | 104           |
|    value_loss           | 7.66e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1642, ResetDay: 3322,Episode: 1455
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1194         |
|    time_elapsed         | 27041        |
|    total_timesteps      | 2445312      |
| train/                  |              |
|    approx_kl            | 773.7903     |
|    clip_fraction        | 0.14         |
|    clip_range           | 0.2          |
|    entropy_loss         | -169         |
|    explained_variance   | 0.123        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.69        |
|    n_updates            | 11930        |
|    policy_gradient_loss | 0.000769     |
|    reward               | 0.0001407898 |
|    std                  | 104          |
|    value_loss           | 7.18e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3322, episode: 1455
begin_total_asset: 200.00
end_total_asset: 229.21
total_reward: 29.21
total_cost: 8.17
total_trades: 42019
Sharpe: 0.276
=================================
Reseting Environment StartDay: 2648, ResetDay: 4328,Episode: 1456
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1195           |
|    time_elapsed         | 27063          |
|    total_timesteps      | 2447360        |
| train/                  |                |
|    approx_kl            | 776.8401       |
|    clip_fraction        | 0.136          |
|    clip_range           | 0.2            |
|    entropy_loss         | -169           |
|    explained_variance   | 0.2            |
|    learning_rate        | 0.00025        |
|    loss                 | -1.7           |
|    n_updates            | 11940          |
|    policy_gradient_loss | -0.00152       |
|    reward               | -2.6750946e-05 |
|    std                  | 104            |
|    value_loss           | 4.02e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1396, ResetDay: 3076,Episode: 1457
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1193, ResetDay: 2873,Episode: 1458
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1196         |
|    time_elapsed         | 27086        |
|    total_timesteps      | 2449408      |
| train/                  |              |
|    approx_kl            | 772.4066     |
|    clip_fraction        | 0.143        |
|    clip_range           | 0.2          |
|    entropy_loss         | -169         |
|    explained_variance   | 0.125        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.66        |
|    n_updates            | 11950        |
|    policy_gradient_loss | 0.000802     |
|    reward               | 5.780506e-06 |
|    std                  | 105          |
|    value_loss           | 1.06e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 545, ResetDay: 2225,Episode: 1459
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1197          |
|    time_elapsed         | 27108         |
|    total_timesteps      | 2451456       |
| train/                  |               |
|    approx_kl            | 775.4997      |
|    clip_fraction        | 0.141         |
|    clip_range           | 0.2           |
|    entropy_loss         | -169          |
|    explained_variance   | -0.341        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.7          |
|    n_updates            | 11960         |
|    policy_gradient_loss | 1.53e-05      |
|    reward               | 0.00016641502 |
|    std                  | 105           |
|    value_loss           | 6.83e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 670, ResetDay: 2350,Episode: 1460
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1198          |
|    time_elapsed         | 27131         |
|    total_timesteps      | 2453504       |
| train/                  |               |
|    approx_kl            | 784.35126     |
|    clip_fraction        | 0.138         |
|    clip_range           | 0.2           |
|    entropy_loss         | -169          |
|    explained_variance   | 0.0952        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.71         |
|    n_updates            | 11970         |
|    policy_gradient_loss | -0.00282      |
|    reward               | -3.973923e-05 |
|    std                  | 105           |
|    value_loss           | 5.56e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2350, episode: 1460
begin_total_asset: 200.00
end_total_asset: 82.18
total_reward: -117.82
total_cost: 17.74
total_trades: 42068
Sharpe: -0.169
=================================
Reseting Environment StartDay: 2367, ResetDay: 4047,Episode: 1461
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1199           |
|    time_elapsed         | 27153          |
|    total_timesteps      | 2455552        |
| train/                  |                |
|    approx_kl            | 792.21826      |
|    clip_fraction        | 0.126          |
|    clip_range           | 0.2            |
|    entropy_loss         | -169           |
|    explained_variance   | 0.158          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.71          |
|    n_updates            | 11980          |
|    policy_gradient_loss | -0.00128       |
|    reward               | -0.00046075057 |
|    std                  | 105            |
|    value_loss           | 3.63e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2111, ResetDay: 3791,Episode: 1462
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1200         |
|    time_elapsed         | 27176        |
|    total_timesteps      | 2457600      |
| train/                  |              |
|    approx_kl            | 796.343      |
|    clip_fraction        | 0.145        |
|    clip_range           | 0.2          |
|    entropy_loss         | -169         |
|    explained_variance   | 0.0762       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.69        |
|    n_updates            | 11990        |
|    policy_gradient_loss | -0.00124     |
|    reward               | 0.0021841782 |
|    std                  | 105          |
|    value_loss           | 1.53e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2593, ResetDay: 4273,Episode: 1463
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 251, ResetDay: 1931,Episode: 1464
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1201           |
|    time_elapsed         | 27198          |
|    total_timesteps      | 2459648        |
| train/                  |                |
|    approx_kl            | 787.8503       |
|    clip_fraction        | 0.135          |
|    clip_range           | 0.2            |
|    entropy_loss         | -169           |
|    explained_variance   | 0.0402         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.71          |
|    n_updates            | 12000          |
|    policy_gradient_loss | -0.00384       |
|    reward               | -0.00024806272 |
|    std                  | 106            |
|    value_loss           | 1.98e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1324, ResetDay: 3004,Episode: 1465
-----------------------------------------
| time/                   |             |
|    fps                  | 90          |
|    iterations           | 1202        |
|    time_elapsed         | 27221       |
|    total_timesteps      | 2461696     |
| train/                  |             |
|    approx_kl            | 797.18555   |
|    clip_fraction        | 0.136       |
|    clip_range           | 0.2         |
|    entropy_loss         | -169        |
|    explained_variance   | 0.063       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.71       |
|    n_updates            | 12010       |
|    policy_gradient_loss | -0.00669    |
|    reward               | 5.90004e-05 |
|    std                  | 106         |
|    value_loss           | 1.44e-06    |
-----------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3004, episode: 1465
begin_total_asset: 200.00
end_total_asset: 215.85
total_reward: 15.85
total_cost: 12.49
total_trades: 41968
Sharpe: 0.197
=================================
Reseting Environment StartDay: 1598, ResetDay: 3278,Episode: 1466
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1203         |
|    time_elapsed         | 27243        |
|    total_timesteps      | 2463744      |
| train/                  |              |
|    approx_kl            | 803.45544    |
|    clip_fraction        | 0.137        |
|    clip_range           | 0.2          |
|    entropy_loss         | -169         |
|    explained_variance   | -0.0572      |
|    learning_rate        | 0.00025      |
|    loss                 | -1.67        |
|    n_updates            | 12020        |
|    policy_gradient_loss | 0.00885      |
|    reward               | 1.272583e-05 |
|    std                  | 106          |
|    value_loss           | 4.08e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 976, ResetDay: 2656,Episode: 1467
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1204          |
|    time_elapsed         | 27266         |
|    total_timesteps      | 2465792       |
| train/                  |               |
|    approx_kl            | 805.36456     |
|    clip_fraction        | 0.135         |
|    clip_range           | 0.2           |
|    entropy_loss         | -169          |
|    explained_variance   | 0.15          |
|    learning_rate        | 0.00025       |
|    loss                 | -1.69         |
|    n_updates            | 12030         |
|    policy_gradient_loss | 0.00668       |
|    reward               | -6.175232e-06 |
|    std                  | 106           |
|    value_loss           | 3.16e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1763, ResetDay: 3443,Episode: 1468
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2299, ResetDay: 3979,Episode: 1469
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1205           |
|    time_elapsed         | 27288          |
|    total_timesteps      | 2467840        |
| train/                  |                |
|    approx_kl            | 806.0267       |
|    clip_fraction        | 0.134          |
|    clip_range           | 0.2            |
|    entropy_loss         | -169           |
|    explained_variance   | -0.0184        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.7           |
|    n_updates            | 12040          |
|    policy_gradient_loss | -0.00117       |
|    reward               | 0.000121293066 |
|    std                  | 106            |
|    value_loss           | 4.98e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 747, ResetDay: 2427,Episode: 1470
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1206          |
|    time_elapsed         | 27310         |
|    total_timesteps      | 2469888       |
| train/                  |               |
|    approx_kl            | 805.282       |
|    clip_fraction        | 0.124         |
|    clip_range           | 0.2           |
|    entropy_loss         | -169          |
|    explained_variance   | 0.162         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.7          |
|    n_updates            | 12050         |
|    policy_gradient_loss | -0.00331      |
|    reward               | 1.7101049e-05 |
|    std                  | 107           |
|    value_loss           | 1.13e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2427, episode: 1470
begin_total_asset: 200.00
end_total_asset: 87.97
total_reward: -112.03
total_cost: 23.02
total_trades: 42056
Sharpe: -0.086
=================================
Reseting Environment StartDay: 6, ResetDay: 1686,Episode: 1471
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1207         |
|    time_elapsed         | 27333        |
|    total_timesteps      | 2471936      |
| train/                  |              |
|    approx_kl            | 810.51843    |
|    clip_fraction        | 0.116        |
|    clip_range           | 0.2          |
|    entropy_loss         | -170         |
|    explained_variance   | 0.155        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.69        |
|    n_updates            | 12060        |
|    policy_gradient_loss | 0.00128      |
|    reward               | -0.001529976 |
|    std                  | 107          |
|    value_loss           | 1.27e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2755, ResetDay: 4435,Episode: 1472
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1208          |
|    time_elapsed         | 27355         |
|    total_timesteps      | 2473984       |
| train/                  |               |
|    approx_kl            | 807.64087     |
|    clip_fraction        | 0.128         |
|    clip_range           | 0.2           |
|    entropy_loss         | -170          |
|    explained_variance   | -0.289        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.7          |
|    n_updates            | 12070         |
|    policy_gradient_loss | 0.00306       |
|    reward               | -9.044189e-05 |
|    std                  | 108           |
|    value_loss           | 1.44e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 578, ResetDay: 2258,Episode: 1473
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1209           |
|    time_elapsed         | 27378          |
|    total_timesteps      | 2476032        |
| train/                  |                |
|    approx_kl            | 821.627        |
|    clip_fraction        | 0.134          |
|    clip_range           | 0.2            |
|    entropy_loss         | -170           |
|    explained_variance   | 0.117          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.69          |
|    n_updates            | 12080          |
|    policy_gradient_loss | 0.00216        |
|    reward               | -2.2447587e-06 |
|    std                  | 108            |
|    value_loss           | 5.68e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2094, ResetDay: 3774,Episode: 1474
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2774, ResetDay: 4454,Episode: 1475
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1210          |
|    time_elapsed         | 27401         |
|    total_timesteps      | 2478080       |
| train/                  |               |
|    approx_kl            | 820.82745     |
|    clip_fraction        | 0.12          |
|    clip_range           | 0.2           |
|    entropy_loss         | -170          |
|    explained_variance   | -0.306        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.65         |
|    n_updates            | 12090         |
|    policy_gradient_loss | 0.0146        |
|    reward               | 3.0154037e-05 |
|    std                  | 108           |
|    value_loss           | 3e-06         |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4454, episode: 1475
begin_total_asset: 200.00
end_total_asset: 304.44
total_reward: 104.44
total_cost: 15.45
total_trades: 41670
Sharpe: 0.374
=================================
Reseting Environment StartDay: 344, ResetDay: 2024,Episode: 1476
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1211          |
|    time_elapsed         | 27424         |
|    total_timesteps      | 2480128       |
| train/                  |               |
|    approx_kl            | 824.0875      |
|    clip_fraction        | 0.124         |
|    clip_range           | 0.2           |
|    entropy_loss         | -170          |
|    explained_variance   | 0.0806        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.7          |
|    n_updates            | 12100         |
|    policy_gradient_loss | -0.00279      |
|    reward               | 7.9152014e-05 |
|    std                  | 108           |
|    value_loss           | 1.35e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1521, ResetDay: 3201,Episode: 1477
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1212         |
|    time_elapsed         | 27446        |
|    total_timesteps      | 2482176      |
| train/                  |              |
|    approx_kl            | 838.65326    |
|    clip_fraction        | 0.125        |
|    clip_range           | 0.2          |
|    entropy_loss         | -170         |
|    explained_variance   | 0.0186       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.7         |
|    n_updates            | 12110        |
|    policy_gradient_loss | -0.00376     |
|    reward               | 6.892204e-05 |
|    std                  | 109          |
|    value_loss           | 1.36e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 512, ResetDay: 2192,Episode: 1478
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1213          |
|    time_elapsed         | 27469         |
|    total_timesteps      | 2484224       |
| train/                  |               |
|    approx_kl            | 838.3839      |
|    clip_fraction        | 0.136         |
|    clip_range           | 0.2           |
|    entropy_loss         | -170          |
|    explained_variance   | 0.158         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.7          |
|    n_updates            | 12120         |
|    policy_gradient_loss | 0.00146       |
|    reward               | 0.00017428894 |
|    std                  | 109           |
|    value_loss           | 4.22e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2754, ResetDay: 4434,Episode: 1479
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2082, ResetDay: 3762,Episode: 1480
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1214           |
|    time_elapsed         | 27491          |
|    total_timesteps      | 2486272        |
| train/                  |                |
|    approx_kl            | 844.54315      |
|    clip_fraction        | 0.136          |
|    clip_range           | 0.2            |
|    entropy_loss         | -170           |
|    explained_variance   | 0.262          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.71          |
|    n_updates            | 12130          |
|    policy_gradient_loss | -0.00637       |
|    reward               | -0.00010474205 |
|    std                  | 109            |
|    value_loss           | 8.16e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3762, episode: 1480
begin_total_asset: 200.00
end_total_asset: 150.07
total_reward: -49.93
total_cost: 12.50
total_trades: 41607
Sharpe: 0.035
=================================
Reseting Environment StartDay: 1938, ResetDay: 3618,Episode: 1481
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1215          |
|    time_elapsed         | 27514         |
|    total_timesteps      | 2488320       |
| train/                  |               |
|    approx_kl            | 842.82935     |
|    clip_fraction        | 0.13          |
|    clip_range           | 0.2           |
|    entropy_loss         | -170          |
|    explained_variance   | 0.0674        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.72         |
|    n_updates            | 12140         |
|    policy_gradient_loss | 0.00404       |
|    reward               | 0.00015322113 |
|    std                  | 110           |
|    value_loss           | 2.9e-06       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1548, ResetDay: 3228,Episode: 1482
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1216         |
|    time_elapsed         | 27537        |
|    total_timesteps      | 2490368      |
| train/                  |              |
|    approx_kl            | 849.6278     |
|    clip_fraction        | 0.124        |
|    clip_range           | 0.2          |
|    entropy_loss         | -170         |
|    explained_variance   | -0.253       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.71        |
|    n_updates            | 12150        |
|    policy_gradient_loss | 0.00218      |
|    reward               | 7.814484e-05 |
|    std                  | 110          |
|    value_loss           | 5.9e-07      |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2622, ResetDay: 4302,Episode: 1483
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1217          |
|    time_elapsed         | 27559         |
|    total_timesteps      | 2492416       |
| train/                  |               |
|    approx_kl            | 863.7083      |
|    clip_fraction        | 0.124         |
|    clip_range           | 0.2           |
|    entropy_loss         | -170          |
|    explained_variance   | 0.13          |
|    learning_rate        | 0.00025       |
|    loss                 | -1.71         |
|    n_updates            | 12160         |
|    policy_gradient_loss | -0.0012       |
|    reward               | -0.0004409771 |
|    std                  | 110           |
|    value_loss           | 1.49e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2072, ResetDay: 3752,Episode: 1484
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1218         |
|    time_elapsed         | 27582        |
|    total_timesteps      | 2494464      |
| train/                  |              |
|    approx_kl            | 859.83276    |
|    clip_fraction        | 0.125        |
|    clip_range           | 0.2          |
|    entropy_loss         | -170         |
|    explained_variance   | 0.26         |
|    learning_rate        | 0.00025      |
|    loss                 | -1.71        |
|    n_updates            | 12170        |
|    policy_gradient_loss | -0.000487    |
|    reward               | 0.0002484751 |
|    std                  | 111          |
|    value_loss           | 5.52e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2038, ResetDay: 3718,Episode: 1485
Environment reached Terminal state as number of trading days reached limit!!
day: 3718, episode: 1485
begin_total_asset: 200.00
end_total_asset: 305.20
total_reward: 105.20
total_cost: 17.83
total_trades: 41650
Sharpe: 0.391
=================================
Reseting Environment StartDay: 816, ResetDay: 2496,Episode: 1486
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1219           |
|    time_elapsed         | 27604          |
|    total_timesteps      | 2496512        |
| train/                  |                |
|    approx_kl            | 870.7761       |
|    clip_fraction        | 0.123          |
|    clip_range           | 0.2            |
|    entropy_loss         | -171           |
|    explained_variance   | 0.0486         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.68          |
|    n_updates            | 12180          |
|    policy_gradient_loss | 0.00488        |
|    reward               | -0.00014528964 |
|    std                  | 111            |
|    value_loss           | 6.14e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1131, ResetDay: 2811,Episode: 1487
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1220          |
|    time_elapsed         | 27627         |
|    total_timesteps      | 2498560       |
| train/                  |               |
|    approx_kl            | 878.0111      |
|    clip_fraction        | 0.106         |
|    clip_range           | 0.2           |
|    entropy_loss         | -171          |
|    explained_variance   | 0.14          |
|    learning_rate        | 0.00025       |
|    loss                 | -1.73         |
|    n_updates            | 12190         |
|    policy_gradient_loss | -0.0023       |
|    reward               | 4.2887877e-05 |
|    std                  | 111           |
|    value_loss           | 9.87e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 644, ResetDay: 2324,Episode: 1488
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1221          |
|    time_elapsed         | 27650         |
|    total_timesteps      | 2500608       |
| train/                  |               |
|    approx_kl            | 878.7406      |
|    clip_fraction        | 0.128         |
|    clip_range           | 0.2           |
|    entropy_loss         | -171          |
|    explained_variance   | 0.101         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.69         |
|    n_updates            | 12200         |
|    policy_gradient_loss | 0.00244       |
|    reward               | 1.7033386e-05 |
|    std                  | 111           |
|    value_loss           | 5.08e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2380, ResetDay: 4060,Episode: 1489
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1222         |
|    time_elapsed         | 27672        |
|    total_timesteps      | 2502656      |
| train/                  |              |
|    approx_kl            | 883.2641     |
|    clip_fraction        | 0.114        |
|    clip_range           | 0.2          |
|    entropy_loss         | -171         |
|    explained_variance   | 0.241        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.71        |
|    n_updates            | 12210        |
|    policy_gradient_loss | 0.000203     |
|    reward               | 0.0005872383 |
|    std                  | 112          |
|    value_loss           | 3.64e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 588, ResetDay: 2268,Episode: 1490
Environment reached Terminal state as number of trading days reached limit!!
day: 2268, episode: 1490
begin_total_asset: 200.00
end_total_asset: 86.46
total_reward: -113.54
total_cost: 25.04
total_trades: 41670
Sharpe: -0.017
=================================
Reseting Environment StartDay: 2341, ResetDay: 4021,Episode: 1491
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1223          |
|    time_elapsed         | 27695         |
|    total_timesteps      | 2504704       |
| train/                  |               |
|    approx_kl            | 887.2241      |
|    clip_fraction        | 0.12          |
|    clip_range           | 0.2           |
|    entropy_loss         | -171          |
|    explained_variance   | 0.138         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.7          |
|    n_updates            | 12220         |
|    policy_gradient_loss | 0.0027        |
|    reward               | 0.00015433312 |
|    std                  | 112           |
|    value_loss           | 9.54e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 213, ResetDay: 1893,Episode: 1492
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1224           |
|    time_elapsed         | 27718          |
|    total_timesteps      | 2506752        |
| train/                  |                |
|    approx_kl            | 892.81555      |
|    clip_fraction        | 0.119          |
|    clip_range           | 0.2            |
|    entropy_loss         | -171           |
|    explained_variance   | -0.00245       |
|    learning_rate        | 0.00025        |
|    loss                 | -1.72          |
|    n_updates            | 12230          |
|    policy_gradient_loss | -0.00331       |
|    reward               | -0.00010563135 |
|    std                  | 112            |
|    value_loss           | 1.5e-06        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1849, ResetDay: 3529,Episode: 1493
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1225          |
|    time_elapsed         | 27741         |
|    total_timesteps      | 2508800       |
| train/                  |               |
|    approx_kl            | 889.53326     |
|    clip_fraction        | 0.122         |
|    clip_range           | 0.2           |
|    entropy_loss         | -171          |
|    explained_variance   | 0.0575        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.73         |
|    n_updates            | 12240         |
|    policy_gradient_loss | -0.00271      |
|    reward               | -0.0001799469 |
|    std                  | 113           |
|    value_loss           | 1.68e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2405, ResetDay: 4085,Episode: 1494
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1226          |
|    time_elapsed         | 27764         |
|    total_timesteps      | 2510848       |
| train/                  |               |
|    approx_kl            | 899.67114     |
|    clip_fraction        | 0.106         |
|    clip_range           | 0.2           |
|    entropy_loss         | -171          |
|    explained_variance   | 0.126         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.72         |
|    n_updates            | 12250         |
|    policy_gradient_loss | 0.00202       |
|    reward               | -5.577965e-05 |
|    std                  | 113           |
|    value_loss           | 1.06e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1676, ResetDay: 3356,Episode: 1495
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1227          |
|    time_elapsed         | 27787         |
|    total_timesteps      | 2512896       |
| train/                  |               |
|    approx_kl            | 909.37256     |
|    clip_fraction        | 0.12          |
|    clip_range           | 0.2           |
|    entropy_loss         | -171          |
|    explained_variance   | 0.192         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.7          |
|    n_updates            | 12260         |
|    policy_gradient_loss | 0.00409       |
|    reward               | 4.1781997e-05 |
|    std                  | 113           |
|    value_loss           | 1.13e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3356, episode: 1495
begin_total_asset: 200.00
end_total_asset: 265.91
total_reward: 65.91
total_cost: 11.15
total_trades: 41388
Sharpe: 0.328
=================================
Reseting Environment StartDay: 1624, ResetDay: 3304,Episode: 1496
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 842, ResetDay: 2522,Episode: 1497
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1228           |
|    time_elapsed         | 27809          |
|    total_timesteps      | 2514944        |
| train/                  |                |
|    approx_kl            | 906.4784       |
|    clip_fraction        | 0.115          |
|    clip_range           | 0.2            |
|    entropy_loss         | -171           |
|    explained_variance   | -0.0454        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.72          |
|    n_updates            | 12270          |
|    policy_gradient_loss | 0.000771       |
|    reward               | -2.7802611e-05 |
|    std                  | 113            |
|    value_loss           | 9.25e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 143, ResetDay: 1823,Episode: 1498
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1229          |
|    time_elapsed         | 27832         |
|    total_timesteps      | 2516992       |
| train/                  |               |
|    approx_kl            | 914.1184      |
|    clip_fraction        | 0.112         |
|    clip_range           | 0.2           |
|    entropy_loss         | -171          |
|    explained_variance   | 0.226         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.73         |
|    n_updates            | 12280         |
|    policy_gradient_loss | 0.00483       |
|    reward               | 5.1026727e-05 |
|    std                  | 114           |
|    value_loss           | 1.19e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1036, ResetDay: 2716,Episode: 1499
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1230          |
|    time_elapsed         | 27854         |
|    total_timesteps      | 2519040       |
| train/                  |               |
|    approx_kl            | 921.92883     |
|    clip_fraction        | 0.119         |
|    clip_range           | 0.2           |
|    entropy_loss         | -171          |
|    explained_variance   | -0.0546       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.69         |
|    n_updates            | 12290         |
|    policy_gradient_loss | -0.000911     |
|    reward               | -9.512806e-06 |
|    std                  | 114           |
|    value_loss           | 4.74e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 86, ResetDay: 1766,Episode: 1500
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1231          |
|    time_elapsed         | 27877         |
|    total_timesteps      | 2521088       |
| train/                  |               |
|    approx_kl            | 915.1915      |
|    clip_fraction        | 0.11          |
|    clip_range           | 0.2           |
|    entropy_loss         | -171          |
|    explained_variance   | 0.395         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.74         |
|    n_updates            | 12300         |
|    policy_gradient_loss | -0.00553      |
|    reward               | 0.00015618572 |
|    std                  | 114           |
|    value_loss           | 6.79e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 1766, episode: 1500
begin_total_asset: 200.00
end_total_asset: 751.34
total_reward: 551.34
total_cost: 38.52
total_trades: 41684
Sharpe: 0.736
=================================
Reseting Environment StartDay: 2570, ResetDay: 4250,Episode: 1501
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1232          |
|    time_elapsed         | 27899         |
|    total_timesteps      | 2523136       |
| train/                  |               |
|    approx_kl            | 917.4487      |
|    clip_fraction        | 0.104         |
|    clip_range           | 0.2           |
|    entropy_loss         | -171          |
|    explained_variance   | 0.183         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.72         |
|    n_updates            | 12310         |
|    policy_gradient_loss | -0.0019       |
|    reward               | -0.0012119637 |
|    std                  | 114           |
|    value_loss           | 2.14e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2567, ResetDay: 4247,Episode: 1502
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 385, ResetDay: 2065,Episode: 1503
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1233         |
|    time_elapsed         | 27921        |
|    total_timesteps      | 2525184      |
| train/                  |              |
|    approx_kl            | 926.55316    |
|    clip_fraction        | 0.115        |
|    clip_range           | 0.2          |
|    entropy_loss         | -171         |
|    explained_variance   | -0.0168      |
|    learning_rate        | 0.00025      |
|    loss                 | -1.73        |
|    n_updates            | 12320        |
|    policy_gradient_loss | 0.000579     |
|    reward               | -0.000616035 |
|    std                  | 115          |
|    value_loss           | 5.88e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1607, ResetDay: 3287,Episode: 1504
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1234         |
|    time_elapsed         | 27944        |
|    total_timesteps      | 2527232      |
| train/                  |              |
|    approx_kl            | 936.02985    |
|    clip_fraction        | 0.104        |
|    clip_range           | 0.2          |
|    entropy_loss         | -172         |
|    explained_variance   | -0.201       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.73        |
|    n_updates            | 12330        |
|    policy_gradient_loss | -0.00316     |
|    reward               | 0.0009374668 |
|    std                  | 115          |
|    value_loss           | 1.94e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2611, ResetDay: 4291,Episode: 1505
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1235           |
|    time_elapsed         | 27967          |
|    total_timesteps      | 2529280        |
| train/                  |                |
|    approx_kl            | 935.29224      |
|    clip_fraction        | 0.114          |
|    clip_range           | 0.2            |
|    entropy_loss         | -172           |
|    explained_variance   | -0.341         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.72          |
|    n_updates            | 12340          |
|    policy_gradient_loss | 0.00518        |
|    reward               | -0.00040474357 |
|    std                  | 115            |
|    value_loss           | 5.35e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4291, episode: 1505
begin_total_asset: 200.00
end_total_asset: 390.68
total_reward: 190.68
total_cost: 29.69
total_trades: 41471
Sharpe: 0.528
=================================
Reseting Environment StartDay: 2521, ResetDay: 4201,Episode: 1506
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1236          |
|    time_elapsed         | 27989         |
|    total_timesteps      | 2531328       |
| train/                  |               |
|    approx_kl            | 945.0648      |
|    clip_fraction        | 0.102         |
|    clip_range           | 0.2           |
|    entropy_loss         | -172          |
|    explained_variance   | 0.189         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.71         |
|    n_updates            | 12350         |
|    policy_gradient_loss | 0.00385       |
|    reward               | 0.00017941819 |
|    std                  | 116           |
|    value_loss           | 6.54e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1911, ResetDay: 3591,Episode: 1507
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1451, ResetDay: 3131,Episode: 1508
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1237          |
|    time_elapsed         | 28011         |
|    total_timesteps      | 2533376       |
| train/                  |               |
|    approx_kl            | 960.0476      |
|    clip_fraction        | 0.102         |
|    clip_range           | 0.2           |
|    entropy_loss         | -172          |
|    explained_variance   | 0.103         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.73         |
|    n_updates            | 12360         |
|    policy_gradient_loss | -0.00204      |
|    reward               | -8.059616e-05 |
|    std                  | 116           |
|    value_loss           | 1.59e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 521, ResetDay: 2201,Episode: 1509
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1238         |
|    time_elapsed         | 28034        |
|    total_timesteps      | 2535424      |
| train/                  |              |
|    approx_kl            | 947.5011     |
|    clip_fraction        | 0.116        |
|    clip_range           | 0.2          |
|    entropy_loss         | -172         |
|    explained_variance   | -0.217       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.72        |
|    n_updates            | 12370        |
|    policy_gradient_loss | -0.00156     |
|    reward               | 9.030023e-05 |
|    std                  | 116          |
|    value_loss           | 7.26e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1678, ResetDay: 3358,Episode: 1510
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1239          |
|    time_elapsed         | 28057         |
|    total_timesteps      | 2537472       |
| train/                  |               |
|    approx_kl            | 956.9584      |
|    clip_fraction        | 0.114         |
|    clip_range           | 0.2           |
|    entropy_loss         | -172          |
|    explained_variance   | 0.0274        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.72         |
|    n_updates            | 12380         |
|    policy_gradient_loss | -0.00103      |
|    reward               | 0.00011278153 |
|    std                  | 117           |
|    value_loss           | 4.06e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3358, episode: 1510
begin_total_asset: 200.00
end_total_asset: 320.36
total_reward: 120.36
total_cost: 17.46
total_trades: 41172
Sharpe: 0.418
=================================
Reseting Environment StartDay: 2657, ResetDay: 4337,Episode: 1511
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1240           |
|    time_elapsed         | 28079          |
|    total_timesteps      | 2539520        |
| train/                  |                |
|    approx_kl            | 972.4881       |
|    clip_fraction        | 0.115          |
|    clip_range           | 0.2            |
|    entropy_loss         | -172           |
|    explained_variance   | 0.155          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.72          |
|    n_updates            | 12390          |
|    policy_gradient_loss | 0.00131        |
|    reward               | -0.00025000572 |
|    std                  | 117            |
|    value_loss           | 2.86e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 830, ResetDay: 2510,Episode: 1512
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1241           |
|    time_elapsed         | 28102          |
|    total_timesteps      | 2541568        |
| train/                  |                |
|    approx_kl            | 969.95557      |
|    clip_fraction        | 0.108          |
|    clip_range           | 0.2            |
|    entropy_loss         | -172           |
|    explained_variance   | 0.0912         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.72          |
|    n_updates            | 12400          |
|    policy_gradient_loss | -0.00218       |
|    reward               | -0.00011579361 |
|    std                  | 117            |
|    value_loss           | 7.62e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1096, ResetDay: 2776,Episode: 1513
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1881, ResetDay: 3561,Episode: 1514
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1242           |
|    time_elapsed         | 28125          |
|    total_timesteps      | 2543616        |
| train/                  |                |
|    approx_kl            | 969.2899       |
|    clip_fraction        | 0.109          |
|    clip_range           | 0.2            |
|    entropy_loss         | -172           |
|    explained_variance   | -0.144         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.74          |
|    n_updates            | 12410          |
|    policy_gradient_loss | -0.000617      |
|    reward               | -9.7249984e-05 |
|    std                  | 117            |
|    value_loss           | 8.73e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 860, ResetDay: 2540,Episode: 1515
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1243           |
|    time_elapsed         | 28147          |
|    total_timesteps      | 2545664        |
| train/                  |                |
|    approx_kl            | 973.68896      |
|    clip_fraction        | 0.0977         |
|    clip_range           | 0.2            |
|    entropy_loss         | -172           |
|    explained_variance   | 0.0185         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.75          |
|    n_updates            | 12420          |
|    policy_gradient_loss | 0.00177        |
|    reward               | -1.2590599e-05 |
|    std                  | 118            |
|    value_loss           | 3.96e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2540, episode: 1515
begin_total_asset: 200.00
end_total_asset: 126.77
total_reward: -73.23
total_cost: 24.64
total_trades: 41258
Sharpe: 0.032
=================================
Reseting Environment StartDay: 2730, ResetDay: 4410,Episode: 1516
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1244          |
|    time_elapsed         | 28169         |
|    total_timesteps      | 2547712       |
| train/                  |               |
|    approx_kl            | 986.79755     |
|    clip_fraction        | 0.107         |
|    clip_range           | 0.2           |
|    entropy_loss         | -172          |
|    explained_variance   | 0.126         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.75         |
|    n_updates            | 12430         |
|    policy_gradient_loss | -0.00315      |
|    reward               | 0.00019657593 |
|    std                  | 118           |
|    value_loss           | 9.57e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1648, ResetDay: 3328,Episode: 1517
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1245          |
|    time_elapsed         | 28192         |
|    total_timesteps      | 2549760       |
| train/                  |               |
|    approx_kl            | 984.078       |
|    clip_fraction        | 0.0967        |
|    clip_range           | 0.2           |
|    entropy_loss         | -172          |
|    explained_variance   | 0.175         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.73         |
|    n_updates            | 12440         |
|    policy_gradient_loss | 0.000696      |
|    reward               | 2.0758629e-05 |
|    std                  | 118           |
|    value_loss           | 9.91e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 547, ResetDay: 2227,Episode: 1518
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1769, ResetDay: 3449,Episode: 1519
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1246         |
|    time_elapsed         | 28215        |
|    total_timesteps      | 2551808      |
| train/                  |              |
|    approx_kl            | 986.29944    |
|    clip_fraction        | 0.106        |
|    clip_range           | 0.2          |
|    entropy_loss         | -172         |
|    explained_variance   | -0.0232      |
|    learning_rate        | 0.00025      |
|    loss                 | -1.72        |
|    n_updates            | 12450        |
|    policy_gradient_loss | -1.25e-05    |
|    reward               | 0.0001628729 |
|    std                  | 119          |
|    value_loss           | 1.4e-06      |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1689, ResetDay: 3369,Episode: 1520
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1247          |
|    time_elapsed         | 28237         |
|    total_timesteps      | 2553856       |
| train/                  |               |
|    approx_kl            | 991.1012      |
|    clip_fraction        | 0.1           |
|    clip_range           | 0.2           |
|    entropy_loss         | -173          |
|    explained_variance   | 0.126         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.74         |
|    n_updates            | 12460         |
|    policy_gradient_loss | 0.00277       |
|    reward               | -8.916092e-06 |
|    std                  | 119           |
|    value_loss           | 6.6e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3369, episode: 1520
begin_total_asset: 200.00
end_total_asset: 241.64
total_reward: 41.64
total_cost: 22.49
total_trades: 40980
Sharpe: 0.285
=================================
Reseting Environment StartDay: 679, ResetDay: 2359,Episode: 1521
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1248           |
|    time_elapsed         | 28260          |
|    total_timesteps      | 2555904        |
| train/                  |                |
|    approx_kl            | 994.5425       |
|    clip_fraction        | 0.103          |
|    clip_range           | 0.2            |
|    entropy_loss         | -173           |
|    explained_variance   | 0.136          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.71          |
|    n_updates            | 12470          |
|    policy_gradient_loss | 0.00194        |
|    reward               | -3.9499217e-05 |
|    std                  | 119            |
|    value_loss           | 8.01e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 202, ResetDay: 1882,Episode: 1522
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1249          |
|    time_elapsed         | 28282         |
|    total_timesteps      | 2557952       |
| train/                  |               |
|    approx_kl            | 1002.3528     |
|    clip_fraction        | 0.101         |
|    clip_range           | 0.2           |
|    entropy_loss         | -173          |
|    explained_variance   | 0.0394        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.72         |
|    n_updates            | 12480         |
|    policy_gradient_loss | -0.00365      |
|    reward               | -8.095762e-05 |
|    std                  | 120           |
|    value_loss           | 5.05e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1420, ResetDay: 3100,Episode: 1523
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1250          |
|    time_elapsed         | 28305         |
|    total_timesteps      | 2560000       |
| train/                  |               |
|    approx_kl            | 1019.431      |
|    clip_fraction        | 0.098         |
|    clip_range           | 0.2           |
|    entropy_loss         | -173          |
|    explained_variance   | 0.19          |
|    learning_rate        | 0.00025       |
|    loss                 | -1.72         |
|    n_updates            | 12490         |
|    policy_gradient_loss | -0.00251      |
|    reward               | -9.057427e-06 |
|    std                  | 120           |
|    value_loss           | 1.34e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1300, ResetDay: 2980,Episode: 1524
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 87, ResetDay: 1767,Episode: 1525
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1251           |
|    time_elapsed         | 28327          |
|    total_timesteps      | 2562048        |
| train/                  |                |
|    approx_kl            | 1016.72314     |
|    clip_fraction        | 0.093          |
|    clip_range           | 0.2            |
|    entropy_loss         | -173           |
|    explained_variance   | 0.122          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.71          |
|    n_updates            | 12500          |
|    policy_gradient_loss | 0.00671        |
|    reward               | -0.00011624684 |
|    std                  | 120            |
|    value_loss           | 1.19e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 1767, episode: 1525
begin_total_asset: 200.00
end_total_asset: 685.92
total_reward: 485.92
total_cost: 47.86
total_trades: 41179
Sharpe: 0.684
=================================
Reseting Environment StartDay: 674, ResetDay: 2354,Episode: 1526
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1252          |
|    time_elapsed         | 28350         |
|    total_timesteps      | 2564096       |
| train/                  |               |
|    approx_kl            | 1008.51715    |
|    clip_fraction        | 0.0963        |
|    clip_range           | 0.2           |
|    entropy_loss         | -173          |
|    explained_variance   | -0.128        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.71         |
|    n_updates            | 12510         |
|    policy_gradient_loss | -3.18e-05     |
|    reward               | 9.0281865e-05 |
|    std                  | 120           |
|    value_loss           | 5.54e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1328, ResetDay: 3008,Episode: 1527
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1253          |
|    time_elapsed         | 28373         |
|    total_timesteps      | 2566144       |
| train/                  |               |
|    approx_kl            | 1028.7334     |
|    clip_fraction        | 0.0995        |
|    clip_range           | 0.2           |
|    entropy_loss         | -173          |
|    explained_variance   | 0.182         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.74         |
|    n_updates            | 12520         |
|    policy_gradient_loss | 0.00156       |
|    reward               | -5.854473e-05 |
|    std                  | 121           |
|    value_loss           | 2.78e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1501, ResetDay: 3181,Episode: 1528
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1254         |
|    time_elapsed         | 28395        |
|    total_timesteps      | 2568192      |
| train/                  |              |
|    approx_kl            | 1037.242     |
|    clip_fraction        | 0.0994       |
|    clip_range           | 0.2          |
|    entropy_loss         | -173         |
|    explained_variance   | 0.061        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.73        |
|    n_updates            | 12530        |
|    policy_gradient_loss | 0.00491      |
|    reward               | 0.0003430786 |
|    std                  | 121          |
|    value_loss           | 1.31e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1303, ResetDay: 2983,Episode: 1529
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1255          |
|    time_elapsed         | 28418         |
|    total_timesteps      | 2570240       |
| train/                  |               |
|    approx_kl            | 1029.0294     |
|    clip_fraction        | 0.0975        |
|    clip_range           | 0.2           |
|    entropy_loss         | -173          |
|    explained_variance   | 0.0199        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.72         |
|    n_updates            | 12540         |
|    policy_gradient_loss | 0.000363      |
|    reward               | 4.1520118e-05 |
|    std                  | 121           |
|    value_loss           | 5.16e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 871, ResetDay: 2551,Episode: 1530
Environment reached Terminal state as number of trading days reached limit!!
day: 2551, episode: 1530
begin_total_asset: 200.00
end_total_asset: 185.86
total_reward: -14.14
total_cost: 21.72
total_trades: 40921
Sharpe: 0.151
=================================
Reseting Environment StartDay: 1023, ResetDay: 2703,Episode: 1531
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1256          |
|    time_elapsed         | 28441         |
|    total_timesteps      | 2572288       |
| train/                  |               |
|    approx_kl            | 1039.8159     |
|    clip_fraction        | 0.0945        |
|    clip_range           | 0.2           |
|    entropy_loss         | -173          |
|    explained_variance   | 0.152         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.7          |
|    n_updates            | 12550         |
|    policy_gradient_loss | 0.0042        |
|    reward               | 0.00023670845 |
|    std                  | 121           |
|    value_loss           | 2.89e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 666, ResetDay: 2346,Episode: 1532
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1257          |
|    time_elapsed         | 28463         |
|    total_timesteps      | 2574336       |
| train/                  |               |
|    approx_kl            | 1042.165      |
|    clip_fraction        | 0.0997        |
|    clip_range           | 0.2           |
|    entropy_loss         | -173          |
|    explained_variance   | 0.233         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.74         |
|    n_updates            | 12560         |
|    policy_gradient_loss | 0.00058       |
|    reward               | 0.00014668825 |
|    std                  | 122           |
|    value_loss           | 4.56e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 770, ResetDay: 2450,Episode: 1533
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1258         |
|    time_elapsed         | 28486        |
|    total_timesteps      | 2576384      |
| train/                  |              |
|    approx_kl            | 1047.4248    |
|    clip_fraction        | 0.0875       |
|    clip_range           | 0.2          |
|    entropy_loss         | -173         |
|    explained_variance   | 0.301        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.74        |
|    n_updates            | 12570        |
|    policy_gradient_loss | 0.000106     |
|    reward               | 0.0001585989 |
|    std                  | 122          |
|    value_loss           | 4.54e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 147, ResetDay: 1827,Episode: 1534
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1259          |
|    time_elapsed         | 28508         |
|    total_timesteps      | 2578432       |
| train/                  |               |
|    approx_kl            | 1055.6426     |
|    clip_fraction        | 0.0965        |
|    clip_range           | 0.2           |
|    entropy_loss         | -173          |
|    explained_variance   | 0.386         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.74         |
|    n_updates            | 12580         |
|    policy_gradient_loss | -0.00152      |
|    reward               | -3.193903e-05 |
|    std                  | 122           |
|    value_loss           | 6.98e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 445, ResetDay: 2125,Episode: 1535
Environment reached Terminal state as number of trading days reached limit!!
day: 2125, episode: 1535
begin_total_asset: 200.00
end_total_asset: 333.34
total_reward: 133.34
total_cost: 55.28
total_trades: 40957
Sharpe: 0.399
=================================
Reseting Environment StartDay: 438, ResetDay: 2118,Episode: 1536
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1260         |
|    time_elapsed         | 28532        |
|    total_timesteps      | 2580480      |
| train/                  |              |
|    approx_kl            | 1058.5793    |
|    clip_fraction        | 0.101        |
|    clip_range           | 0.2          |
|    entropy_loss         | -173         |
|    explained_variance   | 0.176        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.73        |
|    n_updates            | 12590        |
|    policy_gradient_loss | -0.00745     |
|    reward               | 0.0003619217 |
|    std                  | 123          |
|    value_loss           | 1.16e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2148, ResetDay: 3828,Episode: 1537
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1261          |
|    time_elapsed         | 28555         |
|    total_timesteps      | 2582528       |
| train/                  |               |
|    approx_kl            | 1065.3077     |
|    clip_fraction        | 0.0923        |
|    clip_range           | 0.2           |
|    entropy_loss         | -173          |
|    explained_variance   | 0.327         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.73         |
|    n_updates            | 12600         |
|    policy_gradient_loss | 0.00562       |
|    reward               | 0.00032461167 |
|    std                  | 123           |
|    value_loss           | 1.41e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 717, ResetDay: 2397,Episode: 1538
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1262           |
|    time_elapsed         | 28577          |
|    total_timesteps      | 2584576        |
| train/                  |                |
|    approx_kl            | 1074.0669      |
|    clip_fraction        | 0.0939         |
|    clip_range           | 0.2            |
|    entropy_loss         | -174           |
|    explained_variance   | 0.327          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.71          |
|    n_updates            | 12610          |
|    policy_gradient_loss | 0.00354        |
|    reward               | -0.00021006088 |
|    std                  | 123            |
|    value_loss           | 1.13e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1993, ResetDay: 3673,Episode: 1539
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1263          |
|    time_elapsed         | 28600         |
|    total_timesteps      | 2586624       |
| train/                  |               |
|    approx_kl            | 1077.2988     |
|    clip_fraction        | 0.0926        |
|    clip_range           | 0.2           |
|    entropy_loss         | -174          |
|    explained_variance   | 0.0152        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.74         |
|    n_updates            | 12620         |
|    policy_gradient_loss | -0.00474      |
|    reward               | 0.00082726707 |
|    std                  | 124           |
|    value_loss           | 2.33e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 398, ResetDay: 2078,Episode: 1540
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1264          |
|    time_elapsed         | 28622         |
|    total_timesteps      | 2588672       |
| train/                  |               |
|    approx_kl            | 1078.0973     |
|    clip_fraction        | 0.0928        |
|    clip_range           | 0.2           |
|    entropy_loss         | -174          |
|    explained_variance   | -0.0785       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.74         |
|    n_updates            | 12630         |
|    policy_gradient_loss | 0.00491       |
|    reward               | 4.6088506e-05 |
|    std                  | 124           |
|    value_loss           | 6.49e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2078, episode: 1540
begin_total_asset: 200.00
end_total_asset: 168.85
total_reward: -31.15
total_cost: 50.95
total_trades: 40978
Sharpe: 0.155
=================================
Reseting Environment StartDay: 2311, ResetDay: 3991,Episode: 1541
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1375, ResetDay: 3055,Episode: 1542
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1265          |
|    time_elapsed         | 28644         |
|    total_timesteps      | 2590720       |
| train/                  |               |
|    approx_kl            | 1090.3418     |
|    clip_fraction        | 0.108         |
|    clip_range           | 0.2           |
|    entropy_loss         | -174          |
|    explained_variance   | 0.23          |
|    learning_rate        | 0.00025       |
|    loss                 | -1.76         |
|    n_updates            | 12640         |
|    policy_gradient_loss | -0.00394      |
|    reward               | -0.0001196949 |
|    std                  | 124           |
|    value_loss           | 1.29e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2170, ResetDay: 3850,Episode: 1543
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1266          |
|    time_elapsed         | 28667         |
|    total_timesteps      | 2592768       |
| train/                  |               |
|    approx_kl            | 1092.6027     |
|    clip_fraction        | 0.102         |
|    clip_range           | 0.2           |
|    entropy_loss         | -174          |
|    explained_variance   | 0.141         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.75         |
|    n_updates            | 12650         |
|    policy_gradient_loss | -0.00197      |
|    reward               | 1.3059997e-05 |
|    std                  | 125           |
|    value_loss           | 2.62e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 808, ResetDay: 2488,Episode: 1544
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1267          |
|    time_elapsed         | 28689         |
|    total_timesteps      | 2594816       |
| train/                  |               |
|    approx_kl            | 1101.6011     |
|    clip_fraction        | 0.0797        |
|    clip_range           | 0.2           |
|    entropy_loss         | -174          |
|    explained_variance   | -0.523        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.74         |
|    n_updates            | 12660         |
|    policy_gradient_loss | 0.00132       |
|    reward               | -8.362541e-05 |
|    std                  | 125           |
|    value_loss           | 3.08e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 825, ResetDay: 2505,Episode: 1545
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1268           |
|    time_elapsed         | 28712          |
|    total_timesteps      | 2596864        |
| train/                  |                |
|    approx_kl            | 1104.6567      |
|    clip_fraction        | 0.097          |
|    clip_range           | 0.2            |
|    entropy_loss         | -174           |
|    explained_variance   | 0.137          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.73          |
|    n_updates            | 12670          |
|    policy_gradient_loss | 0.000607       |
|    reward               | -0.00021711273 |
|    std                  | 125            |
|    value_loss           | 1.17e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2505, episode: 1545
begin_total_asset: 200.00
end_total_asset: 175.98
total_reward: -24.02
total_cost: 37.60
total_trades: 40970
Sharpe: 0.127
=================================
Reseting Environment StartDay: 2467, ResetDay: 4147,Episode: 1546
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2719, ResetDay: 4399,Episode: 1547
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1269           |
|    time_elapsed         | 28734          |
|    total_timesteps      | 2598912        |
| train/                  |                |
|    approx_kl            | 1106.6653      |
|    clip_fraction        | 0.0912         |
|    clip_range           | 0.2            |
|    entropy_loss         | -174           |
|    explained_variance   | 0.134          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.74          |
|    n_updates            | 12680          |
|    policy_gradient_loss | -0.00335       |
|    reward               | -1.2132645e-05 |
|    std                  | 126            |
|    value_loss           | 4.28e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 677, ResetDay: 2357,Episode: 1548
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1270          |
|    time_elapsed         | 28757         |
|    total_timesteps      | 2600960       |
| train/                  |               |
|    approx_kl            | 1117.0032     |
|    clip_fraction        | 0.0983        |
|    clip_range           | 0.2           |
|    entropy_loss         | -174          |
|    explained_variance   | 0.0801        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.74         |
|    n_updates            | 12690         |
|    policy_gradient_loss | -0.00297      |
|    reward               | -5.711994e-05 |
|    std                  | 126           |
|    value_loss           | 1.75e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1461, ResetDay: 3141,Episode: 1549
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1271           |
|    time_elapsed         | 28779          |
|    total_timesteps      | 2603008        |
| train/                  |                |
|    approx_kl            | 1125.3424      |
|    clip_fraction        | 0.093          |
|    clip_range           | 0.2            |
|    entropy_loss         | -174           |
|    explained_variance   | 0.0582         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.73          |
|    n_updates            | 12700          |
|    policy_gradient_loss | -0.000575      |
|    reward               | -0.00011632633 |
|    std                  | 127            |
|    value_loss           | 9.23e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1495, ResetDay: 3175,Episode: 1550
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1272          |
|    time_elapsed         | 28802         |
|    total_timesteps      | 2605056       |
| train/                  |               |
|    approx_kl            | 1144.0352     |
|    clip_fraction        | 0.11          |
|    clip_range           | 0.2           |
|    entropy_loss         | -174          |
|    explained_variance   | 0.0183        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.75         |
|    n_updates            | 12710         |
|    policy_gradient_loss | -0.00464      |
|    reward               | -8.910618e-05 |
|    std                  | 127           |
|    value_loss           | 3.9e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3175, episode: 1550
begin_total_asset: 200.00
end_total_asset: 198.46
total_reward: -1.54
total_cost: 18.03
total_trades: 40533
Sharpe: 0.189
=================================
Reseting Environment StartDay: 190, ResetDay: 1870,Episode: 1551
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1273          |
|    time_elapsed         | 28824         |
|    total_timesteps      | 2607104       |
| train/                  |               |
|    approx_kl            | 1139.9968     |
|    clip_fraction        | 0.0903        |
|    clip_range           | 0.2           |
|    entropy_loss         | -174          |
|    explained_variance   | 0.164         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.74         |
|    n_updates            | 12720         |
|    policy_gradient_loss | 0.0063        |
|    reward               | -0.0002859354 |
|    std                  | 127           |
|    value_loss           | 3.74e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1041, ResetDay: 2721,Episode: 1552
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1735, ResetDay: 3415,Episode: 1553
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1274          |
|    time_elapsed         | 28847         |
|    total_timesteps      | 2609152       |
| train/                  |               |
|    approx_kl            | 1145.6913     |
|    clip_fraction        | 0.0895        |
|    clip_range           | 0.2           |
|    entropy_loss         | -174          |
|    explained_variance   | 0.217         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.74         |
|    n_updates            | 12730         |
|    policy_gradient_loss | -0.00224      |
|    reward               | 0.00021880073 |
|    std                  | 127           |
|    value_loss           | 1.25e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1761, ResetDay: 3441,Episode: 1554
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1275         |
|    time_elapsed         | 28869        |
|    total_timesteps      | 2611200      |
| train/                  |              |
|    approx_kl            | 1147.1511    |
|    clip_fraction        | 0.0851       |
|    clip_range           | 0.2          |
|    entropy_loss         | -175         |
|    explained_variance   | 0.268        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.77        |
|    n_updates            | 12740        |
|    policy_gradient_loss | -0.000606    |
|    reward               | -3.83091e-06 |
|    std                  | 128          |
|    value_loss           | 8.6e-07      |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 895, ResetDay: 2575,Episode: 1555
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1276           |
|    time_elapsed         | 28892          |
|    total_timesteps      | 2613248        |
| train/                  |                |
|    approx_kl            | 1152.4249      |
|    clip_fraction        | 0.091          |
|    clip_range           | 0.2            |
|    entropy_loss         | -175           |
|    explained_variance   | 0.0625         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.77          |
|    n_updates            | 12750          |
|    policy_gradient_loss | -0.00268       |
|    reward               | -0.00010813952 |
|    std                  | 129            |
|    value_loss           | 8.05e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2575, episode: 1555
begin_total_asset: 200.00
end_total_asset: 113.32
total_reward: -86.68
total_cost: 10.75
total_trades: 40522
Sharpe: 0.051
=================================
Reseting Environment StartDay: 2750, ResetDay: 4430,Episode: 1556
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1277          |
|    time_elapsed         | 28914         |
|    total_timesteps      | 2615296       |
| train/                  |               |
|    approx_kl            | 1169.0952     |
|    clip_fraction        | 0.0774        |
|    clip_range           | 0.2           |
|    entropy_loss         | -175          |
|    explained_variance   | 0.0556        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.75         |
|    n_updates            | 12760         |
|    policy_gradient_loss | -0.00201      |
|    reward               | 0.00037572556 |
|    std                  | 129           |
|    value_loss           | 5.04e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1566, ResetDay: 3246,Episode: 1557
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1996, ResetDay: 3676,Episode: 1558
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1278          |
|    time_elapsed         | 28937         |
|    total_timesteps      | 2617344       |
| train/                  |               |
|    approx_kl            | 1175.7051     |
|    clip_fraction        | 0.0895        |
|    clip_range           | 0.2           |
|    entropy_loss         | -175          |
|    explained_variance   | 0.0444        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.76         |
|    n_updates            | 12770         |
|    policy_gradient_loss | -0.00587      |
|    reward               | 0.00010551348 |
|    std                  | 129           |
|    value_loss           | 1.87e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2727, ResetDay: 4407,Episode: 1559
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1279          |
|    time_elapsed         | 28959         |
|    total_timesteps      | 2619392       |
| train/                  |               |
|    approx_kl            | 1186.8528     |
|    clip_fraction        | 0.07          |
|    clip_range           | 0.2           |
|    entropy_loss         | -175          |
|    explained_variance   | -0.0385       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.76         |
|    n_updates            | 12780         |
|    policy_gradient_loss | 0.00429       |
|    reward               | -0.0001479416 |
|    std                  | 129           |
|    value_loss           | 1.24e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1632, ResetDay: 3312,Episode: 1560
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1280          |
|    time_elapsed         | 28981         |
|    total_timesteps      | 2621440       |
| train/                  |               |
|    approx_kl            | 1179.6578     |
|    clip_fraction        | 0.0788        |
|    clip_range           | 0.2           |
|    entropy_loss         | -175          |
|    explained_variance   | 0.139         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.74         |
|    n_updates            | 12790         |
|    policy_gradient_loss | 0.00294       |
|    reward               | 1.3890839e-05 |
|    std                  | 129           |
|    value_loss           | 6.51e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3312, episode: 1560
begin_total_asset: 200.00
end_total_asset: 225.88
total_reward: 25.88
total_cost: 19.41
total_trades: 40456
Sharpe: 0.277
=================================
Reseting Environment StartDay: 1756, ResetDay: 3436,Episode: 1561
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1281           |
|    time_elapsed         | 29004          |
|    total_timesteps      | 2623488        |
| train/                  |                |
|    approx_kl            | 1189.8743      |
|    clip_fraction        | 0.0938         |
|    clip_range           | 0.2            |
|    entropy_loss         | -175           |
|    explained_variance   | 0.0129         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.74          |
|    n_updates            | 12800          |
|    policy_gradient_loss | -0.000706      |
|    reward               | -3.4290504e-05 |
|    std                  | 129            |
|    value_loss           | 8e-07          |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 779, ResetDay: 2459,Episode: 1562
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1282          |
|    time_elapsed         | 29026         |
|    total_timesteps      | 2625536       |
| train/                  |               |
|    approx_kl            | 1178.2405     |
|    clip_fraction        | 0.0935        |
|    clip_range           | 0.2           |
|    entropy_loss         | -175          |
|    explained_variance   | 0.136         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.74         |
|    n_updates            | 12810         |
|    policy_gradient_loss | 0.00432       |
|    reward               | 0.00014826393 |
|    std                  | 130           |
|    value_loss           | 4.15e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1121, ResetDay: 2801,Episode: 1563
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1501, ResetDay: 3181,Episode: 1564
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1283           |
|    time_elapsed         | 29049          |
|    total_timesteps      | 2627584        |
| train/                  |                |
|    approx_kl            | 1196.8186      |
|    clip_fraction        | 0.0858         |
|    clip_range           | 0.2            |
|    entropy_loss         | -175           |
|    explained_variance   | 0.157          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.73          |
|    n_updates            | 12820          |
|    policy_gradient_loss | 0.00357        |
|    reward               | -1.9232082e-05 |
|    std                  | 130            |
|    value_loss           | 4.76e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 366, ResetDay: 2046,Episode: 1565
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1284          |
|    time_elapsed         | 29072         |
|    total_timesteps      | 2629632       |
| train/                  |               |
|    approx_kl            | 1193.0248     |
|    clip_fraction        | 0.0894        |
|    clip_range           | 0.2           |
|    entropy_loss         | -175          |
|    explained_variance   | 0.205         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.73         |
|    n_updates            | 12830         |
|    policy_gradient_loss | 0.00103       |
|    reward               | -0.0004613058 |
|    std                  | 130           |
|    value_loss           | 3.91e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2046, episode: 1565
begin_total_asset: 200.00
end_total_asset: 149.53
total_reward: -50.47
total_cost: 40.47
total_trades: 40504
Sharpe: 0.099
=================================
Reseting Environment StartDay: 680, ResetDay: 2360,Episode: 1566
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1285          |
|    time_elapsed         | 29094         |
|    total_timesteps      | 2631680       |
| train/                  |               |
|    approx_kl            | 1203.4198     |
|    clip_fraction        | 0.0775        |
|    clip_range           | 0.2           |
|    entropy_loss         | -175          |
|    explained_variance   | 0.207         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.76         |
|    n_updates            | 12840         |
|    policy_gradient_loss | -0.000243     |
|    reward               | -3.973923e-05 |
|    std                  | 131           |
|    value_loss           | 6.32e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 454, ResetDay: 2134,Episode: 1567
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1286           |
|    time_elapsed         | 29116          |
|    total_timesteps      | 2633728        |
| train/                  |                |
|    approx_kl            | 1208.3584      |
|    clip_fraction        | 0.0874         |
|    clip_range           | 0.2            |
|    entropy_loss         | -175           |
|    explained_variance   | 0.0883         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.77          |
|    n_updates            | 12850          |
|    policy_gradient_loss | -0.00466       |
|    reward               | -0.00015440512 |
|    std                  | 131            |
|    value_loss           | 4.52e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2376, ResetDay: 4056,Episode: 1568
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1287           |
|    time_elapsed         | 29139          |
|    total_timesteps      | 2635776        |
| train/                  |                |
|    approx_kl            | 1216.639       |
|    clip_fraction        | 0.0853         |
|    clip_range           | 0.2            |
|    entropy_loss         | -175           |
|    explained_variance   | 0.284          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.76          |
|    n_updates            | 12860          |
|    policy_gradient_loss | 0.00248        |
|    reward               | -4.7107696e-05 |
|    std                  | 131            |
|    value_loss           | 4.87e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 172, ResetDay: 1852,Episode: 1569
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 378, ResetDay: 2058,Episode: 1570
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1288          |
|    time_elapsed         | 29162         |
|    total_timesteps      | 2637824       |
| train/                  |               |
|    approx_kl            | 1218.8875     |
|    clip_fraction        | 0.0878        |
|    clip_range           | 0.2           |
|    entropy_loss         | -175          |
|    explained_variance   | 0.0628        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.76         |
|    n_updates            | 12870         |
|    policy_gradient_loss | -0.00656      |
|    reward               | 0.00024283891 |
|    std                  | 131           |
|    value_loss           | 2.53e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2058, episode: 1570
begin_total_asset: 200.00
end_total_asset: 242.59
total_reward: 42.59
total_cost: 53.13
total_trades: 40566
Sharpe: 0.253
=================================
Reseting Environment StartDay: 2514, ResetDay: 4194,Episode: 1571
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1289           |
|    time_elapsed         | 29185          |
|    total_timesteps      | 2639872        |
| train/                  |                |
|    approx_kl            | 1220.4125      |
|    clip_fraction        | 0.0882         |
|    clip_range           | 0.2            |
|    entropy_loss         | -175           |
|    explained_variance   | -0.11          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.75          |
|    n_updates            | 12880          |
|    policy_gradient_loss | -0.00116       |
|    reward               | -0.00019329414 |
|    std                  | 131            |
|    value_loss           | 9.87e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2390, ResetDay: 4070,Episode: 1572
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1290           |
|    time_elapsed         | 29207          |
|    total_timesteps      | 2641920        |
| train/                  |                |
|    approx_kl            | 1205.7339      |
|    clip_fraction        | 0.0806         |
|    clip_range           | 0.2            |
|    entropy_loss         | -175           |
|    explained_variance   | 0.316          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.75          |
|    n_updates            | 12890          |
|    policy_gradient_loss | 0.00375        |
|    reward               | 0.000115247734 |
|    std                  | 132            |
|    value_loss           | 1.08e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2320, ResetDay: 4000,Episode: 1573
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1291         |
|    time_elapsed         | 29230        |
|    total_timesteps      | 2643968      |
| train/                  |              |
|    approx_kl            | 1221.9487    |
|    clip_fraction        | 0.0847       |
|    clip_range           | 0.2          |
|    entropy_loss         | -175         |
|    explained_variance   | 0.0647       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.77        |
|    n_updates            | 12900        |
|    policy_gradient_loss | 0.00204      |
|    reward               | 0.0008600197 |
|    std                  | 132          |
|    value_loss           | 1.98e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1636, ResetDay: 3316,Episode: 1574
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1744, ResetDay: 3424,Episode: 1575
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1292         |
|    time_elapsed         | 29253        |
|    total_timesteps      | 2646016      |
| train/                  |              |
|    approx_kl            | 1228.4762    |
|    clip_fraction        | 0.0833       |
|    clip_range           | 0.2          |
|    entropy_loss         | -175         |
|    explained_variance   | 0.158        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.73        |
|    n_updates            | 12910        |
|    policy_gradient_loss | 0.00573      |
|    reward               | 9.227447e-05 |
|    std                  | 132          |
|    value_loss           | 1.02e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3424, episode: 1575
begin_total_asset: 200.00
end_total_asset: 324.75
total_reward: 124.75
total_cost: 14.15
total_trades: 40185
Sharpe: 0.426
=================================
Reseting Environment StartDay: 1988, ResetDay: 3668,Episode: 1576
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1293          |
|    time_elapsed         | 29276         |
|    total_timesteps      | 2648064       |
| train/                  |               |
|    approx_kl            | 1229.8452     |
|    clip_fraction        | 0.0805        |
|    clip_range           | 0.2           |
|    entropy_loss         | -175          |
|    explained_variance   | -0.0394       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.78         |
|    n_updates            | 12920         |
|    policy_gradient_loss | 0.00636       |
|    reward               | 0.00018032684 |
|    std                  | 132           |
|    value_loss           | 5.6e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2500, ResetDay: 4180,Episode: 1577
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1294         |
|    time_elapsed         | 29298        |
|    total_timesteps      | 2650112      |
| train/                  |              |
|    approx_kl            | 1235.3628    |
|    clip_fraction        | 0.0799       |
|    clip_range           | 0.2          |
|    entropy_loss         | -176         |
|    explained_variance   | 0.0307       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.76        |
|    n_updates            | 12930        |
|    policy_gradient_loss | -0.00163     |
|    reward               | 7.330742e-05 |
|    std                  | 133          |
|    value_loss           | 4.54e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 295, ResetDay: 1975,Episode: 1578
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1295          |
|    time_elapsed         | 29321         |
|    total_timesteps      | 2652160       |
| train/                  |               |
|    approx_kl            | 1241.0447     |
|    clip_fraction        | 0.0871        |
|    clip_range           | 0.2           |
|    entropy_loss         | -176          |
|    explained_variance   | 0.169         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.77         |
|    n_updates            | 12940         |
|    policy_gradient_loss | -0.00148      |
|    reward               | -8.907814e-05 |
|    std                  | 133           |
|    value_loss           | 8.77e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2113, ResetDay: 3793,Episode: 1579
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1296         |
|    time_elapsed         | 29343        |
|    total_timesteps      | 2654208      |
| train/                  |              |
|    approx_kl            | 1249.3385    |
|    clip_fraction        | 0.0886       |
|    clip_range           | 0.2          |
|    entropy_loss         | -176         |
|    explained_variance   | -0.0557      |
|    learning_rate        | 0.00025      |
|    loss                 | -1.73        |
|    n_updates            | 12950        |
|    policy_gradient_loss | 0.00139      |
|    reward               | 0.0007372055 |
|    std                  | 133          |
|    value_loss           | 1.34e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2588, ResetDay: 4268,Episode: 1580
Environment reached Terminal state as number of trading days reached limit!!
day: 4268, episode: 1580
begin_total_asset: 200.00
end_total_asset: 353.44
total_reward: 153.44
total_cost: 35.34
total_trades: 40114
Sharpe: 0.461
=================================
Reseting Environment StartDay: 1101, ResetDay: 2781,Episode: 1581
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1297           |
|    time_elapsed         | 29366          |
|    total_timesteps      | 2656256        |
| train/                  |                |
|    approx_kl            | 1251.3611      |
|    clip_fraction        | 0.0687         |
|    clip_range           | 0.2            |
|    entropy_loss         | -176           |
|    explained_variance   | 0.124          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.76          |
|    n_updates            | 12960          |
|    policy_gradient_loss | -0.00273       |
|    reward               | -2.3247529e-05 |
|    std                  | 133            |
|    value_loss           | 1.99e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 411, ResetDay: 2091,Episode: 1582
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1298         |
|    time_elapsed         | 29388        |
|    total_timesteps      | 2658304      |
| train/                  |              |
|    approx_kl            | 1252.2627    |
|    clip_fraction        | 0.0821       |
|    clip_range           | 0.2          |
|    entropy_loss         | -176         |
|    explained_variance   | 0.116        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.77        |
|    n_updates            | 12970        |
|    policy_gradient_loss | -0.00407     |
|    reward               | 8.948011e-05 |
|    std                  | 134          |
|    value_loss           | 2.16e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2556, ResetDay: 4236,Episode: 1583
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1299           |
|    time_elapsed         | 29411          |
|    total_timesteps      | 2660352        |
| train/                  |                |
|    approx_kl            | 1262.6001      |
|    clip_fraction        | 0.0791         |
|    clip_range           | 0.2            |
|    entropy_loss         | -176           |
|    explained_variance   | -0.308         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.76          |
|    n_updates            | 12980          |
|    policy_gradient_loss | -0.00307       |
|    reward               | -0.00029681626 |
|    std                  | 134            |
|    value_loss           | 4.95e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1344, ResetDay: 3024,Episode: 1584
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1300          |
|    time_elapsed         | 29433         |
|    total_timesteps      | 2662400       |
| train/                  |               |
|    approx_kl            | 1259.7524     |
|    clip_fraction        | 0.0793        |
|    clip_range           | 0.2           |
|    entropy_loss         | -176          |
|    explained_variance   | 0.141         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.78         |
|    n_updates            | 12990         |
|    policy_gradient_loss | -0.000999     |
|    reward               | 0.00022611236 |
|    std                  | 134           |
|    value_loss           | 1.32e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2304, ResetDay: 3984,Episode: 1585
Environment reached Terminal state as number of trading days reached limit!!
day: 3984, episode: 1585
begin_total_asset: 200.00
end_total_asset: 342.33
total_reward: 142.33
total_cost: 9.79
total_trades: 40079
Sharpe: 0.441
=================================
Reseting Environment StartDay: 2548, ResetDay: 4228,Episode: 1586
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1301          |
|    time_elapsed         | 29456         |
|    total_timesteps      | 2664448       |
| train/                  |               |
|    approx_kl            | 1267.3792     |
|    clip_fraction        | 0.0856        |
|    clip_range           | 0.2           |
|    entropy_loss         | -176          |
|    explained_variance   | 0.0647        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.76         |
|    n_updates            | 13000         |
|    policy_gradient_loss | -0.00516      |
|    reward               | 0.00010417938 |
|    std                  | 134           |
|    value_loss           | 2.82e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 477, ResetDay: 2157,Episode: 1587
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1302           |
|    time_elapsed         | 29479          |
|    total_timesteps      | 2666496        |
| train/                  |                |
|    approx_kl            | 1261.9011      |
|    clip_fraction        | 0.0777         |
|    clip_range           | 0.2            |
|    entropy_loss         | -176           |
|    explained_variance   | 0.0876         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.74          |
|    n_updates            | 13010          |
|    policy_gradient_loss | -0.00289       |
|    reward               | -0.00026919722 |
|    std                  | 135            |
|    value_loss           | 1.06e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2188, ResetDay: 3868,Episode: 1588
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1303           |
|    time_elapsed         | 29501          |
|    total_timesteps      | 2668544        |
| train/                  |                |
|    approx_kl            | 1286.248       |
|    clip_fraction        | 0.0859         |
|    clip_range           | 0.2            |
|    entropy_loss         | -176           |
|    explained_variance   | -0.188         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.77          |
|    n_updates            | 13020          |
|    policy_gradient_loss | 0.00549        |
|    reward               | -0.00016441001 |
|    std                  | 136            |
|    value_loss           | 6.14e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1840, ResetDay: 3520,Episode: 1589
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1304           |
|    time_elapsed         | 29524          |
|    total_timesteps      | 2670592        |
| train/                  |                |
|    approx_kl            | 1293.5173      |
|    clip_fraction        | 0.0813         |
|    clip_range           | 0.2            |
|    entropy_loss         | -176           |
|    explained_variance   | -0.093         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.77          |
|    n_updates            | 13030          |
|    policy_gradient_loss | -0.00171       |
|    reward               | -0.00010462189 |
|    std                  | 136            |
|    value_loss           | 3.36e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 926, ResetDay: 2606,Episode: 1590
---------------------------------------------
| time/                   |                 |
|    fps                  | 90              |
|    iterations           | 1305            |
|    time_elapsed         | 29546           |
|    total_timesteps      | 2672640         |
| train/                  |                 |
|    approx_kl            | 1299.1954       |
|    clip_fraction        | 0.0776          |
|    clip_range           | 0.2             |
|    entropy_loss         | -176            |
|    explained_variance   | 0.137           |
|    learning_rate        | 0.00025         |
|    loss                 | -1.78           |
|    n_updates            | 13040           |
|    policy_gradient_loss | -0.00567        |
|    reward               | -0.000117727664 |
|    std                  | 136             |
|    value_loss           | 1.6e-06         |
---------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2606, episode: 1590
begin_total_asset: 200.00
end_total_asset: 81.90
total_reward: -118.10
total_cost: 13.09
total_trades: 39956
Sharpe: 0.032
=================================
Reseting Environment StartDay: 595, ResetDay: 2275,Episode: 1591
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2307, ResetDay: 3987,Episode: 1592
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1306           |
|    time_elapsed         | 29568          |
|    total_timesteps      | 2674688        |
| train/                  |                |
|    approx_kl            | 1317.5884      |
|    clip_fraction        | 0.0781         |
|    clip_range           | 0.2            |
|    entropy_loss         | -176           |
|    explained_variance   | -0.315         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.76          |
|    n_updates            | 13050          |
|    policy_gradient_loss | -0.00463       |
|    reward               | -4.6991347e-05 |
|    std                  | 136            |
|    value_loss           | 5.36e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2751, ResetDay: 4431,Episode: 1593
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1307         |
|    time_elapsed         | 29591        |
|    total_timesteps      | 2676736      |
| train/                  |              |
|    approx_kl            | 1309.7224    |
|    clip_fraction        | 0.0755       |
|    clip_range           | 0.2          |
|    entropy_loss         | -176         |
|    explained_variance   | 0.2          |
|    learning_rate        | 0.00025      |
|    loss                 | -1.77        |
|    n_updates            | 13060        |
|    policy_gradient_loss | -0.00142     |
|    reward               | 3.117218e-05 |
|    std                  | 136          |
|    value_loss           | 3.62e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 267, ResetDay: 1947,Episode: 1594
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1308         |
|    time_elapsed         | 29613        |
|    total_timesteps      | 2678784      |
| train/                  |              |
|    approx_kl            | 1313.5918    |
|    clip_fraction        | 0.0891       |
|    clip_range           | 0.2          |
|    entropy_loss         | -176         |
|    explained_variance   | 0.0716       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.79        |
|    n_updates            | 13070        |
|    policy_gradient_loss | -0.00616     |
|    reward               | 7.890072e-05 |
|    std                  | 136          |
|    value_loss           | 1.96e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 811, ResetDay: 2491,Episode: 1595
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1309         |
|    time_elapsed         | 29636        |
|    total_timesteps      | 2680832      |
| train/                  |              |
|    approx_kl            | 1310.1799    |
|    clip_fraction        | 0.0771       |
|    clip_range           | 0.2          |
|    entropy_loss         | -176         |
|    explained_variance   | -0.467       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.78        |
|    n_updates            | 13080        |
|    policy_gradient_loss | 0.00194      |
|    reward               | 3.564606e-05 |
|    std                  | 137          |
|    value_loss           | 9.02e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2491, episode: 1595
begin_total_asset: 200.00
end_total_asset: 191.12
total_reward: -8.88
total_cost: 31.57
total_trades: 40227
Sharpe: 0.147
=================================
Reseting Environment StartDay: 1584, ResetDay: 3264,Episode: 1596
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 100, ResetDay: 1780,Episode: 1597
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1310         |
|    time_elapsed         | 29658        |
|    total_timesteps      | 2682880      |
| train/                  |              |
|    approx_kl            | 1306.396     |
|    clip_fraction        | 0.0803       |
|    clip_range           | 0.2          |
|    entropy_loss         | -177         |
|    explained_variance   | 0.254        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.78        |
|    n_updates            | 13090        |
|    policy_gradient_loss | -0.000732    |
|    reward               | 6.167295e-05 |
|    std                  | 137          |
|    value_loss           | 4.27e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 602, ResetDay: 2282,Episode: 1598
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1311          |
|    time_elapsed         | 29681         |
|    total_timesteps      | 2684928       |
| train/                  |               |
|    approx_kl            | 1321.3289     |
|    clip_fraction        | 0.0753        |
|    clip_range           | 0.2           |
|    entropy_loss         | -177          |
|    explained_variance   | -0.0122       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.79         |
|    n_updates            | 13100         |
|    policy_gradient_loss | -0.00167      |
|    reward               | 1.1570692e-05 |
|    std                  | 138           |
|    value_loss           | 7.55e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2164, ResetDay: 3844,Episode: 1599
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1312          |
|    time_elapsed         | 29703         |
|    total_timesteps      | 2686976       |
| train/                  |               |
|    approx_kl            | 1324.9379     |
|    clip_fraction        | 0.0725        |
|    clip_range           | 0.2           |
|    entropy_loss         | -177          |
|    explained_variance   | 0.142         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.77         |
|    n_updates            | 13110         |
|    policy_gradient_loss | 0.00313       |
|    reward               | 4.6250723e-05 |
|    std                  | 138           |
|    value_loss           | 6.64e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 870, ResetDay: 2550,Episode: 1600
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1313         |
|    time_elapsed         | 29726        |
|    total_timesteps      | 2689024      |
| train/                  |              |
|    approx_kl            | 1330.7952    |
|    clip_fraction        | 0.076        |
|    clip_range           | 0.2          |
|    entropy_loss         | -177         |
|    explained_variance   | 0.189        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.74        |
|    n_updates            | 13120        |
|    policy_gradient_loss | 0.00383      |
|    reward               | 9.511423e-05 |
|    std                  | 139          |
|    value_loss           | 4.85e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2550, episode: 1600
begin_total_asset: 200.00
end_total_asset: 126.08
total_reward: -73.92
total_cost: 23.26
total_trades: 39954
Sharpe: -0.006
=================================
Reseting Environment StartDay: 2621, ResetDay: 4301,Episode: 1601
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1314          |
|    time_elapsed         | 29749         |
|    total_timesteps      | 2691072       |
| train/                  |               |
|    approx_kl            | 1344.449      |
|    clip_fraction        | 0.0754        |
|    clip_range           | 0.2           |
|    entropy_loss         | -177          |
|    explained_variance   | 0.149         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.78         |
|    n_updates            | 13130         |
|    policy_gradient_loss | 7.38e-05      |
|    reward               | -0.0003745266 |
|    std                  | 139           |
|    value_loss           | 1.92e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 846, ResetDay: 2526,Episode: 1602
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 445, ResetDay: 2125,Episode: 1603
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1315           |
|    time_elapsed         | 29772          |
|    total_timesteps      | 2693120        |
| train/                  |                |
|    approx_kl            | 1360.8438      |
|    clip_fraction        | 0.0675         |
|    clip_range           | 0.2            |
|    entropy_loss         | -177           |
|    explained_variance   | 0.168          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.78          |
|    n_updates            | 13140          |
|    policy_gradient_loss | -0.00131       |
|    reward               | -8.1411345e-05 |
|    std                  | 140            |
|    value_loss           | 1.18e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 145, ResetDay: 1825,Episode: 1604
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1316         |
|    time_elapsed         | 29794        |
|    total_timesteps      | 2695168      |
| train/                  |              |
|    approx_kl            | 1367.169     |
|    clip_fraction        | 0.0712       |
|    clip_range           | 0.2          |
|    entropy_loss         | -177         |
|    explained_variance   | -0.26        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.77        |
|    n_updates            | 13150        |
|    policy_gradient_loss | 0.00921      |
|    reward               | 0.0004998253 |
|    std                  | 140          |
|    value_loss           | 5.7e-07      |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 429, ResetDay: 2109,Episode: 1605
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1317           |
|    time_elapsed         | 29817          |
|    total_timesteps      | 2697216        |
| train/                  |                |
|    approx_kl            | 1370.06        |
|    clip_fraction        | 0.069          |
|    clip_range           | 0.2            |
|    entropy_loss         | -177           |
|    explained_variance   | 0.242          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.78          |
|    n_updates            | 13160          |
|    policy_gradient_loss | 0.00342        |
|    reward               | -0.00028623798 |
|    std                  | 140            |
|    value_loss           | 5.17e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2109, episode: 1605
begin_total_asset: 200.00
end_total_asset: 203.91
total_reward: 3.91
total_cost: 51.67
total_trades: 39978
Sharpe: 0.190
=================================
Reseting Environment StartDay: 1051, ResetDay: 2731,Episode: 1606
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1318         |
|    time_elapsed         | 29839        |
|    total_timesteps      | 2699264      |
| train/                  |              |
|    approx_kl            | 1382.4463    |
|    clip_fraction        | 0.0721       |
|    clip_range           | 0.2          |
|    entropy_loss         | -177         |
|    explained_variance   | 0.383        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.77        |
|    n_updates            | 13170        |
|    policy_gradient_loss | -0.00171     |
|    reward               | 0.0001368536 |
|    std                  | 141          |
|    value_loss           | 8.85e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1401, ResetDay: 3081,Episode: 1607
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1319          |
|    time_elapsed         | 29863         |
|    total_timesteps      | 2701312       |
| train/                  |               |
|    approx_kl            | 1383.1166     |
|    clip_fraction        | 0.0684        |
|    clip_range           | 0.2           |
|    entropy_loss         | -177          |
|    explained_variance   | 0.214         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.78         |
|    n_updates            | 13180         |
|    policy_gradient_loss | -0.00424      |
|    reward               | 1.7070237e-06 |
|    std                  | 141           |
|    value_loss           | 5.03e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2439, ResetDay: 4119,Episode: 1608
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1652, ResetDay: 3332,Episode: 1609
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1320          |
|    time_elapsed         | 29886         |
|    total_timesteps      | 2703360       |
| train/                  |               |
|    approx_kl            | 1388.0421     |
|    clip_fraction        | 0.0609        |
|    clip_range           | 0.2           |
|    entropy_loss         | -177          |
|    explained_variance   | 0.227         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.76         |
|    n_updates            | 13190         |
|    policy_gradient_loss | 0.00315       |
|    reward               | 2.5606156e-05 |
|    std                  | 141           |
|    value_loss           | 4.45e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2460, ResetDay: 4140,Episode: 1610
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1321          |
|    time_elapsed         | 29908         |
|    total_timesteps      | 2705408       |
| train/                  |               |
|    approx_kl            | 1396.5059     |
|    clip_fraction        | 0.0745        |
|    clip_range           | 0.2           |
|    entropy_loss         | -177          |
|    explained_variance   | 0.0963        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.78         |
|    n_updates            | 13200         |
|    policy_gradient_loss | -0.00243      |
|    reward               | -1.774807e-05 |
|    std                  | 142           |
|    value_loss           | 1.26e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4140, episode: 1610
begin_total_asset: 200.00
end_total_asset: 356.19
total_reward: 156.19
total_cost: 30.37
total_trades: 39424
Sharpe: 0.477
=================================
Reseting Environment StartDay: 718, ResetDay: 2398,Episode: 1611
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1322         |
|    time_elapsed         | 29931        |
|    total_timesteps      | 2707456      |
| train/                  |              |
|    approx_kl            | 1398.2864    |
|    clip_fraction        | 0.0662       |
|    clip_range           | 0.2          |
|    entropy_loss         | -178         |
|    explained_variance   | 0.0315       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.77        |
|    n_updates            | 13210        |
|    policy_gradient_loss | -0.00038     |
|    reward               | 8.577347e-06 |
|    std                  | 142          |
|    value_loss           | 3.65e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2609, ResetDay: 4289,Episode: 1612
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1323           |
|    time_elapsed         | 29953          |
|    total_timesteps      | 2709504        |
| train/                  |                |
|    approx_kl            | 1418.3522      |
|    clip_fraction        | 0.0666         |
|    clip_range           | 0.2            |
|    entropy_loss         | -178           |
|    explained_variance   | 0.0437         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.77          |
|    n_updates            | 13220          |
|    policy_gradient_loss | -0.00148       |
|    reward               | -0.00030522767 |
|    std                  | 142            |
|    value_loss           | 1.03e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1298, ResetDay: 2978,Episode: 1613
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1814, ResetDay: 3494,Episode: 1614
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1324         |
|    time_elapsed         | 29976        |
|    total_timesteps      | 2711552      |
| train/                  |              |
|    approx_kl            | 1408.0425    |
|    clip_fraction        | 0.0567       |
|    clip_range           | 0.2          |
|    entropy_loss         | -178         |
|    explained_variance   | 0.153        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.79        |
|    n_updates            | 13230        |
|    policy_gradient_loss | 0.00138      |
|    reward               | 3.994541e-05 |
|    std                  | 143          |
|    value_loss           | 2.06e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1599, ResetDay: 3279,Episode: 1615
---------------------------------------------
| time/                   |                 |
|    fps                  | 90              |
|    iterations           | 1325            |
|    time_elapsed         | 29998           |
|    total_timesteps      | 2713600         |
| train/                  |                 |
|    approx_kl            | 1428.4692       |
|    clip_fraction        | 0.0681          |
|    clip_range           | 0.2             |
|    entropy_loss         | -178            |
|    explained_variance   | -0.355          |
|    learning_rate        | 0.00025         |
|    loss                 | -1.8            |
|    n_updates            | 13240           |
|    policy_gradient_loss | -0.00184        |
|    reward               | -0.000115054325 |
|    std                  | 143             |
|    value_loss           | 6.16e-07        |
---------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3279, episode: 1615
begin_total_asset: 200.00
end_total_asset: 221.64
total_reward: 21.64
total_cost: 13.79
total_trades: 39431
Sharpe: 0.293
=================================
Reseting Environment StartDay: 638, ResetDay: 2318,Episode: 1616
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1326          |
|    time_elapsed         | 30021         |
|    total_timesteps      | 2715648       |
| train/                  |               |
|    approx_kl            | 1423.5209     |
|    clip_fraction        | 0.0677        |
|    clip_range           | 0.2           |
|    entropy_loss         | -178          |
|    explained_variance   | 0.052         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.78         |
|    n_updates            | 13250         |
|    policy_gradient_loss | -0.00132      |
|    reward               | 3.1704996e-05 |
|    std                  | 143           |
|    value_loss           | 8.35e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1639, ResetDay: 3319,Episode: 1617
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1327          |
|    time_elapsed         | 30044         |
|    total_timesteps      | 2717696       |
| train/                  |               |
|    approx_kl            | 1424.4812     |
|    clip_fraction        | 0.069         |
|    clip_range           | 0.2           |
|    entropy_loss         | -178          |
|    explained_variance   | 0.072         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.78         |
|    n_updates            | 13260         |
|    policy_gradient_loss | -0.000727     |
|    reward               | 0.00011758118 |
|    std                  | 144           |
|    value_loss           | 3.81e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1601, ResetDay: 3281,Episode: 1618
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1328           |
|    time_elapsed         | 30067          |
|    total_timesteps      | 2719744        |
| train/                  |                |
|    approx_kl            | 1437.8625      |
|    clip_fraction        | 0.0615         |
|    clip_range           | 0.2            |
|    entropy_loss         | -178           |
|    explained_variance   | 0.0878         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.79          |
|    n_updates            | 13270          |
|    policy_gradient_loss | -0.00148       |
|    reward               | -0.00016627598 |
|    std                  | 144            |
|    value_loss           | 2.86e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2562, ResetDay: 4242,Episode: 1619
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 408, ResetDay: 2088,Episode: 1620
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1329           |
|    time_elapsed         | 30089          |
|    total_timesteps      | 2721792        |
| train/                  |                |
|    approx_kl            | 1458.3663      |
|    clip_fraction        | 0.0641         |
|    clip_range           | 0.2            |
|    entropy_loss         | -178           |
|    explained_variance   | 0.172          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.78          |
|    n_updates            | 13280          |
|    policy_gradient_loss | -0.0051        |
|    reward               | -0.00018278164 |
|    std                  | 144            |
|    value_loss           | 4.37e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2088, episode: 1620
begin_total_asset: 200.00
end_total_asset: 134.51
total_reward: -65.49
total_cost: 40.60
total_trades: 39620
Sharpe: 0.111
=================================
Reseting Environment StartDay: 989, ResetDay: 2669,Episode: 1621
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1330          |
|    time_elapsed         | 30112         |
|    total_timesteps      | 2723840       |
| train/                  |               |
|    approx_kl            | 1447.959      |
|    clip_fraction        | 0.0748        |
|    clip_range           | 0.2           |
|    entropy_loss         | -178          |
|    explained_variance   | 0.0844        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.79         |
|    n_updates            | 13290         |
|    policy_gradient_loss | 0.001         |
|    reward               | 4.4709206e-05 |
|    std                  | 145           |
|    value_loss           | 1.43e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2183, ResetDay: 3863,Episode: 1622
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1331         |
|    time_elapsed         | 30134        |
|    total_timesteps      | 2725888      |
| train/                  |              |
|    approx_kl            | 1456.8572    |
|    clip_fraction        | 0.0604       |
|    clip_range           | 0.2          |
|    entropy_loss         | -178         |
|    explained_variance   | -0.0656      |
|    learning_rate        | 0.00025      |
|    loss                 | -1.78        |
|    n_updates            | 13300        |
|    policy_gradient_loss | -0.000818    |
|    reward               | 0.0004408388 |
|    std                  | 145          |
|    value_loss           | 5.88e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2713, ResetDay: 4393,Episode: 1623
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1332         |
|    time_elapsed         | 30157        |
|    total_timesteps      | 2727936      |
| train/                  |              |
|    approx_kl            | 1462.606     |
|    clip_fraction        | 0.0637       |
|    clip_range           | 0.2          |
|    entropy_loss         | -178         |
|    explained_variance   | 0.218        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.79        |
|    n_updates            | 13310        |
|    policy_gradient_loss | 0.00416      |
|    reward               | 4.743576e-06 |
|    std                  | 146          |
|    value_loss           | 4.52e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1911, ResetDay: 3591,Episode: 1624
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 531, ResetDay: 2211,Episode: 1625
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1333          |
|    time_elapsed         | 30179         |
|    total_timesteps      | 2729984       |
| train/                  |               |
|    approx_kl            | 1485.9214     |
|    clip_fraction        | 0.0631        |
|    clip_range           | 0.2           |
|    entropy_loss         | -178          |
|    explained_variance   | 0.0967        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.78         |
|    n_updates            | 13320         |
|    policy_gradient_loss | 0.00763       |
|    reward               | -7.961846e-06 |
|    std                  | 146           |
|    value_loss           | 2.44e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2211, episode: 1625
begin_total_asset: 200.00
end_total_asset: 83.72
total_reward: -116.28
total_cost: 50.20
total_trades: 39609
Sharpe: -0.118
=================================
Reseting Environment StartDay: 1954, ResetDay: 3634,Episode: 1626
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1334          |
|    time_elapsed         | 30201         |
|    total_timesteps      | 2732032       |
| train/                  |               |
|    approx_kl            | 1478.1843     |
|    clip_fraction        | 0.0705        |
|    clip_range           | 0.2           |
|    entropy_loss         | -178          |
|    explained_variance   | -0.522        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.78         |
|    n_updates            | 13330         |
|    policy_gradient_loss | 0.0018        |
|    reward               | 0.00013789558 |
|    std                  | 146           |
|    value_loss           | 7.29e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2678, ResetDay: 4358,Episode: 1627
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1335           |
|    time_elapsed         | 30224          |
|    total_timesteps      | 2734080        |
| train/                  |                |
|    approx_kl            | 1490.8586      |
|    clip_fraction        | 0.0722         |
|    clip_range           | 0.2            |
|    entropy_loss         | -178           |
|    explained_variance   | -0.0323        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.61          |
|    n_updates            | 13340          |
|    policy_gradient_loss | 0.00834        |
|    reward               | -0.00071167754 |
|    std                  | 147            |
|    value_loss           | 3.25e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2044, ResetDay: 3724,Episode: 1628
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1336          |
|    time_elapsed         | 30246         |
|    total_timesteps      | 2736128       |
| train/                  |               |
|    approx_kl            | 1496.5759     |
|    clip_fraction        | 0.0598        |
|    clip_range           | 0.2           |
|    entropy_loss         | -178          |
|    explained_variance   | 0.0615        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.78         |
|    n_updates            | 13350         |
|    policy_gradient_loss | -0.00333      |
|    reward               | -6.821671e-05 |
|    std                  | 147           |
|    value_loss           | 9.63e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2534, ResetDay: 4214,Episode: 1629
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1337           |
|    time_elapsed         | 30269          |
|    total_timesteps      | 2738176        |
| train/                  |                |
|    approx_kl            | 1505.306       |
|    clip_fraction        | 0.0625         |
|    clip_range           | 0.2            |
|    entropy_loss         | -178           |
|    explained_variance   | 0.0223         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.78          |
|    n_updates            | 13360          |
|    policy_gradient_loss | 0.00756        |
|    reward               | -0.00024479142 |
|    std                  | 147            |
|    value_loss           | 9.72e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2621, ResetDay: 4301,Episode: 1630
Environment reached Terminal state as number of trading days reached limit!!
day: 4301, episode: 1630
begin_total_asset: 200.00
end_total_asset: 263.73
total_reward: 63.73
total_cost: 39.68
total_trades: 39304
Sharpe: 0.296
=================================
Reseting Environment StartDay: 82, ResetDay: 1762,Episode: 1631
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1338          |
|    time_elapsed         | 30292         |
|    total_timesteps      | 2740224       |
| train/                  |               |
|    approx_kl            | 1495.007      |
|    clip_fraction        | 0.0656        |
|    clip_range           | 0.2           |
|    entropy_loss         | -179          |
|    explained_variance   | 0.18          |
|    learning_rate        | 0.00025       |
|    loss                 | -1.81         |
|    n_updates            | 13370         |
|    policy_gradient_loss | 0.000864      |
|    reward               | 1.3863398e-05 |
|    std                  | 148           |
|    value_loss           | 9.27e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 811, ResetDay: 2491,Episode: 1632
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1339         |
|    time_elapsed         | 30314        |
|    total_timesteps      | 2742272      |
| train/                  |              |
|    approx_kl            | 1519.1879    |
|    clip_fraction        | 0.0566       |
|    clip_range           | 0.2          |
|    entropy_loss         | -179         |
|    explained_variance   | 0.0818       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.79        |
|    n_updates            | 13380        |
|    policy_gradient_loss | -0.000189    |
|    reward               | 0.0003036292 |
|    std                  | 148          |
|    value_loss           | 1.04e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 203, ResetDay: 1883,Episode: 1633
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1340          |
|    time_elapsed         | 30336         |
|    total_timesteps      | 2744320       |
| train/                  |               |
|    approx_kl            | 1537.9922     |
|    clip_fraction        | 0.0635        |
|    clip_range           | 0.2           |
|    entropy_loss         | -179          |
|    explained_variance   | 0.0421        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.79         |
|    n_updates            | 13390         |
|    policy_gradient_loss | -0.00317      |
|    reward               | 0.00049336045 |
|    std                  | 148           |
|    value_loss           | 8.73e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 932, ResetDay: 2612,Episode: 1634
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1341         |
|    time_elapsed         | 30359        |
|    total_timesteps      | 2746368      |
| train/                  |              |
|    approx_kl            | 1543.961     |
|    clip_fraction        | 0.0659       |
|    clip_range           | 0.2          |
|    entropy_loss         | -179         |
|    explained_variance   | 0.257        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.81        |
|    n_updates            | 13400        |
|    policy_gradient_loss | -0.00277     |
|    reward               | 9.498749e-05 |
|    std                  | 149          |
|    value_loss           | 6.02e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 267, ResetDay: 1947,Episode: 1635
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1342           |
|    time_elapsed         | 30382          |
|    total_timesteps      | 2748416        |
| train/                  |                |
|    approx_kl            | 1536.0049      |
|    clip_fraction        | 0.0554         |
|    clip_range           | 0.2            |
|    entropy_loss         | -179           |
|    explained_variance   | 0.219          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.79          |
|    n_updates            | 13410          |
|    policy_gradient_loss | -0.000346      |
|    reward               | -0.00010462303 |
|    std                  | 150            |
|    value_loss           | 4.8e-07        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 1947, episode: 1635
begin_total_asset: 200.00
end_total_asset: 172.81
total_reward: -27.19
total_cost: 52.51
total_trades: 39471
Sharpe: 0.162
=================================
Reseting Environment StartDay: 81, ResetDay: 1761,Episode: 1636
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1529, ResetDay: 3209,Episode: 1637
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1343          |
|    time_elapsed         | 30404         |
|    total_timesteps      | 2750464       |
| train/                  |               |
|    approx_kl            | 1568.2102     |
|    clip_fraction        | 0.0606        |
|    clip_range           | 0.2           |
|    entropy_loss         | -179          |
|    explained_variance   | 0.32          |
|    learning_rate        | 0.00025       |
|    loss                 | -1.79         |
|    n_updates            | 13420         |
|    policy_gradient_loss | -0.00169      |
|    reward               | 4.0369414e-05 |
|    std                  | 150           |
|    value_loss           | 8.75e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 875, ResetDay: 2555,Episode: 1638
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1344          |
|    time_elapsed         | 30427         |
|    total_timesteps      | 2752512       |
| train/                  |               |
|    approx_kl            | 1555.5039     |
|    clip_fraction        | 0.0656        |
|    clip_range           | 0.2           |
|    entropy_loss         | -179          |
|    explained_variance   | 0.279         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.79         |
|    n_updates            | 13430         |
|    policy_gradient_loss | -0.00104      |
|    reward               | -6.386852e-05 |
|    std                  | 150           |
|    value_loss           | 1.92e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 624, ResetDay: 2304,Episode: 1639
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1345          |
|    time_elapsed         | 30450         |
|    total_timesteps      | 2754560       |
| train/                  |               |
|    approx_kl            | 1576.9047     |
|    clip_fraction        | 0.0667        |
|    clip_range           | 0.2           |
|    entropy_loss         | -179          |
|    explained_variance   | -0.00559      |
|    learning_rate        | 0.00025       |
|    loss                 | -1.81         |
|    n_updates            | 13440         |
|    policy_gradient_loss | -0.00882      |
|    reward               | 3.4312437e-05 |
|    std                  | 151           |
|    value_loss           | 9.77e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1283, ResetDay: 2963,Episode: 1640
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1346          |
|    time_elapsed         | 30473         |
|    total_timesteps      | 2756608       |
| train/                  |               |
|    approx_kl            | 1586.2227     |
|    clip_fraction        | 0.0645        |
|    clip_range           | 0.2           |
|    entropy_loss         | -179          |
|    explained_variance   | 0.059         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.79         |
|    n_updates            | 13450         |
|    policy_gradient_loss | -0.00112      |
|    reward               | 1.9244384e-05 |
|    std                  | 151           |
|    value_loss           | 2.91e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2963, episode: 1640
begin_total_asset: 200.00
end_total_asset: 150.62
total_reward: -49.38
total_cost: 20.94
total_trades: 39190
Sharpe: 0.045
=================================
Reseting Environment StartDay: 647, ResetDay: 2327,Episode: 1641
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2209, ResetDay: 3889,Episode: 1642
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1347          |
|    time_elapsed         | 30495         |
|    total_timesteps      | 2758656       |
| train/                  |               |
|    approx_kl            | 1592.9264     |
|    clip_fraction        | 0.0591        |
|    clip_range           | 0.2           |
|    entropy_loss         | -179          |
|    explained_variance   | 0.203         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.78         |
|    n_updates            | 13460         |
|    policy_gradient_loss | -0.00186      |
|    reward               | 0.00011491966 |
|    std                  | 152           |
|    value_loss           | 2.77e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2274, ResetDay: 3954,Episode: 1643
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1348         |
|    time_elapsed         | 30518        |
|    total_timesteps      | 2760704      |
| train/                  |              |
|    approx_kl            | 1613.8739    |
|    clip_fraction        | 0.0602       |
|    clip_range           | 0.2          |
|    entropy_loss         | -179         |
|    explained_variance   | 0.21         |
|    learning_rate        | 0.00025      |
|    loss                 | -1.8         |
|    n_updates            | 13470        |
|    policy_gradient_loss | 0.00775      |
|    reward               | 9.709168e-06 |
|    std                  | 152          |
|    value_loss           | 3.8e-07      |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2251, ResetDay: 3931,Episode: 1644
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1349          |
|    time_elapsed         | 30540         |
|    total_timesteps      | 2762752       |
| train/                  |               |
|    approx_kl            | 1609.0925     |
|    clip_fraction        | 0.0618        |
|    clip_range           | 0.2           |
|    entropy_loss         | -179          |
|    explained_variance   | 0.0979        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.79         |
|    n_updates            | 13480         |
|    policy_gradient_loss | -0.00188      |
|    reward               | 0.00034914416 |
|    std                  | 152           |
|    value_loss           | 2.33e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 836, ResetDay: 2516,Episode: 1645
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1350           |
|    time_elapsed         | 30563          |
|    total_timesteps      | 2764800        |
| train/                  |                |
|    approx_kl            | 1610.7725      |
|    clip_fraction        | 0.0619         |
|    clip_range           | 0.2            |
|    entropy_loss         | -179           |
|    explained_variance   | 0.216          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.79          |
|    n_updates            | 13490          |
|    policy_gradient_loss | 0.00291        |
|    reward               | -1.4752197e-05 |
|    std                  | 152            |
|    value_loss           | 6.91e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2516, episode: 1645
begin_total_asset: 200.00
end_total_asset: 87.03
total_reward: -112.97
total_cost: 19.68
total_trades: 39288
Sharpe: -0.088
=================================
Reseting Environment StartDay: 442, ResetDay: 2122,Episode: 1646
-----------------------------------------
| time/                   |             |
|    fps                  | 90          |
|    iterations           | 1351        |
|    time_elapsed         | 30585       |
|    total_timesteps      | 2766848     |
| train/                  |             |
|    approx_kl            | 1613.5002   |
|    clip_fraction        | 0.0579      |
|    clip_range           | 0.2         |
|    entropy_loss         | -179        |
|    explained_variance   | 0.0708      |
|    learning_rate        | 0.00025     |
|    loss                 | -1.81       |
|    n_updates            | 13500       |
|    policy_gradient_loss | 0.00109     |
|    reward               | 0.000790638 |
|    std                  | 152         |
|    value_loss           | 1.16e-06    |
-----------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 957, ResetDay: 2637,Episode: 1647
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 182, ResetDay: 1862,Episode: 1648
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1352           |
|    time_elapsed         | 30608          |
|    total_timesteps      | 2768896        |
| train/                  |                |
|    approx_kl            | 1600.5701      |
|    clip_fraction        | 0.0578         |
|    clip_range           | 0.2            |
|    entropy_loss         | -180           |
|    explained_variance   | -0.349         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.79          |
|    n_updates            | 13510          |
|    policy_gradient_loss | -0.00364       |
|    reward               | 0.000110244844 |
|    std                  | 153            |
|    value_loss           | 5.02e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 22, ResetDay: 1702,Episode: 1649
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1353          |
|    time_elapsed         | 30630         |
|    total_timesteps      | 2770944       |
| train/                  |               |
|    approx_kl            | 1627.531      |
|    clip_fraction        | 0.0504        |
|    clip_range           | 0.2           |
|    entropy_loss         | -180          |
|    explained_variance   | 0.228         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.8          |
|    n_updates            | 13520         |
|    policy_gradient_loss | 0.000612      |
|    reward               | 1.5630912e-05 |
|    std                  | 153           |
|    value_loss           | 6.27e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2227, ResetDay: 3907,Episode: 1650
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1354           |
|    time_elapsed         | 30653          |
|    total_timesteps      | 2772992        |
| train/                  |                |
|    approx_kl            | 1639.3514      |
|    clip_fraction        | 0.0524         |
|    clip_range           | 0.2            |
|    entropy_loss         | -180           |
|    explained_variance   | 0.194          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.79          |
|    n_updates            | 13530          |
|    policy_gradient_loss | -0.000858      |
|    reward               | -0.00044670104 |
|    std                  | 153            |
|    value_loss           | 1.23e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3907, episode: 1650
begin_total_asset: 200.00
end_total_asset: 737.70
total_reward: 537.70
total_cost: 48.82
total_trades: 38969
Sharpe: 0.682
=================================
Reseting Environment StartDay: 579, ResetDay: 2259,Episode: 1651
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1355          |
|    time_elapsed         | 30676         |
|    total_timesteps      | 2775040       |
| train/                  |               |
|    approx_kl            | 1630.7224     |
|    clip_fraction        | 0.0667        |
|    clip_range           | 0.2           |
|    entropy_loss         | -180          |
|    explained_variance   | 0.183         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.78         |
|    n_updates            | 13540         |
|    policy_gradient_loss | -0.00576      |
|    reward               | -1.975193e-05 |
|    std                  | 154           |
|    value_loss           | 3.78e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1685, ResetDay: 3365,Episode: 1652
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2430, ResetDay: 4110,Episode: 1653
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1356           |
|    time_elapsed         | 30698          |
|    total_timesteps      | 2777088        |
| train/                  |                |
|    approx_kl            | 1656.3013      |
|    clip_fraction        | 0.0631         |
|    clip_range           | 0.2            |
|    entropy_loss         | -180           |
|    explained_variance   | 0.0845         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.81          |
|    n_updates            | 13550          |
|    policy_gradient_loss | -0.00401       |
|    reward               | -8.1617356e-05 |
|    std                  | 154            |
|    value_loss           | 5.83e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 745, ResetDay: 2425,Episode: 1654
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1357           |
|    time_elapsed         | 30721          |
|    total_timesteps      | 2779136        |
| train/                  |                |
|    approx_kl            | 1649.3083      |
|    clip_fraction        | 0.0519         |
|    clip_range           | 0.2            |
|    entropy_loss         | -180           |
|    explained_variance   | -0.689         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.8           |
|    n_updates            | 13560          |
|    policy_gradient_loss | -0.00144       |
|    reward               | -7.6085664e-05 |
|    std                  | 154            |
|    value_loss           | 5.18e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1616, ResetDay: 3296,Episode: 1655
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1358          |
|    time_elapsed         | 30743         |
|    total_timesteps      | 2781184       |
| train/                  |               |
|    approx_kl            | 1641.8218     |
|    clip_fraction        | 0.0579        |
|    clip_range           | 0.2           |
|    entropy_loss         | -180          |
|    explained_variance   | 0.163         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.81         |
|    n_updates            | 13570         |
|    policy_gradient_loss | -0.00288      |
|    reward               | 0.00011354351 |
|    std                  | 155           |
|    value_loss           | 2.01e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3296, episode: 1655
begin_total_asset: 200.00
end_total_asset: 350.28
total_reward: 150.28
total_cost: 19.89
total_trades: 38803
Sharpe: 0.465
=================================
Reseting Environment StartDay: 895, ResetDay: 2575,Episode: 1656
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1359           |
|    time_elapsed         | 30766          |
|    total_timesteps      | 2783232        |
| train/                  |                |
|    approx_kl            | 1666.5472      |
|    clip_fraction        | 0.0539         |
|    clip_range           | 0.2            |
|    entropy_loss         | -180           |
|    explained_variance   | -0.0409        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.8           |
|    n_updates            | 13580          |
|    policy_gradient_loss | -0.000928      |
|    reward               | -2.2128295e-05 |
|    std                  | 155            |
|    value_loss           | 2.81e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1749, ResetDay: 3429,Episode: 1657
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1360         |
|    time_elapsed         | 30788        |
|    total_timesteps      | 2785280      |
| train/                  |              |
|    approx_kl            | 1672.5427    |
|    clip_fraction        | 0.0541       |
|    clip_range           | 0.2          |
|    entropy_loss         | -180         |
|    explained_variance   | 0.191        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.82        |
|    n_updates            | 13590        |
|    policy_gradient_loss | -0.00436     |
|    reward               | 0.0002495868 |
|    std                  | 155          |
|    value_loss           | 4.7e-07      |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 949, ResetDay: 2629,Episode: 1658
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2071, ResetDay: 3751,Episode: 1659
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1361           |
|    time_elapsed         | 30810          |
|    total_timesteps      | 2787328        |
| train/                  |                |
|    approx_kl            | 1664.7246      |
|    clip_fraction        | 0.0553         |
|    clip_range           | 0.2            |
|    entropy_loss         | -180           |
|    explained_variance   | 0.263          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.81          |
|    n_updates            | 13600          |
|    policy_gradient_loss | -0.0054        |
|    reward               | -6.8424226e-05 |
|    std                  | 156            |
|    value_loss           | 4.06e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 245, ResetDay: 1925,Episode: 1660
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1362          |
|    time_elapsed         | 30833         |
|    total_timesteps      | 2789376       |
| train/                  |               |
|    approx_kl            | 1693.9836     |
|    clip_fraction        | 0.063         |
|    clip_range           | 0.2           |
|    entropy_loss         | -180          |
|    explained_variance   | 0.0175        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.81         |
|    n_updates            | 13610         |
|    policy_gradient_loss | -0.0039       |
|    reward               | 0.00033755263 |
|    std                  | 156           |
|    value_loss           | 3.79e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 1925, episode: 1660
begin_total_asset: 200.00
end_total_asset: 68.17
total_reward: -131.83
total_cost: 47.30
total_trades: 39120
Sharpe: -0.109
=================================
Reseting Environment StartDay: 1880, ResetDay: 3560,Episode: 1661
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1363          |
|    time_elapsed         | 30855         |
|    total_timesteps      | 2791424       |
| train/                  |               |
|    approx_kl            | 1698.6216     |
|    clip_fraction        | 0.0504        |
|    clip_range           | 0.2           |
|    entropy_loss         | -180          |
|    explained_variance   | 0.0821        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.8          |
|    n_updates            | 13620         |
|    policy_gradient_loss | -0.00261      |
|    reward               | 1.0607529e-05 |
|    std                  | 157           |
|    value_loss           | 1.23e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1495, ResetDay: 3175,Episode: 1662
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1364           |
|    time_elapsed         | 30878          |
|    total_timesteps      | 2793472        |
| train/                  |                |
|    approx_kl            | 1708.8684      |
|    clip_fraction        | 0.0585         |
|    clip_range           | 0.2            |
|    entropy_loss         | -180           |
|    explained_variance   | 0.133          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.81          |
|    n_updates            | 13630          |
|    policy_gradient_loss | -0.0057        |
|    reward               | -2.4274063e-05 |
|    std                  | 157            |
|    value_loss           | 6.19e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 486, ResetDay: 2166,Episode: 1663
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 28, ResetDay: 1708,Episode: 1664
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1365          |
|    time_elapsed         | 30900         |
|    total_timesteps      | 2795520       |
| train/                  |               |
|    approx_kl            | 1697.8474     |
|    clip_fraction        | 0.0547        |
|    clip_range           | 0.2           |
|    entropy_loss         | -180          |
|    explained_variance   | 0.0842        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.8          |
|    n_updates            | 13640         |
|    policy_gradient_loss | 0.000171      |
|    reward               | -7.005301e-05 |
|    std                  | 157           |
|    value_loss           | 1.31e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1930, ResetDay: 3610,Episode: 1665
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1366          |
|    time_elapsed         | 30923         |
|    total_timesteps      | 2797568       |
| train/                  |               |
|    approx_kl            | 1713.1646     |
|    clip_fraction        | 0.0537        |
|    clip_range           | 0.2           |
|    entropy_loss         | -180          |
|    explained_variance   | 0.0917        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.8          |
|    n_updates            | 13650         |
|    policy_gradient_loss | -0.00102      |
|    reward               | 4.2575073e-05 |
|    std                  | 158           |
|    value_loss           | 6.94e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3610, episode: 1665
begin_total_asset: 200.00
end_total_asset: 641.33
total_reward: 441.33
total_cost: 37.65
total_trades: 38578
Sharpe: 0.908
=================================
Reseting Environment StartDay: 2685, ResetDay: 4365,Episode: 1666
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1367         |
|    time_elapsed         | 30946        |
|    total_timesteps      | 2799616      |
| train/                  |              |
|    approx_kl            | 1704.6333    |
|    clip_fraction        | 0.049        |
|    clip_range           | 0.2          |
|    entropy_loss         | -181         |
|    explained_variance   | 0.198        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.82        |
|    n_updates            | 13660        |
|    policy_gradient_loss | 0.00203      |
|    reward               | 6.310033e-05 |
|    std                  | 158          |
|    value_loss           | 2.73e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1454, ResetDay: 3134,Episode: 1667
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1368           |
|    time_elapsed         | 30968          |
|    total_timesteps      | 2801664        |
| train/                  |                |
|    approx_kl            | 1749.5222      |
|    clip_fraction        | 0.0423         |
|    clip_range           | 0.2            |
|    entropy_loss         | -181           |
|    explained_variance   | 0.0406         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.79          |
|    n_updates            | 13670          |
|    policy_gradient_loss | -0.0018        |
|    reward               | -8.4584426e-05 |
|    std                  | 159            |
|    value_loss           | 2.23e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 684, ResetDay: 2364,Episode: 1668
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1369           |
|    time_elapsed         | 30991          |
|    total_timesteps      | 2803712        |
| train/                  |                |
|    approx_kl            | 1750.3896      |
|    clip_fraction        | 0.0505         |
|    clip_range           | 0.2            |
|    entropy_loss         | -181           |
|    explained_variance   | -0.034         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.81          |
|    n_updates            | 13680          |
|    policy_gradient_loss | 0.00288        |
|    reward               | -1.3466263e-05 |
|    std                  | 159            |
|    value_loss           | 1.02e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1787, ResetDay: 3467,Episode: 1669
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1191, ResetDay: 2871,Episode: 1670
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1370         |
|    time_elapsed         | 31014        |
|    total_timesteps      | 2805760      |
| train/                  |              |
|    approx_kl            | 1754.361     |
|    clip_fraction        | 0.0544       |
|    clip_range           | 0.2          |
|    entropy_loss         | -181         |
|    explained_variance   | -0.0919      |
|    learning_rate        | 0.00025      |
|    loss                 | -1.81        |
|    n_updates            | 13690        |
|    policy_gradient_loss | -0.00531     |
|    reward               | 3.874588e-05 |
|    std                  | 160          |
|    value_loss           | 3.73e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2871, episode: 1670
begin_total_asset: 200.00
end_total_asset: 102.80
total_reward: -97.20
total_cost: 29.41
total_trades: 38622
Sharpe: -0.103
=================================
Reseting Environment StartDay: 2524, ResetDay: 4204,Episode: 1671
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1371          |
|    time_elapsed         | 31036         |
|    total_timesteps      | 2807808       |
| train/                  |               |
|    approx_kl            | 1773.6093     |
|    clip_fraction        | 0.0523        |
|    clip_range           | 0.2           |
|    entropy_loss         | -181          |
|    explained_variance   | 0.0551        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.84         |
|    n_updates            | 13700         |
|    policy_gradient_loss | -0.00596      |
|    reward               | -0.0001130682 |
|    std                  | 160           |
|    value_loss           | 6.34e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1290, ResetDay: 2970,Episode: 1672
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1372         |
|    time_elapsed         | 31059        |
|    total_timesteps      | 2809856      |
| train/                  |              |
|    approx_kl            | 1778.5902    |
|    clip_fraction        | 0.0466       |
|    clip_range           | 0.2          |
|    entropy_loss         | -181         |
|    explained_variance   | 0.204        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.82        |
|    n_updates            | 13710        |
|    policy_gradient_loss | -0.00419     |
|    reward               | 2.393837e-05 |
|    std                  | 161          |
|    value_loss           | 2.66e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1754, ResetDay: 3434,Episode: 1673
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1373          |
|    time_elapsed         | 31081         |
|    total_timesteps      | 2811904       |
| train/                  |               |
|    approx_kl            | 1795.859      |
|    clip_fraction        | 0.0513        |
|    clip_range           | 0.2           |
|    entropy_loss         | -181          |
|    explained_variance   | 0.0988        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.81         |
|    n_updates            | 13720         |
|    policy_gradient_loss | -0.00149      |
|    reward               | -7.035809e-05 |
|    std                  | 161           |
|    value_loss           | 1.86e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 156, ResetDay: 1836,Episode: 1674
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1374         |
|    time_elapsed         | 31104        |
|    total_timesteps      | 2813952      |
| train/                  |              |
|    approx_kl            | 1792.6145    |
|    clip_fraction        | 0.0515       |
|    clip_range           | 0.2          |
|    entropy_loss         | -181         |
|    explained_variance   | -0.0878      |
|    learning_rate        | 0.00025      |
|    loss                 | -1.8         |
|    n_updates            | 13730        |
|    policy_gradient_loss | -0.00468     |
|    reward               | 6.457844e-05 |
|    std                  | 162          |
|    value_loss           | 3.31e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1879, ResetDay: 3559,Episode: 1675
Environment reached Terminal state as number of trading days reached limit!!
day: 3559, episode: 1675
begin_total_asset: 200.00
end_total_asset: 641.00
total_reward: 441.00
total_cost: 35.57
total_trades: 38441
Sharpe: 0.928
=================================
Reseting Environment StartDay: 317, ResetDay: 1997,Episode: 1676
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1375         |
|    time_elapsed         | 31126        |
|    total_timesteps      | 2816000      |
| train/                  |              |
|    approx_kl            | 1802.6641    |
|    clip_fraction        | 0.0502       |
|    clip_range           | 0.2          |
|    entropy_loss         | -181         |
|    explained_variance   | 0.218        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.81        |
|    n_updates            | 13740        |
|    policy_gradient_loss | -0.000156    |
|    reward               | 7.226069e-05 |
|    std                  | 162          |
|    value_loss           | 7.58e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 215, ResetDay: 1895,Episode: 1677
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1376           |
|    time_elapsed         | 31149          |
|    total_timesteps      | 2818048        |
| train/                  |                |
|    approx_kl            | 1841.2728      |
|    clip_fraction        | 0.0489         |
|    clip_range           | 0.2            |
|    entropy_loss         | -181           |
|    explained_variance   | 0.111          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.82          |
|    n_updates            | 13750          |
|    policy_gradient_loss | -0.00594       |
|    reward               | -0.00091887155 |
|    std                  | 163            |
|    value_loss           | 1.62e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2384, ResetDay: 4064,Episode: 1678
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1377         |
|    time_elapsed         | 31171        |
|    total_timesteps      | 2820096      |
| train/                  |              |
|    approx_kl            | 1851.096     |
|    clip_fraction        | 0.0602       |
|    clip_range           | 0.2          |
|    entropy_loss         | -181         |
|    explained_variance   | 0.263        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.81        |
|    n_updates            | 13760        |
|    policy_gradient_loss | -0.00358     |
|    reward               | 0.0009936909 |
|    std                  | 163          |
|    value_loss           | 1.74e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 32, ResetDay: 1712,Episode: 1679
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1378           |
|    time_elapsed         | 31194          |
|    total_timesteps      | 2822144        |
| train/                  |                |
|    approx_kl            | 1857.3738      |
|    clip_fraction        | 0.0401         |
|    clip_range           | 0.2            |
|    entropy_loss         | -181           |
|    explained_variance   | 0.205          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.81          |
|    n_updates            | 13770          |
|    policy_gradient_loss | -0.00221       |
|    reward               | -1.4088154e-05 |
|    std                  | 164            |
|    value_loss           | 1.32e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1379, ResetDay: 3059,Episode: 1680
Environment reached Terminal state as number of trading days reached limit!!
day: 3059, episode: 1680
begin_total_asset: 200.00
end_total_asset: 249.08
total_reward: 49.08
total_cost: 25.50
total_trades: 38342
Sharpe: 0.258
=================================
Reseting Environment StartDay: 497, ResetDay: 2177,Episode: 1681
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1379          |
|    time_elapsed         | 31216         |
|    total_timesteps      | 2824192       |
| train/                  |               |
|    approx_kl            | 1855.728      |
|    clip_fraction        | 0.0519        |
|    clip_range           | 0.2           |
|    entropy_loss         | -182          |
|    explained_variance   | -0.00182      |
|    learning_rate        | 0.00025       |
|    loss                 | -1.83         |
|    n_updates            | 13780         |
|    policy_gradient_loss | 0.00444       |
|    reward               | 9.9470664e-05 |
|    std                  | 164           |
|    value_loss           | 2.88e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2345, ResetDay: 4025,Episode: 1682
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1380           |
|    time_elapsed         | 31239          |
|    total_timesteps      | 2826240        |
| train/                  |                |
|    approx_kl            | 1883.3927      |
|    clip_fraction        | 0.0539         |
|    clip_range           | 0.2            |
|    entropy_loss         | -182           |
|    explained_variance   | -0.0642        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.82          |
|    n_updates            | 13790          |
|    policy_gradient_loss | -0.00798       |
|    reward               | -0.00012136841 |
|    std                  | 165            |
|    value_loss           | 7.19e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1642, ResetDay: 3322,Episode: 1683
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1381          |
|    time_elapsed         | 31262         |
|    total_timesteps      | 2828288       |
| train/                  |               |
|    approx_kl            | 1870.6267     |
|    clip_fraction        | 0.053         |
|    clip_range           | 0.2           |
|    entropy_loss         | -182          |
|    explained_variance   | -0.089        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.81         |
|    n_updates            | 13800         |
|    policy_gradient_loss | -0.00363      |
|    reward               | -6.995296e-05 |
|    std                  | 165           |
|    value_loss           | 3.66e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2048, ResetDay: 3728,Episode: 1684
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1382         |
|    time_elapsed         | 31284        |
|    total_timesteps      | 2830336      |
| train/                  |              |
|    approx_kl            | 1895.1858    |
|    clip_fraction        | 0.0486       |
|    clip_range           | 0.2          |
|    entropy_loss         | -182         |
|    explained_variance   | 0.0734       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.83        |
|    n_updates            | 13810        |
|    policy_gradient_loss | -0.00239     |
|    reward               | 3.865814e-05 |
|    std                  | 166          |
|    value_loss           | 2.15e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2160, ResetDay: 3840,Episode: 1685
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1383          |
|    time_elapsed         | 31307         |
|    total_timesteps      | 2832384       |
| train/                  |               |
|    approx_kl            | 1890.5337     |
|    clip_fraction        | 0.0472        |
|    clip_range           | 0.2           |
|    entropy_loss         | -182          |
|    explained_variance   | 0.211         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.83         |
|    n_updates            | 13820         |
|    policy_gradient_loss | -0.00369      |
|    reward               | 0.00065524294 |
|    std                  | 166           |
|    value_loss           | 4.69e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3840, episode: 1685
begin_total_asset: 200.00
end_total_asset: 338.24
total_reward: 138.24
total_cost: 30.59
total_trades: 38334
Sharpe: 0.436
=================================
Reseting Environment StartDay: 258, ResetDay: 1938,Episode: 1686
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2325, ResetDay: 4005,Episode: 1687
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1384           |
|    time_elapsed         | 31329          |
|    total_timesteps      | 2834432        |
| train/                  |                |
|    approx_kl            | 1932.7964      |
|    clip_fraction        | 0.0473         |
|    clip_range           | 0.2            |
|    entropy_loss         | -182           |
|    explained_variance   | 0.25           |
|    learning_rate        | 0.00025        |
|    loss                 | -1.83          |
|    n_updates            | 13830          |
|    policy_gradient_loss | 0.00222        |
|    reward               | -0.00014363555 |
|    std                  | 167            |
|    value_loss           | 1.4e-06        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 932, ResetDay: 2612,Episode: 1688
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1385           |
|    time_elapsed         | 31352          |
|    total_timesteps      | 2836480        |
| train/                  |                |
|    approx_kl            | 1925.393       |
|    clip_fraction        | 0.045          |
|    clip_range           | 0.2            |
|    entropy_loss         | -182           |
|    explained_variance   | -0.239         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.83          |
|    n_updates            | 13840          |
|    policy_gradient_loss | -0.00498       |
|    reward               | -2.8278828e-05 |
|    std                  | 167            |
|    value_loss           | 9.32e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2586, ResetDay: 4266,Episode: 1689
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1386          |
|    time_elapsed         | 31374         |
|    total_timesteps      | 2838528       |
| train/                  |               |
|    approx_kl            | 1942.4011     |
|    clip_fraction        | 0.0495        |
|    clip_range           | 0.2           |
|    entropy_loss         | -182          |
|    explained_variance   | 0.146         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.83         |
|    n_updates            | 13850         |
|    policy_gradient_loss | -0.00453      |
|    reward               | 7.1289064e-06 |
|    std                  | 168           |
|    value_loss           | 3.36e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2481, ResetDay: 4161,Episode: 1690
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1387          |
|    time_elapsed         | 31397         |
|    total_timesteps      | 2840576       |
| train/                  |               |
|    approx_kl            | 1953.3774     |
|    clip_fraction        | 0.057         |
|    clip_range           | 0.2           |
|    entropy_loss         | -182          |
|    explained_variance   | -0.0352       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.84         |
|    n_updates            | 13860         |
|    policy_gradient_loss | -0.00326      |
|    reward               | 8.9492794e-05 |
|    std                  | 169           |
|    value_loss           | 6.21e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4161, episode: 1690
begin_total_asset: 200.00
end_total_asset: 192.73
total_reward: -7.27
total_cost: 32.75
total_trades: 38142
Sharpe: 0.172
=================================
Reseting Environment StartDay: 483, ResetDay: 2163,Episode: 1691
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 54, ResetDay: 1734,Episode: 1692
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1388           |
|    time_elapsed         | 31419          |
|    total_timesteps      | 2842624        |
| train/                  |                |
|    approx_kl            | 1970.0222      |
|    clip_fraction        | 0.0452         |
|    clip_range           | 0.2            |
|    entropy_loss         | -182           |
|    explained_variance   | 0.131          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.84          |
|    n_updates            | 13870          |
|    policy_gradient_loss | -0.00662       |
|    reward               | -2.3704517e-05 |
|    std                  | 169            |
|    value_loss           | 1.27e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 592, ResetDay: 2272,Episode: 1693
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1389          |
|    time_elapsed         | 31442         |
|    total_timesteps      | 2844672       |
| train/                  |               |
|    approx_kl            | 1994.4414     |
|    clip_fraction        | 0.0437        |
|    clip_range           | 0.2           |
|    entropy_loss         | -182          |
|    explained_variance   | -1.14         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.84         |
|    n_updates            | 13880         |
|    policy_gradient_loss | -0.00397      |
|    reward               | 0.00013386148 |
|    std                  | 169           |
|    value_loss           | 5.67e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2065, ResetDay: 3745,Episode: 1694
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1390          |
|    time_elapsed         | 31464         |
|    total_timesteps      | 2846720       |
| train/                  |               |
|    approx_kl            | 1985.5778     |
|    clip_fraction        | 0.0525        |
|    clip_range           | 0.2           |
|    entropy_loss         | -182          |
|    explained_variance   | 0.237         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.83         |
|    n_updates            | 13890         |
|    policy_gradient_loss | -0.00139      |
|    reward               | 7.3539736e-06 |
|    std                  | 170           |
|    value_loss           | 6.51e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1171, ResetDay: 2851,Episode: 1695
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1391           |
|    time_elapsed         | 31487          |
|    total_timesteps      | 2848768        |
| train/                  |                |
|    approx_kl            | 1998.0735      |
|    clip_fraction        | 0.0382         |
|    clip_range           | 0.2            |
|    entropy_loss         | -183           |
|    explained_variance   | 0.0654         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.83          |
|    n_updates            | 13900          |
|    policy_gradient_loss | -0.003         |
|    reward               | -1.0643768e-05 |
|    std                  | 170            |
|    value_loss           | 3.94e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2851, episode: 1695
begin_total_asset: 200.00
end_total_asset: 52.95
total_reward: -147.05
total_cost: 41.10
total_trades: 38315
Sharpe: -0.243
=================================
Reseting Environment StartDay: 2104, ResetDay: 3784,Episode: 1696
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1392          |
|    time_elapsed         | 31510         |
|    total_timesteps      | 2850816       |
| train/                  |               |
|    approx_kl            | 2012.2002     |
|    clip_fraction        | 0.0517        |
|    clip_range           | 0.2           |
|    entropy_loss         | -183          |
|    explained_variance   | 0.0647        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.82         |
|    n_updates            | 13910         |
|    policy_gradient_loss | -0.00252      |
|    reward               | 0.00039541512 |
|    std                  | 171           |
|    value_loss           | 1.03e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 717, ResetDay: 2397,Episode: 1697
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2745, ResetDay: 4425,Episode: 1698
---------------------------------------------
| time/                   |                 |
|    fps                  | 90              |
|    iterations           | 1393            |
|    time_elapsed         | 31532           |
|    total_timesteps      | 2852864         |
| train/                  |                 |
|    approx_kl            | 2021.5118       |
|    clip_fraction        | 0.0468          |
|    clip_range           | 0.2             |
|    entropy_loss         | -183            |
|    explained_variance   | 0.165           |
|    learning_rate        | 0.00025         |
|    loss                 | -1.83           |
|    n_updates            | 13920           |
|    policy_gradient_loss | -0.003          |
|    reward               | -0.000109495166 |
|    std                  | 172             |
|    value_loss           | 9.66e-07        |
---------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1730, ResetDay: 3410,Episode: 1699
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1394          |
|    time_elapsed         | 31555         |
|    total_timesteps      | 2854912       |
| train/                  |               |
|    approx_kl            | 2059.5452     |
|    clip_fraction        | 0.0354        |
|    clip_range           | 0.2           |
|    entropy_loss         | -183          |
|    explained_variance   | -0.0916       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.83         |
|    n_updates            | 13930         |
|    policy_gradient_loss | 0.00194       |
|    reward               | 3.3457945e-05 |
|    std                  | 172           |
|    value_loss           | 8.45e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2454, ResetDay: 4134,Episode: 1700
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1395          |
|    time_elapsed         | 31577         |
|    total_timesteps      | 2856960       |
| train/                  |               |
|    approx_kl            | 2052.9373     |
|    clip_fraction        | 0.0397        |
|    clip_range           | 0.2           |
|    entropy_loss         | -183          |
|    explained_variance   | 0.0729        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.82         |
|    n_updates            | 13940         |
|    policy_gradient_loss | 0.000523      |
|    reward               | 1.5703583e-05 |
|    std                  | 173           |
|    value_loss           | 1.29e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4134, episode: 1700
begin_total_asset: 200.00
end_total_asset: 344.04
total_reward: 144.04
total_cost: 28.96
total_trades: 38015
Sharpe: 0.447
=================================
Reseting Environment StartDay: 2336, ResetDay: 4016,Episode: 1701
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1396          |
|    time_elapsed         | 31600         |
|    total_timesteps      | 2859008       |
| train/                  |               |
|    approx_kl            | 2073.4368     |
|    clip_fraction        | 0.0446        |
|    clip_range           | 0.2           |
|    entropy_loss         | -183          |
|    explained_variance   | -0.0764       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.84         |
|    n_updates            | 13950         |
|    policy_gradient_loss | -0.00329      |
|    reward               | -6.455841e-05 |
|    std                  | 174           |
|    value_loss           | 3.7e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1808, ResetDay: 3488,Episode: 1702
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1397         |
|    time_elapsed         | 31623        |
|    total_timesteps      | 2861056      |
| train/                  |              |
|    approx_kl            | 2115.2236    |
|    clip_fraction        | 0.057        |
|    clip_range           | 0.2          |
|    entropy_loss         | -183         |
|    explained_variance   | 0.168        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.86        |
|    n_updates            | 13960        |
|    policy_gradient_loss | -0.00371     |
|    reward               | 2.655716e-05 |
|    std                  | 174          |
|    value_loss           | 8.71e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2774, ResetDay: 4454,Episode: 1703
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 265, ResetDay: 1945,Episode: 1704
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1398          |
|    time_elapsed         | 31645         |
|    total_timesteps      | 2863104       |
| train/                  |               |
|    approx_kl            | 2118.7292     |
|    clip_fraction        | 0.0412        |
|    clip_range           | 0.2           |
|    entropy_loss         | -183          |
|    explained_variance   | 0.124         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.83         |
|    n_updates            | 13970         |
|    policy_gradient_loss | -0.00627      |
|    reward               | -1.619358e-05 |
|    std                  | 174           |
|    value_loss           | 5.08e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 287, ResetDay: 1967,Episode: 1705
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1399           |
|    time_elapsed         | 31668          |
|    total_timesteps      | 2865152        |
| train/                  |                |
|    approx_kl            | 2119.7324      |
|    clip_fraction        | 0.0495         |
|    clip_range           | 0.2            |
|    entropy_loss         | -183           |
|    explained_variance   | 0.0346         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.86          |
|    n_updates            | 13980          |
|    policy_gradient_loss | -0.00513       |
|    reward               | -2.7558757e-05 |
|    std                  | 175            |
|    value_loss           | 1.51e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 1967, episode: 1705
begin_total_asset: 200.00
end_total_asset: 157.57
total_reward: -42.43
total_cost: 52.98
total_trades: 38184
Sharpe: 0.070
=================================
Reseting Environment StartDay: 1802, ResetDay: 3482,Episode: 1706
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1400          |
|    time_elapsed         | 31690         |
|    total_timesteps      | 2867200       |
| train/                  |               |
|    approx_kl            | 2124.3904     |
|    clip_fraction        | 0.0384        |
|    clip_range           | 0.2           |
|    entropy_loss         | -183          |
|    explained_variance   | -0.00779      |
|    learning_rate        | 0.00025       |
|    loss                 | -1.85         |
|    n_updates            | 13990         |
|    policy_gradient_loss | -0.00248      |
|    reward               | 2.7199172e-05 |
|    std                  | 175           |
|    value_loss           | 6.43e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2772, ResetDay: 4452,Episode: 1707
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1401           |
|    time_elapsed         | 31713          |
|    total_timesteps      | 2869248        |
| train/                  |                |
|    approx_kl            | 2140.3345      |
|    clip_fraction        | 0.0403         |
|    clip_range           | 0.2            |
|    entropy_loss         | -183           |
|    explained_variance   | 0.16           |
|    learning_rate        | 0.00025        |
|    loss                 | -1.84          |
|    n_updates            | 14000          |
|    policy_gradient_loss | -0.00049       |
|    reward               | -0.00038218117 |
|    std                  | 176            |
|    value_loss           | 8.38e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 12, ResetDay: 1692,Episode: 1708
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 800, ResetDay: 2480,Episode: 1709
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1402         |
|    time_elapsed         | 31735        |
|    total_timesteps      | 2871296      |
| train/                  |              |
|    approx_kl            | 2163.4526    |
|    clip_fraction        | 0.0397       |
|    clip_range           | 0.2          |
|    entropy_loss         | -183         |
|    explained_variance   | 0.103        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.83        |
|    n_updates            | 14010        |
|    policy_gradient_loss | -0.00296     |
|    reward               | 0.0004264122 |
|    std                  | 176          |
|    value_loss           | 1.47e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 93, ResetDay: 1773,Episode: 1710
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1403          |
|    time_elapsed         | 31758         |
|    total_timesteps      | 2873344       |
| train/                  |               |
|    approx_kl            | 2177.447      |
|    clip_fraction        | 0.0435        |
|    clip_range           | 0.2           |
|    entropy_loss         | -184          |
|    explained_variance   | -0.596        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.85         |
|    n_updates            | 14020         |
|    policy_gradient_loss | -0.00261      |
|    reward               | 9.0692934e-05 |
|    std                  | 177           |
|    value_loss           | 1.02e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 1773, episode: 1710
begin_total_asset: 200.00
end_total_asset: 93.17
total_reward: -106.83
total_cost: 61.25
total_trades: 38197
Sharpe: -0.026
=================================
Reseting Environment StartDay: 1710, ResetDay: 3390,Episode: 1711
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1404           |
|    time_elapsed         | 31780          |
|    total_timesteps      | 2875392        |
| train/                  |                |
|    approx_kl            | 2199.705       |
|    clip_fraction        | 0.0376         |
|    clip_range           | 0.2            |
|    entropy_loss         | -184           |
|    explained_variance   | 0.0556         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.85          |
|    n_updates            | 14030          |
|    policy_gradient_loss | -0.00494       |
|    reward               | -0.00014206924 |
|    std                  | 177            |
|    value_loss           | 4.86e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2003, ResetDay: 3683,Episode: 1712
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1405          |
|    time_elapsed         | 31803         |
|    total_timesteps      | 2877440       |
| train/                  |               |
|    approx_kl            | 2179.678      |
|    clip_fraction        | 0.0475        |
|    clip_range           | 0.2           |
|    entropy_loss         | -184          |
|    explained_variance   | 0.332         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.82         |
|    n_updates            | 14040         |
|    policy_gradient_loss | 0.00154       |
|    reward               | 0.00015635337 |
|    std                  | 178           |
|    value_loss           | 4.85e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2404, ResetDay: 4084,Episode: 1713
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1406         |
|    time_elapsed         | 31825        |
|    total_timesteps      | 2879488      |
| train/                  |              |
|    approx_kl            | 2227.3162    |
|    clip_fraction        | 0.0551       |
|    clip_range           | 0.2          |
|    entropy_loss         | -184         |
|    explained_variance   | 0.0238       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.84        |
|    n_updates            | 14050        |
|    policy_gradient_loss | -0.00954     |
|    reward               | 0.0006217613 |
|    std                  | 178          |
|    value_loss           | 8.27e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 263, ResetDay: 1943,Episode: 1714
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1415, ResetDay: 3095,Episode: 1715
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1407         |
|    time_elapsed         | 31848        |
|    total_timesteps      | 2881536      |
| train/                  |              |
|    approx_kl            | 2215.0696    |
|    clip_fraction        | 0.0416       |
|    clip_range           | 0.2          |
|    entropy_loss         | -184         |
|    explained_variance   | 0.193        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.86        |
|    n_updates            | 14060        |
|    policy_gradient_loss | -0.00211     |
|    reward               | 6.429577e-06 |
|    std                  | 179          |
|    value_loss           | 9.67e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3095, episode: 1715
begin_total_asset: 200.00
end_total_asset: 242.87
total_reward: 42.87
total_cost: 21.87
total_trades: 37713
Sharpe: 0.246
=================================
Reseting Environment StartDay: 1716, ResetDay: 3396,Episode: 1716
---------------------------------------------
| time/                   |                 |
|    fps                  | 90              |
|    iterations           | 1408            |
|    time_elapsed         | 31871           |
|    total_timesteps      | 2883584         |
| train/                  |                 |
|    approx_kl            | 2230.6067       |
|    clip_fraction        | 0.0423          |
|    clip_range           | 0.2             |
|    entropy_loss         | -184            |
|    explained_variance   | -0.109          |
|    learning_rate        | 0.00025         |
|    loss                 | -1.85           |
|    n_updates            | 14070           |
|    policy_gradient_loss | 0.00151         |
|    reward               | -0.000105721665 |
|    std                  | 179             |
|    value_loss           | 9.91e-07        |
---------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2334, ResetDay: 4014,Episode: 1717
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1409         |
|    time_elapsed         | 31893        |
|    total_timesteps      | 2885632      |
| train/                  |              |
|    approx_kl            | 2235.9233    |
|    clip_fraction        | 0.048        |
|    clip_range           | 0.2          |
|    entropy_loss         | -184         |
|    explained_variance   | 0.197        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.86        |
|    n_updates            | 14080        |
|    policy_gradient_loss | -0.00384     |
|    reward               | 0.0001832611 |
|    std                  | 179          |
|    value_loss           | 4.25e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 995, ResetDay: 2675,Episode: 1718
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1410           |
|    time_elapsed         | 31916          |
|    total_timesteps      | 2887680        |
| train/                  |                |
|    approx_kl            | 2252.4163      |
|    clip_fraction        | 0.0437         |
|    clip_range           | 0.2            |
|    entropy_loss         | -184           |
|    explained_variance   | 0.175          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.84          |
|    n_updates            | 14090          |
|    policy_gradient_loss | 0.00137        |
|    reward               | -0.00029025422 |
|    std                  | 180            |
|    value_loss           | 4.82e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2576, ResetDay: 4256,Episode: 1719
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1745, ResetDay: 3425,Episode: 1720
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1411           |
|    time_elapsed         | 31938          |
|    total_timesteps      | 2889728        |
| train/                  |                |
|    approx_kl            | 2278.874       |
|    clip_fraction        | 0.0364         |
|    clip_range           | 0.2            |
|    entropy_loss         | -184           |
|    explained_variance   | 0.0872         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.85          |
|    n_updates            | 14100          |
|    policy_gradient_loss | -0.0031        |
|    reward               | -0.00011534386 |
|    std                  | 181            |
|    value_loss           | 8.55e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3425, episode: 1720
begin_total_asset: 200.00
end_total_asset: 165.90
total_reward: -34.10
total_cost: 28.51
total_trades: 37544
Sharpe: 0.162
=================================
Reseting Environment StartDay: 1730, ResetDay: 3410,Episode: 1721
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1412           |
|    time_elapsed         | 31961          |
|    total_timesteps      | 2891776        |
| train/                  |                |
|    approx_kl            | 2272.9844      |
|    clip_fraction        | 0.0375         |
|    clip_range           | 0.2            |
|    entropy_loss         | -184           |
|    explained_variance   | 0.0822         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.85          |
|    n_updates            | 14110          |
|    policy_gradient_loss | 0.00237        |
|    reward               | -0.00015262241 |
|    std                  | 182            |
|    value_loss           | 2.18e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 168, ResetDay: 1848,Episode: 1722
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1413          |
|    time_elapsed         | 31983         |
|    total_timesteps      | 2893824       |
| train/                  |               |
|    approx_kl            | 2315.238      |
|    clip_fraction        | 0.0405        |
|    clip_range           | 0.2           |
|    entropy_loss         | -184          |
|    explained_variance   | -0.545        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.86         |
|    n_updates            | 14120         |
|    policy_gradient_loss | -0.00193      |
|    reward               | 0.00040489202 |
|    std                  | 182           |
|    value_loss           | 2.81e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 392, ResetDay: 2072,Episode: 1723
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1414           |
|    time_elapsed         | 32006          |
|    total_timesteps      | 2895872        |
| train/                  |                |
|    approx_kl            | 2319.689       |
|    clip_fraction        | 0.0377         |
|    clip_range           | 0.2            |
|    entropy_loss         | -184           |
|    explained_variance   | 0.0838         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.83          |
|    n_updates            | 14130          |
|    policy_gradient_loss | 0.000919       |
|    reward               | -1.4902877e-05 |
|    std                  | 182            |
|    value_loss           | 5.63e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2147, ResetDay: 3827,Episode: 1724
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1415          |
|    time_elapsed         | 32028         |
|    total_timesteps      | 2897920       |
| train/                  |               |
|    approx_kl            | 2345.1543     |
|    clip_fraction        | 0.0392        |
|    clip_range           | 0.2           |
|    entropy_loss         | -184          |
|    explained_variance   | 0.305         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.86         |
|    n_updates            | 14140         |
|    policy_gradient_loss | 0.000431      |
|    reward               | 0.00049870607 |
|    std                  | 182           |
|    value_loss           | 4.78e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 305, ResetDay: 1985,Episode: 1725
Environment reached Terminal state as number of trading days reached limit!!
day: 1985, episode: 1725
begin_total_asset: 200.00
end_total_asset: 31.09
total_reward: -168.91
total_cost: 66.96
total_trades: 37765
Sharpe: -0.366
=================================
Reseting Environment StartDay: 759, ResetDay: 2439,Episode: 1726
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1416           |
|    time_elapsed         | 32051          |
|    total_timesteps      | 2899968        |
| train/                  |                |
|    approx_kl            | 2329.3833      |
|    clip_fraction        | 0.0373         |
|    clip_range           | 0.2            |
|    entropy_loss         | -184           |
|    explained_variance   | 0.0905         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.85          |
|    n_updates            | 14150          |
|    policy_gradient_loss | -0.00436       |
|    reward               | -5.8526144e-05 |
|    std                  | 183            |
|    value_loss           | 1.91e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 753, ResetDay: 2433,Episode: 1727
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1417           |
|    time_elapsed         | 32073          |
|    total_timesteps      | 2902016        |
| train/                  |                |
|    approx_kl            | 2349.658       |
|    clip_fraction        | 0.0382         |
|    clip_range           | 0.2            |
|    entropy_loss         | -184           |
|    explained_variance   | -0.122         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.85          |
|    n_updates            | 14160          |
|    policy_gradient_loss | -0.00494       |
|    reward               | -0.00013808327 |
|    std                  | 183            |
|    value_loss           | 1.25e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1152, ResetDay: 2832,Episode: 1728
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1418          |
|    time_elapsed         | 32096         |
|    total_timesteps      | 2904064       |
| train/                  |               |
|    approx_kl            | 2359.8374     |
|    clip_fraction        | 0.0417        |
|    clip_range           | 0.2           |
|    entropy_loss         | -185          |
|    explained_variance   | 0.101         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.83         |
|    n_updates            | 14170         |
|    policy_gradient_loss | 0.00274       |
|    reward               | 2.2278786e-05 |
|    std                  | 184           |
|    value_loss           | 2.72e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2639, ResetDay: 4319,Episode: 1729
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1419          |
|    time_elapsed         | 32118         |
|    total_timesteps      | 2906112       |
| train/                  |               |
|    approx_kl            | 2393.4395     |
|    clip_fraction        | 0.043         |
|    clip_range           | 0.2           |
|    entropy_loss         | -185          |
|    explained_variance   | 0.311         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.84         |
|    n_updates            | 14180         |
|    policy_gradient_loss | -0.00225      |
|    reward               | 0.00033160707 |
|    std                  | 184           |
|    value_loss           | 2.07e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 373, ResetDay: 2053,Episode: 1730
Environment reached Terminal state as number of trading days reached limit!!
day: 2053, episode: 1730
begin_total_asset: 200.00
end_total_asset: 54.03
total_reward: -145.97
total_cost: 55.71
total_trades: 37436
Sharpe: -0.243
=================================
Reseting Environment StartDay: 283, ResetDay: 1963,Episode: 1731
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1420         |
|    time_elapsed         | 32141        |
|    total_timesteps      | 2908160      |
| train/                  |              |
|    approx_kl            | 2382.7012    |
|    clip_fraction        | 0.042        |
|    clip_range           | 0.2          |
|    entropy_loss         | -185         |
|    explained_variance   | 0.104        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.84        |
|    n_updates            | 14190        |
|    policy_gradient_loss | -0.00501     |
|    reward               | 4.208772e-05 |
|    std                  | 185          |
|    value_loss           | 1.2e-06      |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 973, ResetDay: 2653,Episode: 1732
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1421           |
|    time_elapsed         | 32164          |
|    total_timesteps      | 2910208        |
| train/                  |                |
|    approx_kl            | 2396.7117      |
|    clip_fraction        | 0.0353         |
|    clip_range           | 0.2            |
|    entropy_loss         | -185           |
|    explained_variance   | -0.375         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.84          |
|    n_updates            | 14200          |
|    policy_gradient_loss | 0.00995        |
|    reward               | -2.0671483e-05 |
|    std                  | 185            |
|    value_loss           | 1.08e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1526, ResetDay: 3206,Episode: 1733
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1422          |
|    time_elapsed         | 32186         |
|    total_timesteps      | 2912256       |
| train/                  |               |
|    approx_kl            | 2401.4084     |
|    clip_fraction        | 0.0367        |
|    clip_range           | 0.2           |
|    entropy_loss         | -185          |
|    explained_variance   | 0.155         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.87         |
|    n_updates            | 14210         |
|    policy_gradient_loss | 0.0019        |
|    reward               | 0.00011404419 |
|    std                  | 186           |
|    value_loss           | 5.81e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 971, ResetDay: 2651,Episode: 1734
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1423           |
|    time_elapsed         | 32209          |
|    total_timesteps      | 2914304        |
| train/                  |                |
|    approx_kl            | 2414.2117      |
|    clip_fraction        | 0.0308         |
|    clip_range           | 0.2            |
|    entropy_loss         | -185           |
|    explained_variance   | 0.211          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.85          |
|    n_updates            | 14220          |
|    policy_gradient_loss | 0.000351       |
|    reward               | -2.6737976e-05 |
|    std                  | 187            |
|    value_loss           | 3.44e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2278, ResetDay: 3958,Episode: 1735
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1424          |
|    time_elapsed         | 32231         |
|    total_timesteps      | 2916352       |
| train/                  |               |
|    approx_kl            | 2443.124      |
|    clip_fraction        | 0.036         |
|    clip_range           | 0.2           |
|    entropy_loss         | -185          |
|    explained_variance   | 0.0916        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.84         |
|    n_updates            | 14230         |
|    policy_gradient_loss | -0.00301      |
|    reward               | -0.0009810554 |
|    std                  | 187           |
|    value_loss           | 5.62e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3958, episode: 1735
begin_total_asset: 200.00
end_total_asset: 469.91
total_reward: 269.91
total_cost: 33.53
total_trades: 37147
Sharpe: 0.625
=================================
Reseting Environment StartDay: 2547, ResetDay: 4227,Episode: 1736
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1072, ResetDay: 2752,Episode: 1737
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1425         |
|    time_elapsed         | 32254        |
|    total_timesteps      | 2918400      |
| train/                  |              |
|    approx_kl            | 2465.554     |
|    clip_fraction        | 0.0392       |
|    clip_range           | 0.2          |
|    entropy_loss         | -185         |
|    explained_variance   | 0.103        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.86        |
|    n_updates            | 14240        |
|    policy_gradient_loss | -0.00555     |
|    reward               | 8.452606e-06 |
|    std                  | 188          |
|    value_loss           | 2.62e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 82, ResetDay: 1762,Episode: 1738
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1426          |
|    time_elapsed         | 32277         |
|    total_timesteps      | 2920448       |
| train/                  |               |
|    approx_kl            | 2477.4233     |
|    clip_fraction        | 0.0417        |
|    clip_range           | 0.2           |
|    entropy_loss         | -185          |
|    explained_variance   | 0.0478        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.86         |
|    n_updates            | 14250         |
|    policy_gradient_loss | 0.00804       |
|    reward               | 0.00032250877 |
|    std                  | 188           |
|    value_loss           | 1.1e-06       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1364, ResetDay: 3044,Episode: 1739
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1427           |
|    time_elapsed         | 32299          |
|    total_timesteps      | 2922496        |
| train/                  |                |
|    approx_kl            | 2475.646       |
|    clip_fraction        | 0.0333         |
|    clip_range           | 0.2            |
|    entropy_loss         | -185           |
|    explained_variance   | -1.23          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.87          |
|    n_updates            | 14260          |
|    policy_gradient_loss | -0.00364       |
|    reward               | -0.00022581196 |
|    std                  | 188            |
|    value_loss           | 3.51e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2682, ResetDay: 4362,Episode: 1740
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1428           |
|    time_elapsed         | 32322          |
|    total_timesteps      | 2924544        |
| train/                  |                |
|    approx_kl            | 2476.361       |
|    clip_fraction        | 0.0376         |
|    clip_range           | 0.2            |
|    entropy_loss         | -185           |
|    explained_variance   | 0.302          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.87          |
|    n_updates            | 14270          |
|    policy_gradient_loss | -0.00299       |
|    reward               | -0.00024304734 |
|    std                  | 189            |
|    value_loss           | 4.52e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4362, episode: 1740
begin_total_asset: 200.00
end_total_asset: 255.97
total_reward: 55.97
total_cost: 63.63
total_trades: 37361
Sharpe: 0.274
=================================
Reseting Environment StartDay: 2151, ResetDay: 3831,Episode: 1741
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1429           |
|    time_elapsed         | 32344          |
|    total_timesteps      | 2926592        |
| train/                  |                |
|    approx_kl            | 2513.386       |
|    clip_fraction        | 0.0336         |
|    clip_range           | 0.2            |
|    entropy_loss         | -185           |
|    explained_variance   | 0.121          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.86          |
|    n_updates            | 14280          |
|    policy_gradient_loss | -0.0016        |
|    reward               | 0.000121266174 |
|    std                  | 190            |
|    value_loss           | 7.52e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2597, ResetDay: 4277,Episode: 1742
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 725, ResetDay: 2405,Episode: 1743
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1430           |
|    time_elapsed         | 32367          |
|    total_timesteps      | 2928640        |
| train/                  |                |
|    approx_kl            | 2511.7432      |
|    clip_fraction        | 0.0399         |
|    clip_range           | 0.2            |
|    entropy_loss         | -186           |
|    explained_variance   | 0.0162         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.84          |
|    n_updates            | 14290          |
|    policy_gradient_loss | 0.00266        |
|    reward               | -0.00012061605 |
|    std                  | 191            |
|    value_loss           | 5.38e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 143, ResetDay: 1823,Episode: 1744
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1431           |
|    time_elapsed         | 32389          |
|    total_timesteps      | 2930688        |
| train/                  |                |
|    approx_kl            | 2543.9475      |
|    clip_fraction        | 0.0382         |
|    clip_range           | 0.2            |
|    entropy_loss         | -186           |
|    explained_variance   | 0.133          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.87          |
|    n_updates            | 14300          |
|    policy_gradient_loss | -0.00409       |
|    reward               | -0.00011757678 |
|    std                  | 191            |
|    value_loss           | 9.11e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1259, ResetDay: 2939,Episode: 1745
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1432          |
|    time_elapsed         | 32412         |
|    total_timesteps      | 2932736       |
| train/                  |               |
|    approx_kl            | 2579.989      |
|    clip_fraction        | 0.041         |
|    clip_range           | 0.2           |
|    entropy_loss         | -186          |
|    explained_variance   | -0.169        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.88         |
|    n_updates            | 14310         |
|    policy_gradient_loss | -0.000421     |
|    reward               | 2.1450423e-05 |
|    std                  | 192           |
|    value_loss           | 3.52e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2939, episode: 1745
begin_total_asset: 200.00
end_total_asset: 170.89
total_reward: -29.11
total_cost: 34.01
total_trades: 37119
Sharpe: 0.043
=================================
Reseting Environment StartDay: 2660, ResetDay: 4340,Episode: 1746
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1433         |
|    time_elapsed         | 32434        |
|    total_timesteps      | 2934784      |
| train/                  |              |
|    approx_kl            | 2565.6777    |
|    clip_fraction        | 0.0333       |
|    clip_range           | 0.2          |
|    entropy_loss         | -186         |
|    explained_variance   | 0.389        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.87        |
|    n_updates            | 14320        |
|    policy_gradient_loss | -0.00315     |
|    reward               | 0.0004414055 |
|    std                  | 192          |
|    value_loss           | 3.64e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 863, ResetDay: 2543,Episode: 1747
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2245, ResetDay: 3925,Episode: 1748
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1434          |
|    time_elapsed         | 32457         |
|    total_timesteps      | 2936832       |
| train/                  |               |
|    approx_kl            | 2589.584      |
|    clip_fraction        | 0.032         |
|    clip_range           | 0.2           |
|    entropy_loss         | -186          |
|    explained_variance   | 0.0579        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.86         |
|    n_updates            | 14330         |
|    policy_gradient_loss | 0.00112       |
|    reward               | 9.6533775e-05 |
|    std                  | 193           |
|    value_loss           | 7.61e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1109, ResetDay: 2789,Episode: 1749
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1435          |
|    time_elapsed         | 32480         |
|    total_timesteps      | 2938880       |
| train/                  |               |
|    approx_kl            | 2603.3428     |
|    clip_fraction        | 0.0345        |
|    clip_range           | 0.2           |
|    entropy_loss         | -186          |
|    explained_variance   | -0.261        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.86         |
|    n_updates            | 14340         |
|    policy_gradient_loss | 0.00272       |
|    reward               | 3.4063338e-05 |
|    std                  | 194           |
|    value_loss           | 6.53e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1218, ResetDay: 2898,Episode: 1750
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1436          |
|    time_elapsed         | 32502         |
|    total_timesteps      | 2940928       |
| train/                  |               |
|    approx_kl            | 2628.8352     |
|    clip_fraction        | 0.0413        |
|    clip_range           | 0.2           |
|    entropy_loss         | -186          |
|    explained_variance   | 0.0805        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.88         |
|    n_updates            | 14350         |
|    policy_gradient_loss | -0.00301      |
|    reward               | -8.906936e-06 |
|    std                  | 195           |
|    value_loss           | 1.45e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2898, episode: 1750
begin_total_asset: 200.00
end_total_asset: 137.55
total_reward: -62.45
total_cost: 28.67
total_trades: 36894
Sharpe: -0.016
=================================
Reseting Environment StartDay: 2002, ResetDay: 3682,Episode: 1751
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1437          |
|    time_elapsed         | 32525         |
|    total_timesteps      | 2942976       |
| train/                  |               |
|    approx_kl            | 2655.789      |
|    clip_fraction        | 0.0361        |
|    clip_range           | 0.2           |
|    entropy_loss         | -186          |
|    explained_variance   | -0.334        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.87         |
|    n_updates            | 14360         |
|    policy_gradient_loss | -0.000287     |
|    reward               | 0.00039688224 |
|    std                  | 196           |
|    value_loss           | 2.68e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1679, ResetDay: 3359,Episode: 1752
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1438           |
|    time_elapsed         | 32558          |
|    total_timesteps      | 2945024        |
| train/                  |                |
|    approx_kl            | 2686.4043      |
|    clip_fraction        | 0.0354         |
|    clip_range           | 0.2            |
|    entropy_loss         | -186           |
|    explained_variance   | 0.207          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.87          |
|    n_updates            | 14370          |
|    policy_gradient_loss | -0.00549       |
|    reward               | -0.00096901244 |
|    std                  | 197            |
|    value_loss           | 3.84e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 906, ResetDay: 2586,Episode: 1753
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1295, ResetDay: 2975,Episode: 1754
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1439         |
|    time_elapsed         | 32581        |
|    total_timesteps      | 2947072      |
| train/                  |              |
|    approx_kl            | 2710.167     |
|    clip_fraction        | 0.0326       |
|    clip_range           | 0.2          |
|    entropy_loss         | -186         |
|    explained_variance   | 0.179        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.88        |
|    n_updates            | 14380        |
|    policy_gradient_loss | 0.000667     |
|    reward               | 9.544134e-05 |
|    std                  | 197          |
|    value_loss           | 1.02e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2385, ResetDay: 4065,Episode: 1755
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1440         |
|    time_elapsed         | 32603        |
|    total_timesteps      | 2949120      |
| train/                  |              |
|    approx_kl            | 2726.9353    |
|    clip_fraction        | 0.0353       |
|    clip_range           | 0.2          |
|    entropy_loss         | -187         |
|    explained_variance   | -0.558       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.87        |
|    n_updates            | 14390        |
|    policy_gradient_loss | -0.0023      |
|    reward               | 0.0001296999 |
|    std                  | 198          |
|    value_loss           | 4.5e-07      |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4065, episode: 1755
begin_total_asset: 200.00
end_total_asset: 396.13
total_reward: 196.13
total_cost: 44.84
total_trades: 36953
Sharpe: 0.528
=================================
Reseting Environment StartDay: 1844, ResetDay: 3524,Episode: 1756
-----------------------------------------
| time/                   |             |
|    fps                  | 90          |
|    iterations           | 1441        |
|    time_elapsed         | 32626       |
|    total_timesteps      | 2951168     |
| train/                  |             |
|    approx_kl            | 2778.2568   |
|    clip_fraction        | 0.0267      |
|    clip_range           | 0.2         |
|    entropy_loss         | -187        |
|    explained_variance   | 0.203       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.88       |
|    n_updates            | 14400       |
|    policy_gradient_loss | -0.00341    |
|    reward               | 9.79824e-05 |
|    std                  | 198         |
|    value_loss           | 2.31e-07    |
-----------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1636, ResetDay: 3316,Episode: 1757
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1442          |
|    time_elapsed         | 32648         |
|    total_timesteps      | 2953216       |
| train/                  |               |
|    approx_kl            | 2778.3452     |
|    clip_fraction        | 0.0328        |
|    clip_range           | 0.2           |
|    entropy_loss         | -187          |
|    explained_variance   | 0.0896        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.89         |
|    n_updates            | 14410         |
|    policy_gradient_loss | -0.0041       |
|    reward               | 4.9822807e-05 |
|    std                  | 198           |
|    value_loss           | 1.41e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2035, ResetDay: 3715,Episode: 1758
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2368, ResetDay: 4048,Episode: 1759
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1443           |
|    time_elapsed         | 32670          |
|    total_timesteps      | 2955264        |
| train/                  |                |
|    approx_kl            | 2781.7217      |
|    clip_fraction        | 0.0337         |
|    clip_range           | 0.2            |
|    entropy_loss         | -187           |
|    explained_variance   | 0.145          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.88          |
|    n_updates            | 14420          |
|    policy_gradient_loss | -0.00595       |
|    reward               | -2.3161698e-05 |
|    std                  | 199            |
|    value_loss           | 4.17e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1471, ResetDay: 3151,Episode: 1760
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1444           |
|    time_elapsed         | 32693          |
|    total_timesteps      | 2957312        |
| train/                  |                |
|    approx_kl            | 2796.5676      |
|    clip_fraction        | 0.0322         |
|    clip_range           | 0.2            |
|    entropy_loss         | -187           |
|    explained_variance   | 0.237          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.88          |
|    n_updates            | 14430          |
|    policy_gradient_loss | -0.00369       |
|    reward               | -0.00020698071 |
|    std                  | 199            |
|    value_loss           | 4.8e-07        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3151, episode: 1760
begin_total_asset: 200.00
end_total_asset: 145.01
total_reward: -54.99
total_cost: 15.94
total_trades: 36778
Sharpe: 0.059
=================================
Reseting Environment StartDay: 2071, ResetDay: 3751,Episode: 1761
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1445          |
|    time_elapsed         | 32716         |
|    total_timesteps      | 2959360       |
| train/                  |               |
|    approx_kl            | 2787.8682     |
|    clip_fraction        | 0.035         |
|    clip_range           | 0.2           |
|    entropy_loss         | -187          |
|    explained_variance   | 0.187         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.88         |
|    n_updates            | 14440         |
|    policy_gradient_loss | -0.00642      |
|    reward               | 0.00011267967 |
|    std                  | 200           |
|    value_loss           | 7.03e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1764, ResetDay: 3444,Episode: 1762
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1446         |
|    time_elapsed         | 32738        |
|    total_timesteps      | 2961408      |
| train/                  |              |
|    approx_kl            | 2818.152     |
|    clip_fraction        | 0.0241       |
|    clip_range           | 0.2          |
|    entropy_loss         | -187         |
|    explained_variance   | 0.0579       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.88        |
|    n_updates            | 14450        |
|    policy_gradient_loss | 0.00105      |
|    reward               | 5.351162e-05 |
|    std                  | 200          |
|    value_loss           | 2.11e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 960, ResetDay: 2640,Episode: 1763
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1447           |
|    time_elapsed         | 32761          |
|    total_timesteps      | 2963456        |
| train/                  |                |
|    approx_kl            | 2811.645       |
|    clip_fraction        | 0.0298         |
|    clip_range           | 0.2            |
|    entropy_loss         | -187           |
|    explained_variance   | 0.146          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.88          |
|    n_updates            | 14460          |
|    policy_gradient_loss | -0.00155       |
|    reward               | -0.00012436065 |
|    std                  | 201            |
|    value_loss           | 8.33e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 563, ResetDay: 2243,Episode: 1764
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 321, ResetDay: 2001,Episode: 1765
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1448          |
|    time_elapsed         | 32784         |
|    total_timesteps      | 2965504       |
| train/                  |               |
|    approx_kl            | 2842.7563     |
|    clip_fraction        | 0.035         |
|    clip_range           | 0.2           |
|    entropy_loss         | -187          |
|    explained_variance   | -0.334        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.87         |
|    n_updates            | 14470         |
|    policy_gradient_loss | -0.00439      |
|    reward               | 0.00014063799 |
|    std                  | 201           |
|    value_loss           | 4.15e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2001, episode: 1765
begin_total_asset: 200.00
end_total_asset: 110.31
total_reward: -89.69
total_cost: 58.15
total_trades: 36936
Sharpe: -0.052
=================================
Reseting Environment StartDay: 2543, ResetDay: 4223,Episode: 1766
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1449          |
|    time_elapsed         | 32807         |
|    total_timesteps      | 2967552       |
| train/                  |               |
|    approx_kl            | 2853.1252     |
|    clip_fraction        | 0.032         |
|    clip_range           | 0.2           |
|    entropy_loss         | -187          |
|    explained_variance   | 0.189         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.87         |
|    n_updates            | 14480         |
|    policy_gradient_loss | -0.00305      |
|    reward               | 0.00023248444 |
|    std                  | 202           |
|    value_loss           | 4.49e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2163, ResetDay: 3843,Episode: 1767
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1450           |
|    time_elapsed         | 32829          |
|    total_timesteps      | 2969600        |
| train/                  |                |
|    approx_kl            | 2860.2764      |
|    clip_fraction        | 0.0341         |
|    clip_range           | 0.2            |
|    entropy_loss         | -187           |
|    explained_variance   | 0.256          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.88          |
|    n_updates            | 14490          |
|    policy_gradient_loss | -0.000328      |
|    reward               | -0.00038442478 |
|    std                  | 202            |
|    value_loss           | 8.43e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 230, ResetDay: 1910,Episode: 1768
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1451         |
|    time_elapsed         | 32852        |
|    total_timesteps      | 2971648      |
| train/                  |              |
|    approx_kl            | 2892.4453    |
|    clip_fraction        | 0.0246       |
|    clip_range           | 0.2          |
|    entropy_loss         | -187         |
|    explained_variance   | 0.107        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.86        |
|    n_updates            | 14500        |
|    policy_gradient_loss | 0.000212     |
|    reward               | 8.155718e-05 |
|    std                  | 203          |
|    value_loss           | 2.56e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 913, ResetDay: 2593,Episode: 1769
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2496, ResetDay: 4176,Episode: 1770
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1452          |
|    time_elapsed         | 32874         |
|    total_timesteps      | 2973696       |
| train/                  |               |
|    approx_kl            | 2891.377      |
|    clip_fraction        | 0.0423        |
|    clip_range           | 0.2           |
|    entropy_loss         | -187          |
|    explained_variance   | -0.181        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.88         |
|    n_updates            | 14510         |
|    policy_gradient_loss | -0.00183      |
|    reward               | -0.0001726075 |
|    std                  | 203           |
|    value_loss           | 7.41e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4176, episode: 1770
begin_total_asset: 200.00
end_total_asset: 375.62
total_reward: 175.62
total_cost: 52.39
total_trades: 36606
Sharpe: 0.513
=================================
Reseting Environment StartDay: 375, ResetDay: 2055,Episode: 1771
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1453         |
|    time_elapsed         | 32897        |
|    total_timesteps      | 2975744      |
| train/                  |              |
|    approx_kl            | 2915.1587    |
|    clip_fraction        | 0.0335       |
|    clip_range           | 0.2          |
|    entropy_loss         | -187         |
|    explained_variance   | 0.0969       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.88        |
|    n_updates            | 14520        |
|    policy_gradient_loss | -0.00212     |
|    reward               | 4.862957e-05 |
|    std                  | 204          |
|    value_loss           | 4.04e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1167, ResetDay: 2847,Episode: 1772
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1454          |
|    time_elapsed         | 32919         |
|    total_timesteps      | 2977792       |
| train/                  |               |
|    approx_kl            | 2946.6528     |
|    clip_fraction        | 0.029         |
|    clip_range           | 0.2           |
|    entropy_loss         | -187          |
|    explained_variance   | 0.0701        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.88         |
|    n_updates            | 14530         |
|    policy_gradient_loss | -0.000327     |
|    reward               | -7.843609e-05 |
|    std                  | 205           |
|    value_loss           | 1.27e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1093, ResetDay: 2773,Episode: 1773
-----------------------------------------
| time/                   |             |
|    fps                  | 90          |
|    iterations           | 1455        |
|    time_elapsed         | 32942       |
|    total_timesteps      | 2979840     |
| train/                  |             |
|    approx_kl            | 2956.6375   |
|    clip_fraction        | 0.0321      |
|    clip_range           | 0.2         |
|    entropy_loss         | -188        |
|    explained_variance   | -0.335      |
|    learning_rate        | 0.00025     |
|    loss                 | -1.86       |
|    n_updates            | 14540       |
|    policy_gradient_loss | -0.000138   |
|    reward               | 6.58371e-05 |
|    std                  | 205         |
|    value_loss           | 3.98e-07    |
-----------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2769, ResetDay: 4449,Episode: 1774
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1456          |
|    time_elapsed         | 32964         |
|    total_timesteps      | 2981888       |
| train/                  |               |
|    approx_kl            | 2960.234      |
|    clip_fraction        | 0.0256        |
|    clip_range           | 0.2           |
|    entropy_loss         | -188          |
|    explained_variance   | 0.0778        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.88         |
|    n_updates            | 14550         |
|    policy_gradient_loss | -0.000186     |
|    reward               | 0.00011514015 |
|    std                  | 206           |
|    value_loss           | 2.97e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1966, ResetDay: 3646,Episode: 1775
Environment reached Terminal state as number of trading days reached limit!!
day: 3646, episode: 1775
begin_total_asset: 200.00
end_total_asset: 216.02
total_reward: 16.02
total_cost: 40.65
total_trades: 36491
Sharpe: 0.222
=================================
Reseting Environment StartDay: 2464, ResetDay: 4144,Episode: 1776
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1457           |
|    time_elapsed         | 32987          |
|    total_timesteps      | 2983936        |
| train/                  |                |
|    approx_kl            | 2990.5435      |
|    clip_fraction        | 0.0351         |
|    clip_range           | 0.2            |
|    entropy_loss         | -188           |
|    explained_variance   | 0.0587         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.87          |
|    n_updates            | 14560          |
|    policy_gradient_loss | -0.00448       |
|    reward               | 0.000118385695 |
|    std                  | 207            |
|    value_loss           | 1.54e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2781, ResetDay: 4461,Episode: 1777
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1458         |
|    time_elapsed         | 33009        |
|    total_timesteps      | 2985984      |
| train/                  |              |
|    approx_kl            | 3007.2698    |
|    clip_fraction        | 0.025        |
|    clip_range           | 0.2          |
|    entropy_loss         | -188         |
|    explained_variance   | -0.0496      |
|    learning_rate        | 0.00025      |
|    loss                 | -1.87        |
|    n_updates            | 14570        |
|    policy_gradient_loss | -0.00184     |
|    reward               | 7.791137e-06 |
|    std                  | 207          |
|    value_loss           | 6.98e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1976, ResetDay: 3656,Episode: 1778
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1459         |
|    time_elapsed         | 33031        |
|    total_timesteps      | 2988032      |
| train/                  |              |
|    approx_kl            | 3024.926     |
|    clip_fraction        | 0.0257       |
|    clip_range           | 0.2          |
|    entropy_loss         | -188         |
|    explained_variance   | 0.136        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.88        |
|    n_updates            | 14580        |
|    policy_gradient_loss | 0.00196      |
|    reward               | 7.511978e-05 |
|    std                  | 208          |
|    value_loss           | 6.69e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 954, ResetDay: 2634,Episode: 1779
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1460          |
|    time_elapsed         | 33054         |
|    total_timesteps      | 2990080       |
| train/                  |               |
|    approx_kl            | 3050.0671     |
|    clip_fraction        | 0.0284        |
|    clip_range           | 0.2           |
|    entropy_loss         | -188          |
|    explained_variance   | -0.0968       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.89         |
|    n_updates            | 14590         |
|    policy_gradient_loss | -0.00479      |
|    reward               | 4.0711213e-05 |
|    std                  | 208           |
|    value_loss           | 3.64e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2262, ResetDay: 3942,Episode: 1780
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1461          |
|    time_elapsed         | 33077         |
|    total_timesteps      | 2992128       |
| train/                  |               |
|    approx_kl            | 3080.2903     |
|    clip_fraction        | 0.0339        |
|    clip_range           | 0.2           |
|    entropy_loss         | -188          |
|    explained_variance   | 0.175         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.89         |
|    n_updates            | 14600         |
|    policy_gradient_loss | -0.00537      |
|    reward               | 0.00021297073 |
|    std                  | 209           |
|    value_loss           | 4.74e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3942, episode: 1780
begin_total_asset: 200.00
end_total_asset: 420.74
total_reward: 220.74
total_cost: 63.00
total_trades: 36300
Sharpe: 0.573
=================================
Reseting Environment StartDay: 325, ResetDay: 2005,Episode: 1781
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 918, ResetDay: 2598,Episode: 1782
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1462          |
|    time_elapsed         | 33099         |
|    total_timesteps      | 2994176       |
| train/                  |               |
|    approx_kl            | 3080.133      |
|    clip_fraction        | 0.0273        |
|    clip_range           | 0.2           |
|    entropy_loss         | -188          |
|    explained_variance   | 0.0921        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.88         |
|    n_updates            | 14610         |
|    policy_gradient_loss | -0.00574      |
|    reward               | 0.00018387337 |
|    std                  | 210           |
|    value_loss           | 1.86e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 34, ResetDay: 1714,Episode: 1783
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1463           |
|    time_elapsed         | 33122          |
|    total_timesteps      | 2996224        |
| train/                  |                |
|    approx_kl            | 3116.769       |
|    clip_fraction        | 0.0309         |
|    clip_range           | 0.2            |
|    entropy_loss         | -188           |
|    explained_variance   | -0.649         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.89          |
|    n_updates            | 14620          |
|    policy_gradient_loss | -0.00244       |
|    reward               | -0.00040556944 |
|    std                  | 210            |
|    value_loss           | 5.86e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1982, ResetDay: 3662,Episode: 1784
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1464          |
|    time_elapsed         | 33145         |
|    total_timesteps      | 2998272       |
| train/                  |               |
|    approx_kl            | 3130.117      |
|    clip_fraction        | 0.0232        |
|    clip_range           | 0.2           |
|    entropy_loss         | -188          |
|    explained_variance   | 0.143         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.87         |
|    n_updates            | 14630         |
|    policy_gradient_loss | -0.00208      |
|    reward               | 0.00020688649 |
|    std                  | 210           |
|    value_loss           | 7.2e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 717, ResetDay: 2397,Episode: 1785
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1465           |
|    time_elapsed         | 33167          |
|    total_timesteps      | 3000320        |
| train/                  |                |
|    approx_kl            | 3146.1235      |
|    clip_fraction        | 0.0283         |
|    clip_range           | 0.2            |
|    entropy_loss         | -188           |
|    explained_variance   | 0.257          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.87          |
|    n_updates            | 14640          |
|    policy_gradient_loss | 0.00304        |
|    reward               | -3.7565995e-05 |
|    std                  | 211            |
|    value_loss           | 1.16e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2397, episode: 1785
begin_total_asset: 200.00
end_total_asset: 70.50
total_reward: -129.50
total_cost: 46.67
total_trades: 36533
Sharpe: -0.213
=================================
Reseting Environment StartDay: 102, ResetDay: 1782,Episode: 1786
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2083, ResetDay: 3763,Episode: 1787
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1466          |
|    time_elapsed         | 33191         |
|    total_timesteps      | 3002368       |
| train/                  |               |
|    approx_kl            | 3167.657      |
|    clip_fraction        | 0.0291        |
|    clip_range           | 0.2           |
|    entropy_loss         | -188          |
|    explained_variance   | 0.0864        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.89         |
|    n_updates            | 14650         |
|    policy_gradient_loss | -0.00511      |
|    reward               | -9.726047e-06 |
|    std                  | 211           |
|    value_loss           | 1.65e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 368, ResetDay: 2048,Episode: 1788
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1467          |
|    time_elapsed         | 33214         |
|    total_timesteps      | 3004416       |
| train/                  |               |
|    approx_kl            | 3161.7954     |
|    clip_fraction        | 0.0306        |
|    clip_range           | 0.2           |
|    entropy_loss         | -188          |
|    explained_variance   | 0.0484        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.89         |
|    n_updates            | 14660         |
|    policy_gradient_loss | -0.00154      |
|    reward               | 0.00020394135 |
|    std                  | 211           |
|    value_loss           | 6.53e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1275, ResetDay: 2955,Episode: 1789
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1468          |
|    time_elapsed         | 33236         |
|    total_timesteps      | 3006464       |
| train/                  |               |
|    approx_kl            | 3164.7925     |
|    clip_fraction        | 0.0386        |
|    clip_range           | 0.2           |
|    entropy_loss         | -188          |
|    explained_variance   | 0.08          |
|    learning_rate        | 0.00025       |
|    loss                 | -1.91         |
|    n_updates            | 14670         |
|    policy_gradient_loss | -0.00613      |
|    reward               | 2.2281647e-05 |
|    std                  | 212           |
|    value_loss           | 2.5e-06       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2169, ResetDay: 3849,Episode: 1790
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1469          |
|    time_elapsed         | 33259         |
|    total_timesteps      | 3008512       |
| train/                  |               |
|    approx_kl            | 3197.026      |
|    clip_fraction        | 0.0309        |
|    clip_range           | 0.2           |
|    entropy_loss         | -188          |
|    explained_variance   | -0.171        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.88         |
|    n_updates            | 14680         |
|    policy_gradient_loss | -0.00647      |
|    reward               | 0.00014661255 |
|    std                  | 212           |
|    value_loss           | 4.34e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3849, episode: 1790
begin_total_asset: 200.00
end_total_asset: 353.42
total_reward: 153.42
total_cost: 27.59
total_trades: 36355
Sharpe: 0.462
=================================
Reseting Environment StartDay: 1484, ResetDay: 3164,Episode: 1791
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1470          |
|    time_elapsed         | 33281         |
|    total_timesteps      | 3010560       |
| train/                  |               |
|    approx_kl            | 3172.631      |
|    clip_fraction        | 0.0361        |
|    clip_range           | 0.2           |
|    entropy_loss         | -188          |
|    explained_variance   | 0.113         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.88         |
|    n_updates            | 14690         |
|    policy_gradient_loss | -0.00402      |
|    reward               | -0.0010218268 |
|    std                  | 212           |
|    value_loss           | 5.01e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1401, ResetDay: 3081,Episode: 1792
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1080, ResetDay: 2760,Episode: 1793
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1471         |
|    time_elapsed         | 33304        |
|    total_timesteps      | 3012608      |
| train/                  |              |
|    approx_kl            | 3182.8965    |
|    clip_fraction        | 0.029        |
|    clip_range           | 0.2          |
|    entropy_loss         | -188         |
|    explained_variance   | 0.0693       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.89        |
|    n_updates            | 14700        |
|    policy_gradient_loss | -0.00416     |
|    reward               | 0.0002500987 |
|    std                  | 212          |
|    value_loss           | 9.61e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 456, ResetDay: 2136,Episode: 1794
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1472          |
|    time_elapsed         | 33326         |
|    total_timesteps      | 3014656       |
| train/                  |               |
|    approx_kl            | 3187.8618     |
|    clip_fraction        | 0.0248        |
|    clip_range           | 0.2           |
|    entropy_loss         | -189          |
|    explained_variance   | -0.0379       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.88         |
|    n_updates            | 14710         |
|    policy_gradient_loss | -0.00143      |
|    reward               | 0.00049855385 |
|    std                  | 213           |
|    value_loss           | 4.13e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1645, ResetDay: 3325,Episode: 1795
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1473           |
|    time_elapsed         | 33349          |
|    total_timesteps      | 3016704        |
| train/                  |                |
|    approx_kl            | 3216.2378      |
|    clip_fraction        | 0.0323         |
|    clip_range           | 0.2            |
|    entropy_loss         | -189           |
|    explained_variance   | 0.285          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.89          |
|    n_updates            | 14720          |
|    policy_gradient_loss | -0.00499       |
|    reward               | -0.00024151555 |
|    std                  | 214            |
|    value_loss           | 3.17e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3325, episode: 1795
begin_total_asset: 200.00
end_total_asset: 332.36
total_reward: 132.36
total_cost: 32.61
total_trades: 36129
Sharpe: 0.439
=================================
Reseting Environment StartDay: 2127, ResetDay: 3807,Episode: 1796
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1474         |
|    time_elapsed         | 33371        |
|    total_timesteps      | 3018752      |
| train/                  |              |
|    approx_kl            | 3246.9194    |
|    clip_fraction        | 0.0279       |
|    clip_range           | 0.2          |
|    entropy_loss         | -189         |
|    explained_variance   | 0.326        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.89        |
|    n_updates            | 14730        |
|    policy_gradient_loss | -0.00179     |
|    reward               | 6.203079e-06 |
|    std                  | 214          |
|    value_loss           | 4.55e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 788, ResetDay: 2468,Episode: 1797
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1816, ResetDay: 3496,Episode: 1798
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1475          |
|    time_elapsed         | 33394         |
|    total_timesteps      | 3020800       |
| train/                  |               |
|    approx_kl            | 3240.9272     |
|    clip_fraction        | 0.0377        |
|    clip_range           | 0.2           |
|    entropy_loss         | -189          |
|    explained_variance   | 0.0789        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.91         |
|    n_updates            | 14740         |
|    policy_gradient_loss | -0.00422      |
|    reward               | 0.00086594495 |
|    std                  | 214           |
|    value_loss           | 5.29e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 67, ResetDay: 1747,Episode: 1799
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1476           |
|    time_elapsed         | 33416          |
|    total_timesteps      | 3022848        |
| train/                  |                |
|    approx_kl            | 3266.4973      |
|    clip_fraction        | 0.0245         |
|    clip_range           | 0.2            |
|    entropy_loss         | -189           |
|    explained_variance   | 0.0189         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.83          |
|    n_updates            | 14750          |
|    policy_gradient_loss | 0.0121         |
|    reward               | -5.4881653e-05 |
|    std                  | 214            |
|    value_loss           | 7.59e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1268, ResetDay: 2948,Episode: 1800
-----------------------------------------
| time/                   |             |
|    fps                  | 90          |
|    iterations           | 1477        |
|    time_elapsed         | 33439       |
|    total_timesteps      | 3024896     |
| train/                  |             |
|    approx_kl            | 3264.9526   |
|    clip_fraction        | 0.0285      |
|    clip_range           | 0.2         |
|    entropy_loss         | -189        |
|    explained_variance   | -0.0212     |
|    learning_rate        | 0.00025     |
|    loss                 | -1.89       |
|    n_updates            | 14760       |
|    policy_gradient_loss | -0.0054     |
|    reward               | 0.001581276 |
|    std                  | 215         |
|    value_loss           | 7.56e-07    |
-----------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2948, episode: 1800
begin_total_asset: 200.00
end_total_asset: 175.98
total_reward: -24.02
total_cost: 38.66
total_trades: 36215
Sharpe: 0.062
=================================
Reseting Environment StartDay: 2000, ResetDay: 3680,Episode: 1801
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1478         |
|    time_elapsed         | 33461        |
|    total_timesteps      | 3026944      |
| train/                  |              |
|    approx_kl            | 3253.1152    |
|    clip_fraction        | 0.034        |
|    clip_range           | 0.2          |
|    entropy_loss         | -189         |
|    explained_variance   | 0.238        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.89        |
|    n_updates            | 14770        |
|    policy_gradient_loss | -0.0038      |
|    reward               | 2.704773e-05 |
|    std                  | 216          |
|    value_loss           | 8.33e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1614, ResetDay: 3294,Episode: 1802
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1479          |
|    time_elapsed         | 33484         |
|    total_timesteps      | 3028992       |
| train/                  |               |
|    approx_kl            | 3271.982      |
|    clip_fraction        | 0.0294        |
|    clip_range           | 0.2           |
|    entropy_loss         | -189          |
|    explained_variance   | 0.124         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.9          |
|    n_updates            | 14780         |
|    policy_gradient_loss | 0.000422      |
|    reward               | -4.564991e-05 |
|    std                  | 217           |
|    value_loss           | 3.92e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1685, ResetDay: 3365,Episode: 1803
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2797, ResetDay: 4477,Episode: 1804
---------------------------------------------
| time/                   |                 |
|    fps                  | 90              |
|    iterations           | 1480            |
|    time_elapsed         | 33506           |
|    total_timesteps      | 3031040         |
| train/                  |                 |
|    approx_kl            | 3324.3188       |
|    clip_fraction        | 0.026           |
|    clip_range           | 0.2             |
|    entropy_loss         | -189            |
|    explained_variance   | 0.152           |
|    learning_rate        | 0.00025         |
|    loss                 | -1.9            |
|    n_updates            | 14790           |
|    policy_gradient_loss | 0.0023          |
|    reward               | -1.32835385e-05 |
|    std                  | 217             |
|    value_loss           | 9.79e-07        |
---------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1914, ResetDay: 3594,Episode: 1805
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1481           |
|    time_elapsed         | 33529          |
|    total_timesteps      | 3033088        |
| train/                  |                |
|    approx_kl            | 3318.8926      |
|    clip_fraction        | 0.0232         |
|    clip_range           | 0.2            |
|    entropy_loss         | -189           |
|    explained_variance   | 0.186          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.89          |
|    n_updates            | 14800          |
|    policy_gradient_loss | 0.00338        |
|    reward               | -0.00016711044 |
|    std                  | 217            |
|    value_loss           | 5.73e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3594, episode: 1805
begin_total_asset: 200.00
end_total_asset: 190.72
total_reward: -9.28
total_cost: 46.43
total_trades: 36056
Sharpe: 0.211
=================================
Reseting Environment StartDay: 1517, ResetDay: 3197,Episode: 1806
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1482          |
|    time_elapsed         | 33551         |
|    total_timesteps      | 3035136       |
| train/                  |               |
|    approx_kl            | 3342.8037     |
|    clip_fraction        | 0.0253        |
|    clip_range           | 0.2           |
|    entropy_loss         | -189          |
|    explained_variance   | 0.0152        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.89         |
|    n_updates            | 14810         |
|    policy_gradient_loss | -0.00368      |
|    reward               | 4.6319008e-05 |
|    std                  | 218           |
|    value_loss           | 7.55e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 917, ResetDay: 2597,Episode: 1807
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1483          |
|    time_elapsed         | 33574         |
|    total_timesteps      | 3037184       |
| train/                  |               |
|    approx_kl            | 3334.939      |
|    clip_fraction        | 0.0265        |
|    clip_range           | 0.2           |
|    entropy_loss         | -189          |
|    explained_variance   | 0.169         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.89         |
|    n_updates            | 14820         |
|    policy_gradient_loss | -0.000548     |
|    reward               | -1.809311e-05 |
|    std                  | 219           |
|    value_loss           | 3.1e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1098, ResetDay: 2778,Episode: 1808
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1484           |
|    time_elapsed         | 33596          |
|    total_timesteps      | 3039232        |
| train/                  |                |
|    approx_kl            | 3403.2515      |
|    clip_fraction        | 0.0236         |
|    clip_range           | 0.2            |
|    entropy_loss         | -189           |
|    explained_variance   | 0.266          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.9           |
|    n_updates            | 14830          |
|    policy_gradient_loss | -0.00401       |
|    reward               | -0.00018040562 |
|    std                  | 220            |
|    value_loss           | 3.53e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1153, ResetDay: 2833,Episode: 1809
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2205, ResetDay: 3885,Episode: 1810
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1485          |
|    time_elapsed         | 33619         |
|    total_timesteps      | 3041280       |
| train/                  |               |
|    approx_kl            | 3416.7732     |
|    clip_fraction        | 0.0248        |
|    clip_range           | 0.2           |
|    entropy_loss         | -190          |
|    explained_variance   | 0.28          |
|    learning_rate        | 0.00025       |
|    loss                 | -1.91         |
|    n_updates            | 14840         |
|    policy_gradient_loss | -0.000369     |
|    reward               | 2.8193665e-05 |
|    std                  | 220           |
|    value_loss           | 2.32e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3885, episode: 1810
begin_total_asset: 200.00
end_total_asset: 310.59
total_reward: 110.59
total_cost: 38.93
total_trades: 35975
Sharpe: 0.386
=================================
Reseting Environment StartDay: 1973, ResetDay: 3653,Episode: 1811
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1486           |
|    time_elapsed         | 33641          |
|    total_timesteps      | 3043328        |
| train/                  |                |
|    approx_kl            | 3394.9163      |
|    clip_fraction        | 0.0287         |
|    clip_range           | 0.2            |
|    entropy_loss         | -190           |
|    explained_variance   | 0.318          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.9           |
|    n_updates            | 14850          |
|    policy_gradient_loss | -0.00204       |
|    reward               | -0.00018414995 |
|    std                  | 221            |
|    value_loss           | 3.53e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1457, ResetDay: 3137,Episode: 1812
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1487          |
|    time_elapsed         | 33664         |
|    total_timesteps      | 3045376       |
| train/                  |               |
|    approx_kl            | 3450.0635     |
|    clip_fraction        | 0.026         |
|    clip_range           | 0.2           |
|    entropy_loss         | -190          |
|    explained_variance   | -0.00246      |
|    learning_rate        | 0.00025       |
|    loss                 | -1.91         |
|    n_updates            | 14860         |
|    policy_gradient_loss | -0.00252      |
|    reward               | -6.265545e-05 |
|    std                  | 222           |
|    value_loss           | 1.71e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 736, ResetDay: 2416,Episode: 1813
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1488           |
|    time_elapsed         | 33687          |
|    total_timesteps      | 3047424        |
| train/                  |                |
|    approx_kl            | 3455.4507      |
|    clip_fraction        | 0.0289         |
|    clip_range           | 0.2            |
|    entropy_loss         | -190           |
|    explained_variance   | 0.0569         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.91          |
|    n_updates            | 14870          |
|    policy_gradient_loss | -0.00258       |
|    reward               | -2.5343508e-05 |
|    std                  | 222            |
|    value_loss           | 3.26e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2549, ResetDay: 4229,Episode: 1814
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 717, ResetDay: 2397,Episode: 1815
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1489           |
|    time_elapsed         | 33709          |
|    total_timesteps      | 3049472        |
| train/                  |                |
|    approx_kl            | 3485.156       |
|    clip_fraction        | 0.0324         |
|    clip_range           | 0.2            |
|    entropy_loss         | -190           |
|    explained_variance   | 0.155          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.92          |
|    n_updates            | 14880          |
|    policy_gradient_loss | -0.000611      |
|    reward               | 0.000101448444 |
|    std                  | 223            |
|    value_loss           | 2.99e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2397, episode: 1815
begin_total_asset: 200.00
end_total_asset: 41.75
total_reward: -158.25
total_cost: 21.37
total_trades: 35714
Sharpe: -0.268
=================================
Reseting Environment StartDay: 1770, ResetDay: 3450,Episode: 1816
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1490          |
|    time_elapsed         | 33732         |
|    total_timesteps      | 3051520       |
| train/                  |               |
|    approx_kl            | 3512.1438     |
|    clip_fraction        | 0.0257        |
|    clip_range           | 0.2           |
|    entropy_loss         | -190          |
|    explained_variance   | 0.104         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.9          |
|    n_updates            | 14890         |
|    policy_gradient_loss | -0.00348      |
|    reward               | 2.4325562e-05 |
|    std                  | 224           |
|    value_loss           | 1.74e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2463, ResetDay: 4143,Episode: 1817
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1491         |
|    time_elapsed         | 33754        |
|    total_timesteps      | 3053568      |
| train/                  |              |
|    approx_kl            | 3527.627     |
|    clip_fraction        | 0.0305       |
|    clip_range           | 0.2          |
|    entropy_loss         | -190         |
|    explained_variance   | -0.741       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.89        |
|    n_updates            | 14900        |
|    policy_gradient_loss | 0.000813     |
|    reward               | 7.902908e-05 |
|    std                  | 225          |
|    value_loss           | 2.45e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 607, ResetDay: 2287,Episode: 1818
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1492          |
|    time_elapsed         | 33777         |
|    total_timesteps      | 3055616       |
| train/                  |               |
|    approx_kl            | 3584.0156     |
|    clip_fraction        | 0.021         |
|    clip_range           | 0.2           |
|    entropy_loss         | -190          |
|    explained_variance   | 0.173         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.92         |
|    n_updates            | 14910         |
|    policy_gradient_loss | 0.00151       |
|    reward               | 2.5952339e-05 |
|    std                  | 225           |
|    value_loss           | 4.38e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1323, ResetDay: 3003,Episode: 1819
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1493          |
|    time_elapsed         | 33799         |
|    total_timesteps      | 3057664       |
| train/                  |               |
|    approx_kl            | 3571.6482     |
|    clip_fraction        | 0.0171        |
|    clip_range           | 0.2           |
|    entropy_loss         | -190          |
|    explained_variance   | -0.0164       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.89         |
|    n_updates            | 14920         |
|    policy_gradient_loss | 0.00404       |
|    reward               | -5.350876e-05 |
|    std                  | 225           |
|    value_loss           | 1.3e-06       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1967, ResetDay: 3647,Episode: 1820
Environment reached Terminal state as number of trading days reached limit!!
day: 3647, episode: 1820
begin_total_asset: 200.00
end_total_asset: 289.86
total_reward: 89.86
total_cost: 36.97
total_trades: 35648
Sharpe: 0.361
=================================
Reseting Environment StartDay: 124, ResetDay: 1804,Episode: 1821
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1494          |
|    time_elapsed         | 33822         |
|    total_timesteps      | 3059712       |
| train/                  |               |
|    approx_kl            | 3584.5422     |
|    clip_fraction        | 0.0265        |
|    clip_range           | 0.2           |
|    entropy_loss         | -190          |
|    explained_variance   | -0.0942       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.92         |
|    n_updates            | 14930         |
|    policy_gradient_loss | -0.00471      |
|    reward               | 9.0678404e-05 |
|    std                  | 226           |
|    value_loss           | 2.43e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2622, ResetDay: 4302,Episode: 1822
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1495         |
|    time_elapsed         | 33845        |
|    total_timesteps      | 3061760      |
| train/                  |              |
|    approx_kl            | 3609.292     |
|    clip_fraction        | 0.0293       |
|    clip_range           | 0.2          |
|    entropy_loss         | -190         |
|    explained_variance   | 0.134        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.9         |
|    n_updates            | 14940        |
|    policy_gradient_loss | -0.00776     |
|    reward               | -0.000412191 |
|    std                  | 227          |
|    value_loss           | 7.37e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1529, ResetDay: 3209,Episode: 1823
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1496          |
|    time_elapsed         | 33867         |
|    total_timesteps      | 3063808       |
| train/                  |               |
|    approx_kl            | 3664.3008     |
|    clip_fraction        | 0.019         |
|    clip_range           | 0.2           |
|    entropy_loss         | -190          |
|    explained_variance   | 0.205         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.9          |
|    n_updates            | 14950         |
|    policy_gradient_loss | -0.00227      |
|    reward               | 0.00013322945 |
|    std                  | 227           |
|    value_loss           | 1.19e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2561, ResetDay: 4241,Episode: 1824
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1497           |
|    time_elapsed         | 33890          |
|    total_timesteps      | 3065856        |
| train/                  |                |
|    approx_kl            | 3650.0178      |
|    clip_fraction        | 0.026          |
|    clip_range           | 0.2            |
|    entropy_loss         | -190           |
|    explained_variance   | 0.0479         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.9           |
|    n_updates            | 14960          |
|    policy_gradient_loss | -0.00713       |
|    reward               | -2.9901123e-05 |
|    std                  | 228            |
|    value_loss           | 4.65e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1553, ResetDay: 3233,Episode: 1825
Environment reached Terminal state as number of trading days reached limit!!
day: 3233, episode: 1825
begin_total_asset: 200.00
end_total_asset: 132.76
total_reward: -67.24
total_cost: 18.13
total_trades: 35494
Sharpe: 0.114
=================================
Reseting Environment StartDay: 2356, ResetDay: 4036,Episode: 1826
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1498          |
|    time_elapsed         | 33913         |
|    total_timesteps      | 3067904       |
| train/                  |               |
|    approx_kl            | 3675.963      |
|    clip_fraction        | 0.0235        |
|    clip_range           | 0.2           |
|    entropy_loss         | -191          |
|    explained_variance   | -0.0736       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.91         |
|    n_updates            | 14970         |
|    policy_gradient_loss | 0.00049       |
|    reward               | 0.00012429123 |
|    std                  | 228           |
|    value_loss           | 5.87e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1526, ResetDay: 3206,Episode: 1827
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1499          |
|    time_elapsed         | 33935         |
|    total_timesteps      | 3069952       |
| train/                  |               |
|    approx_kl            | 3693.189      |
|    clip_fraction        | 0.0213        |
|    clip_range           | 0.2           |
|    entropy_loss         | -191          |
|    explained_variance   | -0.269        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.9          |
|    n_updates            | 14980         |
|    policy_gradient_loss | 0.00125       |
|    reward               | -3.657341e-06 |
|    std                  | 229           |
|    value_loss           | 3.86e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1231, ResetDay: 2911,Episode: 1828
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1500           |
|    time_elapsed         | 33957          |
|    total_timesteps      | 3072000        |
| train/                  |                |
|    approx_kl            | 3703.0076      |
|    clip_fraction        | 0.0253         |
|    clip_range           | 0.2            |
|    entropy_loss         | -191           |
|    explained_variance   | 0.119          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.91          |
|    n_updates            | 14990          |
|    policy_gradient_loss | 0.000472       |
|    reward               | -1.3276005e-05 |
|    std                  | 230            |
|    value_loss           | 9.89e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 335, ResetDay: 2015,Episode: 1829
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1501         |
|    time_elapsed         | 33980        |
|    total_timesteps      | 3074048      |
| train/                  |              |
|    approx_kl            | 3727.7192    |
|    clip_fraction        | 0.026        |
|    clip_range           | 0.2          |
|    entropy_loss         | -191         |
|    explained_variance   | -0.282       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.9         |
|    n_updates            | 15000        |
|    policy_gradient_loss | -0.00166     |
|    reward               | 0.0003170127 |
|    std                  | 231          |
|    value_loss           | 3.57e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 767, ResetDay: 2447,Episode: 1830
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1502           |
|    time_elapsed         | 34003          |
|    total_timesteps      | 3076096        |
| train/                  |                |
|    approx_kl            | 3760.0771      |
|    clip_fraction        | 0.0194         |
|    clip_range           | 0.2            |
|    entropy_loss         | -191           |
|    explained_variance   | 0.175          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.9           |
|    n_updates            | 15010          |
|    policy_gradient_loss | 0.000887       |
|    reward               | -6.8434047e-06 |
|    std                  | 231            |
|    value_loss           | 3.49e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2447, episode: 1830
begin_total_asset: 200.00
end_total_asset: 106.83
total_reward: -93.17
total_cost: 39.69
total_trades: 35597
Sharpe: -0.091
=================================
Reseting Environment StartDay: 635, ResetDay: 2315,Episode: 1831
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 269, ResetDay: 1949,Episode: 1832
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1503           |
|    time_elapsed         | 34025          |
|    total_timesteps      | 3078144        |
| train/                  |                |
|    approx_kl            | 3803.669       |
|    clip_fraction        | 0.0275         |
|    clip_range           | 0.2            |
|    entropy_loss         | -191           |
|    explained_variance   | 0.353          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.92          |
|    n_updates            | 15020          |
|    policy_gradient_loss | -0.00619       |
|    reward               | -3.0330227e-06 |
|    std                  | 232            |
|    value_loss           | 2.46e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1514, ResetDay: 3194,Episode: 1833
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1504           |
|    time_elapsed         | 34048          |
|    total_timesteps      | 3080192        |
| train/                  |                |
|    approx_kl            | 3849.9114      |
|    clip_fraction        | 0.0215         |
|    clip_range           | 0.2            |
|    entropy_loss         | -191           |
|    explained_variance   | -0.0685        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.92          |
|    n_updates            | 15030          |
|    policy_gradient_loss | -0.00288       |
|    reward               | -0.00012254906 |
|    std                  | 233            |
|    value_loss           | 6.49e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 421, ResetDay: 2101,Episode: 1834
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1505          |
|    time_elapsed         | 34070         |
|    total_timesteps      | 3082240       |
| train/                  |               |
|    approx_kl            | 3872.9436     |
|    clip_fraction        | 0.0217        |
|    clip_range           | 0.2           |
|    entropy_loss         | -191          |
|    explained_variance   | 0.233         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.9          |
|    n_updates            | 15040         |
|    policy_gradient_loss | -0.00271      |
|    reward               | 6.4811706e-05 |
|    std                  | 233           |
|    value_loss           | 3.78e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2793, ResetDay: 4473,Episode: 1835
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1506         |
|    time_elapsed         | 34093        |
|    total_timesteps      | 3084288      |
| train/                  |              |
|    approx_kl            | 3840.5166    |
|    clip_fraction        | 0.0217       |
|    clip_range           | 0.2          |
|    entropy_loss         | -191         |
|    explained_variance   | 0.111        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.92        |
|    n_updates            | 15050        |
|    policy_gradient_loss | -0.00191     |
|    reward               | 0.0002751629 |
|    std                  | 234          |
|    value_loss           | 5.47e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4473, episode: 1835
begin_total_asset: 200.00
end_total_asset: 437.23
total_reward: 237.23
total_cost: 78.86
total_trades: 35643
Sharpe: 0.566
=================================
Reseting Environment StartDay: 585, ResetDay: 2265,Episode: 1836
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 474, ResetDay: 2154,Episode: 1837
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1507         |
|    time_elapsed         | 34115        |
|    total_timesteps      | 3086336      |
| train/                  |              |
|    approx_kl            | 3897.4934    |
|    clip_fraction        | 0.0251       |
|    clip_range           | 0.2          |
|    entropy_loss         | -191         |
|    explained_variance   | 0.0733       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.91        |
|    n_updates            | 15060        |
|    policy_gradient_loss | -0.00379     |
|    reward               | 5.272947e-05 |
|    std                  | 234          |
|    value_loss           | 2.15e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 862, ResetDay: 2542,Episode: 1838
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1508          |
|    time_elapsed         | 34138         |
|    total_timesteps      | 3088384       |
| train/                  |               |
|    approx_kl            | 3905.2583     |
|    clip_fraction        | 0.0266        |
|    clip_range           | 0.2           |
|    entropy_loss         | -191          |
|    explained_variance   | -0.206        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.91         |
|    n_updates            | 15070         |
|    policy_gradient_loss | -0.00379      |
|    reward               | 1.4668537e-05 |
|    std                  | 235           |
|    value_loss           | 1.13e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1647, ResetDay: 3327,Episode: 1839
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1509         |
|    time_elapsed         | 34160        |
|    total_timesteps      | 3090432      |
| train/                  |              |
|    approx_kl            | 3925.0913    |
|    clip_fraction        | 0.0212       |
|    clip_range           | 0.2          |
|    entropy_loss         | -191         |
|    explained_variance   | 0.253        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.9         |
|    n_updates            | 15080        |
|    policy_gradient_loss | 0.00359      |
|    reward               | 8.027649e-05 |
|    std                  | 236          |
|    value_loss           | 3.92e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1986, ResetDay: 3666,Episode: 1840
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1510          |
|    time_elapsed         | 34183         |
|    total_timesteps      | 3092480       |
| train/                  |               |
|    approx_kl            | 3944.6455     |
|    clip_fraction        | 0.0294        |
|    clip_range           | 0.2           |
|    entropy_loss         | -191          |
|    explained_variance   | 0.242         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.91         |
|    n_updates            | 15090         |
|    policy_gradient_loss | -0.00797      |
|    reward               | 2.7056885e-05 |
|    std                  | 236           |
|    value_loss           | 2.7e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3666, episode: 1840
begin_total_asset: 200.00
end_total_asset: 322.36
total_reward: 122.36
total_cost: 25.43
total_trades: 35279
Sharpe: 0.421
=================================
Reseting Environment StartDay: 1283, ResetDay: 2963,Episode: 1841
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1511           |
|    time_elapsed         | 34205          |
|    total_timesteps      | 3094528        |
| train/                  |                |
|    approx_kl            | 3963.2437      |
|    clip_fraction        | 0.0241         |
|    clip_range           | 0.2            |
|    entropy_loss         | -192           |
|    explained_variance   | 0.167          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.93          |
|    n_updates            | 15100          |
|    policy_gradient_loss | -0.000223      |
|    reward               | -0.00013593578 |
|    std                  | 237            |
|    value_loss           | 4.74e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 831, ResetDay: 2511,Episode: 1842
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2096, ResetDay: 3776,Episode: 1843
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1512         |
|    time_elapsed         | 34228        |
|    total_timesteps      | 3096576      |
| train/                  |              |
|    approx_kl            | 3989.6816    |
|    clip_fraction        | 0.0238       |
|    clip_range           | 0.2          |
|    entropy_loss         | -192         |
|    explained_variance   | 0.141        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.93        |
|    n_updates            | 15110        |
|    policy_gradient_loss | 0.00681      |
|    reward               | 6.157837e-05 |
|    std                  | 238          |
|    value_loss           | 6.15e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 325, ResetDay: 2005,Episode: 1844
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1513           |
|    time_elapsed         | 34251          |
|    total_timesteps      | 3098624        |
| train/                  |                |
|    approx_kl            | 4007.5186      |
|    clip_fraction        | 0.0254         |
|    clip_range           | 0.2            |
|    entropy_loss         | -192           |
|    explained_variance   | -0.0484        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.92          |
|    n_updates            | 15120          |
|    policy_gradient_loss | -0.00109       |
|    reward               | -0.00044547042 |
|    std                  | 239            |
|    value_loss           | 2.95e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1909, ResetDay: 3589,Episode: 1845
---------------------------------------
| time/                   |           |
|    fps                  | 90        |
|    iterations           | 1514      |
|    time_elapsed         | 34274     |
|    total_timesteps      | 3100672   |
| train/                  |           |
|    approx_kl            | 4092.2454 |
|    clip_fraction        | 0.0257    |
|    clip_range           | 0.2       |
|    entropy_loss         | -192      |
|    explained_variance   | 0.111     |
|    learning_rate        | 0.00025   |
|    loss                 | -1.93     |
|    n_updates            | 15130     |
|    policy_gradient_loss | -0.00223  |
|    reward               | 0.0       |
|    std                  | 240       |
|    value_loss           | 1.52e-06  |
---------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3589, episode: 1845
begin_total_asset: 200.00
end_total_asset: 568.43
total_reward: 368.43
total_cost: 44.89
total_trades: 35094
Sharpe: 0.834
=================================
Reseting Environment StartDay: 2678, ResetDay: 4358,Episode: 1846
---------------------------------------
| time/                   |           |
|    fps                  | 90        |
|    iterations           | 1515      |
|    time_elapsed         | 34296     |
|    total_timesteps      | 3102720   |
| train/                  |           |
|    approx_kl            | 4073.8093 |
|    clip_fraction        | 0.0254    |
|    clip_range           | 0.2       |
|    entropy_loss         | -192      |
|    explained_variance   | 0.138     |
|    learning_rate        | 0.00025   |
|    loss                 | -1.91     |
|    n_updates            | 15140     |
|    policy_gradient_loss | 0.00235   |
|    reward               | 0.0       |
|    std                  | 241       |
|    value_loss           | 6.44e-07  |
---------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1063, ResetDay: 2743,Episode: 1847
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1516         |
|    time_elapsed         | 34319        |
|    total_timesteps      | 3104768      |
| train/                  |              |
|    approx_kl            | 4156.4756    |
|    clip_fraction        | 0.0147       |
|    clip_range           | 0.2          |
|    entropy_loss         | -192         |
|    explained_variance   | 0.138        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.91        |
|    n_updates            | 15150        |
|    policy_gradient_loss | 0.00246      |
|    reward               | 0.0001097929 |
|    std                  | 241          |
|    value_loss           | 1.14e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 516, ResetDay: 2196,Episode: 1848
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1726, ResetDay: 3406,Episode: 1849
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1517          |
|    time_elapsed         | 34341         |
|    total_timesteps      | 3106816       |
| train/                  |               |
|    approx_kl            | 4159.8184     |
|    clip_fraction        | 0.0238        |
|    clip_range           | 0.2           |
|    entropy_loss         | -192          |
|    explained_variance   | -0.851        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.91         |
|    n_updates            | 15160         |
|    policy_gradient_loss | -0.000634     |
|    reward               | 0.00014750518 |
|    std                  | 242           |
|    value_loss           | 3.73e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1186, ResetDay: 2866,Episode: 1850
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1518           |
|    time_elapsed         | 34364          |
|    total_timesteps      | 3108864        |
| train/                  |                |
|    approx_kl            | 4153.836       |
|    clip_fraction        | 0.0266         |
|    clip_range           | 0.2            |
|    entropy_loss         | -192           |
|    explained_variance   | 0.294          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.93          |
|    n_updates            | 15170          |
|    policy_gradient_loss | 0.00405        |
|    reward               | -5.0155468e-05 |
|    std                  | 243            |
|    value_loss           | 5.02e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2866, episode: 1850
begin_total_asset: 200.00
end_total_asset: 100.66
total_reward: -99.34
total_cost: 24.76
total_trades: 34940
Sharpe: -0.098
=================================
Reseting Environment StartDay: 853, ResetDay: 2533,Episode: 1851
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1519          |
|    time_elapsed         | 34388         |
|    total_timesteps      | 3110912       |
| train/                  |               |
|    approx_kl            | 4214.9326     |
|    clip_fraction        | 0.022         |
|    clip_range           | 0.2           |
|    entropy_loss         | -192          |
|    explained_variance   | 0.0835        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.93         |
|    n_updates            | 15180         |
|    policy_gradient_loss | 0.000584      |
|    reward               | -9.804392e-05 |
|    std                  | 244           |
|    value_loss           | 4.58e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 996, ResetDay: 2676,Episode: 1852
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1520          |
|    time_elapsed         | 34410         |
|    total_timesteps      | 3112960       |
| train/                  |               |
|    approx_kl            | 4254.868      |
|    clip_fraction        | 0.0208        |
|    clip_range           | 0.2           |
|    entropy_loss         | -192          |
|    explained_variance   | 0.313         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.93         |
|    n_updates            | 15190         |
|    policy_gradient_loss | -0.00359      |
|    reward               | 6.9473645e-05 |
|    std                  | 245           |
|    value_loss           | 3.52e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2071, ResetDay: 3751,Episode: 1853
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 538, ResetDay: 2218,Episode: 1854
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1521          |
|    time_elapsed         | 34433         |
|    total_timesteps      | 3115008       |
| train/                  |               |
|    approx_kl            | 4315.1113     |
|    clip_fraction        | 0.024         |
|    clip_range           | 0.2           |
|    entropy_loss         | -192          |
|    explained_variance   | 0.134         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.92         |
|    n_updates            | 15200         |
|    policy_gradient_loss | 3.45e-05      |
|    reward               | 9.3809984e-05 |
|    std                  | 246           |
|    value_loss           | 3.1e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2230, ResetDay: 3910,Episode: 1855
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1522           |
|    time_elapsed         | 34456          |
|    total_timesteps      | 3117056        |
| train/                  |                |
|    approx_kl            | 4306.501       |
|    clip_fraction        | 0.0196         |
|    clip_range           | 0.2            |
|    entropy_loss         | -193           |
|    explained_variance   | 0.0504         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.94          |
|    n_updates            | 15210          |
|    policy_gradient_loss | -0.000268      |
|    reward               | -0.00055565225 |
|    std                  | 246            |
|    value_loss           | 1.56e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3910, episode: 1855
begin_total_asset: 200.00
end_total_asset: 387.50
total_reward: 187.50
total_cost: 41.46
total_trades: 35003
Sharpe: 0.523
=================================
Reseting Environment StartDay: 75, ResetDay: 1755,Episode: 1856
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1523           |
|    time_elapsed         | 34478          |
|    total_timesteps      | 3119104        |
| train/                  |                |
|    approx_kl            | 4372.834       |
|    clip_fraction        | 0.0207         |
|    clip_range           | 0.2            |
|    entropy_loss         | -193           |
|    explained_variance   | -0.197         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.94          |
|    n_updates            | 15220          |
|    policy_gradient_loss | -0.00296       |
|    reward               | -0.00070716377 |
|    std                  | 247            |
|    value_loss           | 3.24e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2644, ResetDay: 4324,Episode: 1857
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1524          |
|    time_elapsed         | 34501         |
|    total_timesteps      | 3121152       |
| train/                  |               |
|    approx_kl            | 4386.213      |
|    clip_fraction        | 0.0252        |
|    clip_range           | 0.2           |
|    entropy_loss         | -193          |
|    explained_variance   | 0.116         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.93         |
|    n_updates            | 15230         |
|    policy_gradient_loss | 0.000959      |
|    reward               | 0.00067223434 |
|    std                  | 247           |
|    value_loss           | 2.17e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2536, ResetDay: 4216,Episode: 1858
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1525         |
|    time_elapsed         | 34524        |
|    total_timesteps      | 3123200      |
| train/                  |              |
|    approx_kl            | 4367.712     |
|    clip_fraction        | 0.022        |
|    clip_range           | 0.2          |
|    entropy_loss         | -193         |
|    explained_variance   | 0.148        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.93        |
|    n_updates            | 15240        |
|    policy_gradient_loss | -0.0034      |
|    reward               | 7.165718e-05 |
|    std                  | 248          |
|    value_loss           | 2.08e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 959, ResetDay: 2639,Episode: 1859
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 721, ResetDay: 2401,Episode: 1860
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1526           |
|    time_elapsed         | 34546          |
|    total_timesteps      | 3125248        |
| train/                  |                |
|    approx_kl            | 4428.7188      |
|    clip_fraction        | 0.014          |
|    clip_range           | 0.2            |
|    entropy_loss         | -193           |
|    explained_variance   | -0.0108        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.94          |
|    n_updates            | 15250          |
|    policy_gradient_loss | -0.00625       |
|    reward               | -0.00016705751 |
|    std                  | 248            |
|    value_loss           | 2.09e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2401, episode: 1860
begin_total_asset: 200.00
end_total_asset: 58.01
total_reward: -141.99
total_cost: 44.54
total_trades: 35243
Sharpe: -0.270
=================================
Reseting Environment StartDay: 427, ResetDay: 2107,Episode: 1861
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1527           |
|    time_elapsed         | 34569          |
|    total_timesteps      | 3127296        |
| train/                  |                |
|    approx_kl            | 4403.189       |
|    clip_fraction        | 0.02           |
|    clip_range           | 0.2            |
|    entropy_loss         | -193           |
|    explained_variance   | -1             |
|    learning_rate        | 0.00025        |
|    loss                 | -1.92          |
|    n_updates            | 15260          |
|    policy_gradient_loss | -0.0018        |
|    reward               | -0.00025372612 |
|    std                  | 249            |
|    value_loss           | 5.72e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 595, ResetDay: 2275,Episode: 1862
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1528          |
|    time_elapsed         | 34591         |
|    total_timesteps      | 3129344       |
| train/                  |               |
|    approx_kl            | 4430.991      |
|    clip_fraction        | 0.0217        |
|    clip_range           | 0.2           |
|    entropy_loss         | -193          |
|    explained_variance   | 0.175         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.94         |
|    n_updates            | 15270         |
|    policy_gradient_loss | -0.00107      |
|    reward               | -0.0001426406 |
|    std                  | 250           |
|    value_loss           | 3.98e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1288, ResetDay: 2968,Episode: 1863
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1529           |
|    time_elapsed         | 34614          |
|    total_timesteps      | 3131392        |
| train/                  |                |
|    approx_kl            | 4466.0557      |
|    clip_fraction        | 0.0187         |
|    clip_range           | 0.2            |
|    entropy_loss         | -193           |
|    explained_variance   | 0.357          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.95          |
|    n_updates            | 15280          |
|    policy_gradient_loss | 0.00143        |
|    reward               | -0.00010502014 |
|    std                  | 251            |
|    value_loss           | 3.22e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1726, ResetDay: 3406,Episode: 1864
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2763, ResetDay: 4443,Episode: 1865
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1530          |
|    time_elapsed         | 34636         |
|    total_timesteps      | 3133440       |
| train/                  |               |
|    approx_kl            | 4532.0894     |
|    clip_fraction        | 0.0207        |
|    clip_range           | 0.2           |
|    entropy_loss         | -193          |
|    explained_variance   | 0.176         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.94         |
|    n_updates            | 15290         |
|    policy_gradient_loss | -0.00158      |
|    reward               | -7.686901e-05 |
|    std                  | 252           |
|    value_loss           | 2.02e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4443, episode: 1865
begin_total_asset: 200.00
end_total_asset: 211.38
total_reward: 11.38
total_cost: 55.57
total_trades: 34746
Sharpe: 0.178
=================================
Reseting Environment StartDay: 2490, ResetDay: 4170,Episode: 1866
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1531          |
|    time_elapsed         | 34658         |
|    total_timesteps      | 3135488       |
| train/                  |               |
|    approx_kl            | 4571.967      |
|    clip_fraction        | 0.0201        |
|    clip_range           | 0.2           |
|    entropy_loss         | -193          |
|    explained_variance   | 0.102         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.93         |
|    n_updates            | 15300         |
|    policy_gradient_loss | -0.00532      |
|    reward               | -5.927353e-05 |
|    std                  | 253           |
|    value_loss           | 4.07e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2403, ResetDay: 4083,Episode: 1867
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1532           |
|    time_elapsed         | 34681          |
|    total_timesteps      | 3137536        |
| train/                  |                |
|    approx_kl            | 4562.83        |
|    clip_fraction        | 0.0215         |
|    clip_range           | 0.2            |
|    entropy_loss         | -193           |
|    explained_variance   | 0.047          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.94          |
|    n_updates            | 15310          |
|    policy_gradient_loss | 0.000285       |
|    reward               | -0.00017480279 |
|    std                  | 253            |
|    value_loss           | 1.17e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1671, ResetDay: 3351,Episode: 1868
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1533          |
|    time_elapsed         | 34703         |
|    total_timesteps      | 3139584       |
| train/                  |               |
|    approx_kl            | 4588.5566     |
|    clip_fraction        | 0.0248        |
|    clip_range           | 0.2           |
|    entropy_loss         | -193          |
|    explained_variance   | 0.186         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.94         |
|    n_updates            | 15320         |
|    policy_gradient_loss | -0.00251      |
|    reward               | -0.0005947208 |
|    std                  | 254           |
|    value_loss           | 8.26e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 842, ResetDay: 2522,Episode: 1869
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1534         |
|    time_elapsed         | 34726        |
|    total_timesteps      | 3141632      |
| train/                  |              |
|    approx_kl            | 4631.4473    |
|    clip_fraction        | 0.0194       |
|    clip_range           | 0.2          |
|    entropy_loss         | -193         |
|    explained_variance   | 0.067        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.94        |
|    n_updates            | 15330        |
|    policy_gradient_loss | -0.000194    |
|    reward               | 7.662201e-06 |
|    std                  | 255          |
|    value_loss           | 7.53e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1062, ResetDay: 2742,Episode: 1870
Environment reached Terminal state as number of trading days reached limit!!
day: 2742, episode: 1870
begin_total_asset: 200.00
end_total_asset: 84.11
total_reward: -115.89
total_cost: 21.19
total_trades: 34616
Sharpe: -0.120
=================================
Reseting Environment StartDay: 2465, ResetDay: 4145,Episode: 1871
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1535          |
|    time_elapsed         | 34749         |
|    total_timesteps      | 3143680       |
| train/                  |               |
|    approx_kl            | 4630.803      |
|    clip_fraction        | 0.0187        |
|    clip_range           | 0.2           |
|    entropy_loss         | -194          |
|    explained_variance   | -0.227        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.94         |
|    n_updates            | 15340         |
|    policy_gradient_loss | 0.00117       |
|    reward               | -0.0011600017 |
|    std                  | 255           |
|    value_loss           | 3.48e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 957, ResetDay: 2637,Episode: 1872
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1536          |
|    time_elapsed         | 34771         |
|    total_timesteps      | 3145728       |
| train/                  |               |
|    approx_kl            | 4671.3135     |
|    clip_fraction        | 0.0254        |
|    clip_range           | 0.2           |
|    entropy_loss         | -194          |
|    explained_variance   | 0.0425        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.93         |
|    n_updates            | 15350         |
|    policy_gradient_loss | -0.00114      |
|    reward               | 1.2724971e-05 |
|    std                  | 256           |
|    value_loss           | 2.9e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 898, ResetDay: 2578,Episode: 1873
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1537           |
|    time_elapsed         | 34794          |
|    total_timesteps      | 3147776        |
| train/                  |                |
|    approx_kl            | 4692.796       |
|    clip_fraction        | 0.0168         |
|    clip_range           | 0.2            |
|    entropy_loss         | -194           |
|    explained_variance   | 0.0737         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.94          |
|    n_updates            | 15360          |
|    policy_gradient_loss | -0.00304       |
|    reward               | -0.00047940284 |
|    std                  | 256            |
|    value_loss           | 1.71e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1597, ResetDay: 3277,Episode: 1874
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1538          |
|    time_elapsed         | 34816         |
|    total_timesteps      | 3149824       |
| train/                  |               |
|    approx_kl            | 4650.0894     |
|    clip_fraction        | 0.0217        |
|    clip_range           | 0.2           |
|    entropy_loss         | -194          |
|    explained_variance   | -0.496        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.96         |
|    n_updates            | 15370         |
|    policy_gradient_loss | 0.00106       |
|    reward               | 0.00014489594 |
|    std                  | 257           |
|    value_loss           | 3.51e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2088, ResetDay: 3768,Episode: 1875
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1539         |
|    time_elapsed         | 34838        |
|    total_timesteps      | 3151872      |
| train/                  |              |
|    approx_kl            | 4715.381     |
|    clip_fraction        | 0.0234       |
|    clip_range           | 0.2          |
|    entropy_loss         | -194         |
|    explained_variance   | 0.19         |
|    learning_rate        | 0.00025      |
|    loss                 | -1.96        |
|    n_updates            | 15380        |
|    policy_gradient_loss | -0.00327     |
|    reward               | 0.0008845894 |
|    std                  | 258          |
|    value_loss           | 3.37e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3768, episode: 1875
begin_total_asset: 200.00
end_total_asset: 195.33
total_reward: -4.67
total_cost: 27.66
total_trades: 34457
Sharpe: 0.133
=================================
Reseting Environment StartDay: 1383, ResetDay: 3063,Episode: 1876
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2581, ResetDay: 4261,Episode: 1877
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1540          |
|    time_elapsed         | 34861         |
|    total_timesteps      | 3153920       |
| train/                  |               |
|    approx_kl            | 4712.6475     |
|    clip_fraction        | 0.0247        |
|    clip_range           | 0.2           |
|    entropy_loss         | -194          |
|    explained_variance   | 0.152         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.95         |
|    n_updates            | 15390         |
|    policy_gradient_loss | -0.00318      |
|    reward               | 5.4335404e-05 |
|    std                  | 259           |
|    value_loss           | 9.11e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1650, ResetDay: 3330,Episode: 1878
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1541          |
|    time_elapsed         | 34883         |
|    total_timesteps      | 3155968       |
| train/                  |               |
|    approx_kl            | 4773.579      |
|    clip_fraction        | 0.0205        |
|    clip_range           | 0.2           |
|    entropy_loss         | -194          |
|    explained_variance   | -0.0839       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.94         |
|    n_updates            | 15400         |
|    policy_gradient_loss | -0.00177      |
|    reward               | 2.4515533e-05 |
|    std                  | 260           |
|    value_loss           | 4.06e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2566, ResetDay: 4246,Episode: 1879
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1542          |
|    time_elapsed         | 34906         |
|    total_timesteps      | 3158016       |
| train/                  |               |
|    approx_kl            | 4847.1714     |
|    clip_fraction        | 0.0196        |
|    clip_range           | 0.2           |
|    entropy_loss         | -194          |
|    explained_variance   | 0.0943        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.95         |
|    n_updates            | 15410         |
|    policy_gradient_loss | -0.00346      |
|    reward               | 0.00036859818 |
|    std                  | 261           |
|    value_loss           | 1.18e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 64, ResetDay: 1744,Episode: 1880
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1543           |
|    time_elapsed         | 34928          |
|    total_timesteps      | 3160064        |
| train/                  |                |
|    approx_kl            | 4931.372       |
|    clip_fraction        | 0.0191         |
|    clip_range           | 0.2            |
|    entropy_loss         | -194           |
|    explained_variance   | 0.215          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.94          |
|    n_updates            | 15420          |
|    policy_gradient_loss | 0.00546        |
|    reward               | -9.3320465e-05 |
|    std                  | 261            |
|    value_loss           | 4.75e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 1744, episode: 1880
begin_total_asset: 200.00
end_total_asset: 60.72
total_reward: -139.28
total_cost: 40.65
total_trades: 34733
Sharpe: -0.120
=================================
Reseting Environment StartDay: 225, ResetDay: 1905,Episode: 1881
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2555, ResetDay: 4235,Episode: 1882
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1544           |
|    time_elapsed         | 34951          |
|    total_timesteps      | 3162112        |
| train/                  |                |
|    approx_kl            | 4833.0254      |
|    clip_fraction        | 0.0212         |
|    clip_range           | 0.2            |
|    entropy_loss         | -194           |
|    explained_variance   | -0.105         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.96          |
|    n_updates            | 15430          |
|    policy_gradient_loss | -0.00458       |
|    reward               | -0.00024822558 |
|    std                  | 262            |
|    value_loss           | 7.87e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1410, ResetDay: 3090,Episode: 1883
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1545          |
|    time_elapsed         | 34974         |
|    total_timesteps      | 3164160       |
| train/                  |               |
|    approx_kl            | 4889.4824     |
|    clip_fraction        | 0.0234        |
|    clip_range           | 0.2           |
|    entropy_loss         | -194          |
|    explained_variance   | 0.279         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.96         |
|    n_updates            | 15440         |
|    policy_gradient_loss | -0.00387      |
|    reward               | 1.1705399e-05 |
|    std                  | 262           |
|    value_loss           | 1.44e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 515, ResetDay: 2195,Episode: 1884
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1546           |
|    time_elapsed         | 34996          |
|    total_timesteps      | 3166208        |
| train/                  |                |
|    approx_kl            | 4929.0103      |
|    clip_fraction        | 0.0226         |
|    clip_range           | 0.2            |
|    entropy_loss         | -194           |
|    explained_variance   | 0.0421         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.92          |
|    n_updates            | 15450          |
|    policy_gradient_loss | 0.00232        |
|    reward               | -2.9588698e-05 |
|    std                  | 262            |
|    value_loss           | 3.11e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1474, ResetDay: 3154,Episode: 1885
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1547          |
|    time_elapsed         | 35019         |
|    total_timesteps      | 3168256       |
| train/                  |               |
|    approx_kl            | 4890.717      |
|    clip_fraction        | 0.0212        |
|    clip_range           | 0.2           |
|    entropy_loss         | -194          |
|    explained_variance   | -1.33         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.95         |
|    n_updates            | 15460         |
|    policy_gradient_loss | -0.000759     |
|    reward               | 0.00043618775 |
|    std                  | 262           |
|    value_loss           | 4.17e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3154, episode: 1885
begin_total_asset: 200.00
end_total_asset: 229.49
total_reward: 29.49
total_cost: 30.71
total_trades: 34435
Sharpe: 0.222
=================================
Reseting Environment StartDay: 906, ResetDay: 2586,Episode: 1886
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1548          |
|    time_elapsed         | 35041         |
|    total_timesteps      | 3170304       |
| train/                  |               |
|    approx_kl            | 4943.919      |
|    clip_fraction        | 0.015         |
|    clip_range           | 0.2           |
|    entropy_loss         | -194          |
|    explained_variance   | 0.0387        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.95         |
|    n_updates            | 15470         |
|    policy_gradient_loss | 0.00227       |
|    reward               | -5.325699e-05 |
|    std                  | 262           |
|    value_loss           | 2.63e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2772, ResetDay: 4452,Episode: 1887
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2643, ResetDay: 4323,Episode: 1888
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1549           |
|    time_elapsed         | 35064          |
|    total_timesteps      | 3172352        |
| train/                  |                |
|    approx_kl            | 4922.526       |
|    clip_fraction        | 0.0225         |
|    clip_range           | 0.2            |
|    entropy_loss         | -194           |
|    explained_variance   | 0.199          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.96          |
|    n_updates            | 15480          |
|    policy_gradient_loss | 0.011          |
|    reward               | -5.3509713e-05 |
|    std                  | 263            |
|    value_loss           | 3.77e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 727, ResetDay: 2407,Episode: 1889
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1550          |
|    time_elapsed         | 35086         |
|    total_timesteps      | 3174400       |
| train/                  |               |
|    approx_kl            | 4942.585      |
|    clip_fraction        | 0.0217        |
|    clip_range           | 0.2           |
|    entropy_loss         | -194          |
|    explained_variance   | 0.0805        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.95         |
|    n_updates            | 15490         |
|    policy_gradient_loss | -0.00499      |
|    reward               | 0.00012117462 |
|    std                  | 264           |
|    value_loss           | 1.88e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 565, ResetDay: 2245,Episode: 1890
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1551          |
|    time_elapsed         | 35109         |
|    total_timesteps      | 3176448       |
| train/                  |               |
|    approx_kl            | 4982.6504     |
|    clip_fraction        | 0.023         |
|    clip_range           | 0.2           |
|    entropy_loss         | -195          |
|    explained_variance   | -0.123        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.95         |
|    n_updates            | 15500         |
|    policy_gradient_loss | -0.00318      |
|    reward               | 1.9870376e-05 |
|    std                  | 265           |
|    value_loss           | 9.51e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2245, episode: 1890
begin_total_asset: 200.00
end_total_asset: 69.05
total_reward: -130.95
total_cost: 50.34
total_trades: 34626
Sharpe: -0.295
=================================
Reseting Environment StartDay: 1736, ResetDay: 3416,Episode: 1891
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1552          |
|    time_elapsed         | 35131         |
|    total_timesteps      | 3178496       |
| train/                  |               |
|    approx_kl            | 4994.094      |
|    clip_fraction        | 0.0198        |
|    clip_range           | 0.2           |
|    entropy_loss         | -195          |
|    explained_variance   | 0.00674       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.96         |
|    n_updates            | 15510         |
|    policy_gradient_loss | -0.00286      |
|    reward               | 0.00039648704 |
|    std                  | 266           |
|    value_loss           | 2.28e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 149, ResetDay: 1829,Episode: 1892
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 883, ResetDay: 2563,Episode: 1893
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1553           |
|    time_elapsed         | 35154          |
|    total_timesteps      | 3180544        |
| train/                  |                |
|    approx_kl            | 5017.571       |
|    clip_fraction        | 0.0234         |
|    clip_range           | 0.2            |
|    entropy_loss         | -195           |
|    explained_variance   | 0.185          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.94          |
|    n_updates            | 15520          |
|    policy_gradient_loss | 0.000608       |
|    reward               | -5.3336593e-05 |
|    std                  | 267            |
|    value_loss           | 2.93e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1790, ResetDay: 3470,Episode: 1894
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1554           |
|    time_elapsed         | 35176          |
|    total_timesteps      | 3182592        |
| train/                  |                |
|    approx_kl            | 5099.2036      |
|    clip_fraction        | 0.0251         |
|    clip_range           | 0.2            |
|    entropy_loss         | -195           |
|    explained_variance   | 0.14           |
|    learning_rate        | 0.00025        |
|    loss                 | -1.94          |
|    n_updates            | 15530          |
|    policy_gradient_loss | -0.00166       |
|    reward               | -2.7141381e-05 |
|    std                  | 268            |
|    value_loss           | 6.32e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1471, ResetDay: 3151,Episode: 1895
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1555         |
|    time_elapsed         | 35199        |
|    total_timesteps      | 3184640      |
| train/                  |              |
|    approx_kl            | 5173.259     |
|    clip_fraction        | 0.0185       |
|    clip_range           | 0.2          |
|    entropy_loss         | -195         |
|    explained_variance   | 0.167        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.96        |
|    n_updates            | 15540        |
|    policy_gradient_loss | 0.000227     |
|    reward               | 8.667412e-05 |
|    std                  | 269          |
|    value_loss           | 3.86e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3151, episode: 1895
begin_total_asset: 200.00
end_total_asset: 174.76
total_reward: -25.24
total_cost: 28.93
total_trades: 34312
Sharpe: 0.094
=================================
Reseting Environment StartDay: 1928, ResetDay: 3608,Episode: 1896
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1556           |
|    time_elapsed         | 35222          |
|    total_timesteps      | 3186688        |
| train/                  |                |
|    approx_kl            | 5189.218       |
|    clip_fraction        | 0.019          |
|    clip_range           | 0.2            |
|    entropy_loss         | -195           |
|    explained_variance   | 0.179          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.95          |
|    n_updates            | 15550          |
|    policy_gradient_loss | -0.000974      |
|    reward               | -0.00020711822 |
|    std                  | 269            |
|    value_loss           | 7.67e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2538, ResetDay: 4218,Episode: 1897
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1557          |
|    time_elapsed         | 35245         |
|    total_timesteps      | 3188736       |
| train/                  |               |
|    approx_kl            | 5213.751      |
|    clip_fraction        | 0.0141        |
|    clip_range           | 0.2           |
|    entropy_loss         | -195          |
|    explained_variance   | 0.227         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.96         |
|    n_updates            | 15560         |
|    policy_gradient_loss | 0.000368      |
|    reward               | 4.2995453e-05 |
|    std                  | 269           |
|    value_loss           | 3.1e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1410, ResetDay: 3090,Episode: 1898
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 46, ResetDay: 1726,Episode: 1899
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1558          |
|    time_elapsed         | 35267         |
|    total_timesteps      | 3190784       |
| train/                  |               |
|    approx_kl            | 5215.5664     |
|    clip_fraction        | 0.015         |
|    clip_range           | 0.2           |
|    entropy_loss         | -195          |
|    explained_variance   | 0.193         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.96         |
|    n_updates            | 15570         |
|    policy_gradient_loss | 0.00263       |
|    reward               | -0.0003196294 |
|    std                  | 269           |
|    value_loss           | 9.76e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2434, ResetDay: 4114,Episode: 1900
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1559         |
|    time_elapsed         | 35290        |
|    total_timesteps      | 3192832      |
| train/                  |              |
|    approx_kl            | 5169.8994    |
|    clip_fraction        | 0.0202       |
|    clip_range           | 0.2          |
|    entropy_loss         | -195         |
|    explained_variance   | -0.515       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.95        |
|    n_updates            | 15580        |
|    policy_gradient_loss | 0.00116      |
|    reward               | -0.000522641 |
|    std                  | 269          |
|    value_loss           | 4.82e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4114, episode: 1900
begin_total_asset: 200.00
end_total_asset: 863.63
total_reward: 663.63
total_cost: 51.24
total_trades: 34037
Sharpe: 0.654
=================================
Reseting Environment StartDay: 160, ResetDay: 1840,Episode: 1901
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1560         |
|    time_elapsed         | 35312        |
|    total_timesteps      | 3194880      |
| train/                  |              |
|    approx_kl            | 5211.264     |
|    clip_fraction        | 0.0138       |
|    clip_range           | 0.2          |
|    entropy_loss         | -195         |
|    explained_variance   | 0.176        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.96        |
|    n_updates            | 15590        |
|    policy_gradient_loss | -0.000585    |
|    reward               | 5.801735e-05 |
|    std                  | 269          |
|    value_loss           | 1.41e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2154, ResetDay: 3834,Episode: 1902
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1561          |
|    time_elapsed         | 35335         |
|    total_timesteps      | 3196928       |
| train/                  |               |
|    approx_kl            | 5172.656      |
|    clip_fraction        | 0.0154        |
|    clip_range           | 0.2           |
|    entropy_loss         | -195          |
|    explained_variance   | 0.0695        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.96         |
|    n_updates            | 15600         |
|    policy_gradient_loss | -0.00256      |
|    reward               | 0.00025498657 |
|    std                  | 270           |
|    value_loss           | 5.46e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 770, ResetDay: 2450,Episode: 1903
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 510, ResetDay: 2190,Episode: 1904
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1562         |
|    time_elapsed         | 35357        |
|    total_timesteps      | 3198976      |
| train/                  |              |
|    approx_kl            | 5195.5234    |
|    clip_fraction        | 0.0227       |
|    clip_range           | 0.2          |
|    entropy_loss         | -195         |
|    explained_variance   | 0.207        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.96        |
|    n_updates            | 15610        |
|    policy_gradient_loss | -0.000444    |
|    reward               | 0.0001364063 |
|    std                  | 271          |
|    value_loss           | 1.84e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2738, ResetDay: 4418,Episode: 1905
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1563          |
|    time_elapsed         | 35380         |
|    total_timesteps      | 3201024       |
| train/                  |               |
|    approx_kl            | 5276.006      |
|    clip_fraction        | 0.0146        |
|    clip_range           | 0.2           |
|    entropy_loss         | -195          |
|    explained_variance   | 0.0116        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.93         |
|    n_updates            | 15620         |
|    policy_gradient_loss | 0.00903       |
|    reward               | 6.0867693e-05 |
|    std                  | 272           |
|    value_loss           | 2.98e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4418, episode: 1905
begin_total_asset: 200.00
end_total_asset: 339.77
total_reward: 139.77
total_cost: 47.41
total_trades: 34204
Sharpe: 0.443
=================================
Reseting Environment StartDay: 1032, ResetDay: 2712,Episode: 1906
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1564          |
|    time_elapsed         | 35403         |
|    total_timesteps      | 3203072       |
| train/                  |               |
|    approx_kl            | 5293.1753     |
|    clip_fraction        | 0.0157        |
|    clip_range           | 0.2           |
|    entropy_loss         | -195          |
|    explained_variance   | 0.067         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.94         |
|    n_updates            | 15630         |
|    policy_gradient_loss | 0.00376       |
|    reward               | 1.2915516e-05 |
|    std                  | 272           |
|    value_loss           | 2.87e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1603, ResetDay: 3283,Episode: 1907
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1565         |
|    time_elapsed         | 35426        |
|    total_timesteps      | 3205120      |
| train/                  |              |
|    approx_kl            | 5308.4116    |
|    clip_fraction        | 0.0159       |
|    clip_range           | 0.2          |
|    entropy_loss         | -195         |
|    explained_variance   | 0.0802       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.96        |
|    n_updates            | 15640        |
|    policy_gradient_loss | 0.0012       |
|    reward               | 0.0006438452 |
|    std                  | 272          |
|    value_loss           | 1.84e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 718, ResetDay: 2398,Episode: 1908
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1566           |
|    time_elapsed         | 35449          |
|    total_timesteps      | 3207168        |
| train/                  |                |
|    approx_kl            | 5289.3965      |
|    clip_fraction        | 0.0262         |
|    clip_range           | 0.2            |
|    entropy_loss         | -195           |
|    explained_variance   | -0.0519        |
|    learning_rate        | 0.00025        |
|    loss                 | -1.96          |
|    n_updates            | 15650          |
|    policy_gradient_loss | -0.00476       |
|    reward               | -0.00010855713 |
|    std                  | 274            |
|    value_loss           | 4e-07          |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2547, ResetDay: 4227,Episode: 1909
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 650, ResetDay: 2330,Episode: 1910
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1567         |
|    time_elapsed         | 35471        |
|    total_timesteps      | 3209216      |
| train/                  |              |
|    approx_kl            | 5334.476     |
|    clip_fraction        | 0.0248       |
|    clip_range           | 0.2          |
|    entropy_loss         | -196         |
|    explained_variance   | 0.217        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.95        |
|    n_updates            | 15660        |
|    policy_gradient_loss | -0.000561    |
|    reward               | 6.199722e-05 |
|    std                  | 275          |
|    value_loss           | 5.27e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2330, episode: 1910
begin_total_asset: 200.00
end_total_asset: 28.57
total_reward: -171.43
total_cost: 20.61
total_trades: 34061
Sharpe: -0.374
=================================
Reseting Environment StartDay: 1632, ResetDay: 3312,Episode: 1911
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1568           |
|    time_elapsed         | 35494          |
|    total_timesteps      | 3211264        |
| train/                  |                |
|    approx_kl            | 5372.623       |
|    clip_fraction        | 0.0213         |
|    clip_range           | 0.2            |
|    entropy_loss         | -196           |
|    explained_variance   | 0.138          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.96          |
|    n_updates            | 15670          |
|    policy_gradient_loss | -0.000746      |
|    reward               | -0.00022893363 |
|    std                  | 277            |
|    value_loss           | 1.66e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1312, ResetDay: 2992,Episode: 1912
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1569           |
|    time_elapsed         | 35516          |
|    total_timesteps      | 3213312        |
| train/                  |                |
|    approx_kl            | 5454.391       |
|    clip_fraction        | 0.0211         |
|    clip_range           | 0.2            |
|    entropy_loss         | -196           |
|    explained_variance   | -0.431         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.98          |
|    n_updates            | 15680          |
|    policy_gradient_loss | -0.00569       |
|    reward               | -0.00017489777 |
|    std                  | 278            |
|    value_loss           | 3.57e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1993, ResetDay: 3673,Episode: 1913
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1570           |
|    time_elapsed         | 35539          |
|    total_timesteps      | 3215360        |
| train/                  |                |
|    approx_kl            | 5539.208       |
|    clip_fraction        | 0.0163         |
|    clip_range           | 0.2            |
|    entropy_loss         | -196           |
|    explained_variance   | 0.184          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.97          |
|    n_updates            | 15690          |
|    policy_gradient_loss | 0.000141       |
|    reward               | -0.00032386437 |
|    std                  | 279            |
|    value_loss           | 4.6e-07        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1758, ResetDay: 3438,Episode: 1914
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1571          |
|    time_elapsed         | 35561         |
|    total_timesteps      | 3217408       |
| train/                  |               |
|    approx_kl            | 5572.8867     |
|    clip_fraction        | 0.0207        |
|    clip_range           | 0.2           |
|    entropy_loss         | -196          |
|    explained_variance   | 0.232         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.96         |
|    n_updates            | 15700         |
|    policy_gradient_loss | 2.92e-05      |
|    reward               | -6.326294e-05 |
|    std                  | 280           |
|    value_loss           | 5.28e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1672, ResetDay: 3352,Episode: 1915
Environment reached Terminal state as number of trading days reached limit!!
day: 3352, episode: 1915
begin_total_asset: 200.00
end_total_asset: 169.60
total_reward: -30.40
total_cost: 16.90
total_trades: 33729
Sharpe: 0.156
=================================
Reseting Environment StartDay: 767, ResetDay: 2447,Episode: 1916
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1572           |
|    time_elapsed         | 35584          |
|    total_timesteps      | 3219456        |
| train/                  |                |
|    approx_kl            | 5642.9854      |
|    clip_fraction        | 0.0161         |
|    clip_range           | 0.2            |
|    entropy_loss         | -196           |
|    explained_variance   | 0.198          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.96          |
|    n_updates            | 15710          |
|    policy_gradient_loss | -0.000269      |
|    reward               | -1.5873242e-05 |
|    std                  | 281            |
|    value_loss           | 1.31e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1509, ResetDay: 3189,Episode: 1917
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1573         |
|    time_elapsed         | 35607        |
|    total_timesteps      | 3221504      |
| train/                  |              |
|    approx_kl            | 5633.2812    |
|    clip_fraction        | 0.02         |
|    clip_range           | 0.2          |
|    entropy_loss         | -196         |
|    explained_variance   | -0.126       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.98        |
|    n_updates            | 15720        |
|    policy_gradient_loss | -0.000465    |
|    reward               | 6.027222e-06 |
|    std                  | 282          |
|    value_loss           | 4.81e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1372, ResetDay: 3052,Episode: 1918
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1574          |
|    time_elapsed         | 35629         |
|    total_timesteps      | 3223552       |
| train/                  |               |
|    approx_kl            | 5752.3716     |
|    clip_fraction        | 0.0158        |
|    clip_range           | 0.2           |
|    entropy_loss         | -196          |
|    explained_variance   | 0.179         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.97         |
|    n_updates            | 15730         |
|    policy_gradient_loss | 0.000182      |
|    reward               | 0.00032422066 |
|    std                  | 282           |
|    value_loss           | 2.63e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 951, ResetDay: 2631,Episode: 1919
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1575         |
|    time_elapsed         | 35652        |
|    total_timesteps      | 3225600      |
| train/                  |              |
|    approx_kl            | 5739.233     |
|    clip_fraction        | 0.0175       |
|    clip_range           | 0.2          |
|    entropy_loss         | -196         |
|    explained_variance   | 0.244        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.97        |
|    n_updates            | 15740        |
|    policy_gradient_loss | -0.00395     |
|    reward               | 9.260559e-06 |
|    std                  | 283          |
|    value_loss           | 3.86e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 516, ResetDay: 2196,Episode: 1920
Environment reached Terminal state as number of trading days reached limit!!
day: 2196, episode: 1920
begin_total_asset: 200.00
end_total_asset: 91.17
total_reward: -108.83
total_cost: 29.12
total_trades: 33760
Sharpe: -0.147
=================================
Reseting Environment StartDay: 1705, ResetDay: 3385,Episode: 1921
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1576           |
|    time_elapsed         | 35674          |
|    total_timesteps      | 3227648        |
| train/                  |                |
|    approx_kl            | 5787.5605      |
|    clip_fraction        | 0.0212         |
|    clip_range           | 0.2            |
|    entropy_loss         | -196           |
|    explained_variance   | 0.102          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.97          |
|    n_updates            | 15750          |
|    policy_gradient_loss | -0.00357       |
|    reward               | -1.7305756e-05 |
|    std                  | 283            |
|    value_loss           | 2.67e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 440, ResetDay: 2120,Episode: 1922
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1577          |
|    time_elapsed         | 35697         |
|    total_timesteps      | 3229696       |
| train/                  |               |
|    approx_kl            | 5774.57       |
|    clip_fraction        | 0.0157        |
|    clip_range           | 0.2           |
|    entropy_loss         | -196          |
|    explained_variance   | 0.237         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.94         |
|    n_updates            | 15760         |
|    policy_gradient_loss | 0.00102       |
|    reward               | 0.00017708808 |
|    std                  | 285           |
|    value_loss           | 3.35e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2320, ResetDay: 4000,Episode: 1923
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1578         |
|    time_elapsed         | 35719        |
|    total_timesteps      | 3231744      |
| train/                  |              |
|    approx_kl            | 5804.6455    |
|    clip_fraction        | 0.0174       |
|    clip_range           | 0.2          |
|    entropy_loss         | -196         |
|    explained_variance   | 0.139        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.96        |
|    n_updates            | 15770        |
|    policy_gradient_loss | 0.0021       |
|    reward               | 2.047119e-05 |
|    std                  | 286          |
|    value_loss           | 7.47e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2070, ResetDay: 3750,Episode: 1924
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1579          |
|    time_elapsed         | 35742         |
|    total_timesteps      | 3233792       |
| train/                  |               |
|    approx_kl            | 5918.582      |
|    clip_fraction        | 0.0236        |
|    clip_range           | 0.2           |
|    entropy_loss         | -197          |
|    explained_variance   | 0.142         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.99         |
|    n_updates            | 15780         |
|    policy_gradient_loss | -0.00439      |
|    reward               | 0.00017145996 |
|    std                  | 287           |
|    value_loss           | 5.95e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1113, ResetDay: 2793,Episode: 1925
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1580           |
|    time_elapsed         | 35764          |
|    total_timesteps      | 3235840        |
| train/                  |                |
|    approx_kl            | 5973.125       |
|    clip_fraction        | 0.0172         |
|    clip_range           | 0.2            |
|    entropy_loss         | -197           |
|    explained_variance   | 0.0918         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.94          |
|    n_updates            | 15790          |
|    policy_gradient_loss | 0.00492        |
|    reward               | -5.7728575e-05 |
|    std                  | 288            |
|    value_loss           | 4.36e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2793, episode: 1925
begin_total_asset: 200.00
end_total_asset: 127.28
total_reward: -72.72
total_cost: 21.77
total_trades: 33723
Sharpe: -0.026
=================================
Reseting Environment StartDay: 1293, ResetDay: 2973,Episode: 1926
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2218, ResetDay: 3898,Episode: 1927
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1581         |
|    time_elapsed         | 35787        |
|    total_timesteps      | 3237888      |
| train/                  |              |
|    approx_kl            | 6018.3       |
|    clip_fraction        | 0.0195       |
|    clip_range           | 0.2          |
|    entropy_loss         | -197         |
|    explained_variance   | -0.229       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.97        |
|    n_updates            | 15800        |
|    policy_gradient_loss | -0.00177     |
|    reward               | 0.0003007988 |
|    std                  | 289          |
|    value_loss           | 7.95e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 649, ResetDay: 2329,Episode: 1928
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1582          |
|    time_elapsed         | 35809         |
|    total_timesteps      | 3239936       |
| train/                  |               |
|    approx_kl            | 5976.4883     |
|    clip_fraction        | 0.0231        |
|    clip_range           | 0.2           |
|    entropy_loss         | -197          |
|    explained_variance   | 0.212         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.98         |
|    n_updates            | 15810         |
|    policy_gradient_loss | 0.000558      |
|    reward               | 0.00021980591 |
|    std                  | 290           |
|    value_loss           | 3.41e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2422, ResetDay: 4102,Episode: 1929
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1583         |
|    time_elapsed         | 35832        |
|    total_timesteps      | 3241984      |
| train/                  |              |
|    approx_kl            | 6111.3486    |
|    clip_fraction        | 0.0183       |
|    clip_range           | 0.2          |
|    entropy_loss         | -197         |
|    explained_variance   | 0.12         |
|    learning_rate        | 0.00025      |
|    loss                 | -1.97        |
|    n_updates            | 15820        |
|    policy_gradient_loss | -0.00184     |
|    reward               | 0.0007239807 |
|    std                  | 291          |
|    value_loss           | 1.47e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2633, ResetDay: 4313,Episode: 1930
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1584         |
|    time_elapsed         | 35855        |
|    total_timesteps      | 3244032      |
| train/                  |              |
|    approx_kl            | 6184.3066    |
|    clip_fraction        | 0.0191       |
|    clip_range           | 0.2          |
|    entropy_loss         | -197         |
|    explained_variance   | 0.111        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.97        |
|    n_updates            | 15830        |
|    policy_gradient_loss | -0.000667    |
|    reward               | 7.347908e-05 |
|    std                  | 292          |
|    value_loss           | 4.45e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4313, episode: 1930
begin_total_asset: 200.00
end_total_asset: 142.70
total_reward: -57.30
total_cost: 24.63
total_trades: 33472
Sharpe: 0.059
=================================
Reseting Environment StartDay: 2555, ResetDay: 4235,Episode: 1931
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1968, ResetDay: 3648,Episode: 1932
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1585          |
|    time_elapsed         | 35878         |
|    total_timesteps      | 3246080       |
| train/                  |               |
|    approx_kl            | 6209.0117     |
|    clip_fraction        | 0.0158        |
|    clip_range           | 0.2           |
|    entropy_loss         | -197          |
|    explained_variance   | 0.104         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.98         |
|    n_updates            | 15840         |
|    policy_gradient_loss | -0.000725     |
|    reward               | -7.373333e-06 |
|    std                  | 292           |
|    value_loss           | 1.12e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2767, ResetDay: 4447,Episode: 1933
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1586          |
|    time_elapsed         | 35900         |
|    total_timesteps      | 3248128       |
| train/                  |               |
|    approx_kl            | 6274.5063     |
|    clip_fraction        | 0.014         |
|    clip_range           | 0.2           |
|    entropy_loss         | -197          |
|    explained_variance   | -0.0288       |
|    learning_rate        | 0.00025       |
|    loss                 | -1.99         |
|    n_updates            | 15850         |
|    policy_gradient_loss | 0.000463      |
|    reward               | -7.674408e-05 |
|    std                  | 292           |
|    value_loss           | 8.21e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1988, ResetDay: 3668,Episode: 1934
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1587          |
|    time_elapsed         | 35923         |
|    total_timesteps      | 3250176       |
| train/                  |               |
|    approx_kl            | 6201.911      |
|    clip_fraction        | 0.0175        |
|    clip_range           | 0.2           |
|    entropy_loss         | -197          |
|    explained_variance   | 0.0437        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.98         |
|    n_updates            | 15860         |
|    policy_gradient_loss | -0.00125      |
|    reward               | -0.0002063322 |
|    std                  | 293           |
|    value_loss           | 3.36e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1847, ResetDay: 3527,Episode: 1935
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1588           |
|    time_elapsed         | 35945          |
|    total_timesteps      | 3252224        |
| train/                  |                |
|    approx_kl            | 6261.507       |
|    clip_fraction        | 0.02           |
|    clip_range           | 0.2            |
|    entropy_loss         | -197           |
|    explained_variance   | 0.111          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.97          |
|    n_updates            | 15870          |
|    policy_gradient_loss | 0.000412       |
|    reward               | -5.9786988e-05 |
|    std                  | 295            |
|    value_loss           | 9.48e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3527, episode: 1935
begin_total_asset: 200.00
end_total_asset: 377.83
total_reward: 177.83
total_cost: 17.27
total_trades: 33545
Sharpe: 0.513
=================================
Reseting Environment StartDay: 396, ResetDay: 2076,Episode: 1936
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1589         |
|    time_elapsed         | 35968        |
|    total_timesteps      | 3254272      |
| train/                  |              |
|    approx_kl            | 6326.133     |
|    clip_fraction        | 0.0147       |
|    clip_range           | 0.2          |
|    entropy_loss         | -197         |
|    explained_variance   | 0.178        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.97        |
|    n_updates            | 15880        |
|    policy_gradient_loss | -0.00258     |
|    reward               | 4.097023e-05 |
|    std                  | 296          |
|    value_loss           | 4.69e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 347, ResetDay: 2027,Episode: 1937
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 148, ResetDay: 1828,Episode: 1938
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1590          |
|    time_elapsed         | 35991         |
|    total_timesteps      | 3256320       |
| train/                  |               |
|    approx_kl            | 6400.187      |
|    clip_fraction        | 0.0232        |
|    clip_range           | 0.2           |
|    entropy_loss         | -197          |
|    explained_variance   | 0.0563        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.98         |
|    n_updates            | 15890         |
|    policy_gradient_loss | -0.00519      |
|    reward               | 0.00033725926 |
|    std                  | 297           |
|    value_loss           | 6.34e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 458, ResetDay: 2138,Episode: 1939
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1591          |
|    time_elapsed         | 36013         |
|    total_timesteps      | 3258368       |
| train/                  |               |
|    approx_kl            | 6400.584      |
|    clip_fraction        | 0.0197        |
|    clip_range           | 0.2           |
|    entropy_loss         | -198          |
|    explained_variance   | 0.0939        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.97         |
|    n_updates            | 15900         |
|    policy_gradient_loss | -0.00304      |
|    reward               | 0.00063404505 |
|    std                  | 298           |
|    value_loss           | 5.87e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2447, ResetDay: 4127,Episode: 1940
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1592          |
|    time_elapsed         | 36036         |
|    total_timesteps      | 3260416       |
| train/                  |               |
|    approx_kl            | 6537.893      |
|    clip_fraction        | 0.0223        |
|    clip_range           | 0.2           |
|    entropy_loss         | -198          |
|    explained_variance   | 0.317         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.98         |
|    n_updates            | 15910         |
|    policy_gradient_loss | -0.000163     |
|    reward               | -0.0004823616 |
|    std                  | 299           |
|    value_loss           | 6.28e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4127, episode: 1940
begin_total_asset: 200.00
end_total_asset: 521.77
total_reward: 321.77
total_cost: 47.85
total_trades: 33509
Sharpe: 0.682
=================================
Reseting Environment StartDay: 2258, ResetDay: 3938,Episode: 1941
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1593          |
|    time_elapsed         | 36058         |
|    total_timesteps      | 3262464       |
| train/                  |               |
|    approx_kl            | 6486.097      |
|    clip_fraction        | 0.02          |
|    clip_range           | 0.2           |
|    entropy_loss         | -198          |
|    explained_variance   | 0.167         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.96         |
|    n_updates            | 15920         |
|    policy_gradient_loss | -0.00139      |
|    reward               | -0.0003920456 |
|    std                  | 300           |
|    value_loss           | 6.79e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2665, ResetDay: 4345,Episode: 1942
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1914, ResetDay: 3594,Episode: 1943
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1594           |
|    time_elapsed         | 36081          |
|    total_timesteps      | 3264512        |
| train/                  |                |
|    approx_kl            | 6632.449       |
|    clip_fraction        | 0.0162         |
|    clip_range           | 0.2            |
|    entropy_loss         | -198           |
|    explained_variance   | 0.128          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.98          |
|    n_updates            | 15930          |
|    policy_gradient_loss | -0.00514       |
|    reward               | -2.5476384e-05 |
|    std                  | 300            |
|    value_loss           | 1.79e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 574, ResetDay: 2254,Episode: 1944
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1595         |
|    time_elapsed         | 36104        |
|    total_timesteps      | 3266560      |
| train/                  |              |
|    approx_kl            | 6600.0435    |
|    clip_fraction        | 0.0197       |
|    clip_range           | 0.2          |
|    entropy_loss         | -198         |
|    explained_variance   | 0.107        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.99        |
|    n_updates            | 15940        |
|    policy_gradient_loss | -0.00826     |
|    reward               | -0.000186795 |
|    std                  | 300          |
|    value_loss           | 1.1e-06      |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1726, ResetDay: 3406,Episode: 1945
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1596           |
|    time_elapsed         | 36126          |
|    total_timesteps      | 3268608        |
| train/                  |                |
|    approx_kl            | 6608.4365      |
|    clip_fraction        | 0.015          |
|    clip_range           | 0.2            |
|    entropy_loss         | -198           |
|    explained_variance   | -0.079         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.98          |
|    n_updates            | 15950          |
|    policy_gradient_loss | 0.000742       |
|    reward               | -0.00018032531 |
|    std                  | 300            |
|    value_loss           | 6.53e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3406, episode: 1945
begin_total_asset: 200.00
end_total_asset: 331.85
total_reward: 131.85
total_cost: 18.47
total_trades: 33393
Sharpe: 0.444
=================================
Reseting Environment StartDay: 640, ResetDay: 2320,Episode: 1946
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1597          |
|    time_elapsed         | 36149         |
|    total_timesteps      | 3270656       |
| train/                  |               |
|    approx_kl            | 6602.4287     |
|    clip_fraction        | 0.0176        |
|    clip_range           | 0.2           |
|    entropy_loss         | -198          |
|    explained_variance   | -0.285        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.98         |
|    n_updates            | 15960         |
|    policy_gradient_loss | -0.00388      |
|    reward               | -4.288387e-06 |
|    std                  | 301           |
|    value_loss           | 2.68e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 904, ResetDay: 2584,Episode: 1947
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1598           |
|    time_elapsed         | 36172          |
|    total_timesteps      | 3272704        |
| train/                  |                |
|    approx_kl            | 6621.599       |
|    clip_fraction        | 0.0153         |
|    clip_range           | 0.2            |
|    entropy_loss         | -198           |
|    explained_variance   | 0.165          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.99          |
|    n_updates            | 15970          |
|    policy_gradient_loss | -0.000939      |
|    reward               | -3.0632018e-06 |
|    std                  | 303            |
|    value_loss           | 5.58e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2596, ResetDay: 4276,Episode: 1948
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 340, ResetDay: 2020,Episode: 1949
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1599         |
|    time_elapsed         | 36194        |
|    total_timesteps      | 3274752      |
| train/                  |              |
|    approx_kl            | 6724.814     |
|    clip_fraction        | 0.0174       |
|    clip_range           | 0.2          |
|    entropy_loss         | -198         |
|    explained_variance   | 0.0599       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.98        |
|    n_updates            | 15980        |
|    policy_gradient_loss | -0.0028      |
|    reward               | 6.340523e-05 |
|    std                  | 303          |
|    value_loss           | 3.46e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1301, ResetDay: 2981,Episode: 1950
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1600           |
|    time_elapsed         | 36217          |
|    total_timesteps      | 3276800        |
| train/                  |                |
|    approx_kl            | 6743.41        |
|    clip_fraction        | 0.0126         |
|    clip_range           | 0.2            |
|    entropy_loss         | -198           |
|    explained_variance   | 0.0807         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.99          |
|    n_updates            | 15990          |
|    policy_gradient_loss | -4.52e-05      |
|    reward               | -0.00010381222 |
|    std                  | 304            |
|    value_loss           | 1.75e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2981, episode: 1950
begin_total_asset: 200.00
end_total_asset: 145.42
total_reward: -54.58
total_cost: 19.28
total_trades: 33364
Sharpe: 0.012
=================================
Reseting Environment StartDay: 881, ResetDay: 2561,Episode: 1951
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1601           |
|    time_elapsed         | 36240          |
|    total_timesteps      | 3278848        |
| train/                  |                |
|    approx_kl            | 6773.42        |
|    clip_fraction        | 0.0175         |
|    clip_range           | 0.2            |
|    entropy_loss         | -198           |
|    explained_variance   | -1.45          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.99          |
|    n_updates            | 16000          |
|    policy_gradient_loss | -0.00164       |
|    reward               | -5.5969907e-05 |
|    std                  | 304            |
|    value_loss           | 3.85e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2109, ResetDay: 3789,Episode: 1952
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1602          |
|    time_elapsed         | 36262         |
|    total_timesteps      | 3280896       |
| train/                  |               |
|    approx_kl            | 6787.7036     |
|    clip_fraction        | 0.0149        |
|    clip_range           | 0.2           |
|    entropy_loss         | -198          |
|    explained_variance   | 0.0881        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.98         |
|    n_updates            | 16010         |
|    policy_gradient_loss | 0.0089        |
|    reward               | 0.00020944519 |
|    std                  | 305           |
|    value_loss           | 2.92e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 601, ResetDay: 2281,Episode: 1953
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1603           |
|    time_elapsed         | 36285          |
|    total_timesteps      | 3282944        |
| train/                  |                |
|    approx_kl            | 6810.0293      |
|    clip_fraction        | 0.0243         |
|    clip_range           | 0.2            |
|    entropy_loss         | -198           |
|    explained_variance   | 0.111          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.99          |
|    n_updates            | 16020          |
|    policy_gradient_loss | -0.00361       |
|    reward               | -0.00017489777 |
|    std                  | 306            |
|    value_loss           | 3.75e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1664, ResetDay: 3344,Episode: 1954
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 404, ResetDay: 2084,Episode: 1955
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1604          |
|    time_elapsed         | 36308         |
|    total_timesteps      | 3284992       |
| train/                  |               |
|    approx_kl            | 6873.771      |
|    clip_fraction        | 0.0168        |
|    clip_range           | 0.2           |
|    entropy_loss         | -198          |
|    explained_variance   | 0.154         |
|    learning_rate        | 0.00025       |
|    loss                 | -1.99         |
|    n_updates            | 16030         |
|    policy_gradient_loss | -0.00326      |
|    reward               | 0.00022677117 |
|    std                  | 306           |
|    value_loss           | 9.67e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2084, episode: 1955
begin_total_asset: 200.00
end_total_asset: 78.29
total_reward: -121.71
total_cost: 46.68
total_trades: 33442
Sharpe: -0.126
=================================
Reseting Environment StartDay: 870, ResetDay: 2550,Episode: 1956
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1605           |
|    time_elapsed         | 36330          |
|    total_timesteps      | 3287040        |
| train/                  |                |
|    approx_kl            | 6879.6426      |
|    clip_fraction        | 0.0123         |
|    clip_range           | 0.2            |
|    entropy_loss         | -198           |
|    explained_variance   | 0.112          |
|    learning_rate        | 0.00025        |
|    loss                 | -2             |
|    n_updates            | 16040          |
|    policy_gradient_loss | -0.000602      |
|    reward               | -0.00011877041 |
|    std                  | 307            |
|    value_loss           | 5.25e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 608, ResetDay: 2288,Episode: 1957
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1606           |
|    time_elapsed         | 36353          |
|    total_timesteps      | 3289088        |
| train/                  |                |
|    approx_kl            | 6848.883       |
|    clip_fraction        | 0.0174         |
|    clip_range           | 0.2            |
|    entropy_loss         | -199           |
|    explained_variance   | 0.205          |
|    learning_rate        | 0.00025        |
|    loss                 | -1.99          |
|    n_updates            | 16050          |
|    policy_gradient_loss | 0.00166        |
|    reward               | -0.00020091647 |
|    std                  | 309            |
|    value_loss           | 8.45e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2580, ResetDay: 4260,Episode: 1958
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1607         |
|    time_elapsed         | 36376        |
|    total_timesteps      | 3291136      |
| train/                  |              |
|    approx_kl            | 6944.8843    |
|    clip_fraction        | 0.0199       |
|    clip_range           | 0.2          |
|    entropy_loss         | -199         |
|    explained_variance   | 0.257        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.99        |
|    n_updates            | 16060        |
|    policy_gradient_loss | -0.00299     |
|    reward               | -0.000497403 |
|    std                  | 310          |
|    value_loss           | 3.72e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 164, ResetDay: 1844,Episode: 1959
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 301, ResetDay: 1981,Episode: 1960
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1608          |
|    time_elapsed         | 36398         |
|    total_timesteps      | 3293184       |
| train/                  |               |
|    approx_kl            | 6990.9346     |
|    clip_fraction        | 0.0158        |
|    clip_range           | 0.2           |
|    entropy_loss         | -199          |
|    explained_variance   | 0.0568        |
|    learning_rate        | 0.00025       |
|    loss                 | -2.01         |
|    n_updates            | 16070         |
|    policy_gradient_loss | -0.00455      |
|    reward               | 0.00026573692 |
|    std                  | 311           |
|    value_loss           | 1.6e-06       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 1981, episode: 1960
begin_total_asset: 200.00
end_total_asset: 192.82
total_reward: -7.18
total_cost: 62.20
total_trades: 33519
Sharpe: 0.145
=================================
Reseting Environment StartDay: 989, ResetDay: 2669,Episode: 1961
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1609           |
|    time_elapsed         | 36421          |
|    total_timesteps      | 3295232        |
| train/                  |                |
|    approx_kl            | 7034.9404      |
|    clip_fraction        | 0.0182         |
|    clip_range           | 0.2            |
|    entropy_loss         | -199           |
|    explained_variance   | -0.425         |
|    learning_rate        | 0.00025        |
|    loss                 | -1.98          |
|    n_updates            | 16080          |
|    policy_gradient_loss | 0.0124         |
|    reward               | -0.00022543869 |
|    std                  | 311            |
|    value_loss           | 8.02e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1759, ResetDay: 3439,Episode: 1962
---------------------------------------
| time/                   |           |
|    fps                  | 90        |
|    iterations           | 1610      |
|    time_elapsed         | 36444     |
|    total_timesteps      | 3297280   |
| train/                  |           |
|    approx_kl            | 7061.086  |
|    clip_fraction        | 0.0172    |
|    clip_range           | 0.2       |
|    entropy_loss         | -199      |
|    explained_variance   | 0.168     |
|    learning_rate        | 0.00025   |
|    loss                 | -1.99     |
|    n_updates            | 16090     |
|    policy_gradient_loss | -0.000485 |
|    reward               | 0.0       |
|    std                  | 312       |
|    value_loss           | 9.86e-07  |
---------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2035, ResetDay: 3715,Episode: 1963
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1611         |
|    time_elapsed         | 36466        |
|    total_timesteps      | 3299328      |
| train/                  |              |
|    approx_kl            | 7184.0938    |
|    clip_fraction        | 0.0143       |
|    clip_range           | 0.2          |
|    entropy_loss         | -199         |
|    explained_variance   | 0.209        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.99        |
|    n_updates            | 16100        |
|    policy_gradient_loss | -0.0046      |
|    reward               | 0.0005171547 |
|    std                  | 313          |
|    value_loss           | 3.18e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 301, ResetDay: 1981,Episode: 1964
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1612          |
|    time_elapsed         | 36489         |
|    total_timesteps      | 3301376       |
| train/                  |               |
|    approx_kl            | 7070.4795     |
|    clip_fraction        | 0.0232        |
|    clip_range           | 0.2           |
|    entropy_loss         | -199          |
|    explained_variance   | 0.152         |
|    learning_rate        | 0.00025       |
|    loss                 | -2            |
|    n_updates            | 16110         |
|    policy_gradient_loss | -0.0045       |
|    reward               | -8.578567e-05 |
|    std                  | 315           |
|    value_loss           | 6.11e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1652, ResetDay: 3332,Episode: 1965
Environment reached Terminal state as number of trading days reached limit!!
day: 3332, episode: 1965
begin_total_asset: 200.00
end_total_asset: 352.42
total_reward: 152.42
total_cost: 38.50
total_trades: 32975
Sharpe: 0.477
=================================
Reseting Environment StartDay: 1484, ResetDay: 3164,Episode: 1966
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1613           |
|    time_elapsed         | 36512          |
|    total_timesteps      | 3303424        |
| train/                  |                |
|    approx_kl            | 7205.2744      |
|    clip_fraction        | 0.016          |
|    clip_range           | 0.2            |
|    entropy_loss         | -199           |
|    explained_variance   | 0.0976         |
|    learning_rate        | 0.00025        |
|    loss                 | -2.01          |
|    n_updates            | 16120          |
|    policy_gradient_loss | -0.00104       |
|    reward               | -5.1470946e-05 |
|    std                  | 316            |
|    value_loss           | 8.21e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1888, ResetDay: 3568,Episode: 1967
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1614          |
|    time_elapsed         | 36535         |
|    total_timesteps      | 3305472       |
| train/                  |               |
|    approx_kl            | 7342.474      |
|    clip_fraction        | 0.0208        |
|    clip_range           | 0.2           |
|    entropy_loss         | -199          |
|    explained_variance   | 0.0518        |
|    learning_rate        | 0.00025       |
|    loss                 | -1.99         |
|    n_updates            | 16130         |
|    policy_gradient_loss | -0.00409      |
|    reward               | 2.1760177e-05 |
|    std                  | 316           |
|    value_loss           | 8.5e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 962, ResetDay: 2642,Episode: 1968
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1615          |
|    time_elapsed         | 36557         |
|    total_timesteps      | 3307520       |
| train/                  |               |
|    approx_kl            | 7321.1743     |
|    clip_fraction        | 0.0179        |
|    clip_range           | 0.2           |
|    entropy_loss         | -199          |
|    explained_variance   | 0.0194        |
|    learning_rate        | 0.00025       |
|    loss                 | -2            |
|    n_updates            | 16140         |
|    policy_gradient_loss | -0.00603      |
|    reward               | -6.950426e-05 |
|    std                  | 317           |
|    value_loss           | 3.51e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2691, ResetDay: 4371,Episode: 1969
-----------------------------------------
| time/                   |             |
|    fps                  | 90          |
|    iterations           | 1616        |
|    time_elapsed         | 36580       |
|    total_timesteps      | 3309568     |
| train/                  |             |
|    approx_kl            | 7334.921    |
|    clip_fraction        | 0.017       |
|    clip_range           | 0.2         |
|    entropy_loss         | -199        |
|    explained_variance   | 0.141       |
|    learning_rate        | 0.00025     |
|    loss                 | -2.01       |
|    n_updates            | 16150       |
|    policy_gradient_loss | -0.00442    |
|    reward               | 0.000318808 |
|    std                  | 319         |
|    value_loss           | 5.71e-07    |
-----------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2074, ResetDay: 3754,Episode: 1970
Environment reached Terminal state as number of trading days reached limit!!
day: 3754, episode: 1970
begin_total_asset: 200.00
end_total_asset: 150.26
total_reward: -49.74
total_cost: 36.25
total_trades: 32966
Sharpe: 0.021
=================================
Reseting Environment StartDay: 717, ResetDay: 2397,Episode: 1971
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1617           |
|    time_elapsed         | 36603          |
|    total_timesteps      | 3311616        |
| train/                  |                |
|    approx_kl            | 7444.528       |
|    clip_fraction        | 0.0165         |
|    clip_range           | 0.2            |
|    entropy_loss         | -200           |
|    explained_variance   | 0.0916         |
|    learning_rate        | 0.00025        |
|    loss                 | -2             |
|    n_updates            | 16160          |
|    policy_gradient_loss | -0.00231       |
|    reward               | -2.5924348e-05 |
|    std                  | 319            |
|    value_loss           | 1.84e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 168, ResetDay: 1848,Episode: 1972
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1618           |
|    time_elapsed         | 36625          |
|    total_timesteps      | 3313664        |
| train/                  |                |
|    approx_kl            | 7394.955       |
|    clip_fraction        | 0.0159         |
|    clip_range           | 0.2            |
|    entropy_loss         | -200           |
|    explained_variance   | -0.0992        |
|    learning_rate        | 0.00025        |
|    loss                 | -2.01          |
|    n_updates            | 16170          |
|    policy_gradient_loss | 0.00429        |
|    reward               | -0.00054259435 |
|    std                  | 321            |
|    value_loss           | 1.27e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 346, ResetDay: 2026,Episode: 1973
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1619         |
|    time_elapsed         | 36648        |
|    total_timesteps      | 3315712      |
| train/                  |              |
|    approx_kl            | 7466.502     |
|    clip_fraction        | 0.0149       |
|    clip_range           | 0.2          |
|    entropy_loss         | -200         |
|    explained_variance   | -0.567       |
|    learning_rate        | 0.00025      |
|    loss                 | -2.01        |
|    n_updates            | 16180        |
|    policy_gradient_loss | 0.000596     |
|    reward               | 9.114256e-05 |
|    std                  | 322          |
|    value_loss           | 3.5e-07      |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1852, ResetDay: 3532,Episode: 1974
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1620          |
|    time_elapsed         | 36670         |
|    total_timesteps      | 3317760       |
| train/                  |               |
|    approx_kl            | 7560.682      |
|    clip_fraction        | 0.0167        |
|    clip_range           | 0.2           |
|    entropy_loss         | -200          |
|    explained_variance   | 0.243         |
|    learning_rate        | 0.00025       |
|    loss                 | -2            |
|    n_updates            | 16190         |
|    policy_gradient_loss | 0.00331       |
|    reward               | 0.00023068383 |
|    std                  | 322           |
|    value_loss           | 4.99e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1253, ResetDay: 2933,Episode: 1975
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1621           |
|    time_elapsed         | 36693          |
|    total_timesteps      | 3319808        |
| train/                  |                |
|    approx_kl            | 7560.118       |
|    clip_fraction        | 0.0159         |
|    clip_range           | 0.2            |
|    entropy_loss         | -200           |
|    explained_variance   | 0.208          |
|    learning_rate        | 0.00025        |
|    loss                 | -2.01          |
|    n_updates            | 16200          |
|    policy_gradient_loss | -0.00341       |
|    reward               | 0.000115457915 |
|    std                  | 324            |
|    value_loss           | 5.65e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2933, episode: 1975
begin_total_asset: 200.00
end_total_asset: 99.55
total_reward: -100.45
total_cost: 21.98
total_trades: 32755
Sharpe: -0.099
=================================
Reseting Environment StartDay: 537, ResetDay: 2217,Episode: 1976
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1478, ResetDay: 3158,Episode: 1977
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1622          |
|    time_elapsed         | 36716         |
|    total_timesteps      | 3321856       |
| train/                  |               |
|    approx_kl            | 7694.5938     |
|    clip_fraction        | 0.0223        |
|    clip_range           | 0.2           |
|    entropy_loss         | -200          |
|    explained_variance   | 0.202         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.02         |
|    n_updates            | 16210         |
|    policy_gradient_loss | -0.00754      |
|    reward               | 0.00029068833 |
|    std                  | 325           |
|    value_loss           | 1.66e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2704, ResetDay: 4384,Episode: 1978
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1623          |
|    time_elapsed         | 36738         |
|    total_timesteps      | 3323904       |
| train/                  |               |
|    approx_kl            | 7704.7236     |
|    clip_fraction        | 0.0179        |
|    clip_range           | 0.2           |
|    entropy_loss         | -200          |
|    explained_variance   | -0.0649       |
|    learning_rate        | 0.00025       |
|    loss                 | -2.02         |
|    n_updates            | 16220         |
|    policy_gradient_loss | -0.00287      |
|    reward               | 0.00063398667 |
|    std                  | 327           |
|    value_loss           | 3.22e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2733, ResetDay: 4413,Episode: 1979
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1624           |
|    time_elapsed         | 36760          |
|    total_timesteps      | 3325952        |
| train/                  |                |
|    approx_kl            | 7837.101       |
|    clip_fraction        | 0.0104         |
|    clip_range           | 0.2            |
|    entropy_loss         | -200           |
|    explained_variance   | 0.276          |
|    learning_rate        | 0.00025        |
|    loss                 | -2             |
|    n_updates            | 16230          |
|    policy_gradient_loss | 0.00026        |
|    reward               | -0.00017346154 |
|    std                  | 327            |
|    value_loss           | 3.48e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 335, ResetDay: 2015,Episode: 1980
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1625          |
|    time_elapsed         | 36783         |
|    total_timesteps      | 3328000       |
| train/                  |               |
|    approx_kl            | 7836.7324     |
|    clip_fraction        | 0.0148        |
|    clip_range           | 0.2           |
|    entropy_loss         | -200          |
|    explained_variance   | 0.066         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.01         |
|    n_updates            | 16240         |
|    policy_gradient_loss | 3.82e-05      |
|    reward               | -4.896641e-05 |
|    std                  | 328           |
|    value_loss           | 1.04e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2015, episode: 1980
begin_total_asset: 200.00
end_total_asset: 44.23
total_reward: -155.77
total_cost: 40.43
total_trades: 33060
Sharpe: -0.222
=================================
Reseting Environment StartDay: 1087, ResetDay: 2767,Episode: 1981
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1626          |
|    time_elapsed         | 36806         |
|    total_timesteps      | 3330048       |
| train/                  |               |
|    approx_kl            | 7848.006      |
|    clip_fraction        | 0.014         |
|    clip_range           | 0.2           |
|    entropy_loss         | -200          |
|    explained_variance   | -0.64         |
|    learning_rate        | 0.00025       |
|    loss                 | -2            |
|    n_updates            | 16250         |
|    policy_gradient_loss | -0.000788     |
|    reward               | 0.00023092232 |
|    std                  | 329           |
|    value_loss           | 7.04e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 615, ResetDay: 2295,Episode: 1982
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2554, ResetDay: 4234,Episode: 1983
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1627          |
|    time_elapsed         | 36828         |
|    total_timesteps      | 3332096       |
| train/                  |               |
|    approx_kl            | 7946.48       |
|    clip_fraction        | 0.0114        |
|    clip_range           | 0.2           |
|    entropy_loss         | -200          |
|    explained_variance   | 0.0943        |
|    learning_rate        | 0.00025       |
|    loss                 | -2.01         |
|    n_updates            | 16260         |
|    policy_gradient_loss | -0.0023       |
|    reward               | 0.00016300792 |
|    std                  | 330           |
|    value_loss           | 2.54e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 890, ResetDay: 2570,Episode: 1984
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1628          |
|    time_elapsed         | 36851         |
|    total_timesteps      | 3334144       |
| train/                  |               |
|    approx_kl            | 7978.6943     |
|    clip_fraction        | 0.0139        |
|    clip_range           | 0.2           |
|    entropy_loss         | -200          |
|    explained_variance   | 0.256         |
|    learning_rate        | 0.00025       |
|    loss                 | -2            |
|    n_updates            | 16270         |
|    policy_gradient_loss | -0.00343      |
|    reward               | 0.00015257645 |
|    std                  | 331           |
|    value_loss           | 3.23e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 700, ResetDay: 2380,Episode: 1985
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1629          |
|    time_elapsed         | 36873         |
|    total_timesteps      | 3336192       |
| train/                  |               |
|    approx_kl            | 8017.3403     |
|    clip_fraction        | 0.0154        |
|    clip_range           | 0.2           |
|    entropy_loss         | -201          |
|    explained_variance   | 0.0952        |
|    learning_rate        | 0.00025       |
|    loss                 | -2.02         |
|    n_updates            | 16280         |
|    policy_gradient_loss | -0.0035       |
|    reward               | 1.3751984e-06 |
|    std                  | 332           |
|    value_loss           | 1.9e-06       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2380, episode: 1985
begin_total_asset: 200.00
end_total_asset: 100.86
total_reward: -99.14
total_cost: 33.93
total_trades: 32708
Sharpe: -0.113
=================================
Reseting Environment StartDay: 805, ResetDay: 2485,Episode: 1986
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1630          |
|    time_elapsed         | 36896         |
|    total_timesteps      | 3338240       |
| train/                  |               |
|    approx_kl            | 8084.07       |
|    clip_fraction        | 0.0146        |
|    clip_range           | 0.2           |
|    entropy_loss         | -201          |
|    explained_variance   | 0.043         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.02         |
|    n_updates            | 16290         |
|    policy_gradient_loss | 0.000956      |
|    reward               | 0.00023219224 |
|    std                  | 333           |
|    value_loss           | 2.78e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2228, ResetDay: 3908,Episode: 1987
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1754, ResetDay: 3434,Episode: 1988
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1631          |
|    time_elapsed         | 36919         |
|    total_timesteps      | 3340288       |
| train/                  |               |
|    approx_kl            | 8088.698      |
|    clip_fraction        | 0.0156        |
|    clip_range           | 0.2           |
|    entropy_loss         | -201          |
|    explained_variance   | 0.356         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.02         |
|    n_updates            | 16300         |
|    policy_gradient_loss | 0.000877      |
|    reward               | 1.7428207e-05 |
|    std                  | 333           |
|    value_loss           | 3.18e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2310, ResetDay: 3990,Episode: 1989
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1632         |
|    time_elapsed         | 36941        |
|    total_timesteps      | 3342336      |
| train/                  |              |
|    approx_kl            | 8130.6953    |
|    clip_fraction        | 0.0171       |
|    clip_range           | 0.2          |
|    entropy_loss         | -201         |
|    explained_variance   | 0.103        |
|    learning_rate        | 0.00025      |
|    loss                 | -2.02        |
|    n_updates            | 16310        |
|    policy_gradient_loss | -0.00404     |
|    reward               | -6.23045e-05 |
|    std                  | 335          |
|    value_loss           | 1.76e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2624, ResetDay: 4304,Episode: 1990
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1633          |
|    time_elapsed         | 36964         |
|    total_timesteps      | 3344384       |
| train/                  |               |
|    approx_kl            | 8276.096      |
|    clip_fraction        | 0.0137        |
|    clip_range           | 0.2           |
|    entropy_loss         | -201          |
|    explained_variance   | 0.123         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.01         |
|    n_updates            | 16320         |
|    policy_gradient_loss | -0.00181      |
|    reward               | 0.00013812256 |
|    std                  | 336           |
|    value_loss           | 4.56e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4304, episode: 1990
begin_total_asset: 200.00
end_total_asset: 159.17
total_reward: -40.83
total_cost: 34.27
total_trades: 32679
Sharpe: 0.112
=================================
Reseting Environment StartDay: 1988, ResetDay: 3668,Episode: 1991
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1634           |
|    time_elapsed         | 36987          |
|    total_timesteps      | 3346432        |
| train/                  |                |
|    approx_kl            | 8299.998       |
|    clip_fraction        | 0.0125         |
|    clip_range           | 0.2            |
|    entropy_loss         | -201           |
|    explained_variance   | 0.175          |
|    learning_rate        | 0.00025        |
|    loss                 | -2.01          |
|    n_updates            | 16330          |
|    policy_gradient_loss | 0.00242        |
|    reward               | -0.00025771523 |
|    std                  | 336            |
|    value_loss           | 1.14e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 952, ResetDay: 2632,Episode: 1992
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1635           |
|    time_elapsed         | 37009          |
|    total_timesteps      | 3348480        |
| train/                  |                |
|    approx_kl            | 8313.044       |
|    clip_fraction        | 0.0188         |
|    clip_range           | 0.2            |
|    entropy_loss         | -201           |
|    explained_variance   | 0.0127         |
|    learning_rate        | 0.00025        |
|    loss                 | -2.01          |
|    n_updates            | 16340          |
|    policy_gradient_loss | -0.00127       |
|    reward               | -0.00022556419 |
|    std                  | 338            |
|    value_loss           | 5.06e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2015, ResetDay: 3695,Episode: 1993
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2351, ResetDay: 4031,Episode: 1994
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1636         |
|    time_elapsed         | 37032        |
|    total_timesteps      | 3350528      |
| train/                  |              |
|    approx_kl            | 8365.385     |
|    clip_fraction        | 0.0193       |
|    clip_range           | 0.2          |
|    entropy_loss         | -201         |
|    explained_variance   | 0.0819       |
|    learning_rate        | 0.00025      |
|    loss                 | -2.02        |
|    n_updates            | 16350        |
|    policy_gradient_loss | -0.00178     |
|    reward               | 0.0006070486 |
|    std                  | 339          |
|    value_loss           | 5.2e-07      |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1523, ResetDay: 3203,Episode: 1995
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1637           |
|    time_elapsed         | 37054          |
|    total_timesteps      | 3352576        |
| train/                  |                |
|    approx_kl            | 8470.584       |
|    clip_fraction        | 0.0164         |
|    clip_range           | 0.2            |
|    entropy_loss         | -201           |
|    explained_variance   | 0.162          |
|    learning_rate        | 0.00025        |
|    loss                 | -2.03          |
|    n_updates            | 16360          |
|    policy_gradient_loss | -0.00394       |
|    reward               | -3.7407874e-06 |
|    std                  | 339            |
|    value_loss           | 1.17e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3203, episode: 1995
begin_total_asset: 200.00
end_total_asset: 163.73
total_reward: -36.27
total_cost: 11.22
total_trades: 32556
Sharpe: 0.179
=================================
Reseting Environment StartDay: 1769, ResetDay: 3449,Episode: 1996
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1638           |
|    time_elapsed         | 37077          |
|    total_timesteps      | 3354624        |
| train/                  |                |
|    approx_kl            | 8463.422       |
|    clip_fraction        | 0.011          |
|    clip_range           | 0.2            |
|    entropy_loss         | -201           |
|    explained_variance   | 0.185          |
|    learning_rate        | 0.00025        |
|    loss                 | -2.02          |
|    n_updates            | 16370          |
|    policy_gradient_loss | -0.00341       |
|    reward               | -1.6993714e-05 |
|    std                  | 340            |
|    value_loss           | 1.1e-06        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1305, ResetDay: 2985,Episode: 1997
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1639         |
|    time_elapsed         | 37099        |
|    total_timesteps      | 3356672      |
| train/                  |              |
|    approx_kl            | 8446.613     |
|    clip_fraction        | 0.0165       |
|    clip_range           | 0.2          |
|    entropy_loss         | -201         |
|    explained_variance   | -0.316       |
|    learning_rate        | 0.00025      |
|    loss                 | -2.02        |
|    n_updates            | 16380        |
|    policy_gradient_loss | -0.000722    |
|    reward               | 7.956085e-05 |
|    std                  | 341          |
|    value_loss           | 3.1e-07      |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1679, ResetDay: 3359,Episode: 1998
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 996, ResetDay: 2676,Episode: 1999
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1640         |
|    time_elapsed         | 37122        |
|    total_timesteps      | 3358720      |
| train/                  |              |
|    approx_kl            | 8553.501     |
|    clip_fraction        | 0.0133       |
|    clip_range           | 0.2          |
|    entropy_loss         | -201         |
|    explained_variance   | 0.163        |
|    learning_rate        | 0.00025      |
|    loss                 | -2.02        |
|    n_updates            | 16390        |
|    policy_gradient_loss | -0.00066     |
|    reward               | 3.381729e-05 |
|    std                  | 342          |
|    value_loss           | 3.87e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1943, ResetDay: 3623,Episode: 2000
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1641           |
|    time_elapsed         | 37145          |
|    total_timesteps      | 3360768        |
| train/                  |                |
|    approx_kl            | 8575.588       |
|    clip_fraction        | 0.0159         |
|    clip_range           | 0.2            |
|    entropy_loss         | -201           |
|    explained_variance   | 0.15           |
|    learning_rate        | 0.00025        |
|    loss                 | -2.02          |
|    n_updates            | 16400          |
|    policy_gradient_loss | -0.000434      |
|    reward               | -0.00011887741 |
|    std                  | 343            |
|    value_loss           | 5.68e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3623, episode: 2000
begin_total_asset: 200.00
end_total_asset: 476.96
total_reward: 276.96
total_cost: 26.71
total_trades: 32632
Sharpe: 0.712
=================================
Reseting Environment StartDay: 284, ResetDay: 1964,Episode: 2001
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1642         |
|    time_elapsed         | 37167        |
|    total_timesteps      | 3362816      |
| train/                  |              |
|    approx_kl            | 8615.713     |
|    clip_fraction        | 0.0152       |
|    clip_range           | 0.2          |
|    entropy_loss         | -202         |
|    explained_variance   | -0.164       |
|    learning_rate        | 0.00025      |
|    loss                 | -1.98        |
|    n_updates            | 16410        |
|    policy_gradient_loss | -0.00132     |
|    reward               | 2.254753e-05 |
|    std                  | 344          |
|    value_loss           | 2.78e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1171, ResetDay: 2851,Episode: 2002
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1643           |
|    time_elapsed         | 37190          |
|    total_timesteps      | 3364864        |
| train/                  |                |
|    approx_kl            | 8685.571       |
|    clip_fraction        | 0.0108         |
|    clip_range           | 0.2            |
|    entropy_loss         | -202           |
|    explained_variance   | 0.0487         |
|    learning_rate        | 0.00025        |
|    loss                 | -2             |
|    n_updates            | 16420          |
|    policy_gradient_loss | 0.00203        |
|    reward               | -3.7540245e-05 |
|    std                  | 345            |
|    value_loss           | 1.68e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 802, ResetDay: 2482,Episode: 2003
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1644          |
|    time_elapsed         | 37212         |
|    total_timesteps      | 3366912       |
| train/                  |               |
|    approx_kl            | 8732.367      |
|    clip_fraction        | 0.0209        |
|    clip_range           | 0.2           |
|    entropy_loss         | -202          |
|    explained_variance   | -0.0435       |
|    learning_rate        | 0.00025       |
|    loss                 | -2.03         |
|    n_updates            | 16430         |
|    policy_gradient_loss | -0.00614      |
|    reward               | -6.128769e-05 |
|    std                  | 346           |
|    value_loss           | 2.97e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2300, ResetDay: 3980,Episode: 2004
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1172, ResetDay: 2852,Episode: 2005
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1645         |
|    time_elapsed         | 37235        |
|    total_timesteps      | 3368960      |
| train/                  |              |
|    approx_kl            | 8760.675     |
|    clip_fraction        | 0.0173       |
|    clip_range           | 0.2          |
|    entropy_loss         | -202         |
|    explained_variance   | 0.262        |
|    learning_rate        | 0.00025      |
|    loss                 | -2.02        |
|    n_updates            | 16440        |
|    policy_gradient_loss | -0.00338     |
|    reward               | 5.283623e-05 |
|    std                  | 347          |
|    value_loss           | 2.95e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2852, episode: 2005
begin_total_asset: 200.00
end_total_asset: 77.24
total_reward: -122.76
total_cost: 19.82
total_trades: 32409
Sharpe: -0.153
=================================
Reseting Environment StartDay: 723, ResetDay: 2403,Episode: 2006
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1646          |
|    time_elapsed         | 37257         |
|    total_timesteps      | 3371008       |
| train/                  |               |
|    approx_kl            | 8857.994      |
|    clip_fraction        | 0.0136        |
|    clip_range           | 0.2           |
|    entropy_loss         | -202          |
|    explained_variance   | 0.103         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.02         |
|    n_updates            | 16450         |
|    policy_gradient_loss | -0.000991     |
|    reward               | -8.396482e-06 |
|    std                  | 348           |
|    value_loss           | 1.11e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1159, ResetDay: 2839,Episode: 2007
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1647          |
|    time_elapsed         | 37280         |
|    total_timesteps      | 3373056       |
| train/                  |               |
|    approx_kl            | 8896.285      |
|    clip_fraction        | 0.0132        |
|    clip_range           | 0.2           |
|    entropy_loss         | -202          |
|    explained_variance   | -0.286        |
|    learning_rate        | 0.00025       |
|    loss                 | -2.02         |
|    n_updates            | 16460         |
|    policy_gradient_loss | -0.000559     |
|    reward               | 2.6734542e-05 |
|    std                  | 350           |
|    value_loss           | 4.51e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2264, ResetDay: 3944,Episode: 2008
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1648           |
|    time_elapsed         | 37303          |
|    total_timesteps      | 3375104        |
| train/                  |                |
|    approx_kl            | 8995.853       |
|    clip_fraction        | 0.0122         |
|    clip_range           | 0.2            |
|    entropy_loss         | -202           |
|    explained_variance   | 0.162          |
|    learning_rate        | 0.00025        |
|    loss                 | -2.03          |
|    n_updates            | 16470          |
|    policy_gradient_loss | -0.00263       |
|    reward               | -1.2553024e-05 |
|    std                  | 351            |
|    value_loss           | 2.75e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1522, ResetDay: 3202,Episode: 2009
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1227, ResetDay: 2907,Episode: 2010
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1649         |
|    time_elapsed         | 37325        |
|    total_timesteps      | 3377152      |
| train/                  |              |
|    approx_kl            | 9032.923     |
|    clip_fraction        | 0.0104       |
|    clip_range           | 0.2          |
|    entropy_loss         | -202         |
|    explained_variance   | 0.181        |
|    learning_rate        | 0.00025      |
|    loss                 | -2.01        |
|    n_updates            | 16480        |
|    policy_gradient_loss | -0.00168     |
|    reward               | -8.78029e-05 |
|    std                  | 352          |
|    value_loss           | 7.87e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2907, episode: 2010
begin_total_asset: 200.00
end_total_asset: 150.48
total_reward: -49.52
total_cost: 17.73
total_trades: 32136
Sharpe: 0.031
=================================
Reseting Environment StartDay: 1564, ResetDay: 3244,Episode: 2011
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1650          |
|    time_elapsed         | 37348         |
|    total_timesteps      | 3379200       |
| train/                  |               |
|    approx_kl            | 9145.449      |
|    clip_fraction        | 0.0177        |
|    clip_range           | 0.2           |
|    entropy_loss         | -202          |
|    explained_variance   | 0.0565        |
|    learning_rate        | 0.00025       |
|    loss                 | -2.02         |
|    n_updates            | 16490         |
|    policy_gradient_loss | -0.0068       |
|    reward               | 2.1949769e-05 |
|    std                  | 352           |
|    value_loss           | 8.24e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2804, ResetDay: 4484,Episode: 2012
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1651         |
|    time_elapsed         | 37371        |
|    total_timesteps      | 3381248      |
| train/                  |              |
|    approx_kl            | 9134.619     |
|    clip_fraction        | 0.0148       |
|    clip_range           | 0.2          |
|    entropy_loss         | -202         |
|    explained_variance   | 0.236        |
|    learning_rate        | 0.00025      |
|    loss                 | -2.04        |
|    n_updates            | 16500        |
|    policy_gradient_loss | -0.00417     |
|    reward               | 8.019066e-05 |
|    std                  | 353          |
|    value_loss           | 3.22e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 366, ResetDay: 2046,Episode: 2013
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1652          |
|    time_elapsed         | 37394         |
|    total_timesteps      | 3383296       |
| train/                  |               |
|    approx_kl            | 9255.366      |
|    clip_fraction        | 0.0156        |
|    clip_range           | 0.2           |
|    entropy_loss         | -202          |
|    explained_variance   | 0.136         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.03         |
|    n_updates            | 16510         |
|    policy_gradient_loss | -0.00363      |
|    reward               | -8.452797e-06 |
|    std                  | 354           |
|    value_loss           | 6.67e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 344, ResetDay: 2024,Episode: 2014
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1653           |
|    time_elapsed         | 37416          |
|    total_timesteps      | 3385344        |
| train/                  |                |
|    approx_kl            | 9207.117       |
|    clip_fraction        | 0.0143         |
|    clip_range           | 0.2            |
|    entropy_loss         | -202           |
|    explained_variance   | -0.16          |
|    learning_rate        | 0.00025        |
|    loss                 | -2.02          |
|    n_updates            | 16520          |
|    policy_gradient_loss | -0.00386       |
|    reward               | 0.000118949414 |
|    std                  | 355            |
|    value_loss           | 8.29e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 925, ResetDay: 2605,Episode: 2015
Environment reached Terminal state as number of trading days reached limit!!
day: 2605, episode: 2015
begin_total_asset: 200.00
end_total_asset: 156.00
total_reward: -44.00
total_cost: 41.49
total_trades: 32424
Sharpe: 0.085
=================================
Reseting Environment StartDay: 1, ResetDay: 1681,Episode: 2016
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1654           |
|    time_elapsed         | 37438          |
|    total_timesteps      | 3387392        |
| train/                  |                |
|    approx_kl            | 9327.276       |
|    clip_fraction        | 0.016          |
|    clip_range           | 0.2            |
|    entropy_loss         | -202           |
|    explained_variance   | 0.141          |
|    learning_rate        | 0.00025        |
|    loss                 | -2.03          |
|    n_updates            | 16530          |
|    policy_gradient_loss | -0.00296       |
|    reward               | -3.2310056e-06 |
|    std                  | 357            |
|    value_loss           | 4.82e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 287, ResetDay: 1967,Episode: 2017
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1655          |
|    time_elapsed         | 37462         |
|    total_timesteps      | 3389440       |
| train/                  |               |
|    approx_kl            | 9466.762      |
|    clip_fraction        | 0.00977       |
|    clip_range           | 0.2           |
|    entropy_loss         | -203          |
|    explained_variance   | -0.286        |
|    learning_rate        | 0.00025       |
|    loss                 | -2.02         |
|    n_updates            | 16540         |
|    policy_gradient_loss | -0.00159      |
|    reward               | 0.00011759615 |
|    std                  | 358           |
|    value_loss           | 5.96e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1413, ResetDay: 3093,Episode: 2018
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1656          |
|    time_elapsed         | 37485         |
|    total_timesteps      | 3391488       |
| train/                  |               |
|    approx_kl            | 9521.58       |
|    clip_fraction        | 0.0134        |
|    clip_range           | 0.2           |
|    entropy_loss         | -203          |
|    explained_variance   | 0.14          |
|    learning_rate        | 0.00025       |
|    loss                 | -2.03         |
|    n_updates            | 16550         |
|    policy_gradient_loss | -0.00413      |
|    reward               | 0.00011556549 |
|    std                  | 358           |
|    value_loss           | 7.82e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 657, ResetDay: 2337,Episode: 2019
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1657          |
|    time_elapsed         | 37508         |
|    total_timesteps      | 3393536       |
| train/                  |               |
|    approx_kl            | 9524.495      |
|    clip_fraction        | 0.0125        |
|    clip_range           | 0.2           |
|    entropy_loss         | -203          |
|    explained_variance   | 0.338         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.04         |
|    n_updates            | 16560         |
|    policy_gradient_loss | -0.00301      |
|    reward               | 5.9260656e-05 |
|    std                  | 360           |
|    value_loss           | 4.21e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2770, ResetDay: 4450,Episode: 2020
-----------------------------------------
| time/                   |             |
|    fps                  | 90          |
|    iterations           | 1658        |
|    time_elapsed         | 37531       |
|    total_timesteps      | 3395584     |
| train/                  |             |
|    approx_kl            | 9620.402    |
|    clip_fraction        | 0.0129      |
|    clip_range           | 0.2         |
|    entropy_loss         | -203        |
|    explained_variance   | 0.124       |
|    learning_rate        | 0.00025     |
|    loss                 | -2.04       |
|    n_updates            | 16570       |
|    policy_gradient_loss | -0.00168    |
|    reward               | 0.001145062 |
|    std                  | 360         |
|    value_loss           | 5.19e-07    |
-----------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4450, episode: 2020
begin_total_asset: 200.00
end_total_asset: 424.67
total_reward: 224.67
total_cost: 66.51
total_trades: 32337
Sharpe: 0.561
=================================
Reseting Environment StartDay: 655, ResetDay: 2335,Episode: 2021
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1431, ResetDay: 3111,Episode: 2022
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1659           |
|    time_elapsed         | 37553          |
|    total_timesteps      | 3397632        |
| train/                  |                |
|    approx_kl            | 9618.986       |
|    clip_fraction        | 0.0172         |
|    clip_range           | 0.2            |
|    entropy_loss         | -203           |
|    explained_variance   | 0.0864         |
|    learning_rate        | 0.00025        |
|    loss                 | -2.05          |
|    n_updates            | 16580          |
|    policy_gradient_loss | -0.00506       |
|    reward               | -2.5015926e-05 |
|    std                  | 361            |
|    value_loss           | 2.61e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1047, ResetDay: 2727,Episode: 2023
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1660          |
|    time_elapsed         | 37576         |
|    total_timesteps      | 3399680       |
| train/                  |               |
|    approx_kl            | 9626.206      |
|    clip_fraction        | 0.0143        |
|    clip_range           | 0.2           |
|    entropy_loss         | -203          |
|    explained_variance   | -0.774        |
|    learning_rate        | 0.00025       |
|    loss                 | -2.02         |
|    n_updates            | 16590         |
|    policy_gradient_loss | 0.0117        |
|    reward               | -5.146637e-05 |
|    std                  | 362           |
|    value_loss           | 5.03e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2655, ResetDay: 4335,Episode: 2024
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1661           |
|    time_elapsed         | 37599          |
|    total_timesteps      | 3401728        |
| train/                  |                |
|    approx_kl            | 9840.586       |
|    clip_fraction        | 0.0137         |
|    clip_range           | 0.2            |
|    entropy_loss         | -203           |
|    explained_variance   | 0.246          |
|    learning_rate        | 0.00025        |
|    loss                 | -2.04          |
|    n_updates            | 16600          |
|    policy_gradient_loss | -0.0043        |
|    reward               | -0.00012102814 |
|    std                  | 362            |
|    value_loss           | 2.55e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1488, ResetDay: 3168,Episode: 2025
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1662           |
|    time_elapsed         | 37621          |
|    total_timesteps      | 3403776        |
| train/                  |                |
|    approx_kl            | 9713.37        |
|    clip_fraction        | 0.0131         |
|    clip_range           | 0.2            |
|    entropy_loss         | -203           |
|    explained_variance   | 0.179          |
|    learning_rate        | 0.00025        |
|    loss                 | -2.04          |
|    n_updates            | 16610          |
|    policy_gradient_loss | -0.00421       |
|    reward               | -2.8813361e-05 |
|    std                  | 364            |
|    value_loss           | 7.49e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3168, episode: 2025
begin_total_asset: 200.00
end_total_asset: 159.81
total_reward: -40.19
total_cost: 16.79
total_trades: 32082
Sharpe: 0.099
=================================
Reseting Environment StartDay: 1429, ResetDay: 3109,Episode: 2026
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1795, ResetDay: 3475,Episode: 2027
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1663          |
|    time_elapsed         | 37644         |
|    total_timesteps      | 3405824       |
| train/                  |               |
|    approx_kl            | 9757.427      |
|    clip_fraction        | 0.016         |
|    clip_range           | 0.2           |
|    entropy_loss         | -203          |
|    explained_variance   | 0.00289       |
|    learning_rate        | 0.00025       |
|    loss                 | -2.04         |
|    n_updates            | 16620         |
|    policy_gradient_loss | -0.00733      |
|    reward               | 2.9051209e-05 |
|    std                  | 365           |
|    value_loss           | 1.2e-06       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1436, ResetDay: 3116,Episode: 2028
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1664          |
|    time_elapsed         | 37666         |
|    total_timesteps      | 3407872       |
| train/                  |               |
|    approx_kl            | 9788.685      |
|    clip_fraction        | 0.0179        |
|    clip_range           | 0.2           |
|    entropy_loss         | -203          |
|    explained_variance   | 0.17          |
|    learning_rate        | 0.00025       |
|    loss                 | -2.03         |
|    n_updates            | 16630         |
|    policy_gradient_loss | -0.0029       |
|    reward               | 0.00012200947 |
|    std                  | 367           |
|    value_loss           | 3.44e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 779, ResetDay: 2459,Episode: 2029
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1665           |
|    time_elapsed         | 37688          |
|    total_timesteps      | 3409920        |
| train/                  |                |
|    approx_kl            | 10026.645      |
|    clip_fraction        | 0.0115         |
|    clip_range           | 0.2            |
|    entropy_loss         | -203           |
|    explained_variance   | 0.243          |
|    learning_rate        | 0.00025        |
|    loss                 | -2.04          |
|    n_updates            | 16640          |
|    policy_gradient_loss | -0.00309       |
|    reward               | -0.00024483062 |
|    std                  | 368            |
|    value_loss           | 5.5e-07        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1523, ResetDay: 3203,Episode: 2030
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1666          |
|    time_elapsed         | 37711         |
|    total_timesteps      | 3411968       |
| train/                  |               |
|    approx_kl            | 10092.789     |
|    clip_fraction        | 0.0143        |
|    clip_range           | 0.2           |
|    entropy_loss         | -203          |
|    explained_variance   | 0.297         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.04         |
|    n_updates            | 16650         |
|    policy_gradient_loss | -0.00156      |
|    reward               | -0.0004907043 |
|    std                  | 368           |
|    value_loss           | 2.83e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3203, episode: 2030
begin_total_asset: 200.00
end_total_asset: 387.56
total_reward: 187.56
total_cost: 19.56
total_trades: 32043
Sharpe: 0.530
=================================
Reseting Environment StartDay: 1097, ResetDay: 2777,Episode: 2031
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1667           |
|    time_elapsed         | 37734          |
|    total_timesteps      | 3414016        |
| train/                  |                |
|    approx_kl            | 10030.385      |
|    clip_fraction        | 0.0161         |
|    clip_range           | 0.2            |
|    entropy_loss         | -203           |
|    explained_variance   | 0.286          |
|    learning_rate        | 0.00025        |
|    loss                 | -2.05          |
|    n_updates            | 16660          |
|    policy_gradient_loss | -0.00216       |
|    reward               | -4.7756193e-06 |
|    std                  | 369            |
|    value_loss           | 4.99e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1949, ResetDay: 3629,Episode: 2032
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1942, ResetDay: 3622,Episode: 2033
----------------------------------------
| time/                   |            |
|    fps                  | 90         |
|    iterations           | 1668       |
|    time_elapsed         | 37756      |
|    total_timesteps      | 3416064    |
| train/                  |            |
|    approx_kl            | 10069.1455 |
|    clip_fraction        | 0.0119     |
|    clip_range           | 0.2        |
|    entropy_loss         | -203       |
|    explained_variance   | -0.0188    |
|    learning_rate        | 0.00025    |
|    loss                 | -2.04      |
|    n_updates            | 16670      |
|    policy_gradient_loss | 0.000954   |
|    reward               | 0.0        |
|    std                  | 370        |
|    value_loss           | 6.2e-07    |
----------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 160, ResetDay: 1840,Episode: 2034
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1669          |
|    time_elapsed         | 37779         |
|    total_timesteps      | 3418112       |
| train/                  |               |
|    approx_kl            | 10165.355     |
|    clip_fraction        | 0.0123        |
|    clip_range           | 0.2           |
|    entropy_loss         | -203          |
|    explained_variance   | 0.158         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.04         |
|    n_updates            | 16680         |
|    policy_gradient_loss | -0.00393      |
|    reward               | 0.00014794541 |
|    std                  | 371           |
|    value_loss           | 7.62e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1634, ResetDay: 3314,Episode: 2035
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1670          |
|    time_elapsed         | 37801         |
|    total_timesteps      | 3420160       |
| train/                  |               |
|    approx_kl            | 10239.85      |
|    clip_fraction        | 0.0191        |
|    clip_range           | 0.2           |
|    entropy_loss         | -204          |
|    explained_variance   | -0.0437       |
|    learning_rate        | 0.00025       |
|    loss                 | -2.05         |
|    n_updates            | 16690         |
|    policy_gradient_loss | -0.00459      |
|    reward               | 0.00048933027 |
|    std                  | 372           |
|    value_loss           | 7.18e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3314, episode: 2035
begin_total_asset: 200.00
end_total_asset: 369.86
total_reward: 169.86
total_cost: 27.30
total_trades: 32152
Sharpe: 0.508
=================================
Reseting Environment StartDay: 2472, ResetDay: 4152,Episode: 2036
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1671           |
|    time_elapsed         | 37824          |
|    total_timesteps      | 3422208        |
| train/                  |                |
|    approx_kl            | 10244.654      |
|    clip_fraction        | 0.0162         |
|    clip_range           | 0.2            |
|    entropy_loss         | -204           |
|    explained_variance   | 0.113          |
|    learning_rate        | 0.00025        |
|    loss                 | -2.06          |
|    n_updates            | 16700          |
|    policy_gradient_loss | -0.00496       |
|    reward               | -2.9632569e-05 |
|    std                  | 373            |
|    value_loss           | 3.87e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1137, ResetDay: 2817,Episode: 2037
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 681, ResetDay: 2361,Episode: 2038
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1672         |
|    time_elapsed         | 37846        |
|    total_timesteps      | 3424256      |
| train/                  |              |
|    approx_kl            | 10294.641    |
|    clip_fraction        | 0.0113       |
|    clip_range           | 0.2          |
|    entropy_loss         | -204         |
|    explained_variance   | 0.105        |
|    learning_rate        | 0.00025      |
|    loss                 | -2.03        |
|    n_updates            | 16710        |
|    policy_gradient_loss | 0.0089       |
|    reward               | 0.0004551817 |
|    std                  | 373          |
|    value_loss           | 1.42e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2042, ResetDay: 3722,Episode: 2039
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1673           |
|    time_elapsed         | 37869          |
|    total_timesteps      | 3426304        |
| train/                  |                |
|    approx_kl            | 10204.191      |
|    clip_fraction        | 0.0187         |
|    clip_range           | 0.2            |
|    entropy_loss         | -204           |
|    explained_variance   | -0.407         |
|    learning_rate        | 0.00025        |
|    loss                 | -2.05          |
|    n_updates            | 16720          |
|    policy_gradient_loss | -0.00753       |
|    reward               | -0.00012513637 |
|    std                  | 376            |
|    value_loss           | 8.21e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2598, ResetDay: 4278,Episode: 2040
---------------------------------------------
| time/                   |                 |
|    fps                  | 90              |
|    iterations           | 1674            |
|    time_elapsed         | 37892           |
|    total_timesteps      | 3428352         |
| train/                  |                 |
|    approx_kl            | 10472.64        |
|    clip_fraction        | 0.0155          |
|    clip_range           | 0.2             |
|    entropy_loss         | -204            |
|    explained_variance   | 0.167           |
|    learning_rate        | 0.00025         |
|    loss                 | -2.05           |
|    n_updates            | 16730           |
|    policy_gradient_loss | -0.00118        |
|    reward               | -0.000109957124 |
|    std                  | 378             |
|    value_loss           | 2.82e-07        |
---------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4278, episode: 2040
begin_total_asset: 200.00
end_total_asset: 364.97
total_reward: 164.97
total_cost: 56.23
total_trades: 32004
Sharpe: 0.483
=================================
Reseting Environment StartDay: 2627, ResetDay: 4307,Episode: 2041
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1675          |
|    time_elapsed         | 37915         |
|    total_timesteps      | 3430400       |
| train/                  |               |
|    approx_kl            | 10552.486     |
|    clip_fraction        | 0.0177        |
|    clip_range           | 0.2           |
|    entropy_loss         | -204          |
|    explained_variance   | 0.143         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.06         |
|    n_updates            | 16740         |
|    policy_gradient_loss | -0.00646      |
|    reward               | 0.00054019544 |
|    std                  | 380           |
|    value_loss           | 7.83e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 635, ResetDay: 2315,Episode: 2042
-----------------------------------------
| time/                   |             |
|    fps                  | 90          |
|    iterations           | 1676        |
|    time_elapsed         | 37937       |
|    total_timesteps      | 3432448     |
| train/                  |             |
|    approx_kl            | 10731.355   |
|    clip_fraction        | 0.0126      |
|    clip_range           | 0.2         |
|    entropy_loss         | -204        |
|    explained_variance   | 0.215       |
|    learning_rate        | 0.00025     |
|    loss                 | -2.05       |
|    n_updates            | 16750       |
|    policy_gradient_loss | -0.00314    |
|    reward               | -4.0273e-05 |
|    std                  | 381         |
|    value_loss           | 1.6e-06     |
-----------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 582, ResetDay: 2262,Episode: 2043
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 519, ResetDay: 2199,Episode: 2044
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1677           |
|    time_elapsed         | 37960          |
|    total_timesteps      | 3434496        |
| train/                  |                |
|    approx_kl            | 10748.496      |
|    clip_fraction        | 0.0137         |
|    clip_range           | 0.2            |
|    entropy_loss         | -204           |
|    explained_variance   | -0.859         |
|    learning_rate        | 0.00025        |
|    loss                 | -2.05          |
|    n_updates            | 16760          |
|    policy_gradient_loss | 0.00288        |
|    reward               | -0.00010215473 |
|    std                  | 383            |
|    value_loss           | 9.16e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1762, ResetDay: 3442,Episode: 2045
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1678         |
|    time_elapsed         | 37982        |
|    total_timesteps      | 3436544      |
| train/                  |              |
|    approx_kl            | 10796.825    |
|    clip_fraction        | 0.0187       |
|    clip_range           | 0.2          |
|    entropy_loss         | -204         |
|    explained_variance   | -0.000577    |
|    learning_rate        | 0.00025      |
|    loss                 | -2.05        |
|    n_updates            | 16770        |
|    policy_gradient_loss | -0.00329     |
|    reward               | 6.895122e-05 |
|    std                  | 384          |
|    value_loss           | 3.59e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3442, episode: 2045
begin_total_asset: 200.00
end_total_asset: 379.76
total_reward: 179.76
total_cost: 15.93
total_trades: 31795
Sharpe: 0.520
=================================
Reseting Environment StartDay: 1050, ResetDay: 2730,Episode: 2046
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1679          |
|    time_elapsed         | 38005         |
|    total_timesteps      | 3438592       |
| train/                  |               |
|    approx_kl            | 10861.166     |
|    clip_fraction        | 0.0161        |
|    clip_range           | 0.2           |
|    entropy_loss         | -204          |
|    explained_variance   | 0.239         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.04         |
|    n_updates            | 16780         |
|    policy_gradient_loss | -0.00351      |
|    reward               | -2.132553e-05 |
|    std                  | 385           |
|    value_loss           | 3.09e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 87, ResetDay: 1767,Episode: 2047
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1680         |
|    time_elapsed         | 38028        |
|    total_timesteps      | 3440640      |
| train/                  |              |
|    approx_kl            | 10945.211    |
|    clip_fraction        | 0.0112       |
|    clip_range           | 0.2          |
|    entropy_loss         | -205         |
|    explained_variance   | 0.151        |
|    learning_rate        | 0.00025      |
|    loss                 | -2.04        |
|    n_updates            | 16790        |
|    policy_gradient_loss | -0.00231     |
|    reward               | 9.299355e-05 |
|    std                  | 386          |
|    value_loss           | 5.54e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 804, ResetDay: 2484,Episode: 2048
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1277, ResetDay: 2957,Episode: 2049
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1681         |
|    time_elapsed         | 38050        |
|    total_timesteps      | 3442688      |
| train/                  |              |
|    approx_kl            | 10963.692    |
|    clip_fraction        | 0.0136       |
|    clip_range           | 0.2          |
|    entropy_loss         | -205         |
|    explained_variance   | -0.0332      |
|    learning_rate        | 0.00025      |
|    loss                 | -2.05        |
|    n_updates            | 16800        |
|    policy_gradient_loss | -0.000968    |
|    reward               | 0.0009832364 |
|    std                  | 387          |
|    value_loss           | 5.14e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1711, ResetDay: 3391,Episode: 2050
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1682          |
|    time_elapsed         | 38073         |
|    total_timesteps      | 3444736       |
| train/                  |               |
|    approx_kl            | 10989.268     |
|    clip_fraction        | 0.0158        |
|    clip_range           | 0.2           |
|    entropy_loss         | -205          |
|    explained_variance   | 0.327         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.05         |
|    n_updates            | 16810         |
|    policy_gradient_loss | -0.00347      |
|    reward               | 0.00016042328 |
|    std                  | 390           |
|    value_loss           | 2.53e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3391, episode: 2050
begin_total_asset: 200.00
end_total_asset: 325.27
total_reward: 125.27
total_cost: 15.58
total_trades: 31713
Sharpe: 0.425
=================================
Reseting Environment StartDay: 404, ResetDay: 2084,Episode: 2051
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1683          |
|    time_elapsed         | 38096         |
|    total_timesteps      | 3446784       |
| train/                  |               |
|    approx_kl            | 11288.172     |
|    clip_fraction        | 0.0142        |
|    clip_range           | 0.2           |
|    entropy_loss         | -205          |
|    explained_variance   | 0.231         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.06         |
|    n_updates            | 16820         |
|    policy_gradient_loss | -0.0036       |
|    reward               | 4.9173057e-05 |
|    std                  | 391           |
|    value_loss           | 3.39e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2770, ResetDay: 4450,Episode: 2052
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1684           |
|    time_elapsed         | 38118          |
|    total_timesteps      | 3448832        |
| train/                  |                |
|    approx_kl            | 11209.826      |
|    clip_fraction        | 0.0157         |
|    clip_range           | 0.2            |
|    entropy_loss         | -205           |
|    explained_variance   | 0.133          |
|    learning_rate        | 0.00025        |
|    loss                 | -2.06          |
|    n_updates            | 16830          |
|    policy_gradient_loss | -0.00431       |
|    reward               | -0.00037962722 |
|    std                  | 393            |
|    value_loss           | 6.21e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2099, ResetDay: 3779,Episode: 2053
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1685          |
|    time_elapsed         | 38141         |
|    total_timesteps      | 3450880       |
| train/                  |               |
|    approx_kl            | 11404.069     |
|    clip_fraction        | 0.0172        |
|    clip_range           | 0.2           |
|    entropy_loss         | -205          |
|    explained_variance   | 0.161         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.07         |
|    n_updates            | 16840         |
|    policy_gradient_loss | -0.00507      |
|    reward               | 0.00050633395 |
|    std                  | 394           |
|    value_loss           | 1.51e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1667, ResetDay: 3347,Episode: 2054
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1727, ResetDay: 3407,Episode: 2055
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1686           |
|    time_elapsed         | 38164          |
|    total_timesteps      | 3452928        |
| train/                  |                |
|    approx_kl            | 11540.5625     |
|    clip_fraction        | 0.0112         |
|    clip_range           | 0.2            |
|    entropy_loss         | -205           |
|    explained_variance   | 0.0353         |
|    learning_rate        | 0.00025        |
|    loss                 | -2.05          |
|    n_updates            | 16850          |
|    policy_gradient_loss | -0.00215       |
|    reward               | -4.7579957e-05 |
|    std                  | 395            |
|    value_loss           | 1.85e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3407, episode: 2055
begin_total_asset: 200.00
end_total_asset: 232.18
total_reward: 32.18
total_cost: 13.85
total_trades: 31522
Sharpe: 0.263
=================================
Reseting Environment StartDay: 166, ResetDay: 1846,Episode: 2056
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1687         |
|    time_elapsed         | 38186        |
|    total_timesteps      | 3454976      |
| train/                  |              |
|    approx_kl            | 11458.15     |
|    clip_fraction        | 0.0152       |
|    clip_range           | 0.2          |
|    entropy_loss         | -205         |
|    explained_variance   | -0.423       |
|    learning_rate        | 0.00025      |
|    loss                 | -2.05        |
|    n_updates            | 16860        |
|    policy_gradient_loss | -0.00526     |
|    reward               | 0.0001295751 |
|    std                  | 397          |
|    value_loss           | 6.37e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1217, ResetDay: 2897,Episode: 2057
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1688          |
|    time_elapsed         | 38209         |
|    total_timesteps      | 3457024       |
| train/                  |               |
|    approx_kl            | 11676.666     |
|    clip_fraction        | 0.0085        |
|    clip_range           | 0.2           |
|    entropy_loss         | -205          |
|    explained_variance   | -0.00654      |
|    learning_rate        | 0.00025       |
|    loss                 | -2.06         |
|    n_updates            | 16870         |
|    policy_gradient_loss | -0.00283      |
|    reward               | 0.00015077648 |
|    std                  | 397           |
|    value_loss           | 4.93e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1466, ResetDay: 3146,Episode: 2058
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1689          |
|    time_elapsed         | 38231         |
|    total_timesteps      | 3459072       |
| train/                  |               |
|    approx_kl            | 11663.533     |
|    clip_fraction        | 0.0135        |
|    clip_range           | 0.2           |
|    entropy_loss         | -205          |
|    explained_variance   | 0.241         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.06         |
|    n_updates            | 16880         |
|    policy_gradient_loss | -0.00276      |
|    reward               | 0.00022611236 |
|    std                  | 398           |
|    value_loss           | 3.31e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1098, ResetDay: 2778,Episode: 2059
---------------------------------------
| time/                   |           |
|    fps                  | 90        |
|    iterations           | 1690      |
|    time_elapsed         | 38254     |
|    total_timesteps      | 3461120   |
| train/                  |           |
|    approx_kl            | 11766.936 |
|    clip_fraction        | 0.0103    |
|    clip_range           | 0.2       |
|    entropy_loss         | -205      |
|    explained_variance   | 0.229     |
|    learning_rate        | 0.00025   |
|    loss                 | -2.06     |
|    n_updates            | 16890     |
|    policy_gradient_loss | -0.00446  |
|    reward               | 0.0       |
|    std                  | 398       |
|    value_loss           | 3.02e-07  |
---------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1443, ResetDay: 3123,Episode: 2060
Environment reached Terminal state as number of trading days reached limit!!
day: 3123, episode: 2060
begin_total_asset: 200.00
end_total_asset: 277.93
total_reward: 77.93
total_cost: 27.90
total_trades: 31451
Sharpe: 0.325
=================================
Reseting Environment StartDay: 1633, ResetDay: 3313,Episode: 2061
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1691         |
|    time_elapsed         | 38277        |
|    total_timesteps      | 3463168      |
| train/                  |              |
|    approx_kl            | 11636.124    |
|    clip_fraction        | 0.0168       |
|    clip_range           | 0.2          |
|    entropy_loss         | -205         |
|    explained_variance   | 0.241        |
|    learning_rate        | 0.00025      |
|    loss                 | -2.07        |
|    n_updates            | 16900        |
|    policy_gradient_loss | 0.0053       |
|    reward               | 6.145801e-05 |
|    std                  | 400          |
|    value_loss           | 2.94e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1169, ResetDay: 2849,Episode: 2062
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1692          |
|    time_elapsed         | 38299         |
|    total_timesteps      | 3465216       |
| train/                  |               |
|    approx_kl            | 11819.932     |
|    clip_fraction        | 0.0165        |
|    clip_range           | 0.2           |
|    entropy_loss         | -206          |
|    explained_variance   | 0.297         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.06         |
|    n_updates            | 16910         |
|    policy_gradient_loss | -0.00185      |
|    reward               | 2.3715878e-05 |
|    std                  | 402           |
|    value_loss           | 7.37e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1789, ResetDay: 3469,Episode: 2063
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1693          |
|    time_elapsed         | 38322         |
|    total_timesteps      | 3467264       |
| train/                  |               |
|    approx_kl            | 11929.914     |
|    clip_fraction        | 0.0104        |
|    clip_range           | 0.2           |
|    entropy_loss         | -206          |
|    explained_variance   | 0.0759        |
|    learning_rate        | 0.00025       |
|    loss                 | -2.04         |
|    n_updates            | 16920         |
|    policy_gradient_loss | 0.00144       |
|    reward               | 0.00041832848 |
|    std                  | 403           |
|    value_loss           | 4.61e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 129, ResetDay: 1809,Episode: 2064
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1694          |
|    time_elapsed         | 38344         |
|    total_timesteps      | 3469312       |
| train/                  |               |
|    approx_kl            | 11954.415     |
|    clip_fraction        | 0.0134        |
|    clip_range           | 0.2           |
|    entropy_loss         | -206          |
|    explained_variance   | 0.105         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.07         |
|    n_updates            | 16930         |
|    policy_gradient_loss | -0.00244      |
|    reward               | 5.3729247e-05 |
|    std                  | 405           |
|    value_loss           | 5.64e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 941, ResetDay: 2621,Episode: 2065
Environment reached Terminal state as number of trading days reached limit!!
day: 2621, episode: 2065
begin_total_asset: 200.00
end_total_asset: 165.38
total_reward: -34.62
total_cost: 36.03
total_trades: 31511
Sharpe: 0.086
=================================
Reseting Environment StartDay: 2091, ResetDay: 3771,Episode: 2066
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1695           |
|    time_elapsed         | 38367          |
|    total_timesteps      | 3471360        |
| train/                  |                |
|    approx_kl            | 12105.08       |
|    clip_fraction        | 0.0106         |
|    clip_range           | 0.2            |
|    entropy_loss         | -206           |
|    explained_variance   | 0.0585         |
|    learning_rate        | 0.00025        |
|    loss                 | -2.06          |
|    n_updates            | 16940          |
|    policy_gradient_loss | -0.000804      |
|    reward               | -0.00022893363 |
|    std                  | 406            |
|    value_loss           | 1.02e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1261, ResetDay: 2941,Episode: 2067
---------------------------------------
| time/                   |           |
|    fps                  | 90        |
|    iterations           | 1696      |
|    time_elapsed         | 38389     |
|    total_timesteps      | 3473408   |
| train/                  |           |
|    approx_kl            | 12274.395 |
|    clip_fraction        | 0.0187    |
|    clip_range           | 0.2       |
|    entropy_loss         | -206      |
|    explained_variance   | -0.0662   |
|    learning_rate        | 0.00025   |
|    loss                 | -2.07     |
|    n_updates            | 16950     |
|    policy_gradient_loss | -0.00369  |
|    reward               | 0.0       |
|    std                  | 407       |
|    value_loss           | 6.27e-07  |
---------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 391, ResetDay: 2071,Episode: 2068
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1697          |
|    time_elapsed         | 38412         |
|    total_timesteps      | 3475456       |
| train/                  |               |
|    approx_kl            | 12326.365     |
|    clip_fraction        | 0.0131        |
|    clip_range           | 0.2           |
|    entropy_loss         | -206          |
|    explained_variance   | 0.0842        |
|    learning_rate        | 0.00025       |
|    loss                 | -2.07         |
|    n_updates            | 16960         |
|    policy_gradient_loss | -0.00457      |
|    reward               | 2.5360107e-05 |
|    std                  | 407           |
|    value_loss           | 1.61e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1006, ResetDay: 2686,Episode: 2069
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1698          |
|    time_elapsed         | 38435         |
|    total_timesteps      | 3477504       |
| train/                  |               |
|    approx_kl            | 12272.116     |
|    clip_fraction        | 0.0134        |
|    clip_range           | 0.2           |
|    entropy_loss         | -206          |
|    explained_variance   | -0.198        |
|    learning_rate        | 0.00025       |
|    loss                 | -2.06         |
|    n_updates            | 16970         |
|    policy_gradient_loss | -0.00329      |
|    reward               | 0.00012045269 |
|    std                  | 408           |
|    value_loss           | 5.6e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2248, ResetDay: 3928,Episode: 2070
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1699           |
|    time_elapsed         | 38457          |
|    total_timesteps      | 3479552        |
| train/                  |                |
|    approx_kl            | 12361.33       |
|    clip_fraction        | 0.0135         |
|    clip_range           | 0.2            |
|    entropy_loss         | -206           |
|    explained_variance   | 0.271          |
|    learning_rate        | 0.00025        |
|    loss                 | -2.07          |
|    n_updates            | 16980          |
|    policy_gradient_loss | -0.00188       |
|    reward               | -0.00066145934 |
|    std                  | 410            |
|    value_loss           | 2.94e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3928, episode: 2070
begin_total_asset: 200.00
end_total_asset: 310.22
total_reward: 110.22
total_cost: 36.11
total_trades: 31461
Sharpe: 0.385
=================================
Reseting Environment StartDay: 1035, ResetDay: 2715,Episode: 2071
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1378, ResetDay: 3058,Episode: 2072
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1700          |
|    time_elapsed         | 38480         |
|    total_timesteps      | 3481600       |
| train/                  |               |
|    approx_kl            | 12548.314     |
|    clip_fraction        | 0.00981       |
|    clip_range           | 0.2           |
|    entropy_loss         | -206          |
|    explained_variance   | 0.0782        |
|    learning_rate        | 0.00025       |
|    loss                 | -2.08         |
|    n_updates            | 16990         |
|    policy_gradient_loss | -0.00375      |
|    reward               | 0.00016889705 |
|    std                  | 411           |
|    value_loss           | 1.28e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1119, ResetDay: 2799,Episode: 2073
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1701          |
|    time_elapsed         | 38503         |
|    total_timesteps      | 3483648       |
| train/                  |               |
|    approx_kl            | 12661.857     |
|    clip_fraction        | 0.0103        |
|    clip_range           | 0.2           |
|    entropy_loss         | -206          |
|    explained_variance   | -0.277        |
|    learning_rate        | 0.00025       |
|    loss                 | -2.06         |
|    n_updates            | 17000         |
|    policy_gradient_loss | -0.00199      |
|    reward               | 3.0025292e-05 |
|    std                  | 411           |
|    value_loss           | 5.13e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1940, ResetDay: 3620,Episode: 2074
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1702          |
|    time_elapsed         | 38526         |
|    total_timesteps      | 3485696       |
| train/                  |               |
|    approx_kl            | 12565.673     |
|    clip_fraction        | 0.0113        |
|    clip_range           | 0.2           |
|    entropy_loss         | -206          |
|    explained_variance   | 0.312         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.05         |
|    n_updates            | 17010         |
|    policy_gradient_loss | 0.00293       |
|    reward               | 5.4340362e-05 |
|    std                  | 412           |
|    value_loss           | 2.99e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1302, ResetDay: 2982,Episode: 2075
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1703           |
|    time_elapsed         | 38548          |
|    total_timesteps      | 3487744        |
| train/                  |                |
|    approx_kl            | 12636.186      |
|    clip_fraction        | 0.0164         |
|    clip_range           | 0.2            |
|    entropy_loss         | -206           |
|    explained_variance   | 0.223          |
|    learning_rate        | 0.00025        |
|    loss                 | -2.08          |
|    n_updates            | 17020          |
|    policy_gradient_loss | -0.00395       |
|    reward               | -3.5004425e-05 |
|    std                  | 414            |
|    value_loss           | 4.77e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2982, episode: 2075
begin_total_asset: 200.00
end_total_asset: 105.02
total_reward: -94.98
total_cost: 8.62
total_trades: 31187
Sharpe: -0.029
=================================
Reseting Environment StartDay: 992, ResetDay: 2672,Episode: 2076
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 751, ResetDay: 2431,Episode: 2077
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1704           |
|    time_elapsed         | 38570          |
|    total_timesteps      | 3489792        |
| train/                  |                |
|    approx_kl            | 12724.357      |
|    clip_fraction        | 0.00928        |
|    clip_range           | 0.2            |
|    entropy_loss         | -206           |
|    explained_variance   | 0.149          |
|    learning_rate        | 0.00025        |
|    loss                 | -2.07          |
|    n_updates            | 17030          |
|    policy_gradient_loss | 0.00176        |
|    reward               | -4.6615492e-05 |
|    std                  | 415            |
|    value_loss           | 1.43e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2525, ResetDay: 4205,Episode: 2078
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1705          |
|    time_elapsed         | 38593         |
|    total_timesteps      | 3491840       |
| train/                  |               |
|    approx_kl            | 12809.581     |
|    clip_fraction        | 0.0137        |
|    clip_range           | 0.2           |
|    entropy_loss         | -207          |
|    explained_variance   | -0.0187       |
|    learning_rate        | 0.00025       |
|    loss                 | -2.07         |
|    n_updates            | 17040         |
|    policy_gradient_loss | -0.00235      |
|    reward               | 0.00021733703 |
|    std                  | 416           |
|    value_loss           | 8.15e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 175, ResetDay: 1855,Episode: 2079
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1706          |
|    time_elapsed         | 38615         |
|    total_timesteps      | 3493888       |
| train/                  |               |
|    approx_kl            | 12935.538     |
|    clip_fraction        | 0.0144        |
|    clip_range           | 0.2           |
|    entropy_loss         | -207          |
|    explained_variance   | 0.369         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.09         |
|    n_updates            | 17050         |
|    policy_gradient_loss | -0.00404      |
|    reward               | 6.4570154e-06 |
|    std                  | 417           |
|    value_loss           | 3.8e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1319, ResetDay: 2999,Episode: 2080
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1707          |
|    time_elapsed         | 38638         |
|    total_timesteps      | 3495936       |
| train/                  |               |
|    approx_kl            | 12956.59      |
|    clip_fraction        | 0.0113        |
|    clip_range           | 0.2           |
|    entropy_loss         | -207          |
|    explained_variance   | 0.0895        |
|    learning_rate        | 0.00025       |
|    loss                 | -2.07         |
|    n_updates            | 17060         |
|    policy_gradient_loss | -0.000179     |
|    reward               | -9.330368e-06 |
|    std                  | 418           |
|    value_loss           | 1.53e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2999, episode: 2080
begin_total_asset: 200.00
end_total_asset: 172.99
total_reward: -27.01
total_cost: 32.58
total_trades: 31471
Sharpe: 0.077
=================================
Reseting Environment StartDay: 1254, ResetDay: 2934,Episode: 2081
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1708         |
|    time_elapsed         | 38661        |
|    total_timesteps      | 3497984      |
| train/                  |              |
|    approx_kl            | 13054.434    |
|    clip_fraction        | 0.0123       |
|    clip_range           | 0.2          |
|    entropy_loss         | -207         |
|    explained_variance   | -0.339       |
|    learning_rate        | 0.00025      |
|    loss                 | -2.08        |
|    n_updates            | 17070        |
|    policy_gradient_loss | -0.00214     |
|    reward               | 8.819866e-05 |
|    std                  | 420          |
|    value_loss           | 2.55e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2614, ResetDay: 4294,Episode: 2082
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 172, ResetDay: 1852,Episode: 2083
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1709           |
|    time_elapsed         | 38683          |
|    total_timesteps      | 3500032        |
| train/                  |                |
|    approx_kl            | 13084.197      |
|    clip_fraction        | 0.0179         |
|    clip_range           | 0.2            |
|    entropy_loss         | -207           |
|    explained_variance   | 0.311          |
|    learning_rate        | 0.00025        |
|    loss                 | -2.08          |
|    n_updates            | 17080          |
|    policy_gradient_loss | -0.00174       |
|    reward               | -3.8123522e-05 |
|    std                  | 422            |
|    value_loss           | 2.66e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 883, ResetDay: 2563,Episode: 2084
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1710          |
|    time_elapsed         | 38706         |
|    total_timesteps      | 3502080       |
| train/                  |               |
|    approx_kl            | 13346.876     |
|    clip_fraction        | 0.0107        |
|    clip_range           | 0.2           |
|    entropy_loss         | -207          |
|    explained_variance   | 0.136         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.08         |
|    n_updates            | 17090         |
|    policy_gradient_loss | -0.000663     |
|    reward               | -8.454037e-05 |
|    std                  | 422           |
|    value_loss           | 1.7e-06       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1612, ResetDay: 3292,Episode: 2085
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1711           |
|    time_elapsed         | 38728          |
|    total_timesteps      | 3504128        |
| train/                  |                |
|    approx_kl            | 13190.354      |
|    clip_fraction        | 0.0164         |
|    clip_range           | 0.2            |
|    entropy_loss         | -207           |
|    explained_variance   | -0.567         |
|    learning_rate        | 0.00025        |
|    loss                 | -2.08          |
|    n_updates            | 17100          |
|    policy_gradient_loss | -0.00218       |
|    reward               | -0.00012687835 |
|    std                  | 423            |
|    value_loss           | 3.61e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3292, episode: 2085
begin_total_asset: 200.00
end_total_asset: 236.54
total_reward: 36.54
total_cost: 25.00
total_trades: 31192
Sharpe: 0.286
=================================
Reseting Environment StartDay: 657, ResetDay: 2337,Episode: 2086
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1712          |
|    time_elapsed         | 38751         |
|    total_timesteps      | 3506176       |
| train/                  |               |
|    approx_kl            | 13369.336     |
|    clip_fraction        | 0.0136        |
|    clip_range           | 0.2           |
|    entropy_loss         | -207          |
|    explained_variance   | 0.138         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.07         |
|    n_updates            | 17110         |
|    policy_gradient_loss | -0.00394      |
|    reward               | 1.3168908e-05 |
|    std                  | 425           |
|    value_loss           | 2.4e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 708, ResetDay: 2388,Episode: 2087
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1713          |
|    time_elapsed         | 38774         |
|    total_timesteps      | 3508224       |
| train/                  |               |
|    approx_kl            | 13478.979     |
|    clip_fraction        | 0.0108        |
|    clip_range           | 0.2           |
|    entropy_loss         | -207          |
|    explained_variance   | 0.157         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.07         |
|    n_updates            | 17120         |
|    policy_gradient_loss | -0.00412      |
|    reward               | 1.5324402e-05 |
|    std                  | 425           |
|    value_loss           | 5.08e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2169, ResetDay: 3849,Episode: 2088
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 168, ResetDay: 1848,Episode: 2089
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1714         |
|    time_elapsed         | 38796        |
|    total_timesteps      | 3510272      |
| train/                  |              |
|    approx_kl            | 13442.78     |
|    clip_fraction        | 0.0128       |
|    clip_range           | 0.2          |
|    entropy_loss         | -207         |
|    explained_variance   | 0.248        |
|    learning_rate        | 0.00025      |
|    loss                 | -2.07        |
|    n_updates            | 17130        |
|    policy_gradient_loss | -0.00208     |
|    reward               | -7.57983e-06 |
|    std                  | 426          |
|    value_loss           | 3.22e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 573, ResetDay: 2253,Episode: 2090
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1715           |
|    time_elapsed         | 38819          |
|    total_timesteps      | 3512320        |
| train/                  |                |
|    approx_kl            | 13505.963      |
|    clip_fraction        | 0.0104         |
|    clip_range           | 0.2            |
|    entropy_loss         | -207           |
|    explained_variance   | 0.0289         |
|    learning_rate        | 0.00025        |
|    loss                 | -2.08          |
|    n_updates            | 17140          |
|    policy_gradient_loss | -0.00272       |
|    reward               | -0.00029045524 |
|    std                  | 427            |
|    value_loss           | 1.92e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2253, episode: 2090
begin_total_asset: 200.00
end_total_asset: 87.60
total_reward: -112.40
total_cost: 74.20
total_trades: 31419
Sharpe: -0.237
=================================
Reseting Environment StartDay: 1524, ResetDay: 3204,Episode: 2091
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1716           |
|    time_elapsed         | 38841          |
|    total_timesteps      | 3514368        |
| train/                  |                |
|    approx_kl            | 13629.256      |
|    clip_fraction        | 0.0139         |
|    clip_range           | 0.2            |
|    entropy_loss         | -207           |
|    explained_variance   | -0.636         |
|    learning_rate        | 0.00025        |
|    loss                 | -2.07          |
|    n_updates            | 17150          |
|    policy_gradient_loss | 0.00137        |
|    reward               | -5.6819918e-05 |
|    std                  | 428            |
|    value_loss           | 3.3e-07        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 574, ResetDay: 2254,Episode: 2092
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1717          |
|    time_elapsed         | 38864         |
|    total_timesteps      | 3516416       |
| train/                  |               |
|    approx_kl            | 13653.256     |
|    clip_fraction        | 0.0126        |
|    clip_range           | 0.2           |
|    entropy_loss         | -207          |
|    explained_variance   | 0.244         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.1          |
|    n_updates            | 17160         |
|    policy_gradient_loss | -0.00405      |
|    reward               | 3.6876678e-05 |
|    std                  | 429           |
|    value_loss           | 4.16e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1252, ResetDay: 2932,Episode: 2093
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 31, ResetDay: 1711,Episode: 2094
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1718           |
|    time_elapsed         | 38886          |
|    total_timesteps      | 3518464        |
| train/                  |                |
|    approx_kl            | 13645.022      |
|    clip_fraction        | 0.0138         |
|    clip_range           | 0.2            |
|    entropy_loss         | -208           |
|    explained_variance   | 0.053          |
|    learning_rate        | 0.00025        |
|    loss                 | -2.08          |
|    n_updates            | 17170          |
|    policy_gradient_loss | -0.0043        |
|    reward               | -0.00012158601 |
|    std                  | 431            |
|    value_loss           | 8.41e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2063, ResetDay: 3743,Episode: 2095
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1719           |
|    time_elapsed         | 38909          |
|    total_timesteps      | 3520512        |
| train/                  |                |
|    approx_kl            | 13816.871      |
|    clip_fraction        | 0.0168         |
|    clip_range           | 0.2            |
|    entropy_loss         | -208           |
|    explained_variance   | -0.162         |
|    learning_rate        | 0.00025        |
|    loss                 | -2.09          |
|    n_updates            | 17180          |
|    policy_gradient_loss | -0.00159       |
|    reward               | -0.00052631646 |
|    std                  | 432            |
|    value_loss           | 4.12e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3743, episode: 2095
begin_total_asset: 200.00
end_total_asset: 564.82
total_reward: 364.82
total_cost: 59.37
total_trades: 31013
Sharpe: 0.690
=================================
Reseting Environment StartDay: 396, ResetDay: 2076,Episode: 2096
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1720         |
|    time_elapsed         | 38931        |
|    total_timesteps      | 3522560      |
| train/                  |              |
|    approx_kl            | 13946.562    |
|    clip_fraction        | 0.012        |
|    clip_range           | 0.2          |
|    entropy_loss         | -208         |
|    explained_variance   | 0.179        |
|    learning_rate        | 0.00025      |
|    loss                 | -2.08        |
|    n_updates            | 17190        |
|    policy_gradient_loss | -0.00422     |
|    reward               | 1.408844e-05 |
|    std                  | 433          |
|    value_loss           | 4.73e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 903, ResetDay: 2583,Episode: 2097
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1721           |
|    time_elapsed         | 38953          |
|    total_timesteps      | 3524608        |
| train/                  |                |
|    approx_kl            | 13930.356      |
|    clip_fraction        | 0.0118         |
|    clip_range           | 0.2            |
|    entropy_loss         | -208           |
|    explained_variance   | 0.109          |
|    learning_rate        | 0.00025        |
|    loss                 | -2.09          |
|    n_updates            | 17200          |
|    policy_gradient_loss | -0.0043        |
|    reward               | -7.8098295e-05 |
|    std                  | 434            |
|    value_loss           | 2.59e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2240, ResetDay: 3920,Episode: 2098
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1722          |
|    time_elapsed         | 38976         |
|    total_timesteps      | 3526656       |
| train/                  |               |
|    approx_kl            | 13955.557     |
|    clip_fraction        | 0.0139        |
|    clip_range           | 0.2           |
|    entropy_loss         | -208          |
|    explained_variance   | -0.428        |
|    learning_rate        | 0.00025       |
|    loss                 | -2.09         |
|    n_updates            | 17210         |
|    policy_gradient_loss | -0.00148      |
|    reward               | -0.0003729992 |
|    std                  | 436           |
|    value_loss           | 2.82e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2434, ResetDay: 4114,Episode: 2099
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2693, ResetDay: 4373,Episode: 2100
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1723          |
|    time_elapsed         | 38998         |
|    total_timesteps      | 3528704       |
| train/                  |               |
|    approx_kl            | 14160.035     |
|    clip_fraction        | 0.0111        |
|    clip_range           | 0.2           |
|    entropy_loss         | -208          |
|    explained_variance   | 0.12          |
|    learning_rate        | 0.00025       |
|    loss                 | -2.09         |
|    n_updates            | 17220         |
|    policy_gradient_loss | -0.00537      |
|    reward               | -3.736439e-05 |
|    std                  | 438           |
|    value_loss           | 1.02e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4373, episode: 2100
begin_total_asset: 200.00
end_total_asset: 120.88
total_reward: -79.12
total_cost: 50.91
total_trades: 31017
Sharpe: -0.008
=================================
Reseting Environment StartDay: 2612, ResetDay: 4292,Episode: 2101
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1724          |
|    time_elapsed         | 39021         |
|    total_timesteps      | 3530752       |
| train/                  |               |
|    approx_kl            | 14307.258     |
|    clip_fraction        | 0.00903       |
|    clip_range           | 0.2           |
|    entropy_loss         | -208          |
|    explained_variance   | 0.0848        |
|    learning_rate        | 0.00025       |
|    loss                 | -2.09         |
|    n_updates            | 17230         |
|    policy_gradient_loss | -0.00646      |
|    reward               | 3.4359742e-05 |
|    std                  | 439           |
|    value_loss           | 6.48e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1606, ResetDay: 3286,Episode: 2102
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1725           |
|    time_elapsed         | 39043          |
|    total_timesteps      | 3532800        |
| train/                  |                |
|    approx_kl            | 14174.855      |
|    clip_fraction        | 0.017          |
|    clip_range           | 0.2            |
|    entropy_loss         | -208           |
|    explained_variance   | 0.187          |
|    learning_rate        | 0.00025        |
|    loss                 | -2.09          |
|    n_updates            | 17240          |
|    policy_gradient_loss | -0.00371       |
|    reward               | 0.000118385695 |
|    std                  | 441            |
|    value_loss           | 3.43e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2501, ResetDay: 4181,Episode: 2103
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1726          |
|    time_elapsed         | 39066         |
|    total_timesteps      | 3534848       |
| train/                  |               |
|    approx_kl            | 14386.699     |
|    clip_fraction        | 0.0123        |
|    clip_range           | 0.2           |
|    entropy_loss         | -208          |
|    explained_variance   | 0.0588        |
|    learning_rate        | 0.00025       |
|    loss                 | -2.06         |
|    n_updates            | 17250         |
|    policy_gradient_loss | -0.00148      |
|    reward               | 4.8772813e-06 |
|    std                  | 444           |
|    value_loss           | 5.16e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1327, ResetDay: 3007,Episode: 2104
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 930, ResetDay: 2610,Episode: 2105
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1727          |
|    time_elapsed         | 39088         |
|    total_timesteps      | 3536896       |
| train/                  |               |
|    approx_kl            | 14711.137     |
|    clip_fraction        | 0.0139        |
|    clip_range           | 0.2           |
|    entropy_loss         | -208          |
|    explained_variance   | 0.209         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.08         |
|    n_updates            | 17260         |
|    policy_gradient_loss | -0.00267      |
|    reward               | -4.263687e-05 |
|    std                  | 445           |
|    value_loss           | 1.14e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2610, episode: 2105
begin_total_asset: 200.00
end_total_asset: 77.09
total_reward: -122.91
total_cost: 45.30
total_trades: 31055
Sharpe: -0.214
=================================
Reseting Environment StartDay: 2303, ResetDay: 3983,Episode: 2106
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1728           |
|    time_elapsed         | 39111          |
|    total_timesteps      | 3538944        |
| train/                  |                |
|    approx_kl            | 14762.327      |
|    clip_fraction        | 0.0114         |
|    clip_range           | 0.2            |
|    entropy_loss         | -208           |
|    explained_variance   | -0.378         |
|    learning_rate        | 0.00025        |
|    loss                 | -2.07          |
|    n_updates            | 17270          |
|    policy_gradient_loss | 0.00121        |
|    reward               | -0.00040892028 |
|    std                  | 447            |
|    value_loss           | 6.46e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 532, ResetDay: 2212,Episode: 2107
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1729          |
|    time_elapsed         | 39133         |
|    total_timesteps      | 3540992       |
| train/                  |               |
|    approx_kl            | 14879.605     |
|    clip_fraction        | 0.00859       |
|    clip_range           | 0.2           |
|    entropy_loss         | -209          |
|    explained_variance   | 0.117         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.1          |
|    n_updates            | 17280         |
|    policy_gradient_loss | 0.00234       |
|    reward               | 3.6632537e-05 |
|    std                  | 447           |
|    value_loss           | 2.62e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 31, ResetDay: 1711,Episode: 2108
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1730           |
|    time_elapsed         | 39156          |
|    total_timesteps      | 3543040        |
| train/                  |                |
|    approx_kl            | 14860.699      |
|    clip_fraction        | 0.0128         |
|    clip_range           | 0.2            |
|    entropy_loss         | -209           |
|    explained_variance   | 0.0765         |
|    learning_rate        | 0.00025        |
|    loss                 | -2.09          |
|    n_updates            | 17290          |
|    policy_gradient_loss | -0.00208       |
|    reward               | -0.00013737773 |
|    std                  | 449            |
|    value_loss           | 1.89e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1244, ResetDay: 2924,Episode: 2109
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1731           |
|    time_elapsed         | 39178          |
|    total_timesteps      | 3545088        |
| train/                  |                |
|    approx_kl            | 15095.162      |
|    clip_fraction        | 0.0133         |
|    clip_range           | 0.2            |
|    entropy_loss         | -209           |
|    explained_variance   | -0.468         |
|    learning_rate        | 0.00025        |
|    loss                 | -2.11          |
|    n_updates            | 17300          |
|    policy_gradient_loss | -0.00556       |
|    reward               | -5.8253478e-05 |
|    std                  | 451            |
|    value_loss           | 4.2e-07        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 862, ResetDay: 2542,Episode: 2110
Environment reached Terminal state as number of trading days reached limit!!
day: 2542, episode: 2110
begin_total_asset: 200.00
end_total_asset: 91.90
total_reward: -108.10
total_cost: 36.74
total_trades: 30786
Sharpe: -0.116
=================================
Reseting Environment StartDay: 1158, ResetDay: 2838,Episode: 2111
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1732          |
|    time_elapsed         | 39201         |
|    total_timesteps      | 3547136       |
| train/                  |               |
|    approx_kl            | 15308.944     |
|    clip_fraction        | 0.00898       |
|    clip_range           | 0.2           |
|    entropy_loss         | -209          |
|    explained_variance   | 0.146         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.1          |
|    n_updates            | 17310         |
|    policy_gradient_loss | 0.000581      |
|    reward               | 3.5252572e-06 |
|    std                  | 452           |
|    value_loss           | 3.54e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1121, ResetDay: 2801,Episode: 2112
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1733         |
|    time_elapsed         | 39223        |
|    total_timesteps      | 3549184      |
| train/                  |              |
|    approx_kl            | 15187.073    |
|    clip_fraction        | 0.01         |
|    clip_range           | 0.2          |
|    entropy_loss         | -209         |
|    explained_variance   | 0.277        |
|    learning_rate        | 0.00025      |
|    loss                 | -2.1         |
|    n_updates            | 17320        |
|    policy_gradient_loss | 0.0068       |
|    reward               | 5.575447e-05 |
|    std                  | 453          |
|    value_loss           | 2.93e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2191, ResetDay: 3871,Episode: 2113
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1734          |
|    time_elapsed         | 39245         |
|    total_timesteps      | 3551232       |
| train/                  |               |
|    approx_kl            | 15391.656     |
|    clip_fraction        | 0.0115        |
|    clip_range           | 0.2           |
|    entropy_loss         | -209          |
|    explained_variance   | 0.336         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.1          |
|    n_updates            | 17330         |
|    policy_gradient_loss | -0.00508      |
|    reward               | 0.00012791443 |
|    std                  | 454           |
|    value_loss           | 2.16e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 310, ResetDay: 1990,Episode: 2114
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1735          |
|    time_elapsed         | 39268         |
|    total_timesteps      | 3553280       |
| train/                  |               |
|    approx_kl            | 15266.545     |
|    clip_fraction        | 0.0108        |
|    clip_range           | 0.2           |
|    entropy_loss         | -209          |
|    explained_variance   | 0.168         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.09         |
|    n_updates            | 17340         |
|    policy_gradient_loss | -0.00206      |
|    reward               | 2.8377533e-06 |
|    std                  | 455           |
|    value_loss           | 4.25e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1386, ResetDay: 3066,Episode: 2115
Environment reached Terminal state as number of trading days reached limit!!
day: 3066, episode: 2115
begin_total_asset: 200.00
end_total_asset: 213.57
total_reward: 13.57
total_cost: 46.35
total_trades: 30722
Sharpe: 0.173
=================================
Reseting Environment StartDay: 188, ResetDay: 1868,Episode: 2116
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1736          |
|    time_elapsed         | 39290         |
|    total_timesteps      | 3555328       |
| train/                  |               |
|    approx_kl            | 15405.664     |
|    clip_fraction        | 0.0117        |
|    clip_range           | 0.2           |
|    entropy_loss         | -209          |
|    explained_variance   | 0.0925        |
|    learning_rate        | 0.00025       |
|    loss                 | -2.1          |
|    n_updates            | 17350         |
|    policy_gradient_loss | 0.00182       |
|    reward               | 9.1812515e-05 |
|    std                  | 456           |
|    value_loss           | 2.06e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2756, ResetDay: 4436,Episode: 2117
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1737          |
|    time_elapsed         | 39313         |
|    total_timesteps      | 3557376       |
| train/                  |               |
|    approx_kl            | 15473.895     |
|    clip_fraction        | 0.0102        |
|    clip_range           | 0.2           |
|    entropy_loss         | -209          |
|    explained_variance   | 0.195         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.1          |
|    n_updates            | 17360         |
|    policy_gradient_loss | -0.00231      |
|    reward               | 1.0146332e-05 |
|    std                  | 457           |
|    value_loss           | 5.14e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1458, ResetDay: 3138,Episode: 2118
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1738           |
|    time_elapsed         | 39336          |
|    total_timesteps      | 3559424        |
| train/                  |                |
|    approx_kl            | 15536.52       |
|    clip_fraction        | 0.0127         |
|    clip_range           | 0.2            |
|    entropy_loss         | -209           |
|    explained_variance   | -0.119         |
|    learning_rate        | 0.00025        |
|    loss                 | -2.09          |
|    n_updates            | 17370          |
|    policy_gradient_loss | 0.00299        |
|    reward               | -6.0317993e-06 |
|    std                  | 458            |
|    value_loss           | 4.35e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1065, ResetDay: 2745,Episode: 2119
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1739           |
|    time_elapsed         | 39358          |
|    total_timesteps      | 3561472        |
| train/                  |                |
|    approx_kl            | 15598.159      |
|    clip_fraction        | 0.0119         |
|    clip_range           | 0.2            |
|    entropy_loss         | -209           |
|    explained_variance   | 0.0697         |
|    learning_rate        | 0.00025        |
|    loss                 | -2.09          |
|    n_updates            | 17380          |
|    policy_gradient_loss | 0.000687       |
|    reward               | -5.6858826e-05 |
|    std                  | 460            |
|    value_loss           | 4.93e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 853, ResetDay: 2533,Episode: 2120
---------------------------------------
| time/                   |           |
|    fps                  | 90        |
|    iterations           | 1740      |
|    time_elapsed         | 39381     |
|    total_timesteps      | 3563520   |
| train/                  |           |
|    approx_kl            | 15831.887 |
|    clip_fraction        | 0.00923   |
|    clip_range           | 0.2       |
|    entropy_loss         | -209      |
|    explained_variance   | -0.461    |
|    learning_rate        | 0.00025   |
|    loss                 | -2.1      |
|    n_updates            | 17390     |
|    policy_gradient_loss | -0.00327  |
|    reward               | 0.0       |
|    std                  | 460       |
|    value_loss           | 2.57e-07  |
---------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2533, episode: 2120
begin_total_asset: 200.00
end_total_asset: 114.01
total_reward: -85.99
total_cost: 28.81
total_trades: 30773
Sharpe: -0.060
=================================
Reseting Environment StartDay: 590, ResetDay: 2270,Episode: 2121
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1662, ResetDay: 3342,Episode: 2122
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1741          |
|    time_elapsed         | 39403         |
|    total_timesteps      | 3565568       |
| train/                  |               |
|    approx_kl            | 15652.562     |
|    clip_fraction        | 0.0104        |
|    clip_range           | 0.2           |
|    entropy_loss         | -209          |
|    explained_variance   | 0.317         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.09         |
|    n_updates            | 17400         |
|    policy_gradient_loss | -0.00169      |
|    reward               | -0.0001211113 |
|    std                  | 463           |
|    value_loss           | 2.07e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1696, ResetDay: 3376,Episode: 2123
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1742         |
|    time_elapsed         | 39426        |
|    total_timesteps      | 3567616      |
| train/                  |              |
|    approx_kl            | 15921.917    |
|    clip_fraction        | 0.0144       |
|    clip_range           | 0.2          |
|    entropy_loss         | -210         |
|    explained_variance   | 0.232        |
|    learning_rate        | 0.00025      |
|    loss                 | -2.11        |
|    n_updates            | 17410        |
|    policy_gradient_loss | -0.00442     |
|    reward               | 8.975696e-05 |
|    std                  | 464          |
|    value_loss           | 2.58e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 94, ResetDay: 1774,Episode: 2124
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1743           |
|    time_elapsed         | 39448          |
|    total_timesteps      | 3569664        |
| train/                  |                |
|    approx_kl            | 15985.049      |
|    clip_fraction        | 0.0139         |
|    clip_range           | 0.2            |
|    entropy_loss         | -210           |
|    explained_variance   | 0.1            |
|    learning_rate        | 0.00025        |
|    loss                 | -2.1           |
|    n_updates            | 17420          |
|    policy_gradient_loss | 0.000356       |
|    reward               | -1.6907119e-05 |
|    std                  | 467            |
|    value_loss           | 5.02e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2573, ResetDay: 4253,Episode: 2125
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1744         |
|    time_elapsed         | 39471        |
|    total_timesteps      | 3571712      |
| train/                  |              |
|    approx_kl            | 16259.809    |
|    clip_fraction        | 0.0145       |
|    clip_range           | 0.2          |
|    entropy_loss         | -210         |
|    explained_variance   | 0.0743       |
|    learning_rate        | 0.00025      |
|    loss                 | -2.11        |
|    n_updates            | 17430        |
|    policy_gradient_loss | -0.00363     |
|    reward               | 0.0010240715 |
|    std                  | 468          |
|    value_loss           | 3.65e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4253, episode: 2125
begin_total_asset: 200.00
end_total_asset: 751.89
total_reward: 551.89
total_cost: 76.70
total_trades: 30681
Sharpe: 0.649
=================================
Reseting Environment StartDay: 20, ResetDay: 1700,Episode: 2126
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1745          |
|    time_elapsed         | 39493         |
|    total_timesteps      | 3573760       |
| train/                  |               |
|    approx_kl            | 16412.541     |
|    clip_fraction        | 0.0122        |
|    clip_range           | 0.2           |
|    entropy_loss         | -210          |
|    explained_variance   | 0.103         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.1          |
|    n_updates            | 17440         |
|    policy_gradient_loss | -0.00376      |
|    reward               | 1.1399078e-05 |
|    std                  | 471           |
|    value_loss           | 3.19e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2005, ResetDay: 3685,Episode: 2127
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2155, ResetDay: 3835,Episode: 2128
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1746          |
|    time_elapsed         | 39516         |
|    total_timesteps      | 3575808       |
| train/                  |               |
|    approx_kl            | 16623.535     |
|    clip_fraction        | 0.0129        |
|    clip_range           | 0.2           |
|    entropy_loss         | -210          |
|    explained_variance   | -0.154        |
|    learning_rate        | 0.00025       |
|    loss                 | -2.11         |
|    n_updates            | 17450         |
|    policy_gradient_loss | -0.00835      |
|    reward               | 0.00025027274 |
|    std                  | 472           |
|    value_loss           | 1.96e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 471, ResetDay: 2151,Episode: 2129
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1747          |
|    time_elapsed         | 39539         |
|    total_timesteps      | 3577856       |
| train/                  |               |
|    approx_kl            | 16785.45      |
|    clip_fraction        | 0.0109        |
|    clip_range           | 0.2           |
|    entropy_loss         | -210          |
|    explained_variance   | 0.0475        |
|    learning_rate        | 0.00025       |
|    loss                 | -2.1          |
|    n_updates            | 17460         |
|    policy_gradient_loss | -0.00442      |
|    reward               | 0.00013526401 |
|    std                  | 473           |
|    value_loss           | 2.47e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2057, ResetDay: 3737,Episode: 2130
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1748           |
|    time_elapsed         | 39561          |
|    total_timesteps      | 3579904        |
| train/                  |                |
|    approx_kl            | 16757.41       |
|    clip_fraction        | 0.0163         |
|    clip_range           | 0.2            |
|    entropy_loss         | -210           |
|    explained_variance   | 0.0517         |
|    learning_rate        | 0.00025        |
|    loss                 | -2.1           |
|    n_updates            | 17470          |
|    policy_gradient_loss | -0.00617       |
|    reward               | -0.00041931306 |
|    std                  | 475            |
|    value_loss           | 8.47e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3737, episode: 2130
begin_total_asset: 200.00
end_total_asset: 366.02
total_reward: 166.02
total_cost: 36.24
total_trades: 30664
Sharpe: 0.531
=================================
Reseting Environment StartDay: 829, ResetDay: 2509,Episode: 2131
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1749          |
|    time_elapsed         | 39584         |
|    total_timesteps      | 3581952       |
| train/                  |               |
|    approx_kl            | 16996.65      |
|    clip_fraction        | 0.00757       |
|    clip_range           | 0.2           |
|    entropy_loss         | -210          |
|    explained_variance   | -0.0735       |
|    learning_rate        | 0.00025       |
|    loss                 | -2.11         |
|    n_updates            | 17480         |
|    policy_gradient_loss | 0.00181       |
|    reward               | 3.1661224e-05 |
|    std                  | 476           |
|    value_loss           | 2.98e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1299, ResetDay: 2979,Episode: 2132
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 769, ResetDay: 2449,Episode: 2133
-----------------------------------------
| time/                   |             |
|    fps                  | 90          |
|    iterations           | 1750        |
|    time_elapsed         | 39607       |
|    total_timesteps      | 3584000     |
| train/                  |             |
|    approx_kl            | 17134.074   |
|    clip_fraction        | 0.0135      |
|    clip_range           | 0.2         |
|    entropy_loss         | -210        |
|    explained_variance   | 0.187       |
|    learning_rate        | 0.00025     |
|    loss                 | -2.11       |
|    n_updates            | 17490       |
|    policy_gradient_loss | 0.00382     |
|    reward               | 3.71005e-05 |
|    std                  | 477         |
|    value_loss           | 8.32e-07    |
-----------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2605, ResetDay: 4285,Episode: 2134
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1751          |
|    time_elapsed         | 39629         |
|    total_timesteps      | 3586048       |
| train/                  |               |
|    approx_kl            | 17094.467     |
|    clip_fraction        | 0.013         |
|    clip_range           | 0.2           |
|    entropy_loss         | -210          |
|    explained_variance   | 0.145         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.11         |
|    n_updates            | 17500         |
|    policy_gradient_loss | -0.00149      |
|    reward               | 0.00011307335 |
|    std                  | 479           |
|    value_loss           | 3.06e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1655, ResetDay: 3335,Episode: 2135
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1752          |
|    time_elapsed         | 39652         |
|    total_timesteps      | 3588096       |
| train/                  |               |
|    approx_kl            | 17221.36      |
|    clip_fraction        | 0.0142        |
|    clip_range           | 0.2           |
|    entropy_loss         | -210          |
|    explained_variance   | 0.369         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.11         |
|    n_updates            | 17510         |
|    policy_gradient_loss | -0.00656      |
|    reward               | -6.529007e-05 |
|    std                  | 481           |
|    value_loss           | 3.35e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3335, episode: 2135
begin_total_asset: 200.00
end_total_asset: 138.19
total_reward: -61.81
total_cost: 23.95
total_trades: 30548
Sharpe: 0.082
=================================
Reseting Environment StartDay: 610, ResetDay: 2290,Episode: 2136
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1753         |
|    time_elapsed         | 39675        |
|    total_timesteps      | 3590144      |
| train/                  |              |
|    approx_kl            | 17535.61     |
|    clip_fraction        | 0.0125       |
|    clip_range           | 0.2          |
|    entropy_loss         | -210         |
|    explained_variance   | 0.102        |
|    learning_rate        | 0.00025      |
|    loss                 | -2.12        |
|    n_updates            | 17520        |
|    policy_gradient_loss | -0.00273     |
|    reward               | 9.471397e-05 |
|    std                  | 481          |
|    value_loss           | 1.75e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1032, ResetDay: 2712,Episode: 2137
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1754           |
|    time_elapsed         | 39697          |
|    total_timesteps      | 3592192        |
| train/                  |                |
|    approx_kl            | 17394.023      |
|    clip_fraction        | 0.00967        |
|    clip_range           | 0.2            |
|    entropy_loss         | -210           |
|    explained_variance   | 0.117          |
|    learning_rate        | 0.00025        |
|    loss                 | -2.11          |
|    n_updates            | 17530          |
|    policy_gradient_loss | -0.00123       |
|    reward               | -0.00022493553 |
|    std                  | 483            |
|    value_loss           | 3.46e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2392, ResetDay: 4072,Episode: 2138
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1756, ResetDay: 3436,Episode: 2139
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1755          |
|    time_elapsed         | 39720         |
|    total_timesteps      | 3594240       |
| train/                  |               |
|    approx_kl            | 17557.963     |
|    clip_fraction        | 0.0128        |
|    clip_range           | 0.2           |
|    entropy_loss         | -211          |
|    explained_variance   | 0.154         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.11         |
|    n_updates            | 17540         |
|    policy_gradient_loss | -0.00292      |
|    reward               | 0.00017700749 |
|    std                  | 484           |
|    value_loss           | 2.49e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1675, ResetDay: 3355,Episode: 2140
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1756          |
|    time_elapsed         | 39743         |
|    total_timesteps      | 3596288       |
| train/                  |               |
|    approx_kl            | 17676.277     |
|    clip_fraction        | 0.0146        |
|    clip_range           | 0.2           |
|    entropy_loss         | -211          |
|    explained_variance   | 0.0908        |
|    learning_rate        | 0.00025       |
|    loss                 | -2.11         |
|    n_updates            | 17550         |
|    policy_gradient_loss | -0.0046       |
|    reward               | 0.00010037384 |
|    std                  | 485           |
|    value_loss           | 3.17e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3355, episode: 2140
begin_total_asset: 200.00
end_total_asset: 433.76
total_reward: 233.76
total_cost: 41.01
total_trades: 30614
Sharpe: 0.635
=================================
Reseting Environment StartDay: 548, ResetDay: 2228,Episode: 2141
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1757         |
|    time_elapsed         | 39765        |
|    total_timesteps      | 3598336      |
| train/                  |              |
|    approx_kl            | 17683.36     |
|    clip_fraction        | 0.0134       |
|    clip_range           | 0.2          |
|    entropy_loss         | -211         |
|    explained_variance   | 0.00755      |
|    learning_rate        | 0.00025      |
|    loss                 | -2.13        |
|    n_updates            | 17560        |
|    policy_gradient_loss | 0.00851      |
|    reward               | 2.120304e-06 |
|    std                  | 487          |
|    value_loss           | 4.12e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1457, ResetDay: 3137,Episode: 2142
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1758          |
|    time_elapsed         | 39788         |
|    total_timesteps      | 3600384       |
| train/                  |               |
|    approx_kl            | 17861.348     |
|    clip_fraction        | 0.0104        |
|    clip_range           | 0.2           |
|    entropy_loss         | -211          |
|    explained_variance   | 0.108         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.1          |
|    n_updates            | 17570         |
|    policy_gradient_loss | 0.00313       |
|    reward               | 6.7968176e-05 |
|    std                  | 490           |
|    value_loss           | 8.14e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 99, ResetDay: 1779,Episode: 2143
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 461, ResetDay: 2141,Episode: 2144
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1759          |
|    time_elapsed         | 39810         |
|    total_timesteps      | 3602432       |
| train/                  |               |
|    approx_kl            | 18174.852     |
|    clip_fraction        | 0.0174        |
|    clip_range           | 0.2           |
|    entropy_loss         | -211          |
|    explained_variance   | 0.215         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.12         |
|    n_updates            | 17580         |
|    policy_gradient_loss | -0.00592      |
|    reward               | 5.9640337e-05 |
|    std                  | 491           |
|    value_loss           | 2.38e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 506, ResetDay: 2186,Episode: 2145
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1760          |
|    time_elapsed         | 39833         |
|    total_timesteps      | 3604480       |
| train/                  |               |
|    approx_kl            | 18295.951     |
|    clip_fraction        | 0.0105        |
|    clip_range           | 0.2           |
|    entropy_loss         | -211          |
|    explained_variance   | -0.322        |
|    learning_rate        | 0.00025       |
|    loss                 | -2.1          |
|    n_updates            | 17590         |
|    policy_gradient_loss | 0.00128       |
|    reward               | 0.00030896257 |
|    std                  | 491           |
|    value_loss           | 3.49e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2186, episode: 2145
begin_total_asset: 200.00
end_total_asset: 61.48
total_reward: -138.52
total_cost: 85.37
total_trades: 30900
Sharpe: -0.332
=================================
Reseting Environment StartDay: 390, ResetDay: 2070,Episode: 2146
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1761          |
|    time_elapsed         | 39855         |
|    total_timesteps      | 3606528       |
| train/                  |               |
|    approx_kl            | 18159.139     |
|    clip_fraction        | 0.00952       |
|    clip_range           | 0.2           |
|    entropy_loss         | -211          |
|    explained_variance   | 0.31          |
|    learning_rate        | 0.00025       |
|    loss                 | -2.07         |
|    n_updates            | 17600         |
|    policy_gradient_loss | -0.000337     |
|    reward               | -9.253547e-06 |
|    std                  | 491           |
|    value_loss           | 7.06e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1181, ResetDay: 2861,Episode: 2147
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1762          |
|    time_elapsed         | 39878         |
|    total_timesteps      | 3608576       |
| train/                  |               |
|    approx_kl            | 18145.992     |
|    clip_fraction        | 0.00986       |
|    clip_range           | 0.2           |
|    entropy_loss         | -211          |
|    explained_variance   | 0.113         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.12         |
|    n_updates            | 17610         |
|    policy_gradient_loss | 0.00131       |
|    reward               | 1.8386077e-05 |
|    std                  | 494           |
|    value_loss           | 2.47e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2741, ResetDay: 4421,Episode: 2148
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1763         |
|    time_elapsed         | 39900        |
|    total_timesteps      | 3610624      |
| train/                  |              |
|    approx_kl            | 18436.537    |
|    clip_fraction        | 0.0135       |
|    clip_range           | 0.2          |
|    entropy_loss         | -211         |
|    explained_variance   | 0.272        |
|    learning_rate        | 0.00025      |
|    loss                 | -2.12        |
|    n_updates            | 17620        |
|    policy_gradient_loss | -0.00276     |
|    reward               | -0.000778883 |
|    std                  | 495          |
|    value_loss           | 1.88e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 284, ResetDay: 1964,Episode: 2149
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 212, ResetDay: 1892,Episode: 2150
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1764           |
|    time_elapsed         | 39923          |
|    total_timesteps      | 3612672        |
| train/                  |                |
|    approx_kl            | 18466.121      |
|    clip_fraction        | 0.0107         |
|    clip_range           | 0.2            |
|    entropy_loss         | -211           |
|    explained_variance   | 0.0412         |
|    learning_rate        | 0.00025        |
|    loss                 | -2.13          |
|    n_updates            | 17630          |
|    policy_gradient_loss | -0.00217       |
|    reward               | -8.1872284e-05 |
|    std                  | 497            |
|    value_loss           | 1.67e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 1892, episode: 2150
begin_total_asset: 200.00
end_total_asset: 82.65
total_reward: -117.35
total_cost: 62.41
total_trades: 30813
Sharpe: -0.179
=================================
Reseting Environment StartDay: 926, ResetDay: 2606,Episode: 2151
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1765         |
|    time_elapsed         | 39946        |
|    total_timesteps      | 3614720      |
| train/                  |              |
|    approx_kl            | 18598.691    |
|    clip_fraction        | 0.0128       |
|    clip_range           | 0.2          |
|    entropy_loss         | -211         |
|    explained_variance   | -0.871       |
|    learning_rate        | 0.00025      |
|    loss                 | -2.12        |
|    n_updates            | 17640        |
|    policy_gradient_loss | -0.00664     |
|    reward               | -8.45375e-05 |
|    std                  | 499          |
|    value_loss           | 6.33e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2028, ResetDay: 3708,Episode: 2152
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1766          |
|    time_elapsed         | 39968         |
|    total_timesteps      | 3616768       |
| train/                  |               |
|    approx_kl            | 18893.238     |
|    clip_fraction        | 0.00791       |
|    clip_range           | 0.2           |
|    entropy_loss         | -211          |
|    explained_variance   | 0.126         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.12         |
|    n_updates            | 17650         |
|    policy_gradient_loss | -0.00131      |
|    reward               | 0.00014945869 |
|    std                  | 500           |
|    value_loss           | 3.6e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 392, ResetDay: 2072,Episode: 2153
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1767          |
|    time_elapsed         | 39991         |
|    total_timesteps      | 3618816       |
| train/                  |               |
|    approx_kl            | 18969.098     |
|    clip_fraction        | 0.0105        |
|    clip_range           | 0.2           |
|    entropy_loss         | -211          |
|    explained_variance   | 0.126         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.12         |
|    n_updates            | 17660         |
|    policy_gradient_loss | -0.00216      |
|    reward               | 1.4961338e-05 |
|    std                  | 501           |
|    value_loss           | 2.73e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 163, ResetDay: 1843,Episode: 2154
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1768           |
|    time_elapsed         | 40014          |
|    total_timesteps      | 3620864        |
| train/                  |                |
|    approx_kl            | 18932.107      |
|    clip_fraction        | 0.0102         |
|    clip_range           | 0.2            |
|    entropy_loss         | -212           |
|    explained_variance   | 0.104          |
|    learning_rate        | 0.00025        |
|    loss                 | -2.12          |
|    n_updates            | 17670          |
|    policy_gradient_loss | 0.00439        |
|    reward               | -0.00011534386 |
|    std                  | 503            |
|    value_loss           | 9.03e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 340, ResetDay: 2020,Episode: 2155
Environment reached Terminal state as number of trading days reached limit!!
day: 2020, episode: 2155
begin_total_asset: 200.00
end_total_asset: 114.83
total_reward: -85.17
total_cost: 99.07
total_trades: 30609
Sharpe: -0.092
=================================
Reseting Environment StartDay: 893, ResetDay: 2573,Episode: 2156
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1769           |
|    time_elapsed         | 40036          |
|    total_timesteps      | 3622912        |
| train/                  |                |
|    approx_kl            | 19225.137      |
|    clip_fraction        | 0.012          |
|    clip_range           | 0.2            |
|    entropy_loss         | -212           |
|    explained_variance   | 0.0573         |
|    learning_rate        | 0.00025        |
|    loss                 | -2.13          |
|    n_updates            | 17680          |
|    policy_gradient_loss | -0.00406       |
|    reward               | -0.00015453475 |
|    std                  | 503            |
|    value_loss           | 3.69e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2723, ResetDay: 4403,Episode: 2157
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1770         |
|    time_elapsed         | 40059        |
|    total_timesteps      | 3624960      |
| train/                  |              |
|    approx_kl            | 19004.629    |
|    clip_fraction        | 0.0127       |
|    clip_range           | 0.2          |
|    entropy_loss         | -212         |
|    explained_variance   | 0.366        |
|    learning_rate        | 0.00025      |
|    loss                 | -2.13        |
|    n_updates            | 17690        |
|    policy_gradient_loss | -0.00274     |
|    reward               | 0.0003321167 |
|    std                  | 505          |
|    value_loss           | 6.12e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 124, ResetDay: 1804,Episode: 2158
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1771           |
|    time_elapsed         | 40081          |
|    total_timesteps      | 3627008        |
| train/                  |                |
|    approx_kl            | 19402.516      |
|    clip_fraction        | 0.0122         |
|    clip_range           | 0.2            |
|    entropy_loss         | -212           |
|    explained_variance   | 0.0307         |
|    learning_rate        | 0.00025        |
|    loss                 | -2.11          |
|    n_updates            | 17700          |
|    policy_gradient_loss | -0.00399       |
|    reward               | -8.8765904e-05 |
|    std                  | 506            |
|    value_loss           | 8.02e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 583, ResetDay: 2263,Episode: 2159
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1772          |
|    time_elapsed         | 40104         |
|    total_timesteps      | 3629056       |
| train/                  |               |
|    approx_kl            | 19268.838     |
|    clip_fraction        | 0.00991       |
|    clip_range           | 0.2           |
|    entropy_loss         | -212          |
|    explained_variance   | 0.0244        |
|    learning_rate        | 0.00025       |
|    loss                 | -2.1          |
|    n_updates            | 17710         |
|    policy_gradient_loss | 0.00712       |
|    reward               | 0.00015930558 |
|    std                  | 507           |
|    value_loss           | 2.09e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2092, ResetDay: 3772,Episode: 2160
Environment reached Terminal state as number of trading days reached limit!!
day: 3772, episode: 2160
begin_total_asset: 200.00
end_total_asset: 250.14
total_reward: 50.14
total_cost: 73.34
total_trades: 30094
Sharpe: 0.261
=================================
Reseting Environment StartDay: 1265, ResetDay: 2945,Episode: 2161
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1773          |
|    time_elapsed         | 40126         |
|    total_timesteps      | 3631104       |
| train/                  |               |
|    approx_kl            | 19370.645     |
|    clip_fraction        | 0.0134        |
|    clip_range           | 0.2           |
|    entropy_loss         | -212          |
|    explained_variance   | 0.0351        |
|    learning_rate        | 0.00025       |
|    loss                 | -2.13         |
|    n_updates            | 17720         |
|    policy_gradient_loss | -0.00351      |
|    reward               | 0.00019021511 |
|    std                  | 509           |
|    value_loss           | 4.96e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 751, ResetDay: 2431,Episode: 2162
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1774         |
|    time_elapsed         | 40149        |
|    total_timesteps      | 3633152      |
| train/                  |              |
|    approx_kl            | 19401.342    |
|    clip_fraction        | 0.0155       |
|    clip_range           | 0.2          |
|    entropy_loss         | -212         |
|    explained_variance   | 0.113        |
|    learning_rate        | 0.00025      |
|    loss                 | -2.13        |
|    n_updates            | 17730        |
|    policy_gradient_loss | -0.00296     |
|    reward               | 4.227066e-05 |
|    std                  | 512          |
|    value_loss           | 1.46e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1072, ResetDay: 2752,Episode: 2163
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1775           |
|    time_elapsed         | 40172          |
|    total_timesteps      | 3635200        |
| train/                  |                |
|    approx_kl            | 19590.703      |
|    clip_fraction        | 0.00923        |
|    clip_range           | 0.2            |
|    entropy_loss         | -212           |
|    explained_variance   | -0.108         |
|    learning_rate        | 0.00025        |
|    loss                 | -2.13          |
|    n_updates            | 17740          |
|    policy_gradient_loss | -0.000196      |
|    reward               | -8.7795066e-05 |
|    std                  | 516            |
|    value_loss           | 2.23e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2271, ResetDay: 3951,Episode: 2164
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1776         |
|    time_elapsed         | 40194        |
|    total_timesteps      | 3637248      |
| train/                  |              |
|    approx_kl            | 19973.176    |
|    clip_fraction        | 0.0132       |
|    clip_range           | 0.2          |
|    entropy_loss         | -212         |
|    explained_variance   | 0.383        |
|    learning_rate        | 0.00025      |
|    loss                 | -2.13        |
|    n_updates            | 17750        |
|    policy_gradient_loss | -0.00316     |
|    reward               | 0.0006020851 |
|    std                  | 518          |
|    value_loss           | 2.01e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2397, ResetDay: 4077,Episode: 2165
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1777         |
|    time_elapsed         | 40217        |
|    total_timesteps      | 3639296      |
| train/                  |              |
|    approx_kl            | 20268.928    |
|    clip_fraction        | 0.0126       |
|    clip_range           | 0.2          |
|    entropy_loss         | -213         |
|    explained_variance   | 0.146        |
|    learning_rate        | 0.00025      |
|    loss                 | -2.13        |
|    n_updates            | 17760        |
|    policy_gradient_loss | -0.00406     |
|    reward               | 0.0006368332 |
|    std                  | 521          |
|    value_loss           | 8.34e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4077, episode: 2165
begin_total_asset: 200.00
end_total_asset: 215.01
total_reward: 15.01
total_cost: 69.45
total_trades: 30226
Sharpe: 0.202
=================================
Reseting Environment StartDay: 744, ResetDay: 2424,Episode: 2166
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 632, ResetDay: 2312,Episode: 2167
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1778          |
|    time_elapsed         | 40239         |
|    total_timesteps      | 3641344       |
| train/                  |               |
|    approx_kl            | 20607.797     |
|    clip_fraction        | 0.015         |
|    clip_range           | 0.2           |
|    entropy_loss         | -213          |
|    explained_variance   | 0.113         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.14         |
|    n_updates            | 17770         |
|    policy_gradient_loss | -0.00412      |
|    reward               | -3.066683e-05 |
|    std                  | 522           |
|    value_loss           | 1.51e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1812, ResetDay: 3492,Episode: 2168
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1779          |
|    time_elapsed         | 40262         |
|    total_timesteps      | 3643392       |
| train/                  |               |
|    approx_kl            | 20581.693     |
|    clip_fraction        | 0.0124        |
|    clip_range           | 0.2           |
|    entropy_loss         | -213          |
|    explained_variance   | -1.38         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.13         |
|    n_updates            | 17780         |
|    policy_gradient_loss | 0.00231       |
|    reward               | 0.00022540856 |
|    std                  | 524           |
|    value_loss           | 4.75e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2777, ResetDay: 4457,Episode: 2169
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1780           |
|    time_elapsed         | 40285          |
|    total_timesteps      | 3645440        |
| train/                  |                |
|    approx_kl            | 20782.34       |
|    clip_fraction        | 0.00845        |
|    clip_range           | 0.2            |
|    entropy_loss         | -213           |
|    explained_variance   | 0.0968         |
|    learning_rate        | 0.00025        |
|    loss                 | -2.13          |
|    n_updates            | 17790          |
|    policy_gradient_loss | -0.00172       |
|    reward               | -0.00020671081 |
|    std                  | 525            |
|    value_loss           | 2.51e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2040, ResetDay: 3720,Episode: 2170
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1781          |
|    time_elapsed         | 40307         |
|    total_timesteps      | 3647488       |
| train/                  |               |
|    approx_kl            | 20889.227     |
|    clip_fraction        | 0.00942       |
|    clip_range           | 0.2           |
|    entropy_loss         | -213          |
|    explained_variance   | 0.0831        |
|    learning_rate        | 0.00025       |
|    loss                 | -2.12         |
|    n_updates            | 17800         |
|    policy_gradient_loss | -0.00176      |
|    reward               | 0.00019329223 |
|    std                  | 526           |
|    value_loss           | 7.41e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3720, episode: 2170
begin_total_asset: 200.00
end_total_asset: 154.97
total_reward: -45.03
total_cost: 47.68
total_trades: 30112
Sharpe: 0.059
=================================
Reseting Environment StartDay: 669, ResetDay: 2349,Episode: 2171
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 73, ResetDay: 1753,Episode: 2172
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1782           |
|    time_elapsed         | 40330          |
|    total_timesteps      | 3649536        |
| train/                  |                |
|    approx_kl            | 20776.102      |
|    clip_fraction        | 0.01           |
|    clip_range           | 0.2            |
|    entropy_loss         | -213           |
|    explained_variance   | -0.126         |
|    learning_rate        | 0.00025        |
|    loss                 | -2.14          |
|    n_updates            | 17810          |
|    policy_gradient_loss | 0.00118        |
|    reward               | -4.6099354e-05 |
|    std                  | 528            |
|    value_loss           | 5.23e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1084, ResetDay: 2764,Episode: 2173
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1783          |
|    time_elapsed         | 40352         |
|    total_timesteps      | 3651584       |
| train/                  |               |
|    approx_kl            | 20945.926     |
|    clip_fraction        | 0.0141        |
|    clip_range           | 0.2           |
|    entropy_loss         | -213          |
|    explained_variance   | -0.166        |
|    learning_rate        | 0.00025       |
|    loss                 | -2.14         |
|    n_updates            | 17820         |
|    policy_gradient_loss | -7.4e-06      |
|    reward               | 3.3932876e-05 |
|    std                  | 530           |
|    value_loss           | 4.07e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1447, ResetDay: 3127,Episode: 2174
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1784          |
|    time_elapsed         | 40375         |
|    total_timesteps      | 3653632       |
| train/                  |               |
|    approx_kl            | 21162.3       |
|    clip_fraction        | 0.0122        |
|    clip_range           | 0.2           |
|    entropy_loss         | -213          |
|    explained_variance   | 0.168         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.14         |
|    n_updates            | 17830         |
|    policy_gradient_loss | -0.0017       |
|    reward               | -5.854473e-05 |
|    std                  | 533           |
|    value_loss           | 4.34e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 816, ResetDay: 2496,Episode: 2175
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1785          |
|    time_elapsed         | 40398         |
|    total_timesteps      | 3655680       |
| train/                  |               |
|    approx_kl            | 21420.24      |
|    clip_fraction        | 0.0121        |
|    clip_range           | 0.2           |
|    entropy_loss         | -213          |
|    explained_variance   | 0.233         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.14         |
|    n_updates            | 17840         |
|    policy_gradient_loss | -0.00177      |
|    reward               | 9.9501034e-05 |
|    std                  | 535           |
|    value_loss           | 2.68e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2496, episode: 2175
begin_total_asset: 200.00
end_total_asset: 79.38
total_reward: -120.62
total_cost: 51.86
total_trades: 30240
Sharpe: -0.184
=================================
Reseting Environment StartDay: 786, ResetDay: 2466,Episode: 2176
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1786          |
|    time_elapsed         | 40420         |
|    total_timesteps      | 3657728       |
| train/                  |               |
|    approx_kl            | 21673.15      |
|    clip_fraction        | 0.0116        |
|    clip_range           | 0.2           |
|    entropy_loss         | -213          |
|    explained_variance   | 0.299         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.11         |
|    n_updates            | 17850         |
|    policy_gradient_loss | -0.000292     |
|    reward               | -2.681408e-05 |
|    std                  | 536           |
|    value_loss           | 3.47e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 751, ResetDay: 2431,Episode: 2177
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 228, ResetDay: 1908,Episode: 2178
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1787          |
|    time_elapsed         | 40443         |
|    total_timesteps      | 3659776       |
| train/                  |               |
|    approx_kl            | 21750.559     |
|    clip_fraction        | 0.011         |
|    clip_range           | 0.2           |
|    entropy_loss         | -213          |
|    explained_variance   | 0.0321        |
|    learning_rate        | 0.00025       |
|    loss                 | -2.13         |
|    n_updates            | 17860         |
|    policy_gradient_loss | 0.00268       |
|    reward               | 1.4092255e-05 |
|    std                  | 537           |
|    value_loss           | 2.38e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 488, ResetDay: 2168,Episode: 2179
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1788           |
|    time_elapsed         | 40465          |
|    total_timesteps      | 3661824        |
| train/                  |                |
|    approx_kl            | 21870.385      |
|    clip_fraction        | 0.00937        |
|    clip_range           | 0.2            |
|    entropy_loss         | -213           |
|    explained_variance   | 0.2            |
|    learning_rate        | 0.00025        |
|    loss                 | -2.14          |
|    n_updates            | 17870          |
|    policy_gradient_loss | -0.00119       |
|    reward               | -0.00019021034 |
|    std                  | 538            |
|    value_loss           | 4.41e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 785, ResetDay: 2465,Episode: 2180
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1789          |
|    time_elapsed         | 40488         |
|    total_timesteps      | 3663872       |
| train/                  |               |
|    approx_kl            | 21997.723     |
|    clip_fraction        | 0.00903       |
|    clip_range           | 0.2           |
|    entropy_loss         | -213          |
|    explained_variance   | 0.259         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.13         |
|    n_updates            | 17880         |
|    policy_gradient_loss | -0.00306      |
|    reward               | 4.2889405e-05 |
|    std                  | 537           |
|    value_loss           | 6.42e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2465, episode: 2180
begin_total_asset: 200.00
end_total_asset: 80.27
total_reward: -119.73
total_cost: 61.98
total_trades: 30209
Sharpe: -0.223
=================================
Reseting Environment StartDay: 589, ResetDay: 2269,Episode: 2181
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1790           |
|    time_elapsed         | 40511          |
|    total_timesteps      | 3665920        |
| train/                  |                |
|    approx_kl            | 21898.633      |
|    clip_fraction        | 0.00791        |
|    clip_range           | 0.2            |
|    entropy_loss         | -213           |
|    explained_variance   | 0.287          |
|    learning_rate        | 0.00025        |
|    loss                 | -2.15          |
|    n_updates            | 17890          |
|    policy_gradient_loss | 0.000555       |
|    reward               | -1.9022369e-05 |
|    std                  | 537            |
|    value_loss           | 4.1e-07        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2558, ResetDay: 4238,Episode: 2182
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 830, ResetDay: 2510,Episode: 2183
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1791           |
|    time_elapsed         | 40533          |
|    total_timesteps      | 3667968        |
| train/                  |                |
|    approx_kl            | 21660.445      |
|    clip_fraction        | 0.0128         |
|    clip_range           | 0.2            |
|    entropy_loss         | -213           |
|    explained_variance   | -0.208         |
|    learning_rate        | 0.00025        |
|    loss                 | -2.12          |
|    n_updates            | 17900          |
|    policy_gradient_loss | -0.00308       |
|    reward               | -0.00014777966 |
|    std                  | 539            |
|    value_loss           | 2.66e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 968, ResetDay: 2648,Episode: 2184
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1792           |
|    time_elapsed         | 40556          |
|    total_timesteps      | 3670016        |
| train/                  |                |
|    approx_kl            | 21894.473      |
|    clip_fraction        | 0.00962        |
|    clip_range           | 0.2            |
|    entropy_loss         | -214           |
|    explained_variance   | 0.0612         |
|    learning_rate        | 0.00025        |
|    loss                 | -2.15          |
|    n_updates            | 17910          |
|    policy_gradient_loss | -0.00228       |
|    reward               | -0.00027185737 |
|    std                  | 541            |
|    value_loss           | 2.64e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 231, ResetDay: 1911,Episode: 2185
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1793          |
|    time_elapsed         | 40578         |
|    total_timesteps      | 3672064       |
| train/                  |               |
|    approx_kl            | 22198.018     |
|    clip_fraction        | 0.0119        |
|    clip_range           | 0.2           |
|    entropy_loss         | -214          |
|    explained_variance   | -1.25         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.15         |
|    n_updates            | 17920         |
|    policy_gradient_loss | -0.00297      |
|    reward               | 0.00035929633 |
|    std                  | 543           |
|    value_loss           | 3.13e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 1911, episode: 2185
begin_total_asset: 200.00
end_total_asset: 59.96
total_reward: -140.04
total_cost: 55.75
total_trades: 30359
Sharpe: -0.289
=================================
Reseting Environment StartDay: 1846, ResetDay: 3526,Episode: 2186
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1794          |
|    time_elapsed         | 40601         |
|    total_timesteps      | 3674112       |
| train/                  |               |
|    approx_kl            | 22211.24      |
|    clip_fraction        | 0.0085        |
|    clip_range           | 0.2           |
|    entropy_loss         | -214          |
|    explained_variance   | 0.145         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.14         |
|    n_updates            | 17930         |
|    policy_gradient_loss | -0.00245      |
|    reward               | 0.00016938859 |
|    std                  | 544           |
|    value_loss           | 3.01e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1337, ResetDay: 3017,Episode: 2187
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1795          |
|    time_elapsed         | 40623         |
|    total_timesteps      | 3676160       |
| train/                  |               |
|    approx_kl            | 22386.791     |
|    clip_fraction        | 0.00977       |
|    clip_range           | 0.2           |
|    entropy_loss         | -214          |
|    explained_variance   | 0.24          |
|    learning_rate        | 0.00025       |
|    loss                 | -2.14         |
|    n_updates            | 17940         |
|    policy_gradient_loss | -0.00261      |
|    reward               | 0.00015211945 |
|    std                  | 544           |
|    value_loss           | 4.69e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 954, ResetDay: 2634,Episode: 2188
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 985, ResetDay: 2665,Episode: 2189
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1796          |
|    time_elapsed         | 40646         |
|    total_timesteps      | 3678208       |
| train/                  |               |
|    approx_kl            | 22256.832     |
|    clip_fraction        | 0.0142        |
|    clip_range           | 0.2           |
|    entropy_loss         | -214          |
|    explained_variance   | 0.132         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.14         |
|    n_updates            | 17950         |
|    policy_gradient_loss | -0.00014      |
|    reward               | 0.00010919857 |
|    std                  | 548           |
|    value_loss           | 1.22e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1495, ResetDay: 3175,Episode: 2190
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1797          |
|    time_elapsed         | 40669         |
|    total_timesteps      | 3680256       |
| train/                  |               |
|    approx_kl            | 22584.695     |
|    clip_fraction        | 0.0146        |
|    clip_range           | 0.2           |
|    entropy_loss         | -214          |
|    explained_variance   | -0.314        |
|    learning_rate        | 0.00025       |
|    loss                 | -2.14         |
|    n_updates            | 17960         |
|    policy_gradient_loss | -0.00574      |
|    reward               | 0.00011284847 |
|    std                  | 550           |
|    value_loss           | 6.12e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3175, episode: 2190
begin_total_asset: 200.00
end_total_asset: 266.11
total_reward: 66.11
total_cost: 25.05
total_trades: 29794
Sharpe: 0.304
=================================
Reseting Environment StartDay: 1576, ResetDay: 3256,Episode: 2191
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1798         |
|    time_elapsed         | 40691        |
|    total_timesteps      | 3682304      |
| train/                  |              |
|    approx_kl            | 22710.547    |
|    clip_fraction        | 0.0128       |
|    clip_range           | 0.2          |
|    entropy_loss         | -214         |
|    explained_variance   | 0.267        |
|    learning_rate        | 0.00025      |
|    loss                 | -2.14        |
|    n_updates            | 17970        |
|    policy_gradient_loss | -0.00377     |
|    reward               | 9.323501e-06 |
|    std                  | 553          |
|    value_loss           | 1.96e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1984, ResetDay: 3664,Episode: 2192
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1799          |
|    time_elapsed         | 40714         |
|    total_timesteps      | 3684352       |
| train/                  |               |
|    approx_kl            | 23196.668     |
|    clip_fraction        | 0.0111        |
|    clip_range           | 0.2           |
|    entropy_loss         | -214          |
|    explained_variance   | 0.235         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.15         |
|    n_updates            | 17980         |
|    policy_gradient_loss | 0.000707      |
|    reward               | -3.607826e-05 |
|    std                  | 555           |
|    value_loss           | 3.92e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 338, ResetDay: 2018,Episode: 2193
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1800           |
|    time_elapsed         | 40736          |
|    total_timesteps      | 3686400        |
| train/                  |                |
|    approx_kl            | 23375.8        |
|    clip_fraction        | 0.0106         |
|    clip_range           | 0.2            |
|    entropy_loss         | -214           |
|    explained_variance   | 0.327          |
|    learning_rate        | 0.00025        |
|    loss                 | -2.16          |
|    n_updates            | 17990          |
|    policy_gradient_loss | -0.00385       |
|    reward               | -0.00010242386 |
|    std                  | 557            |
|    value_loss           | 4.06e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 134, ResetDay: 1814,Episode: 2194
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1077, ResetDay: 2757,Episode: 2195
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1801          |
|    time_elapsed         | 40759         |
|    total_timesteps      | 3688448       |
| train/                  |               |
|    approx_kl            | 23394.777     |
|    clip_fraction        | 0.00986       |
|    clip_range           | 0.2           |
|    entropy_loss         | -214          |
|    explained_variance   | 0.0574        |
|    learning_rate        | 0.00025       |
|    loss                 | -2.15         |
|    n_updates            | 18000         |
|    policy_gradient_loss | 0.000739      |
|    reward               | 1.4982959e-05 |
|    std                  | 559           |
|    value_loss           | 7.13e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2757, episode: 2195
begin_total_asset: 200.00
end_total_asset: 149.78
total_reward: -50.22
total_cost: 62.24
total_trades: 29813
Sharpe: -0.021
=================================
Reseting Environment StartDay: 1490, ResetDay: 3170,Episode: 2196
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1802           |
|    time_elapsed         | 40781          |
|    total_timesteps      | 3690496        |
| train/                  |                |
|    approx_kl            | 23720.895      |
|    clip_fraction        | 0.00962        |
|    clip_range           | 0.2            |
|    entropy_loss         | -215           |
|    explained_variance   | -0.126         |
|    learning_rate        | 0.00025        |
|    loss                 | -2.15          |
|    n_updates            | 18010          |
|    policy_gradient_loss | -0.000187      |
|    reward               | -0.00024913388 |
|    std                  | 561            |
|    value_loss           | 3.65e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2801, ResetDay: 4481,Episode: 2197
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1803          |
|    time_elapsed         | 40804         |
|    total_timesteps      | 3692544       |
| train/                  |               |
|    approx_kl            | 23662.78      |
|    clip_fraction        | 0.0158        |
|    clip_range           | 0.2           |
|    entropy_loss         | -215          |
|    explained_variance   | 0.214         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.16         |
|    n_updates            | 18020         |
|    policy_gradient_loss | -0.00432      |
|    reward               | -0.0020654122 |
|    std                  | 564           |
|    value_loss           | 3.79e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2762, ResetDay: 4442,Episode: 2198
-----------------------------------------
| time/                   |             |
|    fps                  | 90          |
|    iterations           | 1804        |
|    time_elapsed         | 40826       |
|    total_timesteps      | 3694592     |
| train/                  |             |
|    approx_kl            | 23975.797   |
|    clip_fraction        | 0.00884     |
|    clip_range           | 0.2         |
|    entropy_loss         | -215        |
|    explained_variance   | 0.188       |
|    learning_rate        | 0.00025     |
|    loss                 | -2.16       |
|    n_updates            | 18030       |
|    policy_gradient_loss | -0.00252    |
|    reward               | 5.48275e-05 |
|    std                  | 566         |
|    value_loss           | 5.42e-07    |
-----------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 431, ResetDay: 2111,Episode: 2199
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 473, ResetDay: 2153,Episode: 2200
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1805          |
|    time_elapsed         | 40849         |
|    total_timesteps      | 3696640       |
| train/                  |               |
|    approx_kl            | 24320.615     |
|    clip_fraction        | 0.00957       |
|    clip_range           | 0.2           |
|    entropy_loss         | -215          |
|    explained_variance   | 0.0741        |
|    learning_rate        | 0.00025       |
|    loss                 | -2.15         |
|    n_updates            | 18040         |
|    policy_gradient_loss | -0.00327      |
|    reward               | -3.522873e-06 |
|    std                  | 568           |
|    value_loss           | 7.6e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2153, episode: 2200
begin_total_asset: 200.00
end_total_asset: 86.89
total_reward: -113.11
total_cost: 42.93
total_trades: 29855
Sharpe: -0.138
=================================
Reseting Environment StartDay: 2683, ResetDay: 4363,Episode: 2201
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1806           |
|    time_elapsed         | 40872          |
|    total_timesteps      | 3698688        |
| train/                  |                |
|    approx_kl            | 24717.703      |
|    clip_fraction        | 0.0102         |
|    clip_range           | 0.2            |
|    entropy_loss         | -215           |
|    explained_variance   | -0.79          |
|    learning_rate        | 0.00025        |
|    loss                 | -2.15          |
|    n_updates            | 18050          |
|    policy_gradient_loss | -0.00528       |
|    reward               | -0.00034960557 |
|    std                  | 567            |
|    value_loss           | 5.18e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1661, ResetDay: 3341,Episode: 2202
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1807         |
|    time_elapsed         | 40894        |
|    total_timesteps      | 3700736      |
| train/                  |              |
|    approx_kl            | 24411.607    |
|    clip_fraction        | 0.0114       |
|    clip_range           | 0.2          |
|    entropy_loss         | -215         |
|    explained_variance   | 0.276        |
|    learning_rate        | 0.00025      |
|    loss                 | -2.16        |
|    n_updates            | 18060        |
|    policy_gradient_loss | -0.00146     |
|    reward               | 3.524971e-05 |
|    std                  | 568          |
|    value_loss           | 4.66e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1055, ResetDay: 2735,Episode: 2203
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1808         |
|    time_elapsed         | 40917        |
|    total_timesteps      | 3702784      |
| train/                  |              |
|    approx_kl            | 24414.258    |
|    clip_fraction        | 0.0105       |
|    clip_range           | 0.2          |
|    entropy_loss         | -215         |
|    explained_variance   | 0.0814       |
|    learning_rate        | 0.00025      |
|    loss                 | -2.16        |
|    n_updates            | 18070        |
|    policy_gradient_loss | 0.00498      |
|    reward               | 4.105568e-05 |
|    std                  | 571          |
|    value_loss           | 2.25e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1946, ResetDay: 3626,Episode: 2204
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1809          |
|    time_elapsed         | 40939         |
|    total_timesteps      | 3704832       |
| train/                  |               |
|    approx_kl            | 24758.703     |
|    clip_fraction        | 0.0115        |
|    clip_range           | 0.2           |
|    entropy_loss         | -215          |
|    explained_variance   | -0.403        |
|    learning_rate        | 0.00025       |
|    loss                 | -2.16         |
|    n_updates            | 18080         |
|    policy_gradient_loss | -0.00291      |
|    reward               | -0.0003991787 |
|    std                  | 572           |
|    value_loss           | 4.64e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2002, ResetDay: 3682,Episode: 2205
Environment reached Terminal state as number of trading days reached limit!!
day: 3682, episode: 2205
begin_total_asset: 200.00
end_total_asset: 132.45
total_reward: -67.55
total_cost: 58.99
total_trades: 29771
Sharpe: 0.010
=================================
Reseting Environment StartDay: 2045, ResetDay: 3725,Episode: 2206
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1810         |
|    time_elapsed         | 40962        |
|    total_timesteps      | 3706880      |
| train/                  |              |
|    approx_kl            | 24762.844    |
|    clip_fraction        | 0.013        |
|    clip_range           | 0.2          |
|    entropy_loss         | -215         |
|    explained_variance   | 0.127        |
|    learning_rate        | 0.00025      |
|    loss                 | -2.16        |
|    n_updates            | 18090        |
|    policy_gradient_loss | -0.00323     |
|    reward               | 3.649292e-05 |
|    std                  | 573          |
|    value_loss           | 4.51e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1261, ResetDay: 2941,Episode: 2207
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1811           |
|    time_elapsed         | 40985          |
|    total_timesteps      | 3708928        |
| train/                  |                |
|    approx_kl            | 24875.217      |
|    clip_fraction        | 0.0171         |
|    clip_range           | 0.2            |
|    entropy_loss         | -215           |
|    explained_variance   | 0.0503         |
|    learning_rate        | 0.00025        |
|    loss                 | -2.16          |
|    n_updates            | 18100          |
|    policy_gradient_loss | 0.00276        |
|    reward               | -1.4524459e-05 |
|    std                  | 576            |
|    value_loss           | 7.8e-07        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1619, ResetDay: 3299,Episode: 2208
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1812           |
|    time_elapsed         | 41007          |
|    total_timesteps      | 3710976        |
| train/                  |                |
|    approx_kl            | 24859.547      |
|    clip_fraction        | 0.0136         |
|    clip_range           | 0.2            |
|    entropy_loss         | -215           |
|    explained_variance   | 0.0145         |
|    learning_rate        | 0.00025        |
|    loss                 | -2.18          |
|    n_updates            | 18110          |
|    policy_gradient_loss | -0.00255       |
|    reward               | -0.00022730407 |
|    std                  | 579            |
|    value_loss           | 6.14e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2128, ResetDay: 3808,Episode: 2209
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1813          |
|    time_elapsed         | 41030         |
|    total_timesteps      | 3713024       |
| train/                  |               |
|    approx_kl            | 25253.742     |
|    clip_fraction        | 0.0107        |
|    clip_range           | 0.2           |
|    entropy_loss         | -216          |
|    explained_variance   | 0.0797        |
|    learning_rate        | 0.00025       |
|    loss                 | -2.15         |
|    n_updates            | 18120         |
|    policy_gradient_loss | -0.00233      |
|    reward               | 2.1689126e-05 |
|    std                  | 581           |
|    value_loss           | 2.21e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2384, ResetDay: 4064,Episode: 2210
Environment reached Terminal state as number of trading days reached limit!!
day: 4064, episode: 2210
begin_total_asset: 200.00
end_total_asset: 268.63
total_reward: 68.63
total_cost: 43.13
total_trades: 29527
Sharpe: 0.309
=================================
Reseting Environment StartDay: 2087, ResetDay: 3767,Episode: 2211
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1814          |
|    time_elapsed         | 41052         |
|    total_timesteps      | 3715072       |
| train/                  |               |
|    approx_kl            | 25432.46      |
|    clip_fraction        | 0.0112        |
|    clip_range           | 0.2           |
|    entropy_loss         | -216          |
|    explained_variance   | 0.221         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.16         |
|    n_updates            | 18130         |
|    policy_gradient_loss | -0.000185     |
|    reward               | 1.7954255e-05 |
|    std                  | 583           |
|    value_loss           | 5.24e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1987, ResetDay: 3667,Episode: 2212
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1815          |
|    time_elapsed         | 41075         |
|    total_timesteps      | 3717120       |
| train/                  |               |
|    approx_kl            | 25509.459     |
|    clip_fraction        | 0.0131        |
|    clip_range           | 0.2           |
|    entropy_loss         | -216          |
|    explained_variance   | 0.208         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.16         |
|    n_updates            | 18140         |
|    policy_gradient_loss | -0.00185      |
|    reward               | 0.00016210652 |
|    std                  | 585           |
|    value_loss           | 1e-06         |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2620, ResetDay: 4300,Episode: 2213
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1816          |
|    time_elapsed         | 41097         |
|    total_timesteps      | 3719168       |
| train/                  |               |
|    approx_kl            | 25861.33      |
|    clip_fraction        | 0.0105        |
|    clip_range           | 0.2           |
|    entropy_loss         | -216          |
|    explained_variance   | -0.0897       |
|    learning_rate        | 0.00025       |
|    loss                 | -2.16         |
|    n_updates            | 18150         |
|    policy_gradient_loss | 0.00167       |
|    reward               | -0.0005930595 |
|    std                  | 588           |
|    value_loss           | 3.41e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2715, ResetDay: 4395,Episode: 2214
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1817          |
|    time_elapsed         | 41120         |
|    total_timesteps      | 3721216       |
| train/                  |               |
|    approx_kl            | 25955.883     |
|    clip_fraction        | 0.0188        |
|    clip_range           | 0.2           |
|    entropy_loss         | -216          |
|    explained_variance   | 0.234         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.16         |
|    n_updates            | 18160         |
|    policy_gradient_loss | -0.000155     |
|    reward               | 0.00016111221 |
|    std                  | 592           |
|    value_loss           | 4.8e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1384, ResetDay: 3064,Episode: 2215
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1818          |
|    time_elapsed         | 41142         |
|    total_timesteps      | 3723264       |
| train/                  |               |
|    approx_kl            | 26437.846     |
|    clip_fraction        | 0.0125        |
|    clip_range           | 0.2           |
|    entropy_loss         | -216          |
|    explained_variance   | 0.236         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.16         |
|    n_updates            | 18170         |
|    policy_gradient_loss | -0.00191      |
|    reward               | 6.9151305e-05 |
|    std                  | 595           |
|    value_loss           | 1.58e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3064, episode: 2215
begin_total_asset: 200.00
end_total_asset: 111.67
total_reward: -88.33
total_cost: 20.60
total_trades: 29371
Sharpe: -0.027
=================================
Reseting Environment StartDay: 145, ResetDay: 1825,Episode: 2216
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1591, ResetDay: 3271,Episode: 2217
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1819          |
|    time_elapsed         | 41165         |
|    total_timesteps      | 3725312       |
| train/                  |               |
|    approx_kl            | 26759.334     |
|    clip_fraction        | 0.0123        |
|    clip_range           | 0.2           |
|    entropy_loss         | -216          |
|    explained_variance   | -0.487        |
|    learning_rate        | 0.00025       |
|    loss                 | -2.17         |
|    n_updates            | 18180         |
|    policy_gradient_loss | -0.00488      |
|    reward               | 0.00015068435 |
|    std                  | 597           |
|    value_loss           | 5.86e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1795, ResetDay: 3475,Episode: 2218
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1820          |
|    time_elapsed         | 41188         |
|    total_timesteps      | 3727360       |
| train/                  |               |
|    approx_kl            | 27110.016     |
|    clip_fraction        | 0.00835       |
|    clip_range           | 0.2           |
|    entropy_loss         | -216          |
|    explained_variance   | 0.123         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.17         |
|    n_updates            | 18190         |
|    policy_gradient_loss | -0.00245      |
|    reward               | 0.00013406848 |
|    std                  | 598           |
|    value_loss           | 5.48e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1785, ResetDay: 3465,Episode: 2219
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1821          |
|    time_elapsed         | 41210         |
|    total_timesteps      | 3729408       |
| train/                  |               |
|    approx_kl            | 27169.088     |
|    clip_fraction        | 0.0148        |
|    clip_range           | 0.2           |
|    entropy_loss         | -216          |
|    explained_variance   | 0.16          |
|    learning_rate        | 0.00025       |
|    loss                 | -2.16         |
|    n_updates            | 18200         |
|    policy_gradient_loss | -0.0048       |
|    reward               | 0.00086996175 |
|    std                  | 599           |
|    value_loss           | 9e-07         |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 578, ResetDay: 2258,Episode: 2220
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1822         |
|    time_elapsed         | 41233        |
|    total_timesteps      | 3731456      |
| train/                  |              |
|    approx_kl            | 27143.729    |
|    clip_fraction        | 0.0119       |
|    clip_range           | 0.2          |
|    entropy_loss         | -216         |
|    explained_variance   | -0.00947     |
|    learning_rate        | 0.00025      |
|    loss                 | -2.16        |
|    n_updates            | 18210        |
|    policy_gradient_loss | -0.00285     |
|    reward               | 8.714103e-06 |
|    std                  | 601          |
|    value_loss           | 4.52e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2258, episode: 2220
begin_total_asset: 200.00
end_total_asset: 54.08
total_reward: -145.92
total_cost: 39.37
total_trades: 29567
Sharpe: -0.333
=================================
Reseting Environment StartDay: 305, ResetDay: 1985,Episode: 2221
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 724, ResetDay: 2404,Episode: 2222
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1823           |
|    time_elapsed         | 41256          |
|    total_timesteps      | 3733504        |
| train/                  |                |
|    approx_kl            | 27226.973      |
|    clip_fraction        | 0.00937        |
|    clip_range           | 0.2            |
|    entropy_loss         | -217           |
|    explained_variance   | 0.0897         |
|    learning_rate        | 0.00025        |
|    loss                 | -2.15          |
|    n_updates            | 18220          |
|    policy_gradient_loss | -0.000769      |
|    reward               | -0.00023130732 |
|    std                  | 603            |
|    value_loss           | 4.06e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1618, ResetDay: 3298,Episode: 2223
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1824           |
|    time_elapsed         | 41278          |
|    total_timesteps      | 3735552        |
| train/                  |                |
|    approx_kl            | 27243.0        |
|    clip_fraction        | 0.0114         |
|    clip_range           | 0.2            |
|    entropy_loss         | -217           |
|    explained_variance   | 0.136          |
|    learning_rate        | 0.00025        |
|    loss                 | -2.17          |
|    n_updates            | 18230          |
|    policy_gradient_loss | -0.000815      |
|    reward               | -0.00015802718 |
|    std                  | 607            |
|    value_loss           | 3.29e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2533, ResetDay: 4213,Episode: 2224
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1825           |
|    time_elapsed         | 41301          |
|    total_timesteps      | 3737600        |
| train/                  |                |
|    approx_kl            | 28054.7        |
|    clip_fraction        | 0.00786        |
|    clip_range           | 0.2            |
|    entropy_loss         | -217           |
|    explained_variance   | 0.374          |
|    learning_rate        | 0.00025        |
|    loss                 | -2.17          |
|    n_updates            | 18240          |
|    policy_gradient_loss | 0.00022        |
|    reward               | -0.00035049437 |
|    std                  | 607            |
|    value_loss           | 2.57e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1196, ResetDay: 2876,Episode: 2225
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1826          |
|    time_elapsed         | 41323         |
|    total_timesteps      | 3739648       |
| train/                  |               |
|    approx_kl            | 28114.64      |
|    clip_fraction        | 0.01          |
|    clip_range           | 0.2           |
|    entropy_loss         | -217          |
|    explained_variance   | 0.136         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.17         |
|    n_updates            | 18250         |
|    policy_gradient_loss | -0.00211      |
|    reward               | 5.4741286e-05 |
|    std                  | 607           |
|    value_loss           | 5.01e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2876, episode: 2225
begin_total_asset: 200.00
end_total_asset: 51.81
total_reward: -148.19
total_cost: 26.00
total_trades: 29567
Sharpe: -0.251
=================================
Reseting Environment StartDay: 912, ResetDay: 2592,Episode: 2226
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1827          |
|    time_elapsed         | 41346         |
|    total_timesteps      | 3741696       |
| train/                  |               |
|    approx_kl            | 27953.082     |
|    clip_fraction        | 0.00962       |
|    clip_range           | 0.2           |
|    entropy_loss         | -217          |
|    explained_variance   | 0.0126        |
|    learning_rate        | 0.00025       |
|    loss                 | -2.18         |
|    n_updates            | 18260         |
|    policy_gradient_loss | -0.0022       |
|    reward               | 4.5948027e-06 |
|    std                  | 608           |
|    value_loss           | 8.97e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 136, ResetDay: 1816,Episode: 2227
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 505, ResetDay: 2185,Episode: 2228
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1828           |
|    time_elapsed         | 41369          |
|    total_timesteps      | 3743744        |
| train/                  |                |
|    approx_kl            | 28033.125      |
|    clip_fraction        | 0.0127         |
|    clip_range           | 0.2            |
|    entropy_loss         | -217           |
|    explained_variance   | 0.108          |
|    learning_rate        | 0.00025        |
|    loss                 | -2.17          |
|    n_updates            | 18270          |
|    policy_gradient_loss | -0.00205       |
|    reward               | -0.00024207821 |
|    std                  | 611            |
|    value_loss           | 3.37e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 215, ResetDay: 1895,Episode: 2229
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1829          |
|    time_elapsed         | 41391         |
|    total_timesteps      | 3745792       |
| train/                  |               |
|    approx_kl            | 28604.672     |
|    clip_fraction        | 0.011         |
|    clip_range           | 0.2           |
|    entropy_loss         | -217          |
|    explained_variance   | -0.318        |
|    learning_rate        | 0.00025       |
|    loss                 | -2.17         |
|    n_updates            | 18280         |
|    policy_gradient_loss | -0.00247      |
|    reward               | -6.503271e-05 |
|    std                  | 611           |
|    value_loss           | 4e-07         |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2476, ResetDay: 4156,Episode: 2230
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1830           |
|    time_elapsed         | 41414          |
|    total_timesteps      | 3747840        |
| train/                  |                |
|    approx_kl            | 28454.785      |
|    clip_fraction        | 0.0083         |
|    clip_range           | 0.2            |
|    entropy_loss         | -217           |
|    explained_variance   | 0.274          |
|    learning_rate        | 0.00025        |
|    loss                 | -2.18          |
|    n_updates            | 18290          |
|    policy_gradient_loss | -0.00237       |
|    reward               | -0.00013438644 |
|    std                  | 612            |
|    value_loss           | 5.84e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 4156, episode: 2230
begin_total_asset: 200.00
end_total_asset: 557.38
total_reward: 357.38
total_cost: 67.04
total_trades: 29429
Sharpe: 0.618
=================================
Reseting Environment StartDay: 2751, ResetDay: 4431,Episode: 2231
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1831          |
|    time_elapsed         | 41436         |
|    total_timesteps      | 3749888       |
| train/                  |               |
|    approx_kl            | 28719.5       |
|    clip_fraction        | 0.00884       |
|    clip_range           | 0.2           |
|    entropy_loss         | -217          |
|    explained_variance   | 0.156         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.18         |
|    n_updates            | 18300         |
|    policy_gradient_loss | -0.00324      |
|    reward               | 0.00047762488 |
|    std                  | 611           |
|    value_loss           | 6.63e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1213, ResetDay: 2893,Episode: 2232
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1832          |
|    time_elapsed         | 41459         |
|    total_timesteps      | 3751936       |
| train/                  |               |
|    approx_kl            | 28564.395     |
|    clip_fraction        | 0.0137        |
|    clip_range           | 0.2           |
|    entropy_loss         | -217          |
|    explained_variance   | 0.0763        |
|    learning_rate        | 0.00025       |
|    loss                 | -2.18         |
|    n_updates            | 18310         |
|    policy_gradient_loss | -0.00418      |
|    reward               | 2.7761078e-05 |
|    std                  | 612           |
|    value_loss           | 3.12e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1002, ResetDay: 2682,Episode: 2233
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1895, ResetDay: 3575,Episode: 2234
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1833          |
|    time_elapsed         | 41481         |
|    total_timesteps      | 3753984       |
| train/                  |               |
|    approx_kl            | 28438.863     |
|    clip_fraction        | 0.00942       |
|    clip_range           | 0.2           |
|    entropy_loss         | -217          |
|    explained_variance   | -2.36         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.17         |
|    n_updates            | 18320         |
|    policy_gradient_loss | 0.000754      |
|    reward               | 2.0355606e-05 |
|    std                  | 614           |
|    value_loss           | 4.47e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 484, ResetDay: 2164,Episode: 2235
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1834          |
|    time_elapsed         | 41504         |
|    total_timesteps      | 3756032       |
| train/                  |               |
|    approx_kl            | 28627.941     |
|    clip_fraction        | 0.0111        |
|    clip_range           | 0.2           |
|    entropy_loss         | -217          |
|    explained_variance   | 0.112         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.19         |
|    n_updates            | 18330         |
|    policy_gradient_loss | -0.00191      |
|    reward               | -5.110905e-05 |
|    std                  | 615           |
|    value_loss           | 3.36e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2164, episode: 2235
begin_total_asset: 200.00
end_total_asset: 26.33
total_reward: -173.67
total_cost: 60.49
total_trades: 29498
Sharpe: -0.559
=================================
Reseting Environment StartDay: 901, ResetDay: 2581,Episode: 2236
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1835           |
|    time_elapsed         | 41527          |
|    total_timesteps      | 3758080        |
| train/                  |                |
|    approx_kl            | 28574.723      |
|    clip_fraction        | 0.0137         |
|    clip_range           | 0.2            |
|    entropy_loss         | -217           |
|    explained_variance   | 0.107          |
|    learning_rate        | 0.00025        |
|    loss                 | -2.17          |
|    n_updates            | 18340          |
|    policy_gradient_loss | -0.00421       |
|    reward               | -0.00012290955 |
|    std                  | 618            |
|    value_loss           | 6.24e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 326, ResetDay: 2006,Episode: 2237
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1836           |
|    time_elapsed         | 41550          |
|    total_timesteps      | 3760128        |
| train/                  |                |
|    approx_kl            | 29112.055      |
|    clip_fraction        | 0.0105         |
|    clip_range           | 0.2            |
|    entropy_loss         | -217           |
|    explained_variance   | 0.0854         |
|    learning_rate        | 0.00025        |
|    loss                 | -2.18          |
|    n_updates            | 18350          |
|    policy_gradient_loss | 0.000245       |
|    reward               | -1.2868309e-05 |
|    std                  | 620            |
|    value_loss           | 2.77e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 407, ResetDay: 2087,Episode: 2238
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 442, ResetDay: 2122,Episode: 2239
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1837           |
|    time_elapsed         | 41572          |
|    total_timesteps      | 3762176        |
| train/                  |                |
|    approx_kl            | 29359.367      |
|    clip_fraction        | 0.0145         |
|    clip_range           | 0.2            |
|    entropy_loss         | -217           |
|    explained_variance   | 0.028          |
|    learning_rate        | 0.00025        |
|    loss                 | -2.19          |
|    n_updates            | 18360          |
|    policy_gradient_loss | -0.00335       |
|    reward               | -0.00024093704 |
|    std                  | 621            |
|    value_loss           | 3.53e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 225, ResetDay: 1905,Episode: 2240
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1838           |
|    time_elapsed         | 41609          |
|    total_timesteps      | 3764224        |
| train/                  |                |
|    approx_kl            | 29629.217      |
|    clip_fraction        | 0.00942        |
|    clip_range           | 0.2            |
|    entropy_loss         | -217           |
|    explained_variance   | 0.204          |
|    learning_rate        | 0.00025        |
|    loss                 | -2.19          |
|    n_updates            | 18370          |
|    policy_gradient_loss | -0.00379       |
|    reward               | -0.00021013852 |
|    std                  | 622            |
|    value_loss           | 4.42e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 1905, episode: 2240
begin_total_asset: 200.00
end_total_asset: 55.27
total_reward: -144.73
total_cost: 68.45
total_trades: 29718
Sharpe: -0.335
=================================
Reseting Environment StartDay: 1901, ResetDay: 3581,Episode: 2241
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1839           |
|    time_elapsed         | 41631          |
|    total_timesteps      | 3766272        |
| train/                  |                |
|    approx_kl            | 29512.893      |
|    clip_fraction        | 0.0107         |
|    clip_range           | 0.2            |
|    entropy_loss         | -217           |
|    explained_variance   | 0.333          |
|    learning_rate        | 0.00025        |
|    loss                 | -2.17          |
|    n_updates            | 18380          |
|    policy_gradient_loss | 0.000763       |
|    reward               | -0.00029186325 |
|    std                  | 624            |
|    value_loss           | 3.34e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 472, ResetDay: 2152,Episode: 2242
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1840          |
|    time_elapsed         | 41654         |
|    total_timesteps      | 3768320       |
| train/                  |               |
|    approx_kl            | 29727.615     |
|    clip_fraction        | 0.0132        |
|    clip_range           | 0.2           |
|    entropy_loss         | -217          |
|    explained_variance   | 0.216         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.18         |
|    n_updates            | 18390         |
|    policy_gradient_loss | -0.00473      |
|    reward               | -4.559841e-05 |
|    std                  | 626           |
|    value_loss           | 4.63e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2058, ResetDay: 3738,Episode: 2243
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1841          |
|    time_elapsed         | 41676         |
|    total_timesteps      | 3770368       |
| train/                  |               |
|    approx_kl            | 29953.027     |
|    clip_fraction        | 0.0102        |
|    clip_range           | 0.2           |
|    entropy_loss         | -218          |
|    explained_variance   | 0.102         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.17         |
|    n_updates            | 18400         |
|    policy_gradient_loss | 0.001         |
|    reward               | -0.0012669468 |
|    std                  | 628           |
|    value_loss           | 1.29e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2210, ResetDay: 3890,Episode: 2244
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 687, ResetDay: 2367,Episode: 2245
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1842          |
|    time_elapsed         | 41699         |
|    total_timesteps      | 3772416       |
| train/                  |               |
|    approx_kl            | 30178.113     |
|    clip_fraction        | 0.00771       |
|    clip_range           | 0.2           |
|    entropy_loss         | -218          |
|    explained_variance   | 0.156         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.18         |
|    n_updates            | 18410         |
|    policy_gradient_loss | -0.00251      |
|    reward               | -7.001314e-05 |
|    std                  | 628           |
|    value_loss           | 1.06e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2367, episode: 2245
begin_total_asset: 200.00
end_total_asset: 45.92
total_reward: -154.08
total_cost: 53.58
total_trades: 29198
Sharpe: -0.383
=================================
Reseting Environment StartDay: 1704, ResetDay: 3384,Episode: 2246
---------------------------------------------
| time/                   |                 |
|    fps                  | 90              |
|    iterations           | 1843            |
|    time_elapsed         | 41721           |
|    total_timesteps      | 3774464         |
| train/                  |                 |
|    approx_kl            | 30099.812       |
|    clip_fraction        | 0.0104          |
|    clip_range           | 0.2             |
|    entropy_loss         | -218            |
|    explained_variance   | 0.18            |
|    learning_rate        | 0.00025         |
|    loss                 | -2.18           |
|    n_updates            | 18420           |
|    policy_gradient_loss | -0.00298        |
|    reward               | -0.000116329764 |
|    std                  | 631             |
|    value_loss           | 9.58e-07        |
---------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1814, ResetDay: 3494,Episode: 2247
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1844         |
|    time_elapsed         | 41744        |
|    total_timesteps      | 3776512      |
| train/                  |              |
|    approx_kl            | 30652.02     |
|    clip_fraction        | 0.0105       |
|    clip_range           | 0.2          |
|    entropy_loss         | -218         |
|    explained_variance   | -0.399       |
|    learning_rate        | 0.00025      |
|    loss                 | -2.18        |
|    n_updates            | 18430        |
|    policy_gradient_loss | -0.00329     |
|    reward               | 0.0004628309 |
|    std                  | 630          |
|    value_loss           | 4.19e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 238, ResetDay: 1918,Episode: 2248
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1845          |
|    time_elapsed         | 41767         |
|    total_timesteps      | 3778560       |
| train/                  |               |
|    approx_kl            | 30254.037     |
|    clip_fraction        | 0.0149        |
|    clip_range           | 0.2           |
|    entropy_loss         | -218          |
|    explained_variance   | 0.12          |
|    learning_rate        | 0.00025       |
|    loss                 | -2.19         |
|    n_updates            | 18440         |
|    policy_gradient_loss | -0.00472      |
|    reward               | 2.1286012e-06 |
|    std                  | 633           |
|    value_loss           | 7.44e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 965, ResetDay: 2645,Episode: 2249
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 871, ResetDay: 2551,Episode: 2250
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1846          |
|    time_elapsed         | 41789         |
|    total_timesteps      | 3780608       |
| train/                  |               |
|    approx_kl            | 30825.77      |
|    clip_fraction        | 0.00801       |
|    clip_range           | 0.2           |
|    entropy_loss         | -218          |
|    explained_variance   | 0.117         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.17         |
|    n_updates            | 18450         |
|    policy_gradient_loss | 0.00213       |
|    reward               | -7.754127e-05 |
|    std                  | 633           |
|    value_loss           | 1.16e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2551, episode: 2250
begin_total_asset: 200.00
end_total_asset: 127.64
total_reward: -72.36
total_cost: 28.45
total_trades: 29277
Sharpe: 0.004
=================================
Reseting Environment StartDay: 1346, ResetDay: 3026,Episode: 2251
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1847          |
|    time_elapsed         | 41813         |
|    total_timesteps      | 3782656       |
| train/                  |               |
|    approx_kl            | 30783.715     |
|    clip_fraction        | 0.0107        |
|    clip_range           | 0.2           |
|    entropy_loss         | -218          |
|    explained_variance   | 0.0443        |
|    learning_rate        | 0.00025       |
|    loss                 | -2.19         |
|    n_updates            | 18460         |
|    policy_gradient_loss | -0.00294      |
|    reward               | -0.0001158721 |
|    std                  | 636           |
|    value_loss           | 4.25e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1629, ResetDay: 3309,Episode: 2252
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1848           |
|    time_elapsed         | 41835          |
|    total_timesteps      | 3784704        |
| train/                  |                |
|    approx_kl            | 30817.635      |
|    clip_fraction        | 0.00952        |
|    clip_range           | 0.2            |
|    entropy_loss         | -218           |
|    explained_variance   | 0.403          |
|    learning_rate        | 0.00025        |
|    loss                 | -2.18          |
|    n_updates            | 18470          |
|    policy_gradient_loss | -0.00273       |
|    reward               | -4.6315385e-05 |
|    std                  | 638            |
|    value_loss           | 2.9e-07        |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1441, ResetDay: 3121,Episode: 2253
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1849          |
|    time_elapsed         | 41858         |
|    total_timesteps      | 3786752       |
| train/                  |               |
|    approx_kl            | 31035.602     |
|    clip_fraction        | 0.00879       |
|    clip_range           | 0.2           |
|    entropy_loss         | -218          |
|    explained_variance   | 0.202         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.18         |
|    n_updates            | 18480         |
|    policy_gradient_loss | -0.00482      |
|    reward               | -7.889747e-06 |
|    std                  | 639           |
|    value_loss           | 2.43e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 694, ResetDay: 2374,Episode: 2254
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1850          |
|    time_elapsed         | 41880         |
|    total_timesteps      | 3788800       |
| train/                  |               |
|    approx_kl            | 31185.055     |
|    clip_fraction        | 0.0118        |
|    clip_range           | 0.2           |
|    entropy_loss         | -218          |
|    explained_variance   | 0.261         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.19         |
|    n_updates            | 18490         |
|    policy_gradient_loss | 0.00303       |
|    reward               | 4.9377824e-05 |
|    std                  | 642           |
|    value_loss           | 2.9e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1817, ResetDay: 3497,Episode: 2255
Environment reached Terminal state as number of trading days reached limit!!
day: 3497, episode: 2255
begin_total_asset: 200.00
end_total_asset: 380.30
total_reward: 180.30
total_cost: 20.88
total_trades: 28912
Sharpe: 0.518
=================================
Reseting Environment StartDay: 1895, ResetDay: 3575,Episode: 2256
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1851          |
|    time_elapsed         | 41903         |
|    total_timesteps      | 3790848       |
| train/                  |               |
|    approx_kl            | 31444.68      |
|    clip_fraction        | 0.0111        |
|    clip_range           | 0.2           |
|    entropy_loss         | -218          |
|    explained_variance   | 0.204         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.19         |
|    n_updates            | 18500         |
|    policy_gradient_loss | -0.00312      |
|    reward               | 7.2786715e-05 |
|    std                  | 645           |
|    value_loss           | 2.9e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1218, ResetDay: 2898,Episode: 2257
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1852         |
|    time_elapsed         | 41925        |
|    total_timesteps      | 3792896      |
| train/                  |              |
|    approx_kl            | 31662.879    |
|    clip_fraction        | 0.0138       |
|    clip_range           | 0.2          |
|    entropy_loss         | -218         |
|    explained_variance   | 0.138        |
|    learning_rate        | 0.00025      |
|    loss                 | -2.2         |
|    n_updates            | 18510        |
|    policy_gradient_loss | -0.00594     |
|    reward               | -6.60141e-05 |
|    std                  | 649          |
|    value_loss           | 6.64e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 633, ResetDay: 2313,Episode: 2258
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1853          |
|    time_elapsed         | 41948         |
|    total_timesteps      | 3794944       |
| train/                  |               |
|    approx_kl            | 32125.535     |
|    clip_fraction        | 0.0111        |
|    clip_range           | 0.2           |
|    entropy_loss         | -219          |
|    explained_variance   | 0.233         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.2          |
|    n_updates            | 18520         |
|    policy_gradient_loss | -0.00529      |
|    reward               | -6.716347e-05 |
|    std                  | 650           |
|    value_loss           | 4.81e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2306, ResetDay: 3986,Episode: 2259
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1854         |
|    time_elapsed         | 41970        |
|    total_timesteps      | 3796992      |
| train/                  |              |
|    approx_kl            | 32170.82     |
|    clip_fraction        | 0.0105       |
|    clip_range           | 0.2          |
|    entropy_loss         | -219         |
|    explained_variance   | 0.242        |
|    learning_rate        | 0.00025      |
|    loss                 | -2.2         |
|    n_updates            | 18530        |
|    policy_gradient_loss | -0.00169     |
|    reward               | 0.0002985775 |
|    std                  | 652          |
|    value_loss           | 4.17e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 609, ResetDay: 2289,Episode: 2260
---------------------------------------
| time/                   |           |
|    fps                  | 90        |
|    iterations           | 1855      |
|    time_elapsed         | 41993     |
|    total_timesteps      | 3799040   |
| train/                  |           |
|    approx_kl            | 32459.383 |
|    clip_fraction        | 0.0115    |
|    clip_range           | 0.2       |
|    entropy_loss         | -219      |
|    explained_variance   | 0.23      |
|    learning_rate        | 0.00025   |
|    loss                 | -2.21     |
|    n_updates            | 18540     |
|    policy_gradient_loss | -0.00465  |
|    reward               | 0.0       |
|    std                  | 654       |
|    value_loss           | 6.97e-07  |
---------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2289, episode: 2260
begin_total_asset: 200.00
end_total_asset: 12.43
total_reward: -187.57
total_cost: 40.32
total_trades: 29067
Sharpe: -0.604
=================================
Reseting Environment StartDay: 1677, ResetDay: 3357,Episode: 2261
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1085, ResetDay: 2765,Episode: 2262
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1856           |
|    time_elapsed         | 42015          |
|    total_timesteps      | 3801088        |
| train/                  |                |
|    approx_kl            | 32645.52       |
|    clip_fraction        | 0.0113         |
|    clip_range           | 0.2            |
|    entropy_loss         | -219           |
|    explained_variance   | -0.0505        |
|    learning_rate        | 0.00025        |
|    loss                 | -2.19          |
|    n_updates            | 18550          |
|    policy_gradient_loss | -0.00505       |
|    reward               | -2.9721881e-05 |
|    std                  | 657            |
|    value_loss           | 1.33e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1501, ResetDay: 3181,Episode: 2263
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1857           |
|    time_elapsed         | 42038          |
|    total_timesteps      | 3803136        |
| train/                  |                |
|    approx_kl            | 32853.05       |
|    clip_fraction        | 0.0115         |
|    clip_range           | 0.2            |
|    entropy_loss         | -219           |
|    explained_variance   | 0.0874         |
|    learning_rate        | 0.00025        |
|    loss                 | -2.2           |
|    n_updates            | 18560          |
|    policy_gradient_loss | -0.0045        |
|    reward               | -2.7139664e-05 |
|    std                  | 660            |
|    value_loss           | 7.38e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 701, ResetDay: 2381,Episode: 2264
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1858          |
|    time_elapsed         | 42061         |
|    total_timesteps      | 3805184       |
| train/                  |               |
|    approx_kl            | 33207.445     |
|    clip_fraction        | 0.0106        |
|    clip_range           | 0.2           |
|    entropy_loss         | -219          |
|    explained_variance   | -0.0142       |
|    learning_rate        | 0.00025       |
|    loss                 | -2.21         |
|    n_updates            | 18570         |
|    policy_gradient_loss | -0.00332      |
|    reward               | 0.00010906601 |
|    std                  | 661           |
|    value_loss           | 3.6e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 903, ResetDay: 2583,Episode: 2265
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1859          |
|    time_elapsed         | 42083         |
|    total_timesteps      | 3807232       |
| train/                  |               |
|    approx_kl            | 33685.43      |
|    clip_fraction        | 0.0102        |
|    clip_range           | 0.2           |
|    entropy_loss         | -219          |
|    explained_variance   | 0.191         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.21         |
|    n_updates            | 18580         |
|    policy_gradient_loss | -0.00487      |
|    reward               | 6.5120694e-05 |
|    std                  | 661           |
|    value_loss           | 4.8e-07       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2583, episode: 2265
begin_total_asset: 200.00
end_total_asset: 110.41
total_reward: -89.59
total_cost: 44.37
total_trades: 29200
Sharpe: -0.054
=================================
Reseting Environment StartDay: 1850, ResetDay: 3530,Episode: 2266
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1001, ResetDay: 2681,Episode: 2267
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1860          |
|    time_elapsed         | 42106         |
|    total_timesteps      | 3809280       |
| train/                  |               |
|    approx_kl            | 33490.85      |
|    clip_fraction        | 0.0114        |
|    clip_range           | 0.2           |
|    entropy_loss         | -219          |
|    explained_variance   | 0.183         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.2          |
|    n_updates            | 18590         |
|    policy_gradient_loss | -0.0038       |
|    reward               | -0.0001534454 |
|    std                  | 663           |
|    value_loss           | 2.34e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2166, ResetDay: 3846,Episode: 2268
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1861           |
|    time_elapsed         | 42129          |
|    total_timesteps      | 3811328        |
| train/                  |                |
|    approx_kl            | 33674.34       |
|    clip_fraction        | 0.0119         |
|    clip_range           | 0.2            |
|    entropy_loss         | -219           |
|    explained_variance   | 0.103          |
|    learning_rate        | 0.00025        |
|    loss                 | -2.21          |
|    n_updates            | 18600          |
|    policy_gradient_loss | -0.0051        |
|    reward               | -0.00012730026 |
|    std                  | 664            |
|    value_loss           | 9.44e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1777, ResetDay: 3457,Episode: 2269
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1862         |
|    time_elapsed         | 42151        |
|    total_timesteps      | 3813376      |
| train/                  |              |
|    approx_kl            | 33735.715    |
|    clip_fraction        | 0.00884      |
|    clip_range           | 0.2          |
|    entropy_loss         | -219         |
|    explained_variance   | -0.0248      |
|    learning_rate        | 0.00025      |
|    loss                 | -2.2         |
|    n_updates            | 18610        |
|    policy_gradient_loss | -0.00312     |
|    reward               | 9.546661e-06 |
|    std                  | 665          |
|    value_loss           | 3.83e-07     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1406, ResetDay: 3086,Episode: 2270
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1863           |
|    time_elapsed         | 42174          |
|    total_timesteps      | 3815424        |
| train/                  |                |
|    approx_kl            | 33888.547      |
|    clip_fraction        | 0.00815        |
|    clip_range           | 0.2            |
|    entropy_loss         | -219           |
|    explained_variance   | 0.115          |
|    learning_rate        | 0.00025        |
|    loss                 | -2.2           |
|    n_updates            | 18620          |
|    policy_gradient_loss | -0.00163       |
|    reward               | -0.00017521362 |
|    std                  | 667            |
|    value_loss           | 1.35e-06       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 3086, episode: 2270
begin_total_asset: 200.00
end_total_asset: 148.11
total_reward: -51.89
total_cost: 25.49
total_trades: 28954
Sharpe: 0.014
=================================
Reseting Environment StartDay: 2741, ResetDay: 4421,Episode: 2271
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1864           |
|    time_elapsed         | 42197          |
|    total_timesteps      | 3817472        |
| train/                  |                |
|    approx_kl            | 34138.055      |
|    clip_fraction        | 0.00967        |
|    clip_range           | 0.2            |
|    entropy_loss         | -219           |
|    explained_variance   | 0.0937         |
|    learning_rate        | 0.00025        |
|    loss                 | -2.2           |
|    n_updates            | 18630          |
|    policy_gradient_loss | -0.00387       |
|    reward               | -0.00015884892 |
|    std                  | 667            |
|    value_loss           | 4.11e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1625, ResetDay: 3305,Episode: 2272
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 443, ResetDay: 2123,Episode: 2273
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1865          |
|    time_elapsed         | 42219         |
|    total_timesteps      | 3819520       |
| train/                  |               |
|    approx_kl            | 33967.887     |
|    clip_fraction        | 0.00977       |
|    clip_range           | 0.2           |
|    entropy_loss         | -219          |
|    explained_variance   | 0.0798        |
|    learning_rate        | 0.00025       |
|    loss                 | -2.2          |
|    n_updates            | 18640         |
|    policy_gradient_loss | -0.00197      |
|    reward               | 0.00017827682 |
|    std                  | 670           |
|    value_loss           | 1.2e-06       |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2732, ResetDay: 4412,Episode: 2274
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1866          |
|    time_elapsed         | 42242         |
|    total_timesteps      | 3821568       |
| train/                  |               |
|    approx_kl            | 34369.32      |
|    clip_fraction        | 0.0115        |
|    clip_range           | 0.2           |
|    entropy_loss         | -219          |
|    explained_variance   | -0.333        |
|    learning_rate        | 0.00025       |
|    loss                 | -2.21         |
|    n_updates            | 18650         |
|    policy_gradient_loss | 0.000893      |
|    reward               | 0.00024436341 |
|    std                  | 673           |
|    value_loss           | 4.95e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 901, ResetDay: 2581,Episode: 2275
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1867          |
|    time_elapsed         | 42264         |
|    total_timesteps      | 3823616       |
| train/                  |               |
|    approx_kl            | 34836.03      |
|    clip_fraction        | 0.0124        |
|    clip_range           | 0.2           |
|    entropy_loss         | -219          |
|    explained_variance   | 0.105         |
|    learning_rate        | 0.00025       |
|    loss                 | -2.2          |
|    n_updates            | 18660         |
|    policy_gradient_loss | -0.0037       |
|    reward               | 0.00011256838 |
|    std                  | 674           |
|    value_loss           | 3.94e-07      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
day: 2581, episode: 2275
begin_total_asset: 200.00
end_total_asset: 107.90
total_reward: -92.10
total_cost: 28.64
total_trades: 29095
Sharpe: -0.032
=================================
Reseting Environment StartDay: 2620, ResetDay: 4300,Episode: 2276
------------------------------------------
| time/                   |              |
|    fps                  | 90           |
|    iterations           | 1868         |
|    time_elapsed         | 42287        |
|    total_timesteps      | 3825664      |
| train/                  |              |
|    approx_kl            | 35035.855    |
|    clip_fraction        | 0.00977      |
|    clip_range           | 0.2          |
|    entropy_loss         | -219         |
|    explained_variance   | 0.0742       |
|    learning_rate        | 0.00025      |
|    loss                 | -2.2         |
|    n_updates            | 18670        |
|    policy_gradient_loss | -0.00317     |
|    reward               | 0.0012736664 |
|    std                  | 677          |
|    value_loss           | 2.75e-06     |
------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 233, ResetDay: 1913,Episode: 2277
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 1403, ResetDay: 3083,Episode: 2278
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1869          |
|    time_elapsed         | 42310         |
|    total_timesteps      | 3827712       |
| train/                  |               |
|    approx_kl            | 35197.4       |
|    clip_fraction        | 0.0126        |
|    clip_range           | 0.2           |
|    entropy_loss         | -220          |
|    explained_variance   | 0.0785        |
|    learning_rate        | 0.00025       |
|    loss                 | -2.21         |
|    n_updates            | 18680         |
|    policy_gradient_loss | -0.00526      |
|    reward               | -0.0001394886 |
|    std                  | 680           |
|    value_loss           | 1.22e-06      |
-------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 2765, ResetDay: 4445,Episode: 2279
--------------------------------------------
| time/                   |                |
|    fps                  | 90             |
|    iterations           | 1870           |
|    time_elapsed         | 42332          |
|    total_timesteps      | 3829760        |
| train/                  |                |
|    approx_kl            | 35487.586      |
|    clip_fraction        | 0.0125         |
|    clip_range           | 0.2            |
|    entropy_loss         | -220           |
|    explained_variance   | -0.434         |
|    learning_rate        | 0.00025        |
|    loss                 | -2.19          |
|    n_updates            | 18690          |
|    policy_gradient_loss | 0.00605        |
|    reward               | -4.1779327e-05 |
|    std                  | 682            |
|    value_loss           | 8.65e-07       |
--------------------------------------------
Environment reached Terminal state as number of trading days reached limit!!
Reseting Environment StartDay: 729, ResetDay: 2409,Episode: 2280
-------------------------------------------
| time/                   |               |
|    fps                  | 90            |
|    iterations           | 1871          |
|    time_elapsed         | 42355         |
|    total_timesteps      | 3831808       |
| train/                  |               |
|    approx_kl            | 35374.848     |
|    clip_fraction        | 0.0111        |
|    clip_range           | 0.2           |
|    entropy_loss         | -220          |
|    explained_variance   | 0.0254        |
|    learning_rate        | 0.00025       |
|    loss                 | -2.22         |
|    n_updates            | 18700         |
|    policy_gradient_loss | -0.00306      |
|    reward               | 2.6864624e-05 |
|    std                  | 686           |
|    value_loss           | 3.46e-07      |
-------------------------------------------
